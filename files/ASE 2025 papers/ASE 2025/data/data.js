var webpub = {data: {
	"conferences": [
		{
			"title": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ",
			"acronym": "ASE",
			"year": 2025,
			"frontMatter": [
				{
					"class": "FM",
					"type": "FM_TITLE_PAGE_I",
					"text": "Title Page i",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300z001/573300z001.pdf",
					"extraLocations": [],
					"pageNumber": 1,
					"isPageNumberRoman": true
				},
				{
					"class": "FM",
					"type": "FM_TITLE_PAGE_III",
					"text": "Title Page iii",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300z003/573300z003.pdf",
					"extraLocations": [],
					"pageNumber": 3,
					"isPageNumberRoman": true
				},
				{
					"class": "FM",
					"type": "FM_COPYRIGHT_PAGE",
					"text": "Copyright Page",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300z004/573300z004.pdf",
					"extraLocations": [],
					"pageNumber": 4,
					"isPageNumberRoman": true
				},
				{
					"class": "FM",
					"type": "FM_TABLE_OF_CONTENTS",
					"text": "Table of Contents",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300z005/573300z005.pdf",
					"extraLocations": [],
					"pageNumber": 5,
					"isPageNumberRoman": true
				},
				{
					"class": "FM",
					"type": "FM_MESSAGE_GENERAL_CHAIR",
					"text": "Message from the Chairs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300z057/573300z057.pdf",
					"extraLocations": [],
					"pageNumber": 57,
					"isPageNumberRoman": true
				},
				{
					"class": "FM",
					"type": "FM_LON_ORGANIZING_COMMITTEE",
					"text": "Organizing Committee",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300z060/573300z060.pdf",
					"extraLocations": [],
					"pageNumber": 60,
					"isPageNumberRoman": true
				},
				{
					"class": "FM",
					"type": "FM_LON_PROGRAM_COMMITTEE",
					"text": "Program Committee",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300z062/573300z062.pdf",
					"extraLocations": [],
					"pageNumber": 62,
					"isPageNumberRoman": true
				},
				{
					"class": "FM",
					"type": "FM_TEXT_ACKNOWLEDGEMENTS",
					"text": "Sponsors",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300z075/573300z075.pdf",
					"extraLocations": [],
					"pageNumber": 75,
					"isPageNumberRoman": true
				}
			],
			"backMatter": [
				{
					"class": "BM",
					"type": "BM_AUTHOR_INDEX",
					"text": "Author Index",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e157/573300e157.pdf",
					"extraLocations": [],
					"pageNumber": 4157,
					"isPageNumberRoman": false
				}
			],
			"sections": [
				{
					"class": "SD",
					"type": "SD_SESSION",
					"title": "Research Papers",
					"lineItems": [
						{
							"eid": "684n0AAX38grLJEVawJOrK",
							"type": "authorPaper",
							"text": "AlertGuardian: Intelligent Alert Life-Cycle Management for Large-Scale Cloud Systems",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a001/573300a001.pdf",
							"extraLocations": [],
							"authorNames": "Guangba Yu (Sun Yat-sen University, China), Genting Mai (Sun Yat-sen University, China), Rui Wang (Tencent, China), Ruipeng Li (Tencent, China), Pengfei Chen (Sun Yat-sen University, China), Long Pan (Tencent, China), Ruijie Xu (Tencent, China)",
							"abstract": "Alerts are critical for detecting anomalies in large-scale cloud systems, ensuring reliability and user experience. However, current systems generate overwhelming volumes of alerts, degrading operational efficiency due to ineffective alert life-cycle management. This paper details the efforts of Company-X to optimize alert life-cycle management, addressing alert fatigue in cloud systems. We propose AlertGuardian, a framework collaborating large language models (LLMs) and lightweight graph models to optimize the alert life-cycle through three phases: Alert Denoise uses graph learning model with virtual noise to filter noise, Alert Summary employs Retrieval Augmented Generation (RAG) with LLMs to create actionable summary, and Alert Rule Refinement leverages multi-agent iterative feedbacks to improve alert rule quality. Evaluated on four real-world datasets from Company-X's services, AlertGuardian significantly mitigates alert fatigue (94.8% alert reduction ratios) and accelerates fault diagnosis (90.5% diagnosis accuracy). Moreover, AlertGuardian improves 1,174 alert rules, with 375 accepted by SREs (32% acceptance rate). Finally, we share success stories and lessons learned about alert life-cycle management after the deployment of AlertGuardian in Company-X.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 AlertGuardian: Intelligent Alert Life-Cycle Management for Large-Scale Cloud Systems 1759217047237 10.1109/ASE63991.2025.00009 Guangba Yu Sun Yat-sen University, China yugb5@mail2.sysu.edu.cn Genting Mai Sun Yat-sen University, China maigt3@mail2.sysu.edu.cn Rui Wang Tencent, China amurorywang@tencent.com Ruipeng Li Tencent, China tristonli@tencent.com Pengfei Chen Sun Yat-sen University, China chenpf7@mail.sysu.edu.cn Long Pan Tencent, China hydrapan@tencent.com Ruijie Xu Tencent, China rjxu@tencent.com alert life-cycle alert reduction cloud systems Alerts are critical for detecting anomalies in large-scale cloud systems, ensuring reliability and user experience. However, current systems generate overwhelming volumes of alerts, degrading operational efficiency due to ineffective alert life-cycle management. This paper details the efforts of Company-X to optimize alert life-cycle management, addressing alert fatigue in cloud systems. We propose AlertGuardian, a framework collaborating large language models (LLMs) and lightweight graph models to optimize the alert life-cycle through three phases: Alert Denoise uses graph learning model with virtual noise to filter noise, Alert Summary employs Retrieval Augmented Generation (RAG) with LLMs to create actionable summary, and Alert Rule Refinement leverages multi-agent iterative feedbacks to improve alert rule quality. Evaluated on four real-world datasets from Company-X's services, AlertGuardian significantly mitigates alert fatigue (94.8% alert reduction ratios) and accelerates fault diagnosis (90.5% diagnosis accuracy). Moreover, AlertGuardian improves 1,174 alert rules, with 375 accepted by SREs (32% acceptance rate). Finally, we share success stories and lessons learned about alert life-cycle management after the deployment of AlertGuardian in Company-X.",
							"pageNumber": 1,
							"isPageNumberRoman": false
						},
						{
							"eid": "6t0yHAlV3Y5LRKZgw4ZUQk",
							"type": "authorPaper",
							"text": "Argus: Resilience-Oriented Safety Assurance Framework for End-to-End ADSs",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a013/573300a013.pdf",
							"extraLocations": [],
							"authorNames": "Dingji Wang (Fudan University, China), You Lu (Fudan University, China), Bihuan Chen (Fudan University, China), Shuo Hao (Fudan University, China), Haowen Jiang (Fudan University, China), Yifan Tian (Fudan University, China), Xin Peng (Fudan University, China)",
							"abstract": "End-to-end autonomous driving systems (ADSs), with their strong capabilities in environmental perception and generalizable driving decisions, are attracting growing attention from both academia and industry. However, once deployed on public roads, ADSs are inevitably exposed to diverse driving hazards that may compromise safety and degrade system performance. This raises a strong demand for resilience of ADSs, particularly the capability to continuously monitor driving hazards and adaptively respond to potential safety violations, which is crucial for maintaining robust driving behaviors in complex driving scenarios. To bridge this gap, we propose a resilience-oriented runtime framework, named Argus, to mitigate the driving hazards, thus preventing potential safety violations and improving the driving performance of an ADS. Argus continuously monitors the trajectories generated by the ADS for potential hazards and, whenever the EGO vehicle is deemed unsafe, seamlessly takes control via a hazard mitigator. We integrate Argus with three state-of-the-art end-to-end ADSs, i.e., TCP, UniAD and VAD. Our evaluation has demonstrated that Argus effectively and efficiently enhances the resilience of ADSs, improving the driving score of ADSs by 150.30% on average, and preventing 64.38% of the violations, with little additional time overhead.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Argus: Resilience-Oriented Safety Assurance Framework for End-to-End ADSs 1758856341647 10.1109/ASE63991.2025.00010 Dingji Wang Fudan University, China wangdj25@m.fudan.edu.cn You Lu Fudan University, China ylu24@m.fudan.edu.cn Bihuan Chen Fudan University, China bhchen@fudan.edu.cn Shuo Hao Fudan University, China shao20@fudan.edu.cn Haowen Jiang Fudan University, China hwjiang23@m.fudan.edu.cn Yifan Tian Fudan University, China yftian23@m.fudan.edu.cn Xin Peng Fudan University, China pengxin@fudan.edu.cn End-to-end autonomous driving systems (ADSs), with their strong capabilities in environmental perception and generalizable driving decisions, are attracting growing attention from both academia and industry. However, once deployed on public roads, ADSs are inevitably exposed to diverse driving hazards that may compromise safety and degrade system performance. This raises a strong demand for resilience of ADSs, particularly the capability to continuously monitor driving hazards and adaptively respond to potential safety violations, which is crucial for maintaining robust driving behaviors in complex driving scenarios. To bridge this gap, we propose a resilience-oriented runtime framework, named Argus, to mitigate the driving hazards, thus preventing potential safety violations and improving the driving performance of an ADS. Argus continuously monitors the trajectories generated by the ADS for potential hazards and, whenever the EGO vehicle is deemed unsafe, seamlessly takes control via a hazard mitigator. We integrate Argus with three state-of-the-art end-to-end ADSs, i.e., TCP, UniAD and VAD. Our evaluation has demonstrated that Argus effectively and efficiently enhances the resilience of ADSs, improving the driving score of ADSs by 150.30% on average, and preventing 64.38% of the violations, with little additional time overhead.",
							"pageNumber": 13,
							"isPageNumberRoman": false
						},
						{
							"eid": "5fRd9neFF4E3ktKbsK4a2v",
							"type": "authorPaper",
							"text": "Vul-R2: A Reasoning LLM for Automated Vulnerability Repair",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a026/573300a026.pdf",
							"extraLocations": [],
							"authorNames": "Xin-Cheng Wen (Tencent Inc., China), Zirui Lin (City University of Hong Kong, China), Yijun Yang (Tencent Inc., China), Cuiyun Gao (The Chinese University of Hong Kong, China), Deheng  Ye (Tencent Inc., China)",
							"abstract": "The exponential increase in software vulnerabilities has created an urgent need for automatic vulnerability repair (AVR) solutions. Recent research has formulated AVR as a sequence generation problem and has leveraged large language models (LLMs) to address this problem. Typically, these approaches prompt or fine-tune LLMs to generate repairs for vulnerabilities directly. Although these methods show state-of-the-art performance, they face the following challenges: (1) Lack of high-quality, vulnerability-related reasoning data. Current approaches primarily rely on foundation models that mainly encode general programming knowledge. Without vulnerability-related reasoning data, they tend to fail to capture the diverse vulnerability repair patterns. (2) Hard to verify the intermediate vulnerability repair process during LLM training. Existing reinforcement learning methods often leverage intermediate execution feedback from the environment (e.g., sandbox-based execution results) to guide reinforcement learning training. In contrast, the vulnerability repair process generally lacks such intermediate, verifiable feedback, which poses additional challenges for model training. To address these challenges, we propose to model the vulnerability repair task from a reasoning perspective and train a reasoning LLM termed Vulnerability Reasoner and Repair (Vul-R2) which consists of two key modules: (1) a domain-aware reasoning learning module, which comprises a reasoning answer construction component, a reasoning data filtering process, and a supervised fine-tuning process for learning vulnerability-related reasoning knowledge; and (2) a curriculum-based verifiable rewarded training module, which comprises dynamically reinforcement learning with verifiable rewards paradigms based on multiple-choice question answering in an easy stage and character-level matching in a hard stage. We evaluate Vul-R2 on the real-world C/C++ dataset PrimeVul to demonstrate its effectiveness in vulnerability repair. Specifically, Vul-R2 outperforms the best baseline by 11.27% for exact match (EM) and successfully repairs 49 additional vulnerabilities. Furthermore, we demonstrate the effectiveness of the proposed paradigm, fine-tuning Vul-R2 on PrimeVul leads to improved EM performance of 8.78% on a human curated dataset SVEN, even without additional training.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Vul-R2: A Reasoning LLM for Automated Vulnerability Repair 1759127474420 10.1109/ASE63991.2025.00011 Xin-Cheng Wen Tencent Inc., China xiamenwxc@foxmail.com Zirui Lin City University of Hong Kong, China ryanlzr2003@gmail.com Yijun Yang Tencent Inc., China yijun.steven.yang@gmail.com Cuiyun Gao The Chinese University of Hong Kong, China cuiyungao@outlook.com Deheng Ye Tencent Inc., China dericye@tencent.com vulnerability repair large language model reinforcement learning The exponential increase in software vulnerabilities has created an urgent need for automatic vulnerability repair (AVR) solutions. Recent research has formulated AVR as a sequence generation problem and has leveraged large language models (LLMs) to address this problem. Typically, these approaches prompt or fine-tune LLMs to generate repairs for vulnerabilities directly. Although these methods show state-of-the-art performance, they face the following challenges: (1) Lack of high-quality, vulnerability-related reasoning data. Current approaches primarily rely on foundation models that mainly encode general programming knowledge. Without vulnerability-related reasoning data, they tend to fail to capture the diverse vulnerability repair patterns. (2) Hard to verify the intermediate vulnerability repair process during LLM training. Existing reinforcement learning methods often leverage intermediate execution feedback from the environment (e.g., sandbox-based execution results) to guide reinforcement learning training. In contrast, the vulnerability repair process generally lacks such intermediate, verifiable feedback, which poses additional challenges for model training. To address these challenges, we propose to model the vulnerability repair task from a reasoning perspective and train a reasoning LLM termed Vulnerability Reasoner and Repair (Vul-R2) which consists of two key modules: (1) a domain-aware reasoning learning module, which comprises a reasoning answer construction component, a reasoning data filtering process, and a supervised fine-tuning process for learning vulnerability-related reasoning knowledge; and (2) a curriculum-based verifiable rewarded training module, which comprises dynamically reinforcement learning with verifiable rewards paradigms based on multiple-choice question answering in an easy stage and character-level matching in a hard stage. We evaluate Vul-R2 on the real-world C/C++ dataset PrimeVul to demonstrate its effectiveness in vulnerability repair. Specifically, Vul-R2 outperforms the best baseline by 11.27% for exact match (EM) and successfully repairs 49 additional vulnerabilities. Furthermore, we demonstrate the effectiveness of the proposed paradigm, fine-tuning Vul-R2 on PrimeVul leads to improved EM performance of 8.78% on a human curated dataset SVEN, even without additional training.",
							"pageNumber": 26,
							"isPageNumberRoman": false
						},
						{
							"eid": "23C7nTHxdLFlKvnvH7eUQQ",
							"type": "authorPaper",
							"text": "MIMIC: Integrating Diverse Personality Traits for Better Game Testing Using Large Language Model",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a039/573300a039.pdf",
							"extraLocations": [],
							"authorNames": "Yifei Chen (McGill University, Canada), Sarra Habchi (Cohere, Canada), Lili Wei (McGill University, Canada)",
							"abstract": "Modern video games pose significant challenges for traditional automated testing algorithms, yet intensive testing is crucial to ensure game quality. To address these challenges, researchers designed gaming agents using Reinforcement Learning, Imitation Learning, or Large Language Models. However, these agents often neglect the diverse strategies employed by human players due to their different personalities, resulting in repetitive solutions in similar situations. Without mimicking varied gaming strategies, these agents struggle to trigger diverse in-game interactions or uncover edge cases. In this paper, we present MIMIC, a novel framework that integrates diverse personality traits into gaming agents, enabling them to adopt different gaming strategies for similar situations. By mimicking different playstyles, MIMIC can achieve higher test coverage and richer in-game interactions across different games. It also outperforms state-of-the-art agents in Minecraft by achieving a higher task completion rate and providing more diverse solutions. These results highlight MIMIC's significant potential for effective game testing.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 MIMIC: Integrating Diverse Personality Traits for Better Game Testing Using Large Language Model 1758842477140 10.1109/ASE63991.2025.00012 Yifei Chen McGill University, Canada yifei.chen@mail.mcgill.ca Sarra Habchi Cohere, Canada sarra.habchi@cohere.com Lili Wei McGill University, Canada lili.wei@mcgill.ca artificial intelligence human-like gaming agents personality-driven gaming agents automated game testing large language models (llms) Modern video games pose significant challenges for traditional automated testing algorithms, yet intensive testing is crucial to ensure game quality. To address these challenges, researchers designed gaming agents using Reinforcement Learning, Imitation Learning, or Large Language Models. However, these agents often neglect the diverse strategies employed by human players due to their different personalities, resulting in repetitive solutions in similar situations. Without mimicking varied gaming strategies, these agents struggle to trigger diverse in-game interactions or uncover edge cases. In this paper, we present MIMIC, a novel framework that integrates diverse personality traits into gaming agents, enabling them to adopt different gaming strategies for similar situations. By mimicking different playstyles, MIMIC can achieve higher test coverage and richer in-game interactions across different games. It also outperforms state-of-the-art agents in Minecraft by achieving a higher task completion rate and providing more diverse solutions. These results highlight MIMIC's significant potential for effective game testing.",
							"pageNumber": 39,
							"isPageNumberRoman": false
						},
						{
							"eid": "1YOFOVR5ffKeCKotzMRdEU",
							"type": "authorPaper",
							"text": "Learning from the Past: Real-World Exploit Migration for Smart Contract PoC Generation",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a052/573300a052.pdf",
							"extraLocations": [],
							"authorNames": "Kairan Sun (Nanyang Technological University, Singapore), Zhengzi  Xu (Imperial College London, Imperial Global Singapore, Singapore), Kaixuan Li (Nanyang Technological University, Singapore), Lyuye Zhang (Nanyang Technological University, Singapore), Yebo Feng (Nanyang Technological University, Singapore), Daoyuan Wu (Lingnan University, Hong Kong SAR, China), Yang Liu (Nanyang Technological University, Singapore)",
							"abstract": "Smart contract vulnerabilities continue to cause significant financial losses, despite the implementation of security measures such as manual audits and bug bounty platforms. A critical component often required by these security measures is the proof-of-concept (PoC) exploit, which validates vulnerability exploitability, assesses impact severity, and guides developers in fixes. Existing tools have explored automated PoC generation with techniques like symbolic execution, fuzzing, and program synthesis. However, these approaches frequently fail to generate PoCs for vulnerabilities exploited in real-world incidents, primarily due to their limitations in handling complex transaction dependencies, navigating vast on-chain state spaces, or requiring extensive manual specifications. Our migration-based approach extracts critical information from documented security incidents and applies it to generate PoCs for similar vulnerable code. This approach leverages proven exploit patterns rather than generating PoCs from scratch. This approach is motivated by two key observations: the prevalence of code reuse in smart contracts (up to 90% at the function level) and the increasing availability of documented PoCs for real-world incidents. Our approach operates in three phases: (1) abstracting essential components (i.e., environment properties, attack logic, and verification checks) from existing PoCs into templates, (2) given a new target contract, selecting suitable templates with adapted values through clone-detection and property-feasibility analysis, and (3) generating and validating PoCs in simulated environments. Our evaluation demonstrates effectiveness and efficiency across multiple scales. Our approach successfully generates valid PoCs for 62 out of 67 manually validated cases without false positives and completes analysis in 3.8 hours compared to 133.2 and 210.5 hours required by existing tools. Large-scale evaluation on 979,512 contracts identifies 256 vulnerable contracts across multiple blockchain networks, including 64 cross-chain cases, demonstrating real-world applicability.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Learning from the Past: Real-World Exploit Migration for Smart Contract PoC Generation 1759203485914 10.1109/ASE63991.2025.00013 Kairan Sun Nanyang Technological University, Singapore SUNK0013@e.ntu.edu.sg Zhengzi Xu Imperial College London, Imperial Global Singapore, Singapore z.xu@imperial.ac.uk Kaixuan Li Nanyang Technological University, Singapore kaixuan.li@ntu.edu.sg Lyuye Zhang Nanyang Technological University, Singapore zh0004ye@e.ntu.edu.sg Yebo Feng Nanyang Technological University, Singapore yebo.feng@ntu.edu.sg Daoyuan Wu Lingnan University, Hong Kong SAR, China daoyuanwu@ln.edu.hk Yang Liu Nanyang Technological University, Singapore yangliu@ntu.edu.sg smart contract security proof-of-concept exploits real-world incidents Smart contract vulnerabilities continue to cause significant financial losses, despite the implementation of security measures such as manual audits and bug bounty platforms. A critical component often required by these security measures is the proof-of-concept (PoC) exploit, which validates vulnerability exploitability, assesses impact severity, and guides developers in fixes. Existing tools have explored automated PoC generation with techniques like symbolic execution, fuzzing, and program synthesis. However, these approaches frequently fail to generate PoCs for vulnerabilities exploited in real-world incidents, primarily due to their limitations in handling complex transaction dependencies, navigating vast on-chain state spaces, or requiring extensive manual specifications. Our migration-based approach extracts critical information from documented security incidents and applies it to generate PoCs for similar vulnerable code. This approach leverages proven exploit patterns rather than generating PoCs from scratch. This approach is motivated by two key observations: the prevalence of code reuse in smart contracts (up to 90% at the function level) and the increasing availability of documented PoCs for real-world incidents. Our approach operates in three phases: (1) abstracting essential components (i.e., environment properties, attack logic, and verification checks) from existing PoCs into templates, (2) given a new target contract, selecting suitable templates with adapted values through clone-detection and property-feasibility analysis, and (3) generating and validating PoCs in simulated environments. Our evaluation demonstrates effectiveness and efficiency across multiple scales. Our approach successfully generates valid PoCs for 62 out of 67 manually validated cases without false positives and completes analysis in 3.8 hours compared to 133.2 and 210.5 hours required by existing tools. Large-scale evaluation on 979,512 contracts identifies 256 vulnerable contracts across multiple blockchain networks, including 64 cross-chain cases, demonstrating real-world applicability.",
							"pageNumber": 52,
							"isPageNumberRoman": false
						},
						{
							"eid": "5qLghsAhP80BfOnmw1EjdK",
							"type": "authorPaper",
							"text": "Propagation-Based Vulnerability Impact Assessment for Software Supply Chains",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a065/573300a065.pdf",
							"extraLocations": [],
							"authorNames": "Bonan Ruan (National University of Singapore), Zhiwei Lin (National University of Singapore), Jiahao Liu (National University of Singapore), Chuqi Zhang (National University of Singapore), Kaihang Ji (National University of Singapore), Zhenkai Liang (National University of Singapore)",
							"abstract": "Identifying the impact scope and scale is critical for software supply chain vulnerability assessment. However, existing studies face substantial limitations. First, prior studies either work at coarse package-level granularity\u2014producing many false positives\u2014or fail to accomplish whole-ecosystem vulnerability propagation analysis. Second, although vulnerability assessment indicators like CVSS characterize individual vulnerabilities, no metric exists to specifically quantify the dynamic impact of vulnerability propagation across software supply chains. To address these limitations and enable accurate and comprehensive vulnerability impact assessment, we propose a novel approach: (i) a hierarchical worklist-based algorithm for whole-ecosystem and call-graph-level vulnerability propagation analysis and (ii) the Vulnerability Propagation Scoring System (VPSS), a dynamic metric to quantify the scope and evolution of vulnerability impacts in software supply chains. We implement a prototype of our approach in the Java Maven ecosystem and evaluate it on 100 real-world vulnerabilities. Experimental results demonstrate that our approach enables effective ecosystem-wide vulnerability propagation analysis, and provides a practical, quantitative measure of vulnerability impact through VPSS.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Propagation-Based Vulnerability Impact Assessment for Software Supply Chains 1759142502578 10.1109/ASE63991.2025.00014 Bonan Ruan National University of Singapore r-bonan@comp.nus.edu.sg Zhiwei Lin National University of Singapore zhiweil@comp.nus.edu.sg Jiahao Liu National University of Singapore jiahao99@comp.nus.edu.sg Chuqi Zhang National University of Singapore chuqiz@comp.nus.edu.sg Kaihang Ji National University of Singapore kaihang@comp.nus.edu.sg Zhenkai Liang National University of Singapore liangzk@comp.nus.edu.sg n/a Identifying the impact scope and scale is critical for software supply chain vulnerability assessment. However, existing studies face substantial limitations. First, prior studies either work at coarse package-level granularity\u2014producing many false positives\u2014or fail to accomplish whole-ecosystem vulnerability propagation analysis. Second, although vulnerability assessment indicators like CVSS characterize individual vulnerabilities, no metric exists to specifically quantify the dynamic impact of vulnerability propagation across software supply chains. To address these limitations and enable accurate and comprehensive vulnerability impact assessment, we propose a novel approach: (i) a hierarchical worklist-based algorithm for whole-ecosystem and call-graph-level vulnerability propagation analysis and (ii) the Vulnerability Propagation Scoring System (VPSS), a dynamic metric to quantify the scope and evolution of vulnerability impacts in software supply chains. We implement a prototype of our approach in the Java Maven ecosystem and evaluate it on 100 real-world vulnerabilities. Experimental results demonstrate that our approach enables effective ecosystem-wide vulnerability propagation analysis, and provides a practical, quantitative measure of vulnerability impact through VPSS.",
							"pageNumber": 65,
							"isPageNumberRoman": false
						},
						{
							"eid": "71BLD3WaZkygMsytTgFRAg",
							"type": "authorPaper",
							"text": "Debun: Detecting Bundled JavaScript Libraries on Web using Property-Order Graphs",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a078/573300a078.pdf",
							"extraLocations": [],
							"authorNames": "Seojin Kim (Sungkyunkwan University, South Korea), Sungmin Park (Korea University, South Korea), Jihyeok Park (Korea University, South Korea)",
							"abstract": "Detecting front-end JavaScript libraries in web applications is essential for website profiling, vulnerability detection, and dependency management. However, bundlers like Webpack transpile code in various ways, altering the original directory and code structure, which complicates library detection. While state-of-the-art techniques utilize property pattern-based library detection at runtime, they face two key limitations: (1) they cannot detect libraries inaccessible from the global object, and (2) they have limitations in granular version detection. To address these challenges, we present DEBUN, a scalable technique for detecting JavaScript libraries and their versions using function-level fingerprints. Our key insight is that bundlers preserve the property names and execution order of property operations, even after transpilation. To leverage this, we introduce the property-order graph (POG), which represents the execution order of property operations within a function body. We evaluate DEBUN on 68 high-traffic websites with 78 front-end JavaScript libraries. Our approach outperforms existing tools, achieving a 91.76% F1-score in library detection (1.39x higher) and an 79.81% F1-score in version identification with inclusion match (1.36x higher).",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Debun: Detecting Bundled JavaScript Libraries on Web using Property-Order Graphs 1756128301555 10.1109/ASE63991.2025.00015 Seojin Kim Sungkyunkwan University, South Korea 001106ksj@gmail.com Sungmin Park Korea University, South Korea ryan040@korea.ac.kr Jihyeok Park Korea University, South Korea jihyeok_park@korea.ac.kr library detection web application property order graph Detecting front-end JavaScript libraries in web applications is essential for website profiling, vulnerability detection, and dependency management. However, bundlers like Webpack transpile code in various ways, altering the original directory and code structure, which complicates library detection. While state-of-the-art techniques utilize property pattern-based library detection at runtime, they face two key limitations: (1) they cannot detect libraries inaccessible from the global object, and (2) they have limitations in granular version detection. To address these challenges, we present DEBUN, a scalable technique for detecting JavaScript libraries and their versions using function-level fingerprints. Our key insight is that bundlers preserve the property names and execution order of property operations, even after transpilation. To leverage this, we introduce the property-order graph (POG), which represents the execution order of property operations within a function body. We evaluate DEBUN on 68 high-traffic websites with 78 front-end JavaScript libraries. Our approach outperforms existing tools, achieving a 91.76% F1-score in library detection (1.39x higher) and an 79.81% F1-score in version identification with inclusion match (1.36x higher).",
							"pageNumber": 78,
							"isPageNumberRoman": false
						},
						{
							"eid": "22UrxMCk8v18KXRhxCO53s",
							"type": "authorPaper",
							"text": "When AllClose Fails: Round-Off Error Estimation for Deep Learning Programs",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a091/573300a091.pdf",
							"extraLocations": [],
							"authorNames": "Qi Zhan (Zhejiang University, China), Xing Hu (Zhejiang University, China), Yuanyi Lin (Huawei, China), Tongtong Xu (Huawei, China), Xin Xia (Zhejiang University, China), Shanping Li (Zhejiang University, China)",
							"abstract": "Deep learning programs are continually enhanced for improved performance through the use of kernel-level optimizations, parallel training, and low-precision arithmetic. These optimizations provide different implementations that are mathematically equivalent. Round-off error in floating-point computations can lead to differences in the outputs of these implementations, even when the mathematical equivalence holds. When the outputs of customized and reference implementations exceed the tolerance thresholds, it is difficult for developers to distinguish between acceptable round-off errors and implementation bugs. This paper proposes an approach called RENDER to classify the numerical errors between two implementations based on estimating the maximum round-off error. RENDER combines dynamic interval arithmetic and round-off error analysis to compute scalable and tight output bounds. We demonstrate the effectiveness of our method on real-world issues by comparing it with the state-of-the-art tool, SATIRE and a High-Precision Re-execution baseline. Experimental results show that our approach identifies at least 25% more errors and achieves an average speedup of 19\u00D7 compared to SATIRE, enabling developers to debug and optimize implementations more efficiently.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 When AllClose Fails: Round-Off Error Estimation for Deep Learning Programs 1758852353222 10.1109/ASE63991.2025.00016 Qi Zhan Zhejiang University, China qizhan@zju.edu.cn Xing Hu Zhejiang University, China xinghu@zju.edu.cn Yuanyi Lin Huawei, China linyuanyi2@huawei.com Tongtong Xu Huawei, China xutongtong9@huawei.com Xin Xia Zhejiang University, China xin.xia@acm.org Shanping Li Zhejiang University, China shan@zju.edu.cn Round-off error analysis Deep learning pro grams Interval arithmetic Deep learning programs are continually enhanced for improved performance through the use of kernel-level optimizations, parallel training, and low-precision arithmetic. These optimizations provide different implementations that are mathematically equivalent. Round-off error in floating-point computations can lead to differences in the outputs of these implementations, even when the mathematical equivalence holds. When the outputs of customized and reference implementations exceed the tolerance thresholds, it is difficult for developers to distinguish between acceptable round-off errors and implementation bugs. This paper proposes an approach called RENDER to classify the numerical errors between two implementations based on estimating the maximum round-off error. RENDER combines dynamic interval arithmetic and round-off error analysis to compute scalable and tight output bounds. We demonstrate the effectiveness of our method on real-world issues by comparing it with the state-of-the-art tool, SATIRE and a High-Precision Re-execution baseline. Experimental results show that our approach identifies at least 25% more errors and achieves an average speedup of 19\u00D7 compared to SATIRE, enabling developers to debug and optimize implementations more efficiently.",
							"pageNumber": 91,
							"isPageNumberRoman": false
						},
						{
							"eid": "6CUFgLuTUmXk7vr6poRtTg",
							"type": "authorPaper",
							"text": "FAULTSEEKER: LLM-Empowered Framework for Blockchain Transaction Fault Localization",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a104/573300a104.pdf",
							"extraLocations": [],
							"authorNames": "Kairan Sun (Nanyang Technological University, Singapore), Zhengzi Xu (Imperial College London, Imperial Global Singapore, Singapore), Kaixuan Li (Nanyang Technological University, Singapore), Lyuye Zhang (Nanyang Technological University, Singapore), Yuqiang Sun (Nanyang Technological University, Singapore), Liwei Tan (MetaTrust Labs, Singapore), Yang Liu (Nanyang Technological University, Singapore)",
							"abstract": "Web3 applications, particularly decentralized finance (DeFi) protocols, have grown rapidly with over $100 billion locked in smart contracts, attracting sophisticated attacks causing billions in losses. When attack occur, security analysts need to perform fault localization to identify vulnerable functions and understand attack vectors. This critical process currently requires an average of 16.7 analyst hours per incident due to complex blockchain execution models, rapidly evolving protocol interactions, and multi-contract attack patterns that exceed existing analytical capabilities. Despite its critical importance, blockchain fault localization has received limited attention due to fundamental challenges requiring semantic understanding of economic models and protocol-specific logic. Existing blockchain-specific tools target only single vulnerability types, while the only comprehensive solution, DAppFL, relies on machine learning model that may miss sophisticated exploits and lacks interpretability in results. Recent advances in large language models (LLMs) demonstrate remarkable code comprehension capabilities, but existing applications focus on proactive vulnerability detection with minimal exploration of post-incident fault localization. We present FaultSeeker, an LLM-empowered framework for blockchain transaction fault localization. Our two-stage architecture combines transaction-level forensics for strategic scoping with coordinated specialist agents for sustained reasoning. This design provides long-term memory management via orchestrator agents and specialized attention allocation through coordinated workers, enabling comprehensive analysis across complex multi-contract transactions without context loss. We evaluate FaultSeeker on a compiled dataset of 115 real-world malicious transactions with expert-validated annotations spanning diverse attack patterns and complexity levels. Results demonstrate that FaultSeeker significantly outperforms existing approaches, including DAppFL and leading native LLMs (GPT-4o, Claude 3.7 Sonnet, DeepSeek R1), while maintaining practical efficiency (4.4-8.6 minutes) and cost-effectiveness ($1.55-$4.53 per transaction). ",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 FAULTSEEKER: LLM-Empowered Framework for Blockchain Transaction Fault Localization 1759203475202 10.1109/ASE63991.2025.00017 Kairan Sun Nanyang Technological University, Singapore SUNK0013@e.ntu.edu.sg Zhengzi Xu Imperial College London, Imperial Global Singapore, Singapore z.xu@imperial.ac.uk Kaixuan Li Nanyang Technological University, Singapore kaixuan.li@ntu.edu.sg Lyuye Zhang Nanyang Technological University, Singapore zh0004ye@e.ntu.edu.sg Yuqiang Sun Nanyang Technological University, Singapore suny0056@e.ntu.edu.sg Liwei Tan MetaTrust Labs, Singapore daniel.tan@metatrust.io Yang Liu Nanyang Technological University, Singapore yangliu@ntu.edu.sg smart contract security blockchain transaction analysis fault localization Web3 applications, particularly decentralized finance (DeFi) protocols, have grown rapidly with over $100 billion locked in smart contracts, attracting sophisticated attacks causing billions in losses. When attack occur, security analysts need to perform fault localization to identify vulnerable functions and understand attack vectors. This critical process currently requires an average of 16.7 analyst hours per incident due to complex blockchain execution models, rapidly evolving protocol interactions, and multi-contract attack patterns that exceed existing analytical capabilities. Despite its critical importance, blockchain fault localization has received limited attention due to fundamental challenges requiring semantic understanding of economic models and protocol-specific logic. Existing blockchain-specific tools target only single vulnerability types, while the only comprehensive solution, DAppFL, relies on machine learning model that may miss sophisticated exploits and lacks interpretability in results. Recent advances in large language models (LLMs) demonstrate remarkable code comprehension capabilities, but existing applications focus on proactive vulnerability detection with minimal exploration of post-incident fault localization. We present FaultSeeker, an LLM-empowered framework for blockchain transaction fault localization. Our two-stage architecture combines transaction-level forensics for strategic scoping with coordinated specialist agents for sustained reasoning. This design provides long-term memory management via orchestrator agents and specialized attention allocation through coordinated workers, enabling comprehensive analysis across complex multi-contract transactions without context loss. We evaluate FaultSeeker on a compiled dataset of 115 real-world malicious transactions with expert-validated annotations spanning diverse attack patterns and complexity levels. Results demonstrate that FaultSeeker significantly outperforms existing approaches, including DAppFL and leading native LLMs (GPT-4o, Claude 3.7 Sonnet, DeepSeek R1), while maintaining practical efficiency (4.4-8.6 minutes) and cost-effectiveness ($1.55-$4.53 per transaction).",
							"pageNumber": 104,
							"isPageNumberRoman": false
						},
						{
							"eid": "25DKtGpikHaqnLMEMLuiCK",
							"type": "authorPaper",
							"text": "SateLight: A Satellite Application Update Framework for Satellite Computing",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a117/573300a117.pdf",
							"extraLocations": [],
							"authorNames": "Jinfeng Wen (Beijing University of Posts and Telecommunications, China), Jianshu Zhao (Beijing University of Posts and Telecommunications, China), Zixi Zhu (Beijing University of Posts and Telecommunications, China), Xiaomin Zhang (Beijing University of Posts and Telecommunications, China), Qi Liang (Beijing University of Posts and Telecommunications, China), Ao Zhou (Beijing University of Posts and Telecommunications, China), Shangguang Wang (Beijing University of Posts and Telecommunications, China)",
							"abstract": "Satellite computing is an emerging paradigm that empowers satellites to perform onboard processing tasks (i.e., satellite applications), thereby reducing reliance on ground-based systems and improving responsiveness. However, enabling application software updates in this context remains a fundamental challenge due to application heterogeneity, limited ground-to-satellite bandwidth, and harsh space conditions. Existing software update approaches, designed primarily for terrestrial systems, fail to address these constraints, as they assume abundant computational capacity and stable connectivity. To address this gap, we propose SateLight, a practical and effective satellite application update framework tailored for satellite computing. SateLight leverages containerization to encapsulate heterogeneous applications, enabling efficient deployment and maintenance. SateLight further integrates three capabilities: (1) a content-aware differential strategy that minimizes communication data volume, (2) a fine-grained onboard update design that reconstructs target applications, and (3) a layer-based fault-tolerant recovery mechanism to ensure reliability under failure-prone space conditions. Experimental results on a satellite simulation environment with 10 representative satellite applications demonstrate that SateLight reduces transmission latency by up to 91.18% (average 56.54%) compared to the best currently available baseline. It also consistently ensures 100% update correctness across all evaluated applications. Furthermore, a case study on a real-world in-orbit satellite demonstrates the practicality of our approach.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 SateLight: A Satellite Application Update Framework for Satellite Computing 1757939953137 10.1109/ASE63991.2025.00018 Jinfeng Wen Beijing University of Posts and Telecommunications, China jinfeng.wen@bupt.edu.cn Jianshu Zhao Beijing University of Posts and Telecommunications, China jianshuzhao@bupt.edu.cn Zixi Zhu Beijing University of Posts and Telecommunications, China zhuzixi.zzx@gmail.com Xiaomin Zhang Beijing University of Posts and Telecommunications, China zxm987626@bupt.edu.cn Qi Liang Beijing University of Posts and Telecommunications, China liangqi@bupt.edu.cn Ao Zhou Beijing University of Posts and Telecommunications, China aozhou@bupt.edu.cn Shangguang Wang Beijing University of Posts and Telecommunications, China sgwang@bupt.edu.cn satellite computing software update Satellite computing is an emerging paradigm that empowers satellites to perform onboard processing tasks (i.e., satellite applications), thereby reducing reliance on ground-based systems and improving responsiveness. However, enabling application software updates in this context remains a fundamental challenge due to application heterogeneity, limited ground-to-satellite bandwidth, and harsh space conditions. Existing software update approaches, designed primarily for terrestrial systems, fail to address these constraints, as they assume abundant computational capacity and stable connectivity. To address this gap, we propose SateLight, a practical and effective satellite application update framework tailored for satellite computing. SateLight leverages containerization to encapsulate heterogeneous applications, enabling efficient deployment and maintenance. SateLight further integrates three capabilities: (1) a content-aware differential strategy that minimizes communication data volume, (2) a fine-grained onboard update design that reconstructs target applications, and (3) a layer-based fault-tolerant recovery mechanism to ensure reliability under failure-prone space conditions. Experimental results on a satellite simulation environment with 10 representative satellite applications demonstrate that SateLight reduces transmission latency by up to 91.18% (average 56.54%) compared to the best currently available baseline. It also consistently ensures 100% update correctness across all evaluated applications. Furthermore, a case study on a real-world in-orbit satellite demonstrates the practicality of our approach.",
							"pageNumber": 117,
							"isPageNumberRoman": false
						},
						{
							"eid": "1wvWKOKs0VCnCfWWCxvrEH",
							"type": "authorPaper",
							"text": "Diagnosing Performance Differences in Model Checkers via Runtime-Guided Problem Generation",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a129/573300a129.pdf",
							"extraLocations": [],
							"authorNames": "Yibo Dong (National University of Singapore, Singapore), Yicong Xu (East China Normal University, China), Wenjing Deng (East China Normal University, China), Yu Chen (Chuzhou University, China), Xiaoyu Zhang (East China Normal University, China), Jianwen Li (East China Normal University, China), Chengyu Zhang (Loughborough University, United Kingdom), Geguang Pu (East China Normal University, China)",
							"abstract": "Model checking has achieved remarkable success in the hardware domain, largely due to the accumulation of intricate optimizations and finely tuned implementation details. As tools evolve, diagnosing performance differences to better understand the interplay of these factors has become increasingly important. Yet existing problems that reveal such differences are often too large for meaningful inspection, limiting their diagnostic value. To address the problem, this paper proposes AIGROW, a framework for generating hardware model checking problems, and introduces our experience on diagnosing performance differences in model checkers with the generated problems. AIGROW uses a feedback-guided process that evolves problems based on runtime information, selectively retaining those that become more difficult for a target checker. Performance differences are then revealed by evaluating these problems across hardware model checkers that have similar algorithms. Our evaluation demonstrates that AIGROW generates problems that are more than 100 times smaller than those produced by existing generators, while still revealing substantial performance differences. Diagnosing the performance differences has led to concrete improvements in CAR-based checkers: (1) uncovering structural inefficiencies in their exploration strategies, (2) solving 18 previously unsolvable HWMCC'24 problems, and (3) reducing runtime from hours to minutes in several cases.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Diagnosing Performance Differences in Model Checkers via Runtime-Guided Problem Generation 1759383242789 10.1109/ASE63991.2025.00019 Yibo Dong National University of Singapore, Singapore prodongf@gmail.com Yicong Xu East China Normal University, China 51215902150@stu.ecnu.edu.cn Wenjing Deng East China Normal University, China 51215902117@stu.ecnu.edu.cn Yu Chen Chuzhou University, China chenyu@chzu.edu.cn Xiaoyu Zhang East China Normal University, China xiaoyuzhang301@gmail.com Jianwen Li East China Normal University, China lijwen2748@gmail.com Chengyu Zhang Loughborough University, United Kingdom c.zhang4@lboro.ac.uk Geguang Pu East China Normal University, China ggpu@sei.ecnu.edu.cn feedback-driven generation testcase generation hardware model checking Model checking has achieved remarkable success in the hardware domain, largely due to the accumulation of intricate optimizations and finely tuned implementation details. As tools evolve, diagnosing performance differences to better understand the interplay of these factors has become increasingly important. Yet existing problems that reveal such differences are often too large for meaningful inspection, limiting their diagnostic value. To address the problem, this paper proposes AIGROW, a framework for generating hardware model checking problems, and introduces our experience on diagnosing performance differences in model checkers with the generated problems. AIGROW uses a feedback-guided process that evolves problems based on runtime information, selectively retaining those that become more difficult for a target checker. Performance differences are then revealed by evaluating these problems across hardware model checkers that have similar algorithms. Our evaluation demonstrates that AIGROW generates problems that are more than 100 times smaller than those produced by existing generators, while still revealing substantial performance differences. Diagnosing the performance differences has led to concrete improvements in CAR-based checkers: (1) uncovering structural inefficiencies in their exploration strategies, (2) solving 18 previously unsolvable HWMCC'24 problems, and (3) reducing runtime from hours to minutes in several cases.",
							"pageNumber": 129,
							"isPageNumberRoman": false
						},
						{
							"eid": "5aWEIiVvUFHhYUqo9zdZMO",
							"type": "authorPaper",
							"text": "LongCodeZip: Compress Long Context for Code Language Models",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a141/573300a141.pdf",
							"extraLocations": [],
							"authorNames": "Yuling Shi (Shanghai Jiao Tong University, China), Yichun Qian (Stanford University, USA), Hongyu Zhang (Chongqing University, China), Beijun Shen (Shanghai Jiao Tong University, China), Xiaodong Gu (Shanghai Jiao Tong University, China)",
							"abstract": "Code generation under long contexts is becoming increasingly critical as Large Language Models (LLMs) are required to reason over extensive information in the codebase. While recent advances enable code LLMs to process long inputs, high API costs and generation latency remain substantial bottlenecks. Existing context pruning techniques, such as LLMLingua, achieve promising results for general text but overlook code-specific structures and dependencies, leading to suboptimal performance in programming tasks. In this paper, we propose LongCodeZip, a novel plug-and-play code compression framework designed specifically for code LLMs. LongCodeZip employs a dual-stage strategy: (1) coarse-grained compression, which identifies and ranks function-level chunks using conditional perplexity with respect to the instruction, retaining only the most relevant functions; and (2) fine-grained compression, which segments retained functions into blocks based on perplexity and selects an optimal subset under an adaptive token budget to maximize relevance. Evaluations across multiple tasks, including code completion, summarization, and question answering, show that LongCodeZip consistently outperforms baseline methods, achieving up to a 5.6x compression ratio without degrading task performance. By effectively reducing context size while preserving essential information, LongCodeZip enables LLMs to better scale to real-world, large-scale code scenarios, advancing the efficiency and capability of code intelligence applications.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 LongCodeZip: Compress Long Context for Code Language Models 1759316335513 10.1109/ASE63991.2025.00020 Yuling Shi Shanghai Jiao Tong University, China yuling.shi@sjtu.edu.cn Yichun Qian Stanford University, USA ycqian@stanford.edu Hongyu Zhang Chongqing University, China hyzhang@cqu.edu.cn Beijun Shen Shanghai Jiao Tong University, China bjshen@sjtu.edu.cn Xiaodong Gu Shanghai Jiao Tong University, China xiaodong.gu@sjtu.edu.cn large language models code generation Code generation under long contexts is becoming increasingly critical as Large Language Models (LLMs) are required to reason over extensive information in the codebase. While recent advances enable code LLMs to process long inputs, high API costs and generation latency remain substantial bottlenecks. Existing context pruning techniques, such as LLMLingua, achieve promising results for general text but overlook code-specific structures and dependencies, leading to suboptimal performance in programming tasks. In this paper, we propose LongCodeZip, a novel plug-and-play code compression framework designed specifically for code LLMs. LongCodeZip employs a dual-stage strategy: (1) coarse-grained compression, which identifies and ranks function-level chunks using conditional perplexity with respect to the instruction, retaining only the most relevant functions; and (2) fine-grained compression, which segments retained functions into blocks based on perplexity and selects an optimal subset under an adaptive token budget to maximize relevance. Evaluations across multiple tasks, including code completion, summarization, and question answering, show that LongCodeZip consistently outperforms baseline methods, achieving up to a 5.6x compression ratio without degrading task performance. By effectively reducing context size while preserving essential information, LongCodeZip enables LLMs to better scale to real-world, large-scale code scenarios, advancing the efficiency and capability of code intelligence applications.",
							"pageNumber": 141,
							"isPageNumberRoman": false
						},
						{
							"eid": "7ajhzeV4PXamSC0v9g7QzS",
							"type": "authorPaper",
							"text": "CODE-DITING: Automatic Evaluation of Code Generation Without References or Test Cases",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a154/573300a154.pdf",
							"extraLocations": [],
							"authorNames": "Guang Yang (Nanjing University of Aeronautics and Astronautics, China; Nantong Normal College, China; Nantong University, China), Yu Zhou (Nanjing University of Aeronautics and Astronautics, China), Xiang Chen (Nantong University, China), Wei Zheng (Northwestern Polytechnical University, China), Xing Hu (Zhejiang University, China), Xin Zhou (Singapore Management University, Singapore), David Lo (Singapore Management University, Singapore), Taolue Chen (Birkbeck, University of London, UK)",
							"abstract": "Trustworthy evaluation methods for code snippets play a crucial role in neural code generation. Traditional methods, which either rely on reference solutions or require executable test cases, have inherent limitation in flexibility and scalability. The recent LLM-as-Judge methodology offers a promising alternative by directly evaluating functional consistency between the problem description and the generated code. To systematically understand the landscape of these LLM-as-Judge methods, we conduct a comprehensive empirical study across three diverse datasets. Our investigation reveals the pros and cons of two categories of LLM-as-Judge methods: the methods based on general foundation models can achieve good performance but require complex prompts and lack explainability, while the methods based on reasoning foundation models provide better explainability with simpler prompts but demand substantial computational resources due to their large parameter sizes. To address these limitations, we propose CODE-DITING, a novel code evaluation method that balances accuracy, efficiency and explainability. We develop a data distillation framework that effectively transfers reasoning capabilities from DeepSeek-R1671B to our CODE-DITING 1.5B and 7B models, significantly enhancing evaluation explainability and reducing the computational cost. With the majority vote strategy in the inference process, CODE-DITING 1.5B outperforms all models with the same magnitude of parameters and achieves performance which would normally exhibit in a model with 5 times of parameter scale. CODE-DITING 7B surpasses GPT-4o and DeepSeek-V3 671B, even though it only uses 1% of the parameter volume of these large models. Further experiments show that CODEDITING is robust to preference leakage and can serve as a promising alternative for code evaluation.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 CODE-DITING: Automatic Evaluation of Code Generation Without References or Test Cases 1759324119334 10.1109/ASE63991.2025.00021 Guang Yang Nanjing University of Aeronautics and Astronautics, China; Nantong Normal College, China; Nantong University, China novelyg@outlook.com Yu Zhou Nanjing University of Aeronautics and Astronautics, China zhouyu@nuaa.edu.cn Xiang Chen Nantong University, China xchencs@ntu.edu.cn Wei Zheng Northwestern Polytechnical University, China wzheng@nwpu.edu.cn Xing Hu Zhejiang University, China xinghu@zju.edu.cn Xin Zhou Singapore Management University, Singapore xinzhou.2020@phdcs.smu.edu.sg David Lo Singapore Management University, Singapore davidlo@smu.edu.sg Taolue Chen Birkbeck, University of London, UK t.chen@bbk.ac.uk Code Generation Evaluation LLM-as-Judge Trustworthy evaluation methods for code snippets play a crucial role in neural code generation. Traditional methods, which either rely on reference solutions or require executable test cases, have inherent limitation in flexibility and scalability. The recent LLM-as-Judge methodology offers a promising alternative by directly evaluating functional consistency between the problem description and the generated code. To systematically understand the landscape of these LLM-as-Judge methods, we conduct a comprehensive empirical study across three diverse datasets. Our investigation reveals the pros and cons of two categories of LLM-as-Judge methods: the methods based on general foundation models can achieve good performance but require complex prompts and lack explainability, while the methods based on reasoning foundation models provide better explainability with simpler prompts but demand substantial computational resources due to their large parameter sizes. To address these limitations, we propose CODE-DITING, a novel code evaluation method that balances accuracy, efficiency and explainability. We develop a data distillation framework that effectively transfers reasoning capabilities from DeepSeek-R1671B to our CODE-DITING 1.5B and 7B models, significantly enhancing evaluation explainability and reducing the computational cost. With the majority vote strategy in the inference process, CODE-DITING 1.5B outperforms all models with the same magnitude of parameters and achieves performance which would normally exhibit in a model with 5 times of parameter scale. CODE-DITING 7B surpasses GPT-4o and DeepSeek-V3 671B, even though it only uses 1% of the parameter volume of these large models. Further experiments show that CODEDITING is robust to preference leakage and can serve as a promising alternative for code evaluation.",
							"pageNumber": 154,
							"isPageNumberRoman": false
						},
						{
							"eid": "4MyUUd7N2nUqcCzAZYqQYE",
							"type": "authorPaper",
							"text": "An Empirical Study of Knowledge Transfer in AI Pair Programming",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a166/573300a166.pdf",
							"extraLocations": [],
							"authorNames": "Alisa Welter (Saarland University, Germany), Niklas Schneider (Saarland University, Germany), Tobias Dick  (Saarland University, Germany), Kallistos Weis (Saarland University, Germany), Christof Tinnes (Siemens AG, Germany), Marvin Wyrich (Saarland University, Germany), Sven Apel (Saarland University)",
							"abstract": "Knowledge transfer is fundamental to human collaboration and is therefore common in software engineering. Pair programming is a prominent instance. With the rise of AI coding assistants, developers now not only work with human partners but also, as some claim, with AI pair programmers. Although studies confirm knowledge transfer during human pair programming, its effectiveness with AI coding assistants remains uncertain. To analyze knowledge transfer in both human\u2013human and human\u2013AI settings, we conducted an empirical study where developer pairs solved a programming task without AI support, while a separate group of individual developers completed the same task using the AI coding assistant GitHub Copilot. We extended an existing knowledge transfer framework and employed a semi-automated evaluation pipeline to assess differences in knowledge transfer episodes across both settings. We found a similar frequency of successful knowledge transfer episodes and overlapping topical categories across both settings. Two of our key findings are that developers tend to accept GitHub Copilot's suggestions with less scrutiny than those from human pair programming partners, but also that GitHub Copilot can subtly remind developers of important code details they might otherwise overlook.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 An Empirical Study of Knowledge Transfer in AI Pair Programming 1759144514080 10.1109/ASE63991.2025.00022 Alisa Welter Saarland University, Germany welter@cs.uni-saarland.de Niklas Schneider Saarland University, Germany nschneider@cs.uni-saarland.de Tobias Dick Saarland University, Germany tdick@cs.uni-saarland.de Kallistos Weis Saarland University, Germany kallistos@cs.uni-saarland.de Christof Tinnes Siemens AG, Germany christof.tinnes@siemens.com Marvin Wyrich Saarland University, Germany wyrich@cs.uni-saarland.de Sven Apel Saarland University apel@cs.uni-saarland.de AI pair programming knowledge transfer Knowledge transfer is fundamental to human collaboration and is therefore common in software engineering. Pair programming is a prominent instance. With the rise of AI coding assistants, developers now not only work with human partners but also, as some claim, with AI pair programmers. Although studies confirm knowledge transfer during human pair programming, its effectiveness with AI coding assistants remains uncertain. To analyze knowledge transfer in both human\u2013human and human\u2013AI settings, we conducted an empirical study where developer pairs solved a programming task without AI support, while a separate group of individual developers completed the same task using the AI coding assistant GitHub Copilot. We extended an existing knowledge transfer framework and employed a semi-automated evaluation pipeline to assess differences in knowledge transfer episodes across both settings. We found a similar frequency of successful knowledge transfer episodes and overlapping topical categories across both settings. Two of our key findings are that developers tend to accept GitHub Copilot's suggestions with less scrutiny than those from human pair programming partners, but also that GitHub Copilot can subtly remind developers of important code details they might otherwise overlook.",
							"pageNumber": 166,
							"isPageNumberRoman": false
						},
						{
							"eid": "2etGVEw8KqRF4bwWmGWywR",
							"type": "authorPaper",
							"text": "Wired for Reuse: Automating Context-Aware Code Adaptation in IDEs via LLM-Based Agent",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a178/573300a178.pdf",
							"extraLocations": [],
							"authorNames": "Taiming Wang (Beijing Institute of Technology, China), Yanjie Jiang (Tianjin University, China), Chunhao Dong (Beijing Institute of Technology, China), Yuxia Zhang (Beijing Institute of Technology, China), Hui Liu (Beijing Institute of Technology, China)",
							"abstract": "Copy-paste-modify is a widespread and pragmatic practice in software development, where developers adapt reused code snippets, sourced from platforms such as Stack Overflow, GitHub, or LLM outputs, into their local codebase. A critical yet underexplored aspect of this adaptation is code wiring: the context-aware process of substituting unresolved variables in pasted code with suitable variables or expressions from the surrounding context. Existing solutions either rely on heuristic rules or historical templates, often failing to effectively utilize contextual information, despite studies showing that over half of adaptation cases are context-dependent. In this paper, we introduce WIRL, an LLM-based agent for code wiring framed as a Retrieval-Augmented Generation (RAG) infilling task. WIRL combines an LLM, a customized toolkit, and an orchestration module to identify unresolved variables, retrieve context, and perform context-aware substitutions. To balance efficiency and autonomy, the agent adopts a mixed strategy: deterministic rule-based steps for common patterns, and a state-machine-guided decision process for intelligent exploration. We evaluate WIRL on a carefully curated, high-quality dataset consisting of real-world code adaptation scenarios. Our approach achieves an exact match precision of 91.7% and a recall of 90.0%, outperforming advanced LLMs by 22.6 and 13.7 percentage points in precision and recall, respectively, and surpassing IntelliJ IDEA by 54.3 and 49.9 percentage points. These results underscore its practical utility, particularly in contexts with complex variable dependencies or multiple unresolved variables. We believe WIRL paves the way for more intelligent and context-aware developer assistance in modern IDEs.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Wired for Reuse: Automating Context-Aware Code Adaptation in IDEs via LLM-Based Agent 1759896242165 10.1109/ASE63991.2025.00023 Taiming Wang Beijing Institute of Technology, China wangtaiming@bit.edu.cn Yanjie Jiang Tianjin University, China yanjiejiang@tju.edu.cn Chunhao Dong Beijing Institute of Technology, China dongchunhao22@bit.edu.cn Yuxia Zhang Beijing Institute of Technology, China yuxiazh@bit.edu.cn Hui Liu Beijing Institute of Technology, China liuhui08@bit.edu.cn copy-paste-modify practices code reuse code adaptation large language models agent Copy-paste-modify is a widespread and pragmatic practice in software development, where developers adapt reused code snippets, sourced from platforms such as Stack Overflow, GitHub, or LLM outputs, into their local codebase. A critical yet underexplored aspect of this adaptation is code wiring: the context-aware process of substituting unresolved variables in pasted code with suitable variables or expressions from the surrounding context. Existing solutions either rely on heuristic rules or historical templates, often failing to effectively utilize contextual information, despite studies showing that over half of adaptation cases are context-dependent. In this paper, we introduce WIRL, an LLM-based agent for code wiring framed as a Retrieval-Augmented Generation (RAG) infilling task. WIRL combines an LLM, a customized toolkit, and an orchestration module to identify unresolved variables, retrieve context, and perform context-aware substitutions. To balance efficiency and autonomy, the agent adopts a mixed strategy: deterministic rule-based steps for common patterns, and a state-machine-guided decision process for intelligent exploration. We evaluate WIRL on a carefully curated, high-quality dataset consisting of real-world code adaptation scenarios. Our approach achieves an exact match precision of 91.7% and a recall of 90.0%, outperforming advanced LLMs by 22.6 and 13.7 percentage points in precision and recall, respectively, and surpassing IntelliJ IDEA by 54.3 and 49.9 percentage points. These results underscore its practical utility, particularly in contexts with complex variable dependencies or multiple unresolved variables. We believe WIRL paves the way for more intelligent and context-aware developer assistance in modern IDEs.",
							"pageNumber": 178,
							"isPageNumberRoman": false
						},
						{
							"eid": "2vYtmOrg4WbXknH3UAIoWf",
							"type": "authorPaper",
							"text": "\"My Productivity is Boosted, but \u2026\" Demystifying Users' Perception on AI Coding Assistants",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a191/573300a191.pdf",
							"extraLocations": [],
							"authorNames": "Yunbo Lyu (Singapore Management University, Singapore), Zhou Yang (University of Alberta, Canada), Jieke Shi (Singapore Management University, Singapore), Jianming Chang (Southeast University, China), Yue Liu (Singapore Management University, Singapore), David Lo (Singapore Management University, Singapore)",
							"abstract": "This paper aims to explore fundamental questions in the era when AI coding assistants like GitHub Copilot are widely adopted: what do developers truly value and criticize in AI coding assistants, and what does this reveal about their needs and expectations in real-world software development? Unlike previous studies that conduct observational research in controlled and simulated environments, we analyze extensive, first-hand user reviews of AI coding assistants, which capture developers' authentic perspectives and experiences drawn directly from their actual day-to-day work contexts. We identify 1,085 AI coding assistants from the Visual Studio Code Marketplace. Although they only account for 1.64% of all extensions, we observe a surge in these assistants: over 90% of them are released within the past two years. We then manually analyze the user reviews sampled from 32 AI coding assistants that have sufficient installations and reviews to construct a comprehensive taxonomy of user concerns and feedback about these assistants. We manually annotate each review's attitude when mentioning certain aspects of coding assistants, yielding nuanced insights into user satisfaction and dissatisfaction regarding specific features, concerns, and overall tool performance. Built on top of the findings-including how users demand not just intelligent suggestions but also context-aware, customizable, and resource-efficient interactions\u2014we propose five practical implications and suggestions to guide the enhancement of AI coding assistants that satisfy user needs.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 \"My Productivity is Boosted, but \u2026\" Demystifying Users' Perception on AI Coding Assistants 1759416807480 10.1109/ASE63991.2025.00024 Yunbo Lyu Singapore Management University, Singapore yunbolyu@smu.edu.sg Zhou Yang University of Alberta, Canada zhou.yang@ualberta.ca Jieke Shi Singapore Management University, Singapore jiekeshi@smu.edu.sg Jianming Chang Southeast University, China jianmingchang@seu.edu.cn Yue Liu Singapore Management University, Singapore liuyue@smu.edu.sg David Lo Singapore Management University, Singapore davidlo@smu.edu.sg ai assistant ide user experience programming human-computer interaction human factors This paper aims to explore fundamental questions in the era when AI coding assistants like GitHub Copilot are widely adopted: what do developers truly value and criticize in AI coding assistants, and what does this reveal about their needs and expectations in real-world software development? Unlike previous studies that conduct observational research in controlled and simulated environments, we analyze extensive, first-hand user reviews of AI coding assistants, which capture developers' authentic perspectives and experiences drawn directly from their actual day-to-day work contexts. We identify 1,085 AI coding assistants from the Visual Studio Code Marketplace. Although they only account for 1.64% of all extensions, we observe a surge in these assistants: over 90% of them are released within the past two years. We then manually analyze the user reviews sampled from 32 AI coding assistants that have sufficient installations and reviews to construct a comprehensive taxonomy of user concerns and feedback about these assistants. We manually annotate each review's attitude when mentioning certain aspects of coding assistants, yielding nuanced insights into user satisfaction and dissatisfaction regarding specific features, concerns, and overall tool performance. Built on top of the findings-including how users demand not just intelligent suggestions but also context-aware, customizable, and resource-efficient interactions\u2014we propose five practical implications and suggestions to guide the enhancement of AI coding assistants that satisfy user needs.",
							"pageNumber": 191,
							"isPageNumberRoman": false
						},
						{
							"eid": "3sBBiiUWFypcxcSP74STrD",
							"type": "authorPaper",
							"text": "Finding Bugs in WebAssembly Interface Type Binding Generators",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a204/573300a204.pdf",
							"extraLocations": [],
							"authorNames": "Ethan Stanley (University of Utah, USA), Eric Eide (University of Utah, USA)",
							"abstract": "The WebAssembly Component Model is an emerging standard for assembling applications from parts that are implemented in WebAssembly. Unlike ordinary WebAssembly modules, components implement their interfaces in a standardized way, enabling the interoperation of software parts compiled to WebAssembly from different programming languages. A component essentially wraps an ordinary module with binding code, created by a WebAssembly Interface Type (WIT) binding generator, to adapt the module to the WebAssembly component standard. Errors in the generation of binding code can lead to hard-to-diagnose run-time errors, including crashes and silent data corruption, in applications built from WebAssembly components. Prior published work on WebAssembly testing has focused on finding bugs in WebAssembly compilers and runtimes, and has overlooked the potential for bugs in the generation of binding code. In this experience paper, we detail and evaluate our approach to addressing this oversight. We implemented a system to perform random differential testing for two WIT binding generators, called wit-bindgen and wit-bindgen-go. Our system uses these binding generators to produce multiple WebAssembly components with the same behavior from programs written in different high-level languages. If the components' run-time behaviors differ, we expect that there is a bug in one of the generated bindings. Using our framework, we discovered seven previously unknown code-generation defects in wit-bindgen and wit-bindgen-go. We analyze these bugs in this paper and, in addition, share lessons learned that can guide future efforts to test binding generators.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Finding Bugs in WebAssembly Interface Type Binding Generators 1759514534480 10.1109/ASE63991.2025.00025 Ethan Stanley University of Utah, USA ethan.stanley@utah.edu Eric Eide University of Utah, USA eeide@cs.utah.edu components fuzzing webassembly wit The WebAssembly Component Model is an emerging standard for assembling applications from parts that are implemented in WebAssembly. Unlike ordinary WebAssembly modules, components implement their interfaces in a standardized way, enabling the interoperation of software parts compiled to WebAssembly from different programming languages. A component essentially wraps an ordinary module with binding code, created by a WebAssembly Interface Type (WIT) binding generator, to adapt the module to the WebAssembly component standard. Errors in the generation of binding code can lead to hard-to-diagnose run-time errors, including crashes and silent data corruption, in applications built from WebAssembly components. Prior published work on WebAssembly testing has focused on finding bugs in WebAssembly compilers and runtimes, and has overlooked the potential for bugs in the generation of binding code. In this experience paper, we detail and evaluate our approach to addressing this oversight. We implemented a system to perform random differential testing for two WIT binding generators, called wit-bindgen and wit-bindgen-go. Our system uses these binding generators to produce multiple WebAssembly components with the same behavior from programs written in different high-level languages. If the components' run-time behaviors differ, we expect that there is a bug in one of the generated bindings. Using our framework, we discovered seven previously unknown code-generation defects in wit-bindgen and wit-bindgen-go. We analyze these bugs in this paper and, in addition, share lessons learned that can guide future efforts to test binding generators.",
							"pageNumber": 204,
							"isPageNumberRoman": false
						},
						{
							"eid": "6JZf3gMsyb8b4eUKKjy2dH",
							"type": "authorPaper",
							"text": "R3-Bench: Reproducible Real-World Reverse Engineering Dataset for Symbol Recovery",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a217/573300a217.pdf",
							"extraLocations": [],
							"authorNames": "Muzhi Yu (Peking University; Alibaba Group), Zhengran Zeng (Peking University), Wei Ye (Peking University), Jinan Sun (Peking University), Xiaolong Bai (Alibaba Group), Shikun Zhang (Peking University)",
							"abstract": "Symbol recovery in reverse engineering is crucial for restoring variable and data structure information in compiled binaries. While learning-based methods have shown promise in recovering both semantic information (names and types) and syntactic information (shapes), they require comprehensive datasets where expressions in binary code are precisely aligned with their source code equivalents. Current techniques for generating such alignments struggle with complex data access patterns, resulting in incomplete training data and consequently hampering model performance and recovery accuracy. We present AST-Align, a novel technique unifying alignment of variables and struct access expressions across multiple architectures (x86 and ARM) and languages (C/C++/Rust). AST-Align significantly improves the number of generated ground truths, capturing four times more struct fields than previous methods. Using this algorithm, we develop R3-Bench, a metadata-rich, extensible dataset with explicit project inclusion criteria and reproducible processing pipeline, comprising over 10 million functions across multiple architectures. Our evaluation establishes baseline performance by testing various approaches from n-gram models to Large Language Models. The results show that while general LLMs initially perform poorly, their effectiveness dramatically improves with proper demonstration. R3-Bench provides a robust foundation for assessing model capabilities and serves as a valuable reference for future symbol recovery research.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 R3-Bench: Reproducible Real-World Reverse Engineering Dataset for Symbol Recovery 1759254939597 10.1109/ASE63991.2025.00026 Muzhi Yu Peking University; Alibaba Group muzhi.yu@pku.edu.cn Zhengran Zeng Peking University zhengranzeng@stu.pku.edu.cn Wei Ye Peking University wye@pku.edu.cn Jinan Sun Peking University sjn@pku.edu.cn Xiaolong Bai Alibaba Group bxl1989@gmail.com Shikun Zhang Peking University zhangsk@pku.edu.cn n/a Symbol recovery in reverse engineering is crucial for restoring variable and data structure information in compiled binaries. While learning-based methods have shown promise in recovering both semantic information (names and types) and syntactic information (shapes), they require comprehensive datasets where expressions in binary code are precisely aligned with their source code equivalents. Current techniques for generating such alignments struggle with complex data access patterns, resulting in incomplete training data and consequently hampering model performance and recovery accuracy. We present AST-Align, a novel technique unifying alignment of variables and struct access expressions across multiple architectures (x86 and ARM) and languages (C/C++/Rust). AST-Align significantly improves the number of generated ground truths, capturing four times more struct fields than previous methods. Using this algorithm, we develop R3-Bench, a metadata-rich, extensible dataset with explicit project inclusion criteria and reproducible processing pipeline, comprising over 10 million functions across multiple architectures. Our evaluation establishes baseline performance by testing various approaches from n-gram models to Large Language Models. The results show that while general LLMs initially perform poorly, their effectiveness dramatically improves with proper demonstration. R3-Bench provides a robust foundation for assessing model capabilities and serves as a valuable reference for future symbol recovery research.",
							"pageNumber": 217,
							"isPageNumberRoman": false
						},
						{
							"eid": "ka3PCAJZLwat37q2zLlFg",
							"type": "authorPaper",
							"text": "RELIA: Accelerating the Analysis of Cloud Access Control Policies",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a228/573300a228.pdf",
							"extraLocations": [],
							"authorNames": "Dan Wang (Xi'an Jiaotong University), Peng Zhang (Xi'an Jiaotong University), Zhenrong Gu (Xi'an Jiaotong University), Weibo Lin (Huawei Cloud), Shibiao Jiang (Huawei Cloud), Zhu He (Huawei Cloud), Xu Du (Huawei Cloud), Longfei Chen (Huawei Cloud), Jun Li (Huawei Cloud), Xiaohong Guan (Xi'an Jiaotong University)",
							"abstract": "With the diversification of cloud services, cloud providers offer flexible access control by letting users apply fine-grained cloud access control policies to secure their cloud resources. However, flexibility comes with the cost that configuring cloud access control policies is error-prone. Therefore, cloud providers have developed SMT-based tools to formally analyze the user-defined policies. Unfortunately, we find these analyzers slow, due to the complex regular expression matching conditions in policies. To this end, this paper introduces RELIA, a general method to speed up the analysis of cloud access control policies. The key idea of RELIA is to pre-compute a set of String Equivalence Classes (SECs) based on the regular expressions in a policy, assign a unique integer to each SEC, and rewrite the regular constraints into equivalent integer constraints, which are easier to solve. We implement RELIA as a transparent layer between our in-house access analyzer and off-the-shelf SMT solvers. Based on real policies from a large public cloud provider, we show that: when enabling RELIA, our in-house portfolio solver (consisting of Z3, CVC4, and CVC5) can speed up the analysis process for nearly 95% of all cases, with an average speedup of 8.21\u00D7.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 RELIA: Accelerating the Analysis of Cloud Access Control Policies 1759118697448 10.1109/ASE63991.2025.00027 Dan Wang Xi'an Jiaotong University dan-wang@stu.xjtu.edu.cn Peng Zhang Xi'an Jiaotong University p-zhang@xjtu.edu.cn Zhenrong Gu Xi'an Jiaotong University zrgu@stu.xjtu.edu.cn Weibo Lin Huawei Cloud linweibo@huawei.com Shibiao Jiang Huawei Cloud jiangshibiao1@huawei.com Zhu He Huawei Cloud hezhu4@huawei.com Xu Du Huawei Cloud duxu1@huawei.com Longfei Chen Huawei Cloud chenlongfei@huawei.com Jun Li Huawei Cloud alanlee@huawei.com Xiaohong Guan Xi'an Jiaotong University xhguan@xjtu.edu.cn With the diversification of cloud services, cloud providers offer flexible access control by letting users apply fine-grained cloud access control policies to secure their cloud resources. However, flexibility comes with the cost that configuring cloud access control policies is error-prone. Therefore, cloud providers have developed SMT-based tools to formally analyze the user-defined policies. Unfortunately, we find these analyzers slow, due to the complex regular expression matching conditions in policies. To this end, this paper introduces RELIA, a general method to speed up the analysis of cloud access control policies. The key idea of RELIA is to pre-compute a set of String Equivalence Classes (SECs) based on the regular expressions in a policy, assign a unique integer to each SEC, and rewrite the regular constraints into equivalent integer constraints, which are easier to solve. We implement RELIA as a transparent layer between our in-house access analyzer and off-the-shelf SMT solvers. Based on real policies from a large public cloud provider, we show that: when enabling RELIA, our in-house portfolio solver (consisting of Z3, CVC4, and CVC5) can speed up the analysis process for nearly 95% of all cases, with an average speedup of 8.21\u00D7.",
							"pageNumber": 228,
							"isPageNumberRoman": false
						},
						{
							"eid": "ZSCzWRTdfshqlOFtmBUi1",
							"type": "authorPaper",
							"text": "Interaction2Code: Benchmarking MLLM-Based Interactive Webpage Code Generation from Interactive Prototyping",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a241/573300a241.pdf",
							"extraLocations": [],
							"authorNames": "Jingyu Xiao (The Chinese University of Hong Kong, China), Yuxuan Wan (The Chinese University of Hong Kong, China), Yintong Huo (Singapore Management University, Singapore), Zixin Wang (The Chinese University of Hong Kong, China), Xinyi Xu (The Chinese University of Hong Kong, China), Wenxuan Wang (Renmin University of China, China), Zhiyao Xu (Tsinghua University, China), Yuhang Wang (Southwest University, China), Michael R. Lyu (The Chinese University of Hong Kong, China)",
							"abstract": "Multimodal Large Language Models (MLLMs) have demonstrated remarkable performance on the design-to-code task, i.e., generating UI code from UI mock-ups. However, existing benchmarks only contain static web pages for evaluation and ignore the dynamic interaction, limiting the practicality, usability and user engagement of the generated webpages. To bridge these gaps, we present the first systematic investigation of MLLMs in generating interactive webpages. Specifically, we formulate the Interaction-to-Code task and establish the Interaction2Code benchmark, encompassing 127 unique webpages and 374 distinct interactions across 15 webpage types and 31 interaction categories. Through comprehensive experiments utilizing state-of-the-art (SOTA) MLLMs, evaluated via both automatic metrics and human assessments, we identify four critical limitations of MLLM on Interaction-to-Code task: (1) inadequate generation of interaction compared with full page, (2) prone to ten types of failure, (3) poor performance on visually subtle interactions, and (4) insufficient undestanding on interaction when limited to single-modality visual descriptions. To address these limitations, we propose four enhancement strategies: Interactive Element Highlighting, Failure-aware Prompting (FAP), Visual Saliency Enhancement, and Visual-Textual Descriptions Combination, all aiming at improving MLLMs' performance on the Interaction-to-Code task. Our data and code are available in https://github.com/WebPAI/Interaction2Code.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Interaction2Code: Benchmarking MLLM-Based Interactive Webpage Code Generation from Interactive Prototyping 1759328154007 10.1109/ASE63991.2025.00028 Jingyu Xiao The Chinese University of Hong Kong, China jyxiao@link.cuhk.edu.hk Yuxuan Wan The Chinese University of Hong Kong, China yxwan@link.cuhk.edu.hk Yintong Huo Singapore Management University, Singapore ythuo@smu.edu.sg Zixin Wang The Chinese University of Hong Kong, China zixinwang@link.cuhk.edu.hk Xinyi Xu The Chinese University of Hong Kong, China xinyixu@link.cuhk.edu.hk Wenxuan Wang Renmin University of China, China jwxwang@gmail.com Zhiyao Xu Tsinghua University, China xu-zy25@mails.tsinghua.edu.cn Yuhang Wang Southwest University, China wyh20030323@email.swu.edu.cn Michael R. Lyu The Chinese University of Hong Kong, China lyu@cse.cuhk.edu.hk multimodal large language models code generation web development Multimodal Large Language Models (MLLMs) have demonstrated remarkable performance on the design-to-code task, i.e., generating UI code from UI mock-ups. However, existing benchmarks only contain static web pages for evaluation and ignore the dynamic interaction, limiting the practicality, usability and user engagement of the generated webpages. To bridge these gaps, we present the first systematic investigation of MLLMs in generating interactive webpages. Specifically, we formulate the Interaction-to-Code task and establish the Interaction2Code benchmark, encompassing 127 unique webpages and 374 distinct interactions across 15 webpage types and 31 interaction categories. Through comprehensive experiments utilizing state-of-the-art (SOTA) MLLMs, evaluated via both automatic metrics and human assessments, we identify four critical limitations of MLLM on Interaction-to-Code task: (1) inadequate generation of interaction compared with full page, (2) prone to ten types of failure, (3) poor performance on visually subtle interactions, and (4) insufficient undestanding on interaction when limited to single-modality visual descriptions. To address these limitations, we propose four enhancement strategies: Interactive Element Highlighting, Failure-aware Prompting (FAP), Visual Saliency Enhancement, and Visual-Textual Descriptions Combination, all aiming at improving MLLMs' performance on the Interaction-to-Code task. Our data and code are available in https://github.com/WebPAI/Interaction2Code.",
							"pageNumber": 241,
							"isPageNumberRoman": false
						},
						{
							"eid": "13RStxQYLDgGAtdae6Llc5",
							"type": "authorPaper",
							"text": "Defects4C: Benchmarking Large Language Model Repair Capability with C/C++ Bugs",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a254/573300a254.pdf",
							"extraLocations": [],
							"authorNames": "Jian Wang (Singapore Management University, Singapore), xiaofei xie (Singapore Management University, Singapore), qiang hu (Tianjin University, China), shangqing liu (Nanjing University, China), Jiongchi  Yu (Singapore Management University, Singapore), Jiaolong Kong (Singapore Management University, Singapore), Yi Li (Nanyang Technological University, Singapore)",
							"abstract": "Automated Program Repair (APR) plays a critical role in enhancing the quality and reliability of software systems. While substantial progress has been made in Java-based APR, largely facilitated by benchmarks like Defects4J, there remains a significant gap in research on C/C++ program repair, despite the widespread use of C/C++ and the prevalence of associated vulnerabilities. This gap is primarily due to the lack of high-quality, open-source benchmarks tailored for C/C++. To address this issue, we introduce Defects4C, a comprehensive and executable benchmark specifically designed for C/C++ program repair. Our dataset is constructed from real-world C/C++ repositories and includes a large collection of bug-relevant commits (9M in total), 248 high-quality buggy functions, and 102 vulnerable functions, all paired with test cases for reproduction. These resources enable rigorous evaluation of repair techniques and support the retraining of learning-based approaches for enhanced performance. Using Defects4C, we conduct a comprehensive empirical study evaluating the effectiveness of 24 state-of-the-art large language models (LLMs) in repairing C/C++ faults. Our findings offer valuable insights into the strengths and limitations of current LLM-based APR techniques in this domain, highlighting both the need for more robust methods and the critical role of Defects4C in advancing future research.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Defects4C: Benchmarking Large Language Model Repair Capability with C/C++ Bugs 1758198088062 10.1109/ASE63991.2025.00029 Jian Wang Singapore Management University, Singapore jian004@e.ntu.edu.sg xiaofei xie Singapore Management University, Singapore xfxie@smu.edu.sg qiang hu Tianjin University, China qianghu@tju.edu.cn shangqing liu Nanjing University, China shangqingliu@nju.edu.cn Jiongchi Yu Singapore Management University, Singapore n/a Jiaolong Kong Singapore Management University, Singapore n/a Yi Li Nanyang Technological University, Singapore yi_li@ntu.edu.sg c++ program repair benchmark llm Automated Program Repair (APR) plays a critical role in enhancing the quality and reliability of software systems. While substantial progress has been made in Java-based APR, largely facilitated by benchmarks like Defects4J, there remains a significant gap in research on C/C++ program repair, despite the widespread use of C/C++ and the prevalence of associated vulnerabilities. This gap is primarily due to the lack of high-quality, open-source benchmarks tailored for C/C++. To address this issue, we introduce Defects4C, a comprehensive and executable benchmark specifically designed for C/C++ program repair. Our dataset is constructed from real-world C/C++ repositories and includes a large collection of bug-relevant commits (9M in total), 248 high-quality buggy functions, and 102 vulnerable functions, all paired with test cases for reproduction. These resources enable rigorous evaluation of repair techniques and support the retraining of learning-based approaches for enhanced performance. Using Defects4C, we conduct a comprehensive empirical study evaluating the effectiveness of 24 state-of-the-art large language models (LLMs) in repairing C/C++ faults. Our findings offer valuable insights into the strengths and limitations of current LLM-based APR techniques in this domain, highlighting both the need for more robust methods and the critical role of Defects4C in advancing future research.",
							"pageNumber": 254,
							"isPageNumberRoman": false
						},
						{
							"eid": "6IVSUnVA1HN7oee8Lu2p4R",
							"type": "authorPaper",
							"text": "Evolution-Aware Heuristics for GR(1) Realizability Checking",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a266/573300a266.pdf",
							"extraLocations": [],
							"authorNames": "Dor Ma'ayan (Tel Aviv University, Israel), Shahar Maoz (Tel Aviv University, Israel), Jan Oliver Ringert (Bauhaus University Weimar, Germany)",
							"abstract": "Reactive synthesis is an automated procedure to obtain a correct-by-construction reactive system from its temporal logic specification. Despite significant research progress over the past few decades, reactive synthesis is still in its early stages of practical adoption. One significant barrier to using reactive synthesis outside academia is the long realizability checking and synthesis time of specifications. This paper introduces a novel, evolution-aware approach for realizability checking. Our approach leverages the key observation that realizability checking is an operation that developers frequently perform during iterative specification development; therefore, utilizing intermediate data from previous realizability checks can substantially improve running times. Our approach computes a local semantic diff between previous and current versions of the specification, and, based on the diff and the previous realizability checking result, applies a set of sound heuristics. These heuristics reuse intermediate data collected during the previous specification's realizability checking to accelerate the current specification's realizability checking. Our evaluation demonstrates that these heuristics are applicable in 70% of cases from a real-world dataset containing thousands of specifications, and that their application significantly improves the running time of realizability checking.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Evolution-Aware Heuristics for GR(1) Realizability Checking 1759491697956 10.1109/ASE63991.2025.00030 Dor Ma'ayan Tel Aviv University, Israel dor.d.ma@gmail.com Shahar Maoz Tel Aviv University, Israel maoz@cs.tau.ac.il Jan Oliver Ringert Bauhaus University Weimar, Germany jan.ringert@uni-weimar.de reactive synthesis Reactive synthesis is an automated procedure to obtain a correct-by-construction reactive system from its temporal logic specification. Despite significant research progress over the past few decades, reactive synthesis is still in its early stages of practical adoption. One significant barrier to using reactive synthesis outside academia is the long realizability checking and synthesis time of specifications. This paper introduces a novel, evolution-aware approach for realizability checking. Our approach leverages the key observation that realizability checking is an operation that developers frequently perform during iterative specification development; therefore, utilizing intermediate data from previous realizability checks can substantially improve running times. Our approach computes a local semantic diff between previous and current versions of the specification, and, based on the diff and the previous realizability checking result, applies a set of sound heuristics. These heuristics reuse intermediate data collected during the previous specification's realizability checking to accelerate the current specification's realizability checking. Our evaluation demonstrates that these heuristics are applicable in 70% of cases from a real-world dataset containing thousands of specifications, and that their application significantly improves the running time of realizability checking.",
							"pageNumber": 266,
							"isPageNumberRoman": false
						},
						{
							"eid": "6MV1TIWDhHGFej4w1FybA2",
							"type": "authorPaper",
							"text": "Do LLMs Generate Useful Test Oracles? An Empirical Study with an Unbiased Dataset",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a278/573300a278.pdf",
							"extraLocations": [],
							"authorNames": "Davide Molinelli (Universit\u00E0 della Svizzera italiana, Switzerland), Luca Di Grazia (Universit\u00E0 della Svizzera italiana, Switzerland), Alberto Martin-Lopez (Universit\u00E0 della Svizzera italiana, Switzerland), Michael D. Ernst (University of Washington, USA), Mauro Pezz\u00E8 (Universit\u00E0 della Svizzera italiana, Switzerland)",
							"abstract": "Generation of thorough test oracles is an open problem. Popular test case generators, like EvoSuite and Randoop, rely on implicit, rule-based, and regression oracles that miss failures that depend on the semantics of the program under test. Formal specifications can yield test oracles but are expensive to create. Large Language Models (LLMs) have the potential to overcome these limitations. The few studies of using LLMs to generate test oracles use modest-sized public benchmarks, such as Defects4J, that are likely to be included in the LLM training data, which threatens the validity of the results. This paper presents an empirical study of the effectiveness of LLMs in generating test oracles. Our experiments use 13,866 test oracles, from 135 Java projects, that were created after the LLMs training cut-off dates. Thus, our dataset is unbiased. In our experiments, LLMs generated oracles with average mutation score of 43%\u2014similar to the 45% score of human-designed test oracles. Our results also indicate that the test prefix and the methods called in the program under test provide sufficient information to generate good oracles, while additional code context does not bring relevant benefits. These findings provide actionable insights into using LLMs for automatic testing and highlight their current limitations in generating complex oracles.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Do LLMs Generate Useful Test Oracles? An Empirical Study with an Unbiased Dataset 1759148623483 10.1109/ASE63991.2025.00031 Davide Molinelli Universit\u00E0 della Svizzera italiana, Switzerland davide.molinelli@usi.ch Luca Di Grazia Universit\u00E0 della Svizzera italiana, Switzerland work@lucadigrazia.com Alberto Martin-Lopez Universit\u00E0 della Svizzera italiana, Switzerland amarlop@us.es Michael D. Ernst University of Washington, USA mernst@cs.washington.edu Mauro Pezz\u00E8 Universit\u00E0 della Svizzera italiana, Switzerland mauro.pezze@usi.ch software testing ai for software engineering oracle generation Generation of thorough test oracles is an open problem. Popular test case generators, like EvoSuite and Randoop, rely on implicit, rule-based, and regression oracles that miss failures that depend on the semantics of the program under test. Formal specifications can yield test oracles but are expensive to create. Large Language Models (LLMs) have the potential to overcome these limitations. The few studies of using LLMs to generate test oracles use modest-sized public benchmarks, such as Defects4J, that are likely to be included in the LLM training data, which threatens the validity of the results. This paper presents an empirical study of the effectiveness of LLMs in generating test oracles. Our experiments use 13,866 test oracles, from 135 Java projects, that were created after the LLMs training cut-off dates. Thus, our dataset is unbiased. In our experiments, LLMs generated oracles with average mutation score of 43%\u2014similar to the 45% score of human-designed test oracles. Our results also indicate that the test prefix and the methods called in the program under test provide sufficient information to generate good oracles, while additional code context does not bring relevant benefits. These findings provide actionable insights into using LLMs for automatic testing and highlight their current limitations in generating complex oracles.",
							"pageNumber": 278,
							"isPageNumberRoman": false
						},
						{
							"eid": "59mqrtkZ3lFP0LoxfQS9r1",
							"type": "authorPaper",
							"text": "Loupe: End-to-End Learning of Loop Unrolling Heuristics for Abstract Interpretation",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a291/573300a291.pdf",
							"extraLocations": [],
							"authorNames": "Maykel Mattar (Universit\u00E9 Paris-Saclay, Universit\u00E9 Bretagne Sud, France), Michele Alberti  (Universit\u00E9 Paris-Saclay, France), Valentin  Perrelle (Universit\u00E9 Paris-Saclay, France), Salah Sadou (Universit\u00E9 Bretagne Sud, France)",
							"abstract": "While static program analyzers based on abstract interpretation implement precision-improving techniques to reduce false alarms, such as loop unrolling, their computational cost requires carefully devised heuristics for selective application. Manually designing such heuristics is non-trivial and error-prone, possibly leading to state explosion. This paper presents Loupe, a novel end-to-end approach for automatically learning loop unrolling heuristics for static program analysis. Unlike previous data-driven methods, Loupe leverages Graph Neural Networks (GNNs) to learn directly from graph-based program representations. To enable supervised learning, we use the static analyzer itself to automatically label training data. We implement Loupe on top of Frama-C/EVA, an open source C static analyzer, and demonstrate that the best performing heuristic (GINE) outperforms the Frama-C/EVA built-in heuristic on real-world programs, reducing false alarms by 1.5x while improving analysis performance by 56%. Remarkably, GINE accurately predicts loop unrolling decisions made by expert Frama-C/EVA engineers, while maintaining acceptable false-positive rates. Finally, we show that Loupe can effectively learn heuristics for other static analyzers such as Mopsa.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Loupe: End-to-End Learning of Loop Unrolling Heuristics for Abstract Interpretation 1755508620810 10.1109/ASE63991.2025.00032 Maykel Mattar Universit\u00E9 Paris-Saclay, Universit\u00E9 Bretagne Sud, France maykel.mattar@cea.fr Michele Alberti Universit\u00E9 Paris-Saclay, France michele.alberti@cea.fr Valentin Perrelle Universit\u00E9 Paris-Saclay, France valentin.perrelle@cea.fr Salah Sadou Universit\u00E9 Bretagne Sud, France salah.sadou@irisa.fr automatic parametrization static program analysis machine learning graph neural networks While static program analyzers based on abstract interpretation implement precision-improving techniques to reduce false alarms, such as loop unrolling, their computational cost requires carefully devised heuristics for selective application. Manually designing such heuristics is non-trivial and error-prone, possibly leading to state explosion. This paper presents Loupe, a novel end-to-end approach for automatically learning loop unrolling heuristics for static program analysis. Unlike previous data-driven methods, Loupe leverages Graph Neural Networks (GNNs) to learn directly from graph-based program representations. To enable supervised learning, we use the static analyzer itself to automatically label training data. We implement Loupe on top of Frama-C/EVA, an open source C static analyzer, and demonstrate that the best performing heuristic (GINE) outperforms the Frama-C/EVA built-in heuristic on real-world programs, reducing false alarms by 1.5x while improving analysis performance by 56%. Remarkably, GINE accurately predicts loop unrolling decisions made by expert Frama-C/EVA engineers, while maintaining acceptable false-positive rates. Finally, we show that Loupe can effectively learn heuristics for other static analyzers such as Mopsa.",
							"pageNumber": 291,
							"isPageNumberRoman": false
						},
						{
							"eid": "6GVBRpsWnwNi85cm9pzUpm",
							"type": "authorPaper",
							"text": "Advancing Binary Code Similarity Detection via Context-Content Fusion and LLM Verification",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a304/573300a304.pdf",
							"extraLocations": [],
							"authorNames": "Chaopeng Dong (Institute of Information Engineering, China; University of Chinese Academy of Sciences, China), Jingdong Guo (Institute of Information Engineering, China; University of Chinese Academy of Sciences, China), Shouguo Yang (Zhongguancun Laboratory, China), Yi Li (Nanyang Technological University, Singapore), Dongliang Fang (Institute of Information Engineering, China; University of Chinese Academy of Sciences, China), Yang Xiao (Institute of Information Engineering, China; University of Chinese Academy of Sciences, China), Yongle Chen (Taiyuan University of Technology, China), Limin Sun (Institute of Information Engineering, China; University of Chinese Academy of Sciences, China)",
							"abstract": "Binary Code Similarity Detection (BCSD), essential for binary-code related tasks like vulnerability detection, has attracted increasing attention in recent years. However, existing methods frequently fall short of achieving both high precision and recall at scale, and their results often lack interpretability due to the neglect of function context and reliance on purely similarity-driven outputs. Our key insights are twofold: 1) Binary functions are not self-contained; they depend on other code and data beyond their content to fulfill their functionalities. 2) Large language models (LLMs) excel not only at analyzing code but also at generating reasonable explanations. Motivated by these insights, we propose a general BCSD framework, Co2FuLL. We first systematically select stable and representative code and data features, along with their corresponding dependencies on the functions, to construct the function context. Then, by fusing function context with content similarities computed by the existing BCSD approach, we substantially narrow down the search space. Ultimately, we employ LLMs with a carefully designed prompt to verify the remaining candidates and produce clear, human-readable explanations. We conduct comprehensive experiments on a large function pool under varying compilation settings and after binary stripping. The results show that Co2FuLL based on HermesSim and DeepSeek-V3 achieves 80.5% precision and 94.4% recall, improving the baseline HermesSim by 142.5% and 42.2%, respectively, providing an accurate and interpretable solution for BCSD.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Advancing Binary Code Similarity Detection via Context-Content Fusion and LLM Verification 1758850562512 10.1109/ASE63991.2025.00033 Chaopeng Dong Institute of Information Engineering, China; University of Chinese Academy of Sciences, China dongchaopeng@iie.ac.cn Jingdong Guo Institute of Information Engineering, China; University of Chinese Academy of Sciences, China guojingdong@iie.ac.cn Shouguo Yang Zhongguancun Laboratory, China yangshouguo@outlook.com Yi Li Nanyang Technological University, Singapore yi_li@ntu.edu.sg Dongliang Fang Institute of Information Engineering, China; University of Chinese Academy of Sciences, China fangdongliang@iie.ac.cn Yang Xiao Institute of Information Engineering, China; University of Chinese Academy of Sciences, China xiaoyang@iie.ac.cn Yongle Chen Taiyuan University of Technology, China chenyongle@tyut.edu.cn Limin Sun Institute of Information Engineering, China; University of Chinese Academy of Sciences, China sunlimin@iie.ac.cn vulnerability detection binary code similarity detection large language model function context Binary Code Similarity Detection (BCSD), essential for binary-code related tasks like vulnerability detection, has attracted increasing attention in recent years. However, existing methods frequently fall short of achieving both high precision and recall at scale, and their results often lack interpretability due to the neglect of function context and reliance on purely similarity-driven outputs. Our key insights are twofold: 1) Binary functions are not self-contained; they depend on other code and data beyond their content to fulfill their functionalities. 2) Large language models (LLMs) excel not only at analyzing code but also at generating reasonable explanations. Motivated by these insights, we propose a general BCSD framework, Co2FuLL. We first systematically select stable and representative code and data features, along with their corresponding dependencies on the functions, to construct the function context. Then, by fusing function context with content similarities computed by the existing BCSD approach, we substantially narrow down the search space. Ultimately, we employ LLMs with a carefully designed prompt to verify the remaining candidates and produce clear, human-readable explanations. We conduct comprehensive experiments on a large function pool under varying compilation settings and after binary stripping. The results show that Co2FuLL based on HermesSim and DeepSeek-V3 achieves 80.5% precision and 94.4% recall, improving the baseline HermesSim by 142.5% and 42.2%, respectively, providing an accurate and interpretable solution for BCSD.",
							"pageNumber": 304,
							"isPageNumberRoman": false
						},
						{
							"eid": "2FLzgHfxNbFXzVVF9eg4Ph",
							"type": "authorPaper",
							"text": "PrefGen: A Preference-Driven Methodology for Secure Yet Gas-Efficient Smart Contract Generation",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a317/573300a317.pdf",
							"extraLocations": [],
							"authorNames": "Zhiyuan Peng (Shanghai Jiao Tong University), Xin Yin (Zhejiang University), Zijie Zhou (China University of Petroleum, (Beijing)), Chenhao Ying (Shanghai Jiao Tong University), Chao Ni (Zhejiang University), Yuan Luo (Shanghai Jiao Tong University)",
							"abstract": "While Large Language Models (LLMs) have demonstrated remarkable progress in generating functionally correct Solidity code, they continue to face critical challenges in producing gas-efficient and secure code, which are critical requirements for real-world smart contract deployment. Although recent advances leverage Supervised Fine-Tuning (SFT) and Direct Preference Optimization (DPO) for code preference alignment, existing approaches treat functional correctness, gas optimization, and security as independent objectives, resulting in contracts that may achieve operational soundness but suffer from prohibitive execution costs or dangerous vulnerabilities. To address these limitations, we propose PrefGen, a novel framework that extends standard DPO beyond human preferences to incorporate quantifiable blockchain-specific metrics, enabling holistic multi-objective optimization specifically tailored for smart contract generation. Our framework introduces a comprehensive evaluation methodology with four complementary metrics: Pass@k (functional correctness), Compile@k (syntactic correctness), Gas@k (gas efficiency), and Secure@k (security assessment), providing rigorous multi-dimensional contract evaluation. Through extensive experimentation, we demonstrate that PrefGen significantly outperforms existing approaches across all critical dimensions, achieving 66.7% Pass@5, 58.9% Gas@5, and 62.5% Secure@5, while generating production-ready smart contracts that are functionally correct, cost-efficient, and secure.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 PrefGen: A Preference-Driven Methodology for Secure Yet Gas-Efficient Smart Contract Generation 1758037210899 10.1109/ASE63991.2025.00034 Zhiyuan Peng Shanghai Jiao Tong University pzy2000@sjtu.edu.cn Xin Yin Zhejiang University xyin@zju.edu.cn Zijie Zhou China University of Petroleum, (Beijing) zhouzijie@student.cup.edu.cn Chenhao Ying Shanghai Jiao Tong University yingchenhao@sjtu.edu.cn Chao Ni Zhejiang University chaoni@zju.edu.cn Yuan Luo Shanghai Jiao Tong University yuanluo@sjtu.edu.cn Smart Contract Generation Supervised Fine Tuning Direct Preference Optimization While Large Language Models (LLMs) have demonstrated remarkable progress in generating functionally correct Solidity code, they continue to face critical challenges in producing gas-efficient and secure code, which are critical requirements for real-world smart contract deployment. Although recent advances leverage Supervised Fine-Tuning (SFT) and Direct Preference Optimization (DPO) for code preference alignment, existing approaches treat functional correctness, gas optimization, and security as independent objectives, resulting in contracts that may achieve operational soundness but suffer from prohibitive execution costs or dangerous vulnerabilities. To address these limitations, we propose PrefGen, a novel framework that extends standard DPO beyond human preferences to incorporate quantifiable blockchain-specific metrics, enabling holistic multi-objective optimization specifically tailored for smart contract generation. Our framework introduces a comprehensive evaluation methodology with four complementary metrics: Pass@k (functional correctness), Compile@k (syntactic correctness), Gas@k (gas efficiency), and Secure@k (security assessment), providing rigorous multi-dimensional contract evaluation. Through extensive experimentation, we demonstrate that PrefGen significantly outperforms existing approaches across all critical dimensions, achieving 66.7% Pass@5, 58.9% Gas@5, and 62.5% Secure@5, while generating production-ready smart contracts that are functionally correct, cost-efficient, and secure.",
							"pageNumber": 317,
							"isPageNumberRoman": false
						},
						{
							"eid": "2sfruZvMf3JLAntysS3lVG",
							"type": "authorPaper",
							"text": "LogMoE: Lightweight Expert Mixture for Cross-System Log Anomaly Detection",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a330/573300a330.pdf",
							"extraLocations": [],
							"authorNames": "Jiaxing Qi (Beihang University, China), Zhongzhi Luan (Beihang University, China), Shaohan Huang  (Beihang University, China), Carol Fung (Concordia University, Canada), Yuchen Wang (Beihang University, China), Aibin Wang (Beihang University, China), Hongyu Zhang (Chongqing University, China), Hailong Yang (Beihang University, China), Depei Qian (Beihang University, China)",
							"abstract": "Robust anomaly detection in system logs plays a crucial role in maintaining stable and reliable software operations. However, existing methods often struggle to accommodate evolving log formats and distributional shifts across systems, as they heavily rely on large volumes of labeled data, log parsing, and predefined event templates. To address these challenges, we propose LogMoE, a scalable and parsing-free log anomaly detection framework. LogMoE utilizes labeled logs from multiple mature systems to train a set of lightweight expert models, which are integrated via a gating mechanism within a Mixture-of-Experts (MoE) architecture. This design enables LogMoE to generalize effectively to previously unseen target systems. By eliminating the need for log parsing, our approach remains robust against the heterogeneity of log formats and syntactic structures. We conduct extensive evaluations on eight log datasets under varying generalization scenarios: single-system, homogeneous-system, and heterogeneous-system. Experimental results demonstrate that LogMoE consistently achieves robust generalization, particularly under conditions with scarce labeled data in the target system. As such, LogMoE provides a scalable, parsing-free, and generalization-capable solution tailored for complex and continuously evolving software system environments, positioning it as a future-ready approach to log anomaly detection. ",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 LogMoE: Lightweight Expert Mixture for Cross-System Log Anomaly Detection 1759208355170 10.1109/ASE63991.2025.00035 Jiaxing Qi Beihang University, China jiaxingqi@buaa.edu.cn Zhongzhi Luan Beihang University, China luan.zhongzhi@buaa.edu.cn Shaohan Huang Beihang University, China huangshanhao@buaa.edu.cn Carol Fung Concordia University, Canada carol.fung@concordia.ca Yuchen Wang Beihang University, China wangyuchen21@buaa.edu.cn Aibin Wang Beihang University, China by2406132@buaa.edu.cn Hongyu Zhang Chongqing University, China hyzhang@cqu.edu.cn Hailong Yang Beihang University, China hailongyang@buaa.edu.cn Depei Qian Beihang University, China depeiq@buaa.edu.cn system logs anomaly detection software reliability Robust anomaly detection in system logs plays a crucial role in maintaining stable and reliable software operations. However, existing methods often struggle to accommodate evolving log formats and distributional shifts across systems, as they heavily rely on large volumes of labeled data, log parsing, and predefined event templates. To address these challenges, we propose LogMoE, a scalable and parsing-free log anomaly detection framework. LogMoE utilizes labeled logs from multiple mature systems to train a set of lightweight expert models, which are integrated via a gating mechanism within a Mixture-of-Experts (MoE) architecture. This design enables LogMoE to generalize effectively to previously unseen target systems. By eliminating the need for log parsing, our approach remains robust against the heterogeneity of log formats and syntactic structures. We conduct extensive evaluations on eight log datasets under varying generalization scenarios: single-system, homogeneous-system, and heterogeneous-system. Experimental results demonstrate that LogMoE consistently achieves robust generalization, particularly under conditions with scarce labeled data in the target system. As such, LogMoE provides a scalable, parsing-free, and generalization-capable solution tailored for complex and continuously evolving software system environments, positioning it as a future-ready approach to log anomaly detection.",
							"pageNumber": 330,
							"isPageNumberRoman": false
						},
						{
							"eid": "5xhOc7w4XvWZIDZaNdV88C",
							"type": "authorPaper",
							"text": "Risk Estimation in Differential Fuzzing via Extreme Value Theory",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a342/573300a342.pdf",
							"extraLocations": [],
							"authorNames": "Rafael Baez (University of Texas at El Paso), Alejandro Olivas (University of Texas at El Paso), Nathan K. Diamond (University of Texas at El Paso), Marcelo Frias (University of Texas at El Paso), Yannic Noller (Ruhr University Bochum), Saeid Tizpaz-Niari (University of Illinois Chicago)",
							"abstract": "Differential testing is a highly effective technique for automatically detecting software bugs and vulnerabilities when the specifications involve an analysis over multiple executions simultaneously. Differential fuzzing, in particular, operates as a guided randomized search, aiming to find (similar) inputs that lead to a maximum difference in software outputs or their behaviors. However, fuzzing, as a dynamic analysis, lacks any guarantees on the absence of bugs: from a differential fuzzing campaign that has observed no bugs (or a minimal difference), what is the risk of observing a bug (or a larger difference) if we run the fuzzer for one or more steps? This paper investigates the application of Extreme Value Theory (EVT) to address the risk of missing or underestimating bugs in differential fuzzing. The key observation is that differential fuzzing as a random process resembles the maximum distribution of observed differences. Hence, EVT, a branch of statistics dealing with extreme values, is an ideal framework to analyze the tail of the differential fuzzing campaign to contain the risk. We perform experiments on a set of real-world Java libraries and use differential fuzzing to find information leaks via side channels in these libraries. We first explore the feasibility of EVT for this task and the optimal hyperparameters for EVT distributions. We then compare EVT-based extrapolation against baseline statistical methods like Markov's as well as Chebyshev's inequalities, and the Bayes factor. EVT-based extrapolations outperform the baseline techniques in 14.3% of cases and tie with the baseline in 64.2% of cases. Finally, we evaluate the accuracy and performance gains of EVT-enabled differential fuzzing in real-world Java libraries, where we reported an average saving of tens of millions of bytecode executions by an early stop.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Risk Estimation in Differential Fuzzing via Extreme Value Theory 1759516962527 10.1109/ASE63991.2025.00036 Rafael Baez University of Texas at El Paso rbaez2@miners.utep.edu Alejandro Olivas University of Texas at El Paso aolivas23@miners.utep.edu Nathan K. Diamond University of Texas at El Paso nkdiamond@miners.utep.edu Marcelo Frias University of Texas at El Paso mfrias4@utep.edu Yannic Noller Ruhr University Bochum yannic.noller@acm.org Saeid Tizpaz-Niari University of Illinois Chicago saeid@uic.edu differential testing and fuzzing statistical guarantee extreme value theory Differential testing is a highly effective technique for automatically detecting software bugs and vulnerabilities when the specifications involve an analysis over multiple executions simultaneously. Differential fuzzing, in particular, operates as a guided randomized search, aiming to find (similar) inputs that lead to a maximum difference in software outputs or their behaviors. However, fuzzing, as a dynamic analysis, lacks any guarantees on the absence of bugs: from a differential fuzzing campaign that has observed no bugs (or a minimal difference), what is the risk of observing a bug (or a larger difference) if we run the fuzzer for one or more steps? This paper investigates the application of Extreme Value Theory (EVT) to address the risk of missing or underestimating bugs in differential fuzzing. The key observation is that differential fuzzing as a random process resembles the maximum distribution of observed differences. Hence, EVT, a branch of statistics dealing with extreme values, is an ideal framework to analyze the tail of the differential fuzzing campaign to contain the risk. We perform experiments on a set of real-world Java libraries and use differential fuzzing to find information leaks via side channels in these libraries. We first explore the feasibility of EVT for this task and the optimal hyperparameters for EVT distributions. We then compare EVT-based extrapolation against baseline statistical methods like Markov's as well as Chebyshev's inequalities, and the Bayes factor. EVT-based extrapolations outperform the baseline techniques in 14.3% of cases and tie with the baseline in 64.2% of cases. Finally, we evaluate the accuracy and performance gains of EVT-enabled differential fuzzing in real-world Java libraries, where we reported an average saving of tens of millions of bytecode executions by an early stop.",
							"pageNumber": 342,
							"isPageNumberRoman": false
						},
						{
							"eid": "7J03yMKNIHrxrdTi5s0O0c",
							"type": "authorPaper",
							"text": "Enhancing LLMs with Staged Grouping and Dehallucination for Header File Decomposition",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a355/573300a355.pdf",
							"extraLocations": [],
							"authorNames": "Yue Wang (Peking University, China), Jiaxuan Sun (Peking University, China), Yanzhen Zou (Peking University, China), Bing Xie (Peking University, China)",
							"abstract": "God Header Files, large header files included by numerous other code files, present significant challenges for code comprehension and maintenance. Existing approaches leverage various code similarity metrics to decompose them, but these metrics do not always capture the code's functional essence accurately. Large Language Models (LLMs), with their advanced capabilities in code understanding and generation, offer a promising alternative for producing more effective refactorings. However, LLMs face three critical limitations that hinder practical application: they struggle with lengthy header files due to token constraints, suffer from hallucination by generating incomplete or spurious results, and produce cyclic dependencies that violate architectural principles and cause compilation failures. To address these challenges, we propose HFDecomposer, a hybrid approach that enhances LLMs with staged grouping and dehallucination techniques to effectively decompose header files. Our approach introduces a two-stage grouping framework for lengthy header files: it first groups strongly related code entities using traditional similarity metrics, then feeds group summaries to the LLM for higher-level semantic aggregation. To mitigate LLM hallucinations, we enhance prompts with factual knowledge extracted from static analysis, detect errors in LLM output, and make necessary corrections by reassigning missing entities and resolving cyclic dependencies. Our evaluation on real-world header file decomposition refactorings demonstrates that our method effectively overcomes the limitations of purely LLM-based techniques and outperforms the traditional state-of-the-art approach by 11%, delivering more accurate and reliable decomposition results. Our approach enables LLMs to handle lengthy header files efficiently, significantly reduces hallucinations, and ensures the reliability and practicality of the final decomposition.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Enhancing LLMs with Staged Grouping and Dehallucination for Header File Decomposition 1759494078354 10.1109/ASE63991.2025.00037 Yue Wang Peking University, China wangyue0502@pku.edu.cn Jiaxuan Sun Peking University, China mandala@stu.pku.edu.cn Yanzhen Zou Peking University, China zouyz@pku.edu.cn Bing Xie Peking University, China xiebing@pku.edu.cn software maintenance code refactoring header file God Header Files, large header files included by numerous other code files, present significant challenges for code comprehension and maintenance. Existing approaches leverage various code similarity metrics to decompose them, but these metrics do not always capture the code's functional essence accurately. Large Language Models (LLMs), with their advanced capabilities in code understanding and generation, offer a promising alternative for producing more effective refactorings. However, LLMs face three critical limitations that hinder practical application: they struggle with lengthy header files due to token constraints, suffer from hallucination by generating incomplete or spurious results, and produce cyclic dependencies that violate architectural principles and cause compilation failures. To address these challenges, we propose HFDecomposer, a hybrid approach that enhances LLMs with staged grouping and dehallucination techniques to effectively decompose header files. Our approach introduces a two-stage grouping framework for lengthy header files: it first groups strongly related code entities using traditional similarity metrics, then feeds group summaries to the LLM for higher-level semantic aggregation. To mitigate LLM hallucinations, we enhance prompts with factual knowledge extracted from static analysis, detect errors in LLM output, and make necessary corrections by reassigning missing entities and resolving cyclic dependencies. Our evaluation on real-world header file decomposition refactorings demonstrates that our method effectively overcomes the limitations of purely LLM-based techniques and outperforms the traditional state-of-the-art approach by 11%, delivering more accurate and reliable decomposition results. Our approach enables LLMs to handle lengthy header files efficiently, significantly reduces hallucinations, and ensures the reliability and practicality of the final decomposition.",
							"pageNumber": 355,
							"isPageNumberRoman": false
						},
						{
							"eid": "PTEl4oiVlUHWtMdvfCbMH",
							"type": "authorPaper",
							"text": "Automated Repair of Ambiguous Problem Descriptions for LLM-Based Code Generation",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a367/573300a367.pdf",
							"extraLocations": [],
							"authorNames": "Haoxiang Jia (Peking University, China), Robbie Morris (University College London, United Kingdom), He Ye (University College London, United Kingdom), Federica  Sarro (University College London, United Kingdom), Sergey Mechtaev (Peking University, China)",
							"abstract": "The growing use of large language models (LLMs) has increased the importance of natural language (NL) in software engineering. However, ambiguity of NL can harm software quality, as unclear problem descriptions may lead to incorrect program generation. Detecting and resolving such ambiguity is challenging, motivating our introduction of the automated repair of ambiguous NL descriptions, which we approach by reducing code generation uncertainty and better aligning NL with input\u2013output examples. Ambiguity repair is difficult for LLMs because they must understand how their interpretation of a description changes when the text is altered. We find that directly prompting LLMs to clarify ambiguity often produces irrelevant or inconsistent edits. To address this, we decompose this task into two simpler steps: (1) analyzing and repairing the LLM's interpretation of the description\u2014captured by the distribution of programs it induces\u2014using traditional testing and program repair, and (2) refining the description based on distribution changes via a method we call contrastive specification inference. We implement this approach in a tool called SpecFix and evaluate it using four state-of-the-art LLMs (GPT-4o, GPT-4o-mini, DeepSeek-V3, and Qwen2.5-Coder-32B-Instruct) on three popular code generation benchmarks (HumanEval+, MBPP+ and LiveCodeBench). Without human intervention or external information, SpecFix modified 43.58% of descriptions, improving Pass@1 on the modified set by 30.9%. This yields a 4.09% absolute improvement across the entire benchmark. Repairs also transfer across models: descriptions repaired for one model improve other models' performance by 10.48%.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Automated Repair of Ambiguous Problem Descriptions for LLM-Based Code Generation 1759410178253 10.1109/ASE63991.2025.00038 Haoxiang Jia Peking University, China haoxiangjia@stu.pku.edu.cn Robbie Morris University College London, United Kingdom robbie.morris.22@ucl.ac.uk He Ye University College London, United Kingdom he.ye@ucl.ac.uk Federica Sarro University College London, United Kingdom f.sarro@ucl.ac.uk Sergey Mechtaev Peking University, China mechtaev@pku.edu.cn ambiguous problem description automated repair code generation large language model The growing use of large language models (LLMs) has increased the importance of natural language (NL) in software engineering. However, ambiguity of NL can harm software quality, as unclear problem descriptions may lead to incorrect program generation. Detecting and resolving such ambiguity is challenging, motivating our introduction of the automated repair of ambiguous NL descriptions, which we approach by reducing code generation uncertainty and better aligning NL with input\u2013output examples. Ambiguity repair is difficult for LLMs because they must understand how their interpretation of a description changes when the text is altered. We find that directly prompting LLMs to clarify ambiguity often produces irrelevant or inconsistent edits. To address this, we decompose this task into two simpler steps: (1) analyzing and repairing the LLM's interpretation of the description\u2014captured by the distribution of programs it induces\u2014using traditional testing and program repair, and (2) refining the description based on distribution changes via a method we call contrastive specification inference. We implement this approach in a tool called SpecFix and evaluate it using four state-of-the-art LLMs (GPT-4o, GPT-4o-mini, DeepSeek-V3, and Qwen2.5-Coder-32B-Instruct) on three popular code generation benchmarks (HumanEval+, MBPP+ and LiveCodeBench). Without human intervention or external information, SpecFix modified 43.58% of descriptions, improving Pass@1 on the modified set by 30.9%. This yields a 4.09% absolute improvement across the entire benchmark. Repairs also transfer across models: descriptions repaired for one model improve other models' performance by 10.48%.",
							"pageNumber": 367,
							"isPageNumberRoman": false
						},
						{
							"eid": "3VdHkUX92edv9i2nfN89ol",
							"type": "authorPaper",
							"text": "Towards More Accurate Static Analysis for Taint-Style Bug Detection in Linux Kernel",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a380/573300a380.pdf",
							"extraLocations": [],
							"authorNames": "Haonan Li (University of California, USA), Hang Zhang (Indiana University Bloomington, USA), Kexin Pei (The University of Chicago, USA), Zhiyun Qian (University of California, USA)",
							"abstract": "Static analysis plays a crucial role in software vulnerability detection, yet faces a persistent precision-scalability tradeoff. In large codebases like the Linux kernel, traditional static analysis tools often generate excessive false positives due to simplified vulnerability modeling and over-approximation of path and data constraints. While large language models (LLMs) demonstrate promising code understanding capabilities, their direct application to program analysis remains unreliable due to inherent reasoning limitations. We introduce BugLens, a post-refinement framework that significantly enhances static analysis precision for bug detection. BugLens guides LLMs through structured reasoning steps to assess security impact and validate constraints from the source code. When evaluated on Linux kernel taint-style bugs detected by static analysis tools, BugLens improves precision approximately 7-fold (from 0.10 to 0.72), substantially reducing false positives while uncovering four previously unreported vulnerabilities. Our results demonstrate that a well-structured, fully automated LLM-based workflow can effectively complement and enhance traditional static analysis techniques",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Towards More Accurate Static Analysis for Taint-Style Bug Detection in Linux Kernel 1756088934414 10.1109/ASE63991.2025.00039 Haonan Li University of California, USA hli333@ucr.edu Hang Zhang Indiana University Bloomington, USA hz64@iu.edu Kexin Pei The University of Chicago, USA kpei@cs.uchicago.edu Zhiyun Qian University of California, USA zhiyunq@ucr.edu static analysis bug detection large language models Static analysis plays a crucial role in software vulnerability detection, yet faces a persistent precision-scalability tradeoff. In large codebases like the Linux kernel, traditional static analysis tools often generate excessive false positives due to simplified vulnerability modeling and over-approximation of path and data constraints. While large language models (LLMs) demonstrate promising code understanding capabilities, their direct application to program analysis remains unreliable due to inherent reasoning limitations. We introduce BugLens, a post-refinement framework that significantly enhances static analysis precision for bug detection. BugLens guides LLMs through structured reasoning steps to assess security impact and validate constraints from the source code. When evaluated on Linux kernel taint-style bugs detected by static analysis tools, BugLens improves precision approximately 7-fold (from 0.10 to 0.72), substantially reducing false positives while uncovering four previously unreported vulnerabilities. Our results demonstrate that a well-structured, fully automated LLM-based workflow can effectively complement and enhance traditional static analysis techniques",
							"pageNumber": 380,
							"isPageNumberRoman": false
						},
						{
							"eid": "5mK5mBmvzbMJTX8azWaDNz",
							"type": "authorPaper",
							"text": "Democratizing the Cryptocurrency Ecosystem by Just-In-Time Transformation of Mining Programs",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a393/573300a393.pdf",
							"extraLocations": [],
							"authorNames": "Wei Liu (Tsinghua University, China), Zhenhua Li (Tsinghua University, China), Feng Qian (University of Southern California, USA), Feiyu Jin (Tsinghua University, China), Hao Lin (Tsinghua University, China), Yannan Zheng (Ant Group, China), Bo Xiao (Ant Group, China), Xiaokang Qin (Ant Group, China), Tianyin Xu (University of Illinois Urbana-Champaign, USA)",
							"abstract": "Democracy is crucial to a cryptocurrency ecosystem, as the diversity of miners (farms, personal computers, web clients, or even cloud functions) underlays the credibility of the cryptocurrency. Among miners, web clients used to be the vast majority, e.g., 50M+ as of March 2018. As time went on, however, cryptomining was gradually monopolized by mining farms with dedicated hardware (e.g., ASICs), and web clients scaled down to ~0.1M. To suppress mining farms, certain cryptocurrencies (like Monero) adopted new mining algorithms such as RandomX whose execution relies on general-purpose hardware architectures. Unfortunately, this further impairs web-based cryptomining as web clients cannot provide the desired architecture support to these algorithms. This paper explores how to revive software democracy of efficient web-based cryptomining, using a novel program transformation technique termed Vectra. Vectra employs just-in-time (JIT) transformations of mining programs for web architectures; it effectively identifies and merges isomorphic instructions upon execution. Vectra ensures correct transformations based on symbolic constraints of the instructions. Real-world deployments show that Vectra reduces WASM instructions by about 7\u00D7 and achieves a 3\u00D7\u201316\u00D7 speedup for web cryptomining in diverse execution environments like PCs, mobile phones, and serverless platforms, which translates to a high (69%\u2013274%) return-on-investment (ROI) for common users.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Democratizing the Cryptocurrency Ecosystem by Just-In-Time Transformation of Mining Programs 1759338792599 10.1109/ASE63991.2025.00040 Wei Liu Tsinghua University, China liuwei199803@gmail.com Zhenhua Li Tsinghua University, China lizhenhua1983@gmail.com Feng Qian University of Southern California, USA fengqian@usc.edu Feiyu Jin Tsinghua University, China fy-jin@tsinghua.edu.cn Hao Lin Tsinghua University, China linhaomails@gmail.com Yannan Zheng Ant Group, China zhengyannan.zyn@antgroup.com Bo Xiao Ant Group, China xiaobo.xiao@antgroup.com Xiaokang Qin Ant Group, China xiaokang.qxk@antgroup.com Tianyin Xu University of Illinois Urbana-Champaign, USA tyxu@illinois.edu cryptocurrency ecosystem web cryptomining serverless computing just-in-time program transformation Democracy is crucial to a cryptocurrency ecosystem, as the diversity of miners (farms, personal computers, web clients, or even cloud functions) underlays the credibility of the cryptocurrency. Among miners, web clients used to be the vast majority, e.g., 50M+ as of March 2018. As time went on, however, cryptomining was gradually monopolized by mining farms with dedicated hardware (e.g., ASICs), and web clients scaled down to ~0.1M. To suppress mining farms, certain cryptocurrencies (like Monero) adopted new mining algorithms such as RandomX whose execution relies on general-purpose hardware architectures. Unfortunately, this further impairs web-based cryptomining as web clients cannot provide the desired architecture support to these algorithms. This paper explores how to revive software democracy of efficient web-based cryptomining, using a novel program transformation technique termed Vectra. Vectra employs just-in-time (JIT) transformations of mining programs for web architectures; it effectively identifies and merges isomorphic instructions upon execution. Vectra ensures correct transformations based on symbolic constraints of the instructions. Real-world deployments show that Vectra reduces WASM instructions by about 7\u00D7 and achieves a 3\u00D7\u201316\u00D7 speedup for web cryptomining in diverse execution environments like PCs, mobile phones, and serverless platforms, which translates to a high (69%\u2013274%) return-on-investment (ROI) for common users.",
							"pageNumber": 393,
							"isPageNumberRoman": false
						},
						{
							"eid": "4wzZFF5xspyQfV8jPhKqbV",
							"type": "authorPaper",
							"text": "From Sparse to Structured: A Diffusion-Enhanced and Feature-Aligned Framework for Coincidental Correctness Detection",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a406/573300a406.pdf",
							"extraLocations": [],
							"authorNames": "Huan Xie (Chongqing University, China), Chunyan Liu (Chongqing University, China), Yan Lei (Chongqing University, China), Zhenyu Wu (Chongqing University, China), Jinping Wang  (Chongqing University, China)",
							"abstract": "Coincidental correctness (CC) refers to test cases that execute faulty code but still produce excepted outputs. This phenomenon introduces noise into the data of software testing-related tasks. As demonstrated in the literature, CC has negative impact on test suite reduction, test case prioritization, fault localization, and automated program repair. Thus, it is essential to detect and mitigate the impact of CC. Although CC is commonly observed across a large number of programs, CC test cases are typically sparse within each program's test suite. In other words, CC test cases generally make up merely a small portion of the passing test cases. The proportions vary from 3.27% to 31.74% within Defects4J V1.4. This results in a highly imbalanced distribution of CC versus non-CC test cases, posing challenges for accurate detection. To address this issue, we propose a Diffusion-Enhanced and Feature-Aligned Framework for Coincidental Correctness detection, named DEFACC, to obtain more structured representations of test cases. Specifically, DEFACC first introduces a diffusionbased generation module. This module generates new CC samples from original samples to alleviate class imbalance issue and enhance the diversity of CC samples. However, generated feature samples may deviate from the distribution of real CC samples. Such shifts can hurt model reliability and generalization. To resolve this, DEFACC integrates a feature alignment module that is founded on the Maximum Mean Discrepancy (MMD) loss. This module enforces distributional consistency between generated and original CC samples during training. Together, these components ensure that the augmented samples are from sparse to structured, which is not only quantitatively balanced but also semantically faithful. Experimental results show that the DEFACC significantly improves the performance of existing CC detection methods and provides a stronger representation foundation for accurate fault localization.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 From Sparse to Structured: A Diffusion-Enhanced and Feature-Aligned Framework for Coincidental Correctness Detection 1759125993290 10.1109/ASE63991.2025.00041 Huan Xie Chongqing University, China huanxie@cqu.edu.cn Chunyan Liu Chongqing University, China chunyanliu@cqu.edu.cn Yan Lei Chongqing University, China yanlei@cqu.edu.cn Zhenyu Wu Chongqing University, China zhenyu_wu@stu.cqu.edu.cn Jinping Wang Chongqing University, China jpwang@stu.cqu.edu.cn coincidental correctness detection data imbalance fault localization diffusion model feature alignment Coincidental correctness (CC) refers to test cases that execute faulty code but still produce excepted outputs. This phenomenon introduces noise into the data of software testing-related tasks. As demonstrated in the literature, CC has negative impact on test suite reduction, test case prioritization, fault localization, and automated program repair. Thus, it is essential to detect and mitigate the impact of CC. Although CC is commonly observed across a large number of programs, CC test cases are typically sparse within each program's test suite. In other words, CC test cases generally make up merely a small portion of the passing test cases. The proportions vary from 3.27% to 31.74% within Defects4J V1.4. This results in a highly imbalanced distribution of CC versus non-CC test cases, posing challenges for accurate detection. To address this issue, we propose a Diffusion-Enhanced and Feature-Aligned Framework for Coincidental Correctness detection, named DEFACC, to obtain more structured representations of test cases. Specifically, DEFACC first introduces a diffusionbased generation module. This module generates new CC samples from original samples to alleviate class imbalance issue and enhance the diversity of CC samples. However, generated feature samples may deviate from the distribution of real CC samples. Such shifts can hurt model reliability and generalization. To resolve this, DEFACC integrates a feature alignment module that is founded on the Maximum Mean Discrepancy (MMD) loss. This module enforces distributional consistency between generated and original CC samples during training. Together, these components ensure that the augmented samples are from sparse to structured, which is not only quantitatively balanced but also semantically faithful. Experimental results show that the DEFACC significantly improves the performance of existing CC detection methods and provides a stronger representation foundation for accurate fault localization.",
							"pageNumber": 406,
							"isPageNumberRoman": false
						},
						{
							"eid": "SYPmaj84iWiKmxz0sPjE8",
							"type": "authorPaper",
							"text": "ProfMal: Detecting Malicious NPM Packages by the Synergy between Static and Dynamic Analysis",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a419/573300a419.pdf",
							"extraLocations": [],
							"authorNames": "Yiheng Huang (Fudan University, China), Wen Zheng (Fudan University, China), Susheng Wu (Fudan University, China), Bihuan Chen (Fudan University, China), You Lu (Fudan University, China), Zhuotong Zhou (Fudan University, China), Yiheng Cao (Fudan University, China), Xiaoyu Li (Fudan University, China), Xin Peng (Fudan University, China)",
							"abstract": "Open source software (OSS) has become the foundation of modern applications, but its transitive dependencies make it especially vulnerable to supply chain attacks. One common tactic is to inject malicious code into third-party packages. NPM, in particular, due to its widespread use and large volume of packages, has become the popular target of malicious code injection. While various detectors have been proposed, they suffer three limitations, i.e., inadequate behavior modeling of obfuscated code, ignoring object-centric features of JavaScript, and lack of synergy between static and dynamic analysis. These limitations lead to imprecise modeling of program behavior and hinder detection effectiveness. To address these limitations, we propose ProfMal to identify malicious NPM packages, which leverages the synergy between static and dynamic analysis to construct behavior graphs for each package. Specifically, our static analysis constructs the behavior graphs through object-sensitive analysis, while identifying sensitive API calls and locating statically unresolved calls. Our dynamic analysis augments the behavior graphs by resolving those statically unresolved calls. Based on these comprehensive behavior graphs, we train a graph-based classifier to identify maliciousness. Our evaluation has indicated that ProfMal achieves the highest F1-score of 92.4%, outperforming the state-of-the-arts by 6.2% to 48.8%. During a three-month real-world detection, ProfMal has detected 496 previously unknown malicious NPM packages, and all of them have been confirmed and removed from NPM.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 ProfMal: Detecting Malicious NPM Packages by the Synergy between Static and Dynamic Analysis 1756222948048 10.1109/ASE63991.2025.00042 Yiheng Huang Fudan University, China yihenghuang23@m.fudan.edu.cn Wen Zheng Fudan University, China 22307130492@m.fudan.edu.cn Susheng Wu Fudan University, China scwu24@m.fudan.edu.cn Bihuan Chen Fudan University, China bhchen@fudan.edu.cn You Lu Fudan University, China ylu24@m.fudan.edu.cn Zhuotong Zhou Fudan University, China zhouzt23@m.fudan.edu.cn Yiheng Cao Fudan University, China caoyh23@m.fudan.edu.cn Xiaoyu Li Fudan University, China 24210240214@m.fudan.edu.cn Xin Peng Fudan University, China pengxin@fudan.edu.cn Open source software (OSS) has become the foundation of modern applications, but its transitive dependencies make it especially vulnerable to supply chain attacks. One common tactic is to inject malicious code into third-party packages. NPM, in particular, due to its widespread use and large volume of packages, has become the popular target of malicious code injection. While various detectors have been proposed, they suffer three limitations, i.e., inadequate behavior modeling of obfuscated code, ignoring object-centric features of JavaScript, and lack of synergy between static and dynamic analysis. These limitations lead to imprecise modeling of program behavior and hinder detection effectiveness. To address these limitations, we propose ProfMal to identify malicious NPM packages, which leverages the synergy between static and dynamic analysis to construct behavior graphs for each package. Specifically, our static analysis constructs the behavior graphs through object-sensitive analysis, while identifying sensitive API calls and locating statically unresolved calls. Our dynamic analysis augments the behavior graphs by resolving those statically unresolved calls. Based on these comprehensive behavior graphs, we train a graph-based classifier to identify maliciousness. Our evaluation has indicated that ProfMal achieves the highest F1-score of 92.4%, outperforming the state-of-the-arts by 6.2% to 48.8%. During a three-month real-world detection, ProfMal has detected 496 previously unknown malicious NPM packages, and all of them have been confirmed and removed from NPM.",
							"pageNumber": 419,
							"isPageNumberRoman": false
						},
						{
							"eid": "6fURj4x01OI7bB4sD5GaTh",
							"type": "authorPaper",
							"text": "Why AI Agents Still Need You: Findings from Developer-Agent Collaborations in the Wild",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a432/573300a432.pdf",
							"extraLocations": [],
							"authorNames": "Aayush Kumar (Microsoft, India), Yasharth Bajpai (Microsoft, India), Sumit Gulwani (Microsoft, USA), Gustavo Soares (Microsoft, USA), Emerson Murphy-Hill (Microsoft, USA)",
							"abstract": "Software Engineering Agents (SWE agents) can autonomously perform development tasks on benchmarks like SWE Bench, but still face challenges when tackling complex and ambiguous real-world tasks. Consequently, SWE agents are often designed to allow interactivity with developers, enabling collaborative problem-solving. To understand how developers collaborate with SWE agents and the barriers they face in such interactions, we observed 19 developers using an in-IDE agent to resolve 33 open issues in repositories to which they had previously contributed. Participants successfully resolved about half of these issues, with those solving issues incrementally having greater success than those using a one-shot approach. Participants who actively collaborated with the agent and iterated on its outputs were also more successful, though they faced challenges in trusting the agent\u2019s responses and collaborating on debugging and testing. Our findings suggest that to facilitate successful collaborations, both SWE agents and developers should actively contribute to tasks throughout all stages of the software development process. SWE agents can enable this by challenging and engaging in discussions with developers, rather than being conclusive or sycophantic.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Why AI Agents Still Need You: Findings from Developer-Agent Collaborations in the Wild 1759527269377 10.1109/ASE63991.2025.00043 Aayush Kumar Microsoft, India t-aaykumar@microsoft.com Yasharth Bajpai Microsoft, India ybajpai@microsoft.com Sumit Gulwani Microsoft, USA sumitg@microsoft.com Gustavo Soares Microsoft, USA gustavo.soares@microsoft.com Emerson Murphy-Hill Microsoft, USA emerson.rex@microsoft.com agent-based systems software development tools collaboration communication developer experience Software Engineering Agents (SWE agents) can autonomously perform development tasks on benchmarks like SWE Bench, but still face challenges when tackling complex and ambiguous real-world tasks. Consequently, SWE agents are often designed to allow interactivity with developers, enabling collaborative problem-solving. To understand how developers collaborate with SWE agents and the barriers they face in such interactions, we observed 19 developers using an in-IDE agent to resolve 33 open issues in repositories to which they had previously contributed. Participants successfully resolved about half of these issues, with those solving issues incrementally having greater success than those using a one-shot approach. Participants who actively collaborated with the agent and iterated on its outputs were also more successful, though they faced challenges in trusting the agent\u2019s responses and collaborating on debugging and testing. Our findings suggest that to facilitate successful collaborations, both SWE agents and developers should actively contribute to tasks throughout all stages of the software development process. SWE agents can enable this by challenging and engaging in discussions with developers, rather than being conclusive or sycophantic.",
							"pageNumber": 432,
							"isPageNumberRoman": false
						},
						{
							"eid": "4zaOW4Jt0MjEjYXPPJtGRN",
							"type": "authorPaper",
							"text": "TensorGuard: Gradient-Based Model Fingerprinting for LLM Similarity Detection and Family Classification",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a445/573300a445.pdf",
							"extraLocations": [],
							"authorNames": "Zehao Wu (Huazhong University of Science and Technology, China), Yanjie Zhao (Huazhong University of Science and Technology, China), Haoyu Wang (Huazhong University of Science and Technology, China)",
							"abstract": "As Large Language Models (LLMs) become integral software components in modern applications, unauthorized model derivations through fine-tuning, merging, and redistribution have emerged as critical software engineering challenges. Unlike traditional software where clone detection and license compliance are well-established, the LLM ecosystem lacks effective mechanisms to detect model lineage and enforce licensing agreements. This gap is particularly problematic when opensource model creators, such as Meta's LLaMA, require derivative works to maintain naming conventions for attribution, yet no technical means exist to verify compliance. To fill this gap, treating LLMs as software artifacts requiring provenance tracking, we present TENSORGUARD, a gradient based fingerprinting framework for LLM similarity detection and family classification. Our approach extracts model-intrinsic behavioral signatures by analyzing gradient responses to random input perturbations across tensor layers, operating independently of training data, watermarks, or specific model formats. TENSORGUARD supports the widely-adopted safetensors format and constructs high-dimensional fingerprints through statistical analysis of gradient features. These fingerprints enable two complementary capabilities: direct pairwise similarity assessment between arbitrary models through distance computation, and systematic family classification of unknown models via the K-Means clustering algorithm with domain-informed centroid initialization using known base models. Experimental evaluation on 58 models comprising 8 base models and 50 derivatives across five model families (Llama, Qwen, Gemma, Phi, Mistral) demonstrates 94% classification accuracy under our centroid initialized K-Means clustering. Our work establishes a new paradigm for model similarity detection, bridging traditional software engineering practices with modern LLM distribution and compliance challenges.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 TensorGuard: Gradient-Based Model Fingerprinting for LLM Similarity Detection and Family Classification 1759394275146 10.1109/ASE63991.2025.00044 Zehao Wu Huazhong University of Science and Technology, China wuzehao195@hust.edu.cn Yanjie Zhao Huazhong University of Science and Technology, China yanjie_zhao@hust.edu.cn Haoyu Wang Huazhong University of Science and Technology, China haoyuwang@hust.edu.cn large language models model fingerprinting model similarity detection model family classification As Large Language Models (LLMs) become integral software components in modern applications, unauthorized model derivations through fine-tuning, merging, and redistribution have emerged as critical software engineering challenges. Unlike traditional software where clone detection and license compliance are well-established, the LLM ecosystem lacks effective mechanisms to detect model lineage and enforce licensing agreements. This gap is particularly problematic when opensource model creators, such as Meta's LLaMA, require derivative works to maintain naming conventions for attribution, yet no technical means exist to verify compliance. To fill this gap, treating LLMs as software artifacts requiring provenance tracking, we present TENSORGUARD, a gradient based fingerprinting framework for LLM similarity detection and family classification. Our approach extracts model-intrinsic behavioral signatures by analyzing gradient responses to random input perturbations across tensor layers, operating independently of training data, watermarks, or specific model formats. TENSORGUARD supports the widely-adopted safetensors format and constructs high-dimensional fingerprints through statistical analysis of gradient features. These fingerprints enable two complementary capabilities: direct pairwise similarity assessment between arbitrary models through distance computation, and systematic family classification of unknown models via the K-Means clustering algorithm with domain-informed centroid initialization using known base models. Experimental evaluation on 58 models comprising 8 base models and 50 derivatives across five model families (Llama, Qwen, Gemma, Phi, Mistral) demonstrates 94% classification accuracy under our centroid initialized K-Means clustering. Our work establishes a new paradigm for model similarity detection, bridging traditional software engineering practices with modern LLM distribution and compliance challenges.",
							"pageNumber": 445,
							"isPageNumberRoman": false
						},
						{
							"eid": "5rWy6XcZyYxOa3xf1oyKHH",
							"type": "authorPaper",
							"text": "Uncovering Prompt Elements: Cloning System Prompts from Behavioral Traces",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a457/573300a457.pdf",
							"extraLocations": [],
							"authorNames": "Yi Qian (Nanjing University, China), Fei Peng (Nanjing University, China), Hao Wu (Nanjing University, China), Ligeng Chen (Hornor Device Co., Ltd. China), Bing Mao (Nanjing University, China)",
							"abstract": "We introduce prompt cloning, a new black-box attack that reconstructs functionally equivalent system prompts rather than extracts original system prompts. Unlike prompt stealing, prompt cloning exploits the insight that system prompts leave persistent behavioral traces in outputs, even under strong alignment and prompt-level defenses. Our method decomposes system behavior into semantically interpretable elements, selectively elicits them through carefully designed queries, and aggregates representative traces to synthesize high-fidelity cloned prompts. Extensive evaluations show that cloned prompts replicate functional behavior with up to 85% semantic similarity, outperforming base LLMs by up to 8%, and even exceeding original system prompts when transferred to different back-end models. We also conduct a large-scale study on GitHub repositories, revealing that single-prompt architectures remain widespread in open-source LLM applications, reinforcing the real-world relevance of our threat model. Our findings reveal that prompt cloning enables unauthorized replication of confidential LLM behavior and underscore the urgent need for defenses that go beyond hiding prompt text.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Uncovering Prompt Elements: Cloning System Prompts from Behavioral Traces 1759419907050 10.1109/ASE63991.2025.00045 Yi Qian Nanjing University, China yi_qian@smail.nju.edu.cn Fei Peng Nanjing University, China luanruy5@gmail.com Hao Wu Nanjing University, China hao.wu@nju.edu.cn Ligeng Chen Hornor Device Co., Ltd. China chenlg@smail.nju.edu.cn Bing Mao Nanjing University, China maobing@nju.edu.cn n/a We introduce prompt cloning, a new black-box attack that reconstructs functionally equivalent system prompts rather than extracts original system prompts. Unlike prompt stealing, prompt cloning exploits the insight that system prompts leave persistent behavioral traces in outputs, even under strong alignment and prompt-level defenses. Our method decomposes system behavior into semantically interpretable elements, selectively elicits them through carefully designed queries, and aggregates representative traces to synthesize high-fidelity cloned prompts. Extensive evaluations show that cloned prompts replicate functional behavior with up to 85% semantic similarity, outperforming base LLMs by up to 8%, and even exceeding original system prompts when transferred to different back-end models. We also conduct a large-scale study on GitHub repositories, revealing that single-prompt architectures remain widespread in open-source LLM applications, reinforcing the real-world relevance of our threat model. Our findings reveal that prompt cloning enables unauthorized replication of confidential LLM behavior and underscore the urgent need for defenses that go beyond hiding prompt text.",
							"pageNumber": 457,
							"isPageNumberRoman": false
						},
						{
							"eid": "7GRTiSJIyHcrzG9IyuZNE2",
							"type": "authorPaper",
							"text": "Comprehend, Imitate, and then Update: Unleashing the Power of LLMs in Test Suite Evolution",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a469/573300a469.pdf",
							"extraLocations": [],
							"authorNames": "Tangzhi Xu (Nanjing University, China), Jianhan Liu (Nanjing University, China), Yuan Yao (Nanjing University, China), Cong Li (ETH Zurich, Switzerland), Feng Xu (Nanjing University, China), Xiaoxing Ma (Nanjing University, China)",
							"abstract": "Software testing plays a crucial role in software engineering, ensuring the reliability and correctness of evolving systems. Well-maintained test suites are essential for ensuring software quality. However, in modern development cycles that emphasize rapid feature iteration, the co-evolution of test suites often lags behind, leading to more appearance of obsolete tests. To this end, automated approaches for updating obsolete test code have been proposed, and recent approaches have achieved the state-of-the-art performance with the support of large language models (LLMs). This paper presents CommitUp, a new approach that leverages LLMs to effectively automate method-level obsolete test code updates. CommitUp mimics how humans solve the problem, first comprehending the code modifications, searching for similar examples to imitate, and finally performing the update. We evaluate CommitUp on a curated dataset from real-world Java projects. The results demonstrate the superior performance of CommitUp, achieving 96.4%, 94.4%, 93.1% success rates for generating compilable, runtime failure-free, and full coverage updates, respectively. We believe our study can provide new insight into LLM-based test code update. The dataset and code are available at https://github.com/SoftWiser-group/CommitUp.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Comprehend, Imitate, and then Update: Unleashing the Power of LLMs in Test Suite Evolution 1758869489701 10.1109/ASE63991.2025.00046 Tangzhi Xu Nanjing University, China xutz@smail.nju.edu.cn Jianhan Liu Nanjing University, China jh.liu@smail.nju.edu.cn Yuan Yao Nanjing University, China y.yao@nju.edu.cn Cong Li ETH Zurich, Switzerland cong.li@inf.ethz.ch Feng Xu Nanjing University, China xf@nju.edu.cn Xiaoxing Ma Nanjing University, China xxm@nju.edu.cn test suite evolution large language model software quality maintenance Software testing plays a crucial role in software engineering, ensuring the reliability and correctness of evolving systems. Well-maintained test suites are essential for ensuring software quality. However, in modern development cycles that emphasize rapid feature iteration, the co-evolution of test suites often lags behind, leading to more appearance of obsolete tests. To this end, automated approaches for updating obsolete test code have been proposed, and recent approaches have achieved the state-of-the-art performance with the support of large language models (LLMs). This paper presents CommitUp, a new approach that leverages LLMs to effectively automate method-level obsolete test code updates. CommitUp mimics how humans solve the problem, first comprehending the code modifications, searching for similar examples to imitate, and finally performing the update. We evaluate CommitUp on a curated dataset from real-world Java projects. The results demonstrate the superior performance of CommitUp, achieving 96.4%, 94.4%, 93.1% success rates for generating compilable, runtime failure-free, and full coverage updates, respectively. We believe our study can provide new insight into LLM-based test code update. The dataset and code are available at https://github.com/SoftWiser-group/CommitUp.",
							"pageNumber": 469,
							"isPageNumberRoman": false
						},
						{
							"eid": "79YVnr5boKF9T8NU6LHGKd",
							"type": "authorPaper",
							"text": "VRExplorer: A Model-Based Approach for Semi-Automated Testing of Virtual Reality Scenes",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a482/573300a482.pdf",
							"extraLocations": [],
							"authorNames": "Zhengyang Zhu (Sun Yat-sen University, China; Peng Cheng Laboratory, China), Hong-Ning Dai (Hong Kong Baptist University, China), Hanyang Guo (Sun Yat-sen University, China), Zeqin Liao (Sun Yat-sen University, China), Zibin Zheng (Sun Yat-sen University, China)",
							"abstract": "With the proliferation of Virtual Reality (VR) markets, VR applications are rapidly expanding in scale and complexity, thereby driving an urgent need for assuring VR software quality. Different from traditional mobile applications and computer software, VR testing faces unique challenges due to diverse interactions with virtual objects, complex 3D virtual environments, and intricate sequences to complete tasks. All of these emerging challenges hinder existing VR testing tools from effectively and systematically testing VR applications. In this paper, we present VRExplorer, a novel model-based testing tool to effectively interact with diverse virtual objects and explore complex VR scenes. Particularly, we design the Entity, Action, and Task (EAT) framework for modeling diverse VR interactions in a generic way. Built upon the EAT framework, we then present the VRExplorer agent, which can achieve effective scene exploration by incorporating meticulously designed path-finding algorithms into Unity's NavMesh. Moreover, the VRExplorer agent can also systematically execute interaction decisions on top of the Probabilistic Finite State Machine (PFSM). Experimental evaluation on 11 representative VR projects shows that VRExplorer consistently outperforms the state-of-the-art (SOTA) approach VRGuide by achieving significantly higher coverage and better efficiency. Specifically, VRExplorer yields up to 122.8% and 52.8% improvements over VRGuide in terms of executable lines of code (ELOC) coverage and method (function) coverage, respectively. Furthermore, ablation results also verify the essential contributions of each designed module. More importantly, our VRExplorer has successfully detected two functional bugs and one non-functional bug from real-world projects.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 VRExplorer: A Model-Based Approach for Semi-Automated Testing of Virtual Reality Scenes 1759282771138 10.1109/ASE63991.2025.00047 Zhengyang Zhu Sun Yat-sen University, China; Peng Cheng Laboratory, China zhuzhy57@mail2.sysu.edu.cn Hong-Ning Dai Hong Kong Baptist University, China hndai@ieee.org Hanyang Guo Sun Yat-sen University, China guohy36@mail2.sysu.edu.cn Zeqin Liao Sun Yat-sen University, China liaozq8@mail2.sysu.edu.cn Zibin Zheng Sun Yat-sen University, China zhzibin@mail.sysu.edu.cn software testing virtual reality model-based testing scene exploration With the proliferation of Virtual Reality (VR) markets, VR applications are rapidly expanding in scale and complexity, thereby driving an urgent need for assuring VR software quality. Different from traditional mobile applications and computer software, VR testing faces unique challenges due to diverse interactions with virtual objects, complex 3D virtual environments, and intricate sequences to complete tasks. All of these emerging challenges hinder existing VR testing tools from effectively and systematically testing VR applications. In this paper, we present VRExplorer, a novel model-based testing tool to effectively interact with diverse virtual objects and explore complex VR scenes. Particularly, we design the Entity, Action, and Task (EAT) framework for modeling diverse VR interactions in a generic way. Built upon the EAT framework, we then present the VRExplorer agent, which can achieve effective scene exploration by incorporating meticulously designed path-finding algorithms into Unity's NavMesh. Moreover, the VRExplorer agent can also systematically execute interaction decisions on top of the Probabilistic Finite State Machine (PFSM). Experimental evaluation on 11 representative VR projects shows that VRExplorer consistently outperforms the state-of-the-art (SOTA) approach VRGuide by achieving significantly higher coverage and better efficiency. Specifically, VRExplorer yields up to 122.8% and 52.8% improvements over VRGuide in terms of executable lines of code (ELOC) coverage and method (function) coverage, respectively. Furthermore, ablation results also verify the essential contributions of each designed module. More importantly, our VRExplorer has successfully detected two functional bugs and one non-functional bug from real-world projects.",
							"pageNumber": 482,
							"isPageNumberRoman": false
						},
						{
							"eid": "7ACfE0wrsmr3SqVoU3zDiE",
							"type": "authorPaper",
							"text": "RSFuzz: A Robustness-Guided Swarm Fuzzing Framework Based on Behavioral Constraints",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a495/573300a495.pdf",
							"extraLocations": [],
							"authorNames": "Ruoyu Zhou (Xidian University, China), Zhiwei Zhang (Xidian University, China), Haocheng Han (Xidian University, China), Xiaodong Zhang (University of Science and Technology of China, China), Zehan Chen (Xidian University, China), Jun Sun (Singapore Management University, Singapore), Yulong Shen (Xidian University, China), Dehai Xu (Yiqiyin (Hangzhou) Technology Co., Ltd. Xi\u2019an Branch, China)",
							"abstract": "Multi-robot swarms play an essential role in complex missions including battlefield reconnaissance, agricultural pest monitoring, as well as disaster search and rescue. Unfortunately, given the complexity of swarm algorithms, logical vulnerabilities are inevitable and often lead to severe safety and security consequences. Although various methods have been presented for detecting logical vulnerabilities through software testing, when they are used in swarm environments, these techniques face significant challenges: 1) Due to the swarm's vast composable parameter space, it is extremely difficult to generate failure-triggering scenarios, which is crucial to effectively expose logical vulnerabilities; 2) Because of the swarm's high flexibility and dynamism, it is challenging to model and evaluate the global swarm state, particularly in terms of cooperative behaviors, which makes it difficult to detect logical vulnerabilities. In this work, we propose RSFuzz, a robustness-guided swarm fuzzing framework designed to detect logical vulnerabilities in multi-robot systems. It leverages the robustness of behavioral constraints to quantitatively evaluate the swarm state and guide the generation of failure-triggering scenarios. In addition, RSFuzz identifies and targets key swarm nodes for perturbations, effectively reducing the input space. Upon the RSFuzz framework, we construct two swarm fuzzing schemes, Single Attacker Fuzzing (SA-Fuzzing) and Multiple Attacker Fuzzing (MA-Fuzzing), which employ single and multiple attackers, respectively, during fuzzing to disturb swarm mission execution. We evaluated RSFuzz's performance with three popular swarm algorithms in simulated environments. The results show that RSFuzz outperforms the state-of-the-art with an average improvement of 17.75% in effectiveness and a 38.4% increase in efficiency. We also validated some detected vulnerabilities in real-world environments. Our code and data are publicly available.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 RSFuzz: A Robustness-Guided Swarm Fuzzing Framework Based on Behavioral Constraints 1758853546581 10.1109/ASE63991.2025.00048 Ruoyu Zhou Xidian University, China ruoyuzhou@stu.xidian.edu.cn Zhiwei Zhang Xidian University, China zwzhang@xidian.edu.cn Haocheng Han Xidian University, China xd_hchan@stu.xidian.edu.cn Xiaodong Zhang University of Science and Technology of China, China zhangxiaodong@ustc.edu.cn Zehan Chen Xidian University, China zehanchen@stu.xidian.edu.cn Jun Sun Singapore Management University, Singapore junsun@smu.edu.sg Yulong Shen Xidian University, China ylshen@xidian.edu.cn Dehai Xu Yiqiyin (Hangzhou) Technology Co., Ltd. Xi\u2019an Branch, China 15504446630@163.com fuzzing behavioral constraints swarm logical vulnerabilities robustness Multi-robot swarms play an essential role in complex missions including battlefield reconnaissance, agricultural pest monitoring, as well as disaster search and rescue. Unfortunately, given the complexity of swarm algorithms, logical vulnerabilities are inevitable and often lead to severe safety and security consequences. Although various methods have been presented for detecting logical vulnerabilities through software testing, when they are used in swarm environments, these techniques face significant challenges: 1) Due to the swarm's vast composable parameter space, it is extremely difficult to generate failure-triggering scenarios, which is crucial to effectively expose logical vulnerabilities; 2) Because of the swarm's high flexibility and dynamism, it is challenging to model and evaluate the global swarm state, particularly in terms of cooperative behaviors, which makes it difficult to detect logical vulnerabilities. In this work, we propose RSFuzz, a robustness-guided swarm fuzzing framework designed to detect logical vulnerabilities in multi-robot systems. It leverages the robustness of behavioral constraints to quantitatively evaluate the swarm state and guide the generation of failure-triggering scenarios. In addition, RSFuzz identifies and targets key swarm nodes for perturbations, effectively reducing the input space. Upon the RSFuzz framework, we construct two swarm fuzzing schemes, Single Attacker Fuzzing (SA-Fuzzing) and Multiple Attacker Fuzzing (MA-Fuzzing), which employ single and multiple attackers, respectively, during fuzzing to disturb swarm mission execution. We evaluated RSFuzz's performance with three popular swarm algorithms in simulated environments. The results show that RSFuzz outperforms the state-of-the-art with an average improvement of 17.75% in effectiveness and a 38.4% increase in efficiency. We also validated some detected vulnerabilities in real-world environments. Our code and data are publicly available.",
							"pageNumber": 495,
							"isPageNumberRoman": false
						},
						{
							"eid": "2NaCZXDY4a8l1yBdgkUMT5",
							"type": "authorPaper",
							"text": "Provable Fairness Repair for Deep Neural Networks",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a508/573300a508.pdf",
							"extraLocations": [],
							"authorNames": "Jianan Ma (Hangzhou Dianzi University, China; Zhejiang University, China), Jingyi Wang (Zhejiang University, China), Qi Xuan (Zhejiang University of Technology, China), Zhen Wang (Hangzhou Dianzi University, China)",
							"abstract": "Deep neural networks (DNNs) are suffering from ethical issues such as individual discrimination. In response, extensive NN repair techniques have been developed to adjust models and mitigate such undesired behaviors. However, existing fairness repair methods are typically data-centric, which often lack provable guarantees and generalization to unseen samples. To overcome these limitations, we propose ProF, a novel fairness repair framework with provable guarantees. The key intuition of ProF is to leverage interval bound propagation (a widely used NN verification technique) to soundly capture model outputs over the whole set S(x) around a biased sample x. The derived bounds are utilized to guide fairness repair which encourages the model to produce consistent outputs on S(x). Specifically, we integrate fairness constraints and model modifications into a unified constraint-solving formulation, which can be transformed to a Mixed-Integer Linear Programming (MILP) problem solvable by off-the-shelf solvers. The solution to the MILP problem effectively induces a repaired model with guaranteed fairness over the whole set S(x). We evaluate ProF on four widely used benchmark datasets and demonstrate that it achieves provable fairness repair, with generalization of up to 95.93% on full datasets and 93.16% on the entire input space. Notably, ProF can be easily configured to support multiple sensitive attributes and more practical fairness definitions, while providing provable repair guarantees and delivering around 90% fairness improvement. Our code is available in the repository.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Provable Fairness Repair for Deep Neural Networks 1758843656283 10.1109/ASE63991.2025.00049 Jianan Ma Hangzhou Dianzi University, China; Zhejiang University, China majianannn@gmail.com Jingyi Wang Zhejiang University, China wangjyee@zju.edu.cn Qi Xuan Zhejiang University of Technology, China xuanqi@zjut.edu.cn Zhen Wang Hangzhou Dianzi University, China wangzhen@hdu.edu.cn neural network repair fairness interval bound propagation Deep neural networks (DNNs) are suffering from ethical issues such as individual discrimination. In response, extensive NN repair techniques have been developed to adjust models and mitigate such undesired behaviors. However, existing fairness repair methods are typically data-centric, which often lack provable guarantees and generalization to unseen samples. To overcome these limitations, we propose ProF, a novel fairness repair framework with provable guarantees. The key intuition of ProF is to leverage interval bound propagation (a widely used NN verification technique) to soundly capture model outputs over the whole set S(x) around a biased sample x. The derived bounds are utilized to guide fairness repair which encourages the model to produce consistent outputs on S(x). Specifically, we integrate fairness constraints and model modifications into a unified constraint-solving formulation, which can be transformed to a Mixed-Integer Linear Programming (MILP) problem solvable by off-the-shelf solvers. The solution to the MILP problem effectively induces a repaired model with guaranteed fairness over the whole set S(x). We evaluate ProF on four widely used benchmark datasets and demonstrate that it achieves provable fairness repair, with generalization of up to 95.93% on full datasets and 93.16% on the entire input space. Notably, ProF can be easily configured to support multiple sensitive attributes and more practical fairness definitions, while providing provable repair guarantees and delivering around 90% fairness improvement. Our code is available in the repository.",
							"pageNumber": 508,
							"isPageNumberRoman": false
						},
						{
							"eid": "2sgPbzBciOJDbSnz1VG3lA",
							"type": "authorPaper",
							"text": "GlassWing: A Tailored Static Analysis Approach for Flutter Android Apps",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a521/573300a521.pdf",
							"extraLocations": [],
							"authorNames": "Xiangyu Zhang (Nankai University, China; Zhongguancun Academy, China), Yucheng Su (Xiaohongshu Inc., China), Lingling Fan (Nankai University, China), Miaoying Cai (Nankai University, China), Sen Chen (Nankai University, China)",
							"abstract": "The variety of mobile operating systems available in the market has led to the emergence of cross-platform frameworks, which simplify the development and deployment of mobile applications across multiple platforms simultaneously. Among these, the Flutter framework promoted by Google has become the most widely used cross-platform development framework. To date, no work has provided support for the static analysis of Flutter applications on the Android platform. State-of-the-art static analyzers fail to \"see\" the implicit invocation between the Dart language used by the Flutter framework and the Java used by the native Android platform, posing a significant threat to the completeness of the mobile software analysis. In this paper, we present GlassWing, the first tailored approach to static analysis for Flutter Android apps. GlassWing leverages a data-flow-oriented approach to conduct key program semantic extraction of Flutter apps and discloses the implicit Dart-Java invocation relations, thereby making cross-language invocation visible. Extensive evaluation on 1,023 popular real-world Flutter apps indicates that GlassWing enhances static analysis of Flutter apps integrated with Soot by parsing 141% more Jimple code lines, extending the call graph with more edges and nodes, and revealing almost 3X sensitive data leaks that were previously undetected with FlowDroid. GlassWing sheds light on downstream research fields for Flutter apps (e.g., program graph analysis, taint analysis, and malicious software analysis). Many current and future Android analysis initiatives can be enhanced by seamlessly incorporating GlassWing's insights.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 GlassWing: A Tailored Static Analysis Approach for Flutter Android Apps 1759411794837 10.1109/ASE63991.2025.00050 Xiangyu Zhang Nankai University, China; Zhongguancun Academy, China 1120240353@mail.nankai.edu.cn Yucheng Su Xiaohongshu Inc., China suyucheng@xiaohongshu.com Lingling Fan Nankai University, China linglingfan@nankai.edu.cn Miaoying Cai Nankai University, China miaoyingcai@mail.nankai.edu.cn Sen Chen Nankai University, China senchen@nankai.edu.cn static analysis flutter android apps cross- platform framework The variety of mobile operating systems available in the market has led to the emergence of cross-platform frameworks, which simplify the development and deployment of mobile applications across multiple platforms simultaneously. Among these, the Flutter framework promoted by Google has become the most widely used cross-platform development framework. To date, no work has provided support for the static analysis of Flutter applications on the Android platform. State-of-the-art static analyzers fail to \"see\" the implicit invocation between the Dart language used by the Flutter framework and the Java used by the native Android platform, posing a significant threat to the completeness of the mobile software analysis. In this paper, we present GlassWing, the first tailored approach to static analysis for Flutter Android apps. GlassWing leverages a data-flow-oriented approach to conduct key program semantic extraction of Flutter apps and discloses the implicit Dart-Java invocation relations, thereby making cross-language invocation visible. Extensive evaluation on 1,023 popular real-world Flutter apps indicates that GlassWing enhances static analysis of Flutter apps integrated with Soot by parsing 141% more Jimple code lines, extending the call graph with more edges and nodes, and revealing almost 3X sensitive data leaks that were previously undetected with FlowDroid. GlassWing sheds light on downstream research fields for Flutter apps (e.g., program graph analysis, taint analysis, and malicious software analysis). Many current and future Android analysis initiatives can be enhanced by seamlessly incorporating GlassWing's insights.",
							"pageNumber": 521,
							"isPageNumberRoman": false
						},
						{
							"eid": "2TtKC7Q78RJYQFTh4Xu8TS",
							"type": "authorPaper",
							"text": "RustAssure: Differential Symbolic Testing for LLM-Transpiled C-to-Rust Code",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a534/573300a534.pdf",
							"extraLocations": [],
							"authorNames": "Yubo Bai (University of California, USA), Tapti Palit (University of California, USA)",
							"abstract": "Rust is a memory-safe programming language that significantly improves software security. Existing codebases written in unsafe memory languages, such as C, must first be transpiled to Rust to take advantage of Rust's improved safety guarantees. RustAssure presents a system that uses Large Language Models (LLMs) to automatically transpile existing C codebases to Rust. RustAssure uses prompt engineering techniques to maximize the chances of the LLM generating idiomatic and safe Rust code. Moreover, because LLMs often generate code with subtle bugs that can be missed under traditional unit or fuzz testing, RustAssure performs differential symbolic testing to establish the semantic similarity between the original C and LLM-transpiled Rust code. We evaluated RustAssure with five real-world applications and libraries, and showed that our system is able to generate compilable Rust functions for 89.8% of all C functions, of which 72% produced equivalent symbolic return values for both the C and Rust functions.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 RustAssure: Differential Symbolic Testing for LLM-Transpiled C-to-Rust Code 1759422284021 10.1109/ASE63991.2025.00051 Yubo Bai University of California, USA gabbai@ucdavis.edu Tapti Palit University of California, USA tpalit@ucdavis.edu c to rust transpilation differential testing symbolic execution Rust is a memory-safe programming language that significantly improves software security. Existing codebases written in unsafe memory languages, such as C, must first be transpiled to Rust to take advantage of Rust's improved safety guarantees. RustAssure presents a system that uses Large Language Models (LLMs) to automatically transpile existing C codebases to Rust. RustAssure uses prompt engineering techniques to maximize the chances of the LLM generating idiomatic and safe Rust code. Moreover, because LLMs often generate code with subtle bugs that can be missed under traditional unit or fuzz testing, RustAssure performs differential symbolic testing to establish the semantic similarity between the original C and LLM-transpiled Rust code. We evaluated RustAssure with five real-world applications and libraries, and showed that our system is able to generate compilable Rust functions for 89.8% of all C functions, of which 72% produced equivalent symbolic return values for both the C and Rust functions.",
							"pageNumber": 534,
							"isPageNumberRoman": false
						},
						{
							"eid": "7711iZID9GJLlEysj3xrXG",
							"type": "authorPaper",
							"text": "DNAFuzz: Descriptor-Aware Fuzzing for USB Drivers",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a547/573300a547.pdf",
							"extraLocations": [],
							"authorNames": "Zhengshu Wang (Hubei University, China), Peng He (Hubei University, China), Fuchen Ma (Tsinghua University, China), Yuanliang Chen (Tsinghua University, China), Shuoshuo Duan (Shuimu Yulin Technology Co., Ltd), Yiyuan Bai (Shuimu Yulin Technology Co., Ltd), Yu Jiang (Tsinghua University, China)",
							"abstract": "USB is a widely used interface standard in modern operating systems for connecting computers to various external devices. External devices can launch attacks by injecting random data into the host via USB, causing memory errors or even system-level crashes. Fuzzing has been proven to be an effective method to detect USB driver vulnerabilities. However, existing fuzzing methods generate testing inputs without considering the format and semantics of USB descriptors, which define device functionality. As a result, many test cases fail to pass the host's input validation mechanism, leading to ineffective testing. In this paper, we propose DNAFuzz, a USB driver fuzzer that generates descriptor-aware payloads. First, it utilizes USB specifications to parse the field definitions and item types of USB descriptors for modeling. Then, based on the field description list and semantic information, DNAFuzz designs mutation strategies to guide the generation of payloads. This approach improves the quality of test cases and the fuzzing effectiveness. Currently, we evaluated DNAFuzz on multiple versions of Linux kernel USB drivers and compared it with state-of-the-art fuzzers, including USBFuzz and Syzkaller. Results show that DNAFuzz significantly improves input quality, successfully increasing the proportion of tests with execution times exceeding 2 seconds by 358% and 65%. In addition, DNAFuzz detected 15 bugs, 11 of which have been fixed or confirmed by the corresponding maintainers.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 DNAFuzz: Descriptor-Aware Fuzzing for USB Drivers 1759051623852 10.1109/ASE63991.2025.00052 Zhengshu Wang Hubei University, China wangzhengshu39@gmail.com Peng He Hubei University, China penghe@hubu.edu.cn Fuchen Ma Tsinghua University, China fuchenma525@gmail.com Yuanliang Chen Tsinghua University, China sard.chen@gmail.com Shuoshuo Duan Shuimu Yulin Technology Co., Ltd duanshuoshuo@shuimuyulin.com Yiyuan Bai Shuimu Yulin Technology Co., Ltd baiyiyuan@shuimuyulin.com Yu Jiang Tsinghua University, China jiangyu198964@126.com USB is a widely used interface standard in modern operating systems for connecting computers to various external devices. External devices can launch attacks by injecting random data into the host via USB, causing memory errors or even system-level crashes. Fuzzing has been proven to be an effective method to detect USB driver vulnerabilities. However, existing fuzzing methods generate testing inputs without considering the format and semantics of USB descriptors, which define device functionality. As a result, many test cases fail to pass the host's input validation mechanism, leading to ineffective testing. In this paper, we propose DNAFuzz, a USB driver fuzzer that generates descriptor-aware payloads. First, it utilizes USB specifications to parse the field definitions and item types of USB descriptors for modeling. Then, based on the field description list and semantic information, DNAFuzz designs mutation strategies to guide the generation of payloads. This approach improves the quality of test cases and the fuzzing effectiveness. Currently, we evaluated DNAFuzz on multiple versions of Linux kernel USB drivers and compared it with state-of-the-art fuzzers, including USBFuzz and Syzkaller. Results show that DNAFuzz significantly improves input quality, successfully increasing the proportion of tests with execution times exceeding 2 seconds by 358% and 65%. In addition, DNAFuzz detected 15 bugs, 11 of which have been fixed or confirmed by the corresponding maintainers.",
							"pageNumber": 547,
							"isPageNumberRoman": false
						},
						{
							"eid": "3ZRWJ2vUqIhtl4JBM3MBir",
							"type": "authorPaper",
							"text": "Security Debt in LLM Agent Applications: A Measurement Study of Vulnerabilities and Mitigation Trade-Offs",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a559/573300a559.pdf",
							"extraLocations": [],
							"authorNames": "Zhuoxiang Shen (Fudan University, China), Jiarun Dai (Fudan University, China), Yuan Zhang (Fudan University, China), Min Yang (Fudan University, China)",
							"abstract": "The advantages of large language models (LLMs) in content comprehension and question answering have led to the rapid emergence of LLM agent. Developers across diverse domains are actively building their own agent applications (apps), as these apps can streamline workflows, boost efficiency, or deliver innovative solutions, thereby enhancing the competitiveness of their products. Agent apps are playing an increasingly important role in our daily lives. However, numerous serious vulnerabilities and security issues have been identified in these apps. To effectively manage future security risks, it is essential to systematically understand the unique characteristics of agent app vulnerabilities and their mitigation. In this paper, we present the first comprehensive study on the vulnerabilities of agent apps, the mitigation practices of app developers, and the associated challenges and trade-offs. We identify 14 types of vulnerabilities and 16 root causes across 7 components, based on an analysis of 221 real-world vulnerabilities. Our study further investigates developer reactions, evaluates the effectiveness of various mitigation strategies, and explores the practical challenges and inevitable trade-offs in vulnerability mitigation. Finally, we distill 12 key findings, discuss their implications for agent app developers, maintainers, and security researchers, and offer suggestions for future research directions.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Security Debt in LLM Agent Applications: A Measurement Study of Vulnerabilities and Mitigation Trade-Offs 1756780299841 10.1109/ASE63991.2025.00053 Zhuoxiang Shen Fudan University, China zxshen22@m.fudan.edu.cn Jiarun Dai Fudan University, China jrdai@fudan.edu.cn Yuan Zhang Fudan University, China yuanxzhang@fudan.edu.cn Min Yang Fudan University, China m_yang@fudan.edu.cn llm agent software application security vulnerability mitigation measurement study The advantages of large language models (LLMs) in content comprehension and question answering have led to the rapid emergence of LLM agent. Developers across diverse domains are actively building their own agent applications (apps), as these apps can streamline workflows, boost efficiency, or deliver innovative solutions, thereby enhancing the competitiveness of their products. Agent apps are playing an increasingly important role in our daily lives. However, numerous serious vulnerabilities and security issues have been identified in these apps. To effectively manage future security risks, it is essential to systematically understand the unique characteristics of agent app vulnerabilities and their mitigation. In this paper, we present the first comprehensive study on the vulnerabilities of agent apps, the mitigation practices of app developers, and the associated challenges and trade-offs. We identify 14 types of vulnerabilities and 16 root causes across 7 components, based on an analysis of 221 real-world vulnerabilities. Our study further investigates developer reactions, evaluates the effectiveness of various mitigation strategies, and explores the practical challenges and inevitable trade-offs in vulnerability mitigation. Finally, we distill 12 key findings, discuss their implications for agent app developers, maintainers, and security researchers, and offer suggestions for future research directions.",
							"pageNumber": 559,
							"isPageNumberRoman": false
						},
						{
							"eid": "2PT7hXbdF7ETgNLbn4zaNu",
							"type": "authorPaper",
							"text": "SSR: Safeguarding Staking Rewards by Defining and Detecting Logical Defects in DeFi Staking",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a571/573300a571.pdf",
							"extraLocations": [],
							"authorNames": "Zewei Lin (Sun Yat-sen University; Peng Cheng Laboratory), Jiachi Chen (Sun Yat-sen University), Jingwen Zhang (Sun Yat sen University; Peng Cheng Laboratory), Zexu Wang (Sun Yat-sen University; Peng Cheng Laboratory), Yuming Feng (Peng Cheng Laboratory), Weizhe Zhang (Harbin Institute of Technology; Peng Cheng Laboratory), Zibin Zheng (Sun Yat-sen University)",
							"abstract": "Decentralized Finance (DeFi) staking is one of the most prominent applications within the DeFi ecosystem, where DeFi projects enable users to stake tokens on the platform and reward participants with additional tokens. However, logical defects in DeFi staking could enable attackers to claim unwarranted rewards by manipulating reward amounts, repeatedly claiming rewards, or engaging in other malicious actions. To mitigate these threats, we conducted the first study focused on defining and detecting logical defects in DeFi staking. Through the analysis of 64 security incidents and 144 audit reports, we identified six distinct types of logical defects, each accompanied by detailed descriptions and code examples. Building on this empirical research, we developed SSR (Safeguarding Staking Reward), a static analysis tool designed to detect logical defects in DeFi staking contracts. SSR utilizes a large language model (LLM) to extract fundamental information about staking logic and constructs a DeFi staking model. It then identifies logical defects by analyzing the model and the associated semantic features. We constructed a ground truth dataset based on known security incidents and audit reports to evaluate the effectiveness of SSR. The results indicate that SSR achieves an overall precision of 92.31%, a recall of 87.92%, and an F1-score of 88.85%. Additionally, to assess the prevalence of logical defects in real-world smart contracts, we compiled a large-scale dataset of 15,992 DeFi staking contracts. SSR detected that 3,557 (22.24%) of these contracts contained at least one logical defect.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 SSR: Safeguarding Staking Rewards by Defining and Detecting Logical Defects in DeFi Staking 1759076559403 10.1109/ASE63991.2025.00054 Zewei Lin Sun Yat-sen University; Peng Cheng Laboratory linzw3@mail2.sysu.edu.cn Jiachi Chen Sun Yat-sen University chenjch86@mail.sysu.edu.cn Jingwen Zhang Sun Yat sen University; Peng Cheng Laboratory zhangjw273@mail2.sysu.edu.cn Zexu Wang Sun Yat-sen University; Peng Cheng Laboratory wangzx97@mail2.sysu.edu.cn Yuming Feng Peng Cheng Laboratory fengym@pcl.ac.cn Weizhe Zhang Harbin Institute of Technology; Peng Cheng Laboratory wzzhang@hit.edu.cn Zibin Zheng Sun Yat-sen University zhzibin@mail.sysu.edu.cn defi staking smart contracts logical defects detection llm static analysis Decentralized Finance (DeFi) staking is one of the most prominent applications within the DeFi ecosystem, where DeFi projects enable users to stake tokens on the platform and reward participants with additional tokens. However, logical defects in DeFi staking could enable attackers to claim unwarranted rewards by manipulating reward amounts, repeatedly claiming rewards, or engaging in other malicious actions. To mitigate these threats, we conducted the first study focused on defining and detecting logical defects in DeFi staking. Through the analysis of 64 security incidents and 144 audit reports, we identified six distinct types of logical defects, each accompanied by detailed descriptions and code examples. Building on this empirical research, we developed SSR (Safeguarding Staking Reward), a static analysis tool designed to detect logical defects in DeFi staking contracts. SSR utilizes a large language model (LLM) to extract fundamental information about staking logic and constructs a DeFi staking model. It then identifies logical defects by analyzing the model and the associated semantic features. We constructed a ground truth dataset based on known security incidents and audit reports to evaluate the effectiveness of SSR. The results indicate that SSR achieves an overall precision of 92.31%, a recall of 87.92%, and an F1-score of 88.85%. Additionally, to assess the prevalence of logical defects in real-world smart contracts, we compiled a large-scale dataset of 15,992 DeFi staking contracts. SSR detected that 3,557 (22.24%) of these contracts contained at least one logical defect.",
							"pageNumber": 571,
							"isPageNumberRoman": false
						},
						{
							"eid": "1TYxdM4bawPBNlwM9A5g8f",
							"type": "authorPaper",
							"text": "EditFusion: Resolving Code Merge Conflicts via Edit Selection",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a584/573300a584.pdf",
							"extraLocations": [],
							"authorNames": "Changxin Wang (Nanjing University, China), Lei Xu (Nanjing University, China), Rundong Wang (Nanjing University, China), Yiming Ma (Nanjing University, China), Weifeng Zhang (Nanjing University of Posts and Telecommunications, China)",
							"abstract": "Merge conflicts in Distributed Version Control Systems (DVCS) like Git are a persistent challenge in the software development lifecycle. If not handled properly or overlooked, they can lead to issues like hindering collaboration and introducing errors. While automated resolution methods exist, prevailing approaches-such as multi-class classification and direct code generation-often suffer from limited interpretability, demanding substantial manual effort to refine predictions, and risk producing subtly flawed code. Critically, existing research often overlooks a prevalent conflict type: adjacent-line conflicts, where independent edits to contiguous lines are flagged by tools like Git. Our empirical analysis reveals that these make up a substantial portion of all conflicts. Moreover, they can often be resolved using simple patterns. Motivated by these limitations and empirical findings, we propose a novel approach: modeling merge conflict resolution as edit script selection. Instead of predicting abstract categories or generating code from scratch, our method makes a binary decision for each atomic line-level edit script contributing to the conflict: accept or reject. Our method inherently makes the reasoning behind proposed solutions transparent, as decisions directly correspond to individual, developer-authored code modifications. It also aligns closely with how developers naturally approach conflict analysis by considering each change in context. Our method applies to the vast majority (94.18%) of conflicts that can be correctly resolved without introducing any novel code lines\u2014that is, lines not present in any of the parent versions being merged; this selection process directly yields the resolved code by applying the chosen subset of existing edits. We developed EditFusion, a deep learning model that performs edit script selection by leveraging semantic embeddings and edit metadata. Extensive evaluation on large-scale, real-world datasets demonstrates both the prevalence of adjacent-line conflicts and EditFusion's superior performance in accurately resolving conflicts compared to baselines. Our work represents an attempt towards more transparent, intuitive, and practical automated merge conflict resolution.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 EditFusion: Resolving Code Merge Conflicts via Edit Selection 1759495626540 10.1109/ASE63991.2025.00055 Changxin Wang Nanjing University, China 502022330044@smail.nju.edu.cn Lei Xu Nanjing University, China xlei@nju.edu.cn Rundong Wang Nanjing University, China 522024330143@smail.nju.edu.cn Yiming Ma Nanjing University, China 502024330038@smail.nju.edu.cn Weifeng Zhang Nanjing University of Posts and Telecommunications, China zhangwf@njupt.edu.cn code merging automated conflict resolution edit script adjacent-line conflict Merge conflicts in Distributed Version Control Systems (DVCS) like Git are a persistent challenge in the software development lifecycle. If not handled properly or overlooked, they can lead to issues like hindering collaboration and introducing errors. While automated resolution methods exist, prevailing approaches-such as multi-class classification and direct code generation-often suffer from limited interpretability, demanding substantial manual effort to refine predictions, and risk producing subtly flawed code. Critically, existing research often overlooks a prevalent conflict type: adjacent-line conflicts, where independent edits to contiguous lines are flagged by tools like Git. Our empirical analysis reveals that these make up a substantial portion of all conflicts. Moreover, they can often be resolved using simple patterns. Motivated by these limitations and empirical findings, we propose a novel approach: modeling merge conflict resolution as edit script selection. Instead of predicting abstract categories or generating code from scratch, our method makes a binary decision for each atomic line-level edit script contributing to the conflict: accept or reject. Our method inherently makes the reasoning behind proposed solutions transparent, as decisions directly correspond to individual, developer-authored code modifications. It also aligns closely with how developers naturally approach conflict analysis by considering each change in context. Our method applies to the vast majority (94.18%) of conflicts that can be correctly resolved without introducing any novel code lines\u2014that is, lines not present in any of the parent versions being merged; this selection process directly yields the resolved code by applying the chosen subset of existing edits. We developed EditFusion, a deep learning model that performs edit script selection by leveraging semantic embeddings and edit metadata. Extensive evaluation on large-scale, real-world datasets demonstrates both the prevalence of adjacent-line conflicts and EditFusion's superior performance in accurately resolving conflicts compared to baselines. Our work represents an attempt towards more transparent, intuitive, and practical automated merge conflict resolution.",
							"pageNumber": 584,
							"isPageNumberRoman": false
						},
						{
							"eid": "7M8uPCiFbbGPeyk57h2zTK",
							"type": "authorPaper",
							"text": "Automatic Fixing of Missing Dependency Errors",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a597/573300a597.pdf",
							"extraLocations": [],
							"authorNames": "Jun Lyu (Nanjing University, China), He  Zhang (Nanjing University, China), Lanxin Yang (Nanjing University, China), Yue Li (Nanjing University, China), Chenxing Zhong (Nanjing University of Science and Technology, China), Manuel Rigger (National University of Singapore, Singapore)",
							"abstract": "Many build systems, such as Make, rely on build scripts that are written by users to specify dependencies. As a serious dependency error in Makefiles, Missing Dependencies (MDs) can result in compiling and linking outdated artifacts in incremental builds, preventing software project updates from being applied correctly. Many studies have explored the detection of MDs. Automatically fixing those missing build dependency errors has become an apparent but challenging task. The challenges mainly result from Makefiles having complex semantics and project maintainers declaring dependencies in a variety of ways. To address these challenges, we propose a new approach to fixing MDs called MDfixer. The core idea of MDfixer is to identify the dependency declaration style in a Makefile and generate patches for the same declaration style based on declaration graphs and automatic prompt generation. Specifically, MDfixer locates dependency declarations for targets that have errors in the Makefile based on error reports, and then builds a declaration graph for each build target with errors and identifies the target's declaration style based on a distance metric between the target and the dependencies. Based on the declaration graph and automatic prompt generation, MDfixer generates patches with the same style for the dependencies that need to be added. We evaluated the effectiveness and efficiency of MDfixer with 35 well-known projects. The evaluation results show that MDfixer can fix all MDs. We submitted fixes for 2,786 individual dependency issues across 17 projects, with 11 of them merging our pull requests, resulting in a total of 2,099 errors being fixed. MDfixer consumes an average time of 3.31 min for fixing a project, with a median of 62.999s. It can assist practitioners in the effective and efficient fixing of MDs.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Automatic Fixing of Missing Dependency Errors 1758849090108 10.1109/ASE63991.2025.00056 Jun Lyu Nanjing University, China lvjun@smail.nju.edu.cn He Zhang Nanjing University, China hezhang@nju.edu.cn Lanxin Yang Nanjing University, China lxyang@nju.edu.cn Yue Li Nanjing University, China yueli.dom@outlook.com Chenxing Zhong Nanjing University of Science and Technology, China chenxingzhong@njust.edu.cn Manuel Rigger National University of Singapore, Singapore rigger@nus.edu.sg build tool build system maintenance build dependency errors automatic program repair Many build systems, such as Make, rely on build scripts that are written by users to specify dependencies. As a serious dependency error in Makefiles, Missing Dependencies (MDs) can result in compiling and linking outdated artifacts in incremental builds, preventing software project updates from being applied correctly. Many studies have explored the detection of MDs. Automatically fixing those missing build dependency errors has become an apparent but challenging task. The challenges mainly result from Makefiles having complex semantics and project maintainers declaring dependencies in a variety of ways. To address these challenges, we propose a new approach to fixing MDs called MDfixer. The core idea of MDfixer is to identify the dependency declaration style in a Makefile and generate patches for the same declaration style based on declaration graphs and automatic prompt generation. Specifically, MDfixer locates dependency declarations for targets that have errors in the Makefile based on error reports, and then builds a declaration graph for each build target with errors and identifies the target's declaration style based on a distance metric between the target and the dependencies. Based on the declaration graph and automatic prompt generation, MDfixer generates patches with the same style for the dependencies that need to be added. We evaluated the effectiveness and efficiency of MDfixer with 35 well-known projects. The evaluation results show that MDfixer can fix all MDs. We submitted fixes for 2,786 individual dependency issues across 17 projects, with 11 of them merging our pull requests, resulting in a total of 2,099 errors being fixed. MDfixer consumes an average time of 3.31 min for fixing a project, with a median of 62.999s. It can assist practitioners in the effective and efficient fixing of MDs.",
							"pageNumber": 597,
							"isPageNumberRoman": false
						},
						{
							"eid": "3C2M2m6Mbx9IPzYsLiIOwE",
							"type": "authorPaper",
							"text": "RustRepoTrans: Repository-Level Context Code Translation Benchmark Targeting Rust",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a610/573300a610.pdf",
							"extraLocations": [],
							"authorNames": "Guangshen Ou (Sun Yat-sen University, China), Mingwei Liu (Sun Yat-sen University, China), Yuxuan Chen (Sun Yat-sen University, China), Yanlin Wang (Sun Yat-sen University, China), Xin Peng (Fudan University, China), Zibin Zheng (Sun Yat-sen University, China)",
							"abstract": "Recent advancements in large language models (LLMs) have demonstrated impressive capabilities in code translation, typically evaluated using benchmarks like CodeTransOcean and RepoTransBench. However, dependency-free benchmarks fail to capture real-world complexities by focusing primarily on simple function-level translations and overlooking repository-level context (e.g., dependencies). Full-repository translation benchmarks significantly exceed the current capabilities of existing models, resulting in performance bottlenecks that fail to provide actionable insights for guiding model development. Furthermore, existing benchmarks do not account for the scenario of incrementally translating new or modified modules from the source to the target language, which demands careful handling of repository-level contexts such as dependencies, cross-module references, and architectural divergence. Moreover, LLMs' effectiveness in translating to newer, low-resource languages like Rust remains largely underexplored. To address these gaps, we introduce RustRepoTrans, the first repository-level context code translation benchmark targeting incremental translation, comprising 375 tasks translating into Rust from C, Java, and Python. Using this benchmark, we evaluate seven representative LLMs, analyzing their errors to assess limitations in complex translation scenarios. Among them, DeepSeek-R1 performs best with 51.5% Pass@1, excelling in both basic functionality and additional translation abilities, such as noise robustness and syntactical difference identification. However, even DeepSeek-R1 experiences a 22.2% performance drop (Pass@1 from 73.7% to 51.5%) when handling repository-level context compared to previous benchmarks without such context. Meanwhile, we propose a set of more fine-grained evaluation metrics and an enhanced evaluation framework, enabling a more comprehensive analysis of LLM performance in repository-level context code translation tasks to provide fine-grained insights that can effectively inform the development of code translation techniques.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 RustRepoTrans: Repository-Level Context Code Translation Benchmark Targeting Rust 1759141370903 10.1109/ASE63991.2025.00057 Guangshen Ou Sun Yat-sen University, China ougsh3@mail2.sysu.edu.cn Mingwei Liu Sun Yat-sen University, China liumw26@mail.sysu.edu.cn Yuxuan Chen Sun Yat-sen University, China chenyx677@mail2.sysu.edu.cn Yanlin Wang Sun Yat-sen University, China wangylin36@mail.sysu.edu.cn Xin Peng Fudan University, China pengxin@fudan.edu.cn Zibin Zheng Sun Yat-sen University, China zhzibin@mail.sysu.edu.cn n/a Recent advancements in large language models (LLMs) have demonstrated impressive capabilities in code translation, typically evaluated using benchmarks like CodeTransOcean and RepoTransBench. However, dependency-free benchmarks fail to capture real-world complexities by focusing primarily on simple function-level translations and overlooking repository-level context (e.g., dependencies). Full-repository translation benchmarks significantly exceed the current capabilities of existing models, resulting in performance bottlenecks that fail to provide actionable insights for guiding model development. Furthermore, existing benchmarks do not account for the scenario of incrementally translating new or modified modules from the source to the target language, which demands careful handling of repository-level contexts such as dependencies, cross-module references, and architectural divergence. Moreover, LLMs' effectiveness in translating to newer, low-resource languages like Rust remains largely underexplored. To address these gaps, we introduce RustRepoTrans, the first repository-level context code translation benchmark targeting incremental translation, comprising 375 tasks translating into Rust from C, Java, and Python. Using this benchmark, we evaluate seven representative LLMs, analyzing their errors to assess limitations in complex translation scenarios. Among them, DeepSeek-R1 performs best with 51.5% Pass@1, excelling in both basic functionality and additional translation abilities, such as noise robustness and syntactical difference identification. However, even DeepSeek-R1 experiences a 22.2% performance drop (Pass@1 from 73.7% to 51.5%) when handling repository-level context compared to previous benchmarks without such context. Meanwhile, we propose a set of more fine-grained evaluation metrics and an enhanced evaluation framework, enabling a more comprehensive analysis of LLM performance in repository-level context code translation tasks to provide fine-grained insights that can effectively inform the development of code translation techniques.",
							"pageNumber": 610,
							"isPageNumberRoman": false
						},
						{
							"eid": "4Z6tVC07eJyXDSOLkjHSEm",
							"type": "authorPaper",
							"text": "Enhancing LLM's Ability to Generate More Repository-Aware Unit Tests Through Precise Context Injection",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a623/573300a623.pdf",
							"extraLocations": [],
							"authorNames": "Xin Yin (Zhejiang University, China), Chao Ni (Zhejiang University, China), Xinrui Li (Zhejiang University, China), Liushan Chen (ByteDance, China), Guojun Ma (ByteDance, China), Xiaohu Yang (Zhejiang University, China)",
							"abstract": "Recently, Large Language Models (LLMs) have gained attention for their ability to handle a broad range of tasks, including unit test generation. Despite their success, LLMs may exhibit hallucinations when generating unit tests for focal methods or functions due to their lack of awareness regarding the project's global context. While many studies have explored the role of context, they often extract fixed patterns of context for different models and focal methods, which may not be suitable for all generation processes (e.g., excessive irrelevant context could lead to redundancy, preventing the model from focusing on essential information). To overcome this limitation, we propose RATester, which integrates language servers to provide dynamic definition lookup to assist the LLM. When RATester encounters an unfamiliar identifier, it first leverages language servers (e.g., Gopls) to fetch relevant definitions and documentation comments, and then uses this global knowledge to guide the LLM. We evaluate the effectiveness and efficiency of RATester by constructing a new Golang dataset from real-world projects. On our Golang dataset, RATester achieves an average line coverage of 26.25%, representing an improvement of 9.10% to 165.69% over the baselines. In mutation testing, RATester shows superior performance by successfully killing 18 to 147 more mutants than the baselines. Additionally, our model-agnostic and generalizability analysis confirms RATester's effectiveness across different models, programming languages, and model scales, validating its broad applicability.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Enhancing LLM's Ability to Generate More Repository-Aware Unit Tests Through Precise Context Injection 1759405076821 10.1109/ASE63991.2025.00058 Xin Yin Zhejiang University, China xyin@zju.edu.cn Chao Ni Zhejiang University, China chaoni@zju.edu.cn Xinrui Li Zhejiang University, China lixinrui@zju.edu.cn Liushan Chen ByteDance, China chenliushan@bytedance.com Guojun Ma ByteDance, China maguojun@bytedance.com Xiaohu Yang Zhejiang University, China yangxh@zju.edu.cn unit test generation large language model precise context Recently, Large Language Models (LLMs) have gained attention for their ability to handle a broad range of tasks, including unit test generation. Despite their success, LLMs may exhibit hallucinations when generating unit tests for focal methods or functions due to their lack of awareness regarding the project's global context. While many studies have explored the role of context, they often extract fixed patterns of context for different models and focal methods, which may not be suitable for all generation processes (e.g., excessive irrelevant context could lead to redundancy, preventing the model from focusing on essential information). To overcome this limitation, we propose RATester, which integrates language servers to provide dynamic definition lookup to assist the LLM. When RATester encounters an unfamiliar identifier, it first leverages language servers (e.g., Gopls) to fetch relevant definitions and documentation comments, and then uses this global knowledge to guide the LLM. We evaluate the effectiveness and efficiency of RATester by constructing a new Golang dataset from real-world projects. On our Golang dataset, RATester achieves an average line coverage of 26.25%, representing an improvement of 9.10% to 165.69% over the baselines. In mutation testing, RATester shows superior performance by successfully killing 18 to 147 more mutants than the baselines. Additionally, our model-agnostic and generalizability analysis confirms RATester's effectiveness across different models, programming languages, and model scales, validating its broad applicability.",
							"pageNumber": 623,
							"isPageNumberRoman": false
						},
						{
							"eid": "6pxSybWGfW0m43AjWDWV1r",
							"type": "authorPaper",
							"text": "Finding Bugs in MLIR Compiler Infrastructure via Lowering Space Exploration",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a636/573300a636.pdf",
							"extraLocations": [],
							"authorNames": "Jingjing Liang (East China Normal University, China), Shan Huang (East China Normal University, China), Ting Su (East China Normal University, China)",
							"abstract": "MLIR is a widely adopted compiler infrastructure that supports multi-level IRs and reusable components. Ensuring its correctness is critical, as bugs can propagate to downstream systems. MLIR provides a lowering mechanism that transforms high-level programs into low-level representations through configurable sequences of passes, and allows multiple valid lowering paths for a given program. This gives rise to a lowering equivalence property: all valid lowering paths for the same MLIR program should produce semantically equivalent results. In this paper, we leverage this property and propose lowering space exploration, to effectively test the MLIR infrastructure. Our approach dynamically constructs diverse lowering paths in an adaptive, stepwise manner using a feedback-based scheduling mechanism. It finds bugs by comparing the execution results across these paths. Any inconsistencies indicate potential bugs in the MLIR infrastructure. To the best of our knowledge, this is the first work to test MLIR from the perspective of exploring its compilation space. We implement our approach in a tool named LOBE and evaluate it on latest MLIR versions. LOBE discovers 38 previously unknown bugs, including 8 miscompilations and 30 crash bugs, with 25 confirmed/fixed.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Finding Bugs in MLIR Compiler Infrastructure via Lowering Space Exploration 1759494583143 10.1109/ASE63991.2025.00059 Jingjing Liang East China Normal University, China jjliang@sei.ecnu.edu.cn Shan Huang East China Normal University, China shan.huang@stu.ecnu.edu.cn Ting Su East China Normal University, China tsu@sei.ecnu.edu.cn MLIR is a widely adopted compiler infrastructure that supports multi-level IRs and reusable components. Ensuring its correctness is critical, as bugs can propagate to downstream systems. MLIR provides a lowering mechanism that transforms high-level programs into low-level representations through configurable sequences of passes, and allows multiple valid lowering paths for a given program. This gives rise to a lowering equivalence property: all valid lowering paths for the same MLIR program should produce semantically equivalent results. In this paper, we leverage this property and propose lowering space exploration, to effectively test the MLIR infrastructure. Our approach dynamically constructs diverse lowering paths in an adaptive, stepwise manner using a feedback-based scheduling mechanism. It finds bugs by comparing the execution results across these paths. Any inconsistencies indicate potential bugs in the MLIR infrastructure. To the best of our knowledge, this is the first work to test MLIR from the perspective of exploring its compilation space. We implement our approach in a tool named LOBE and evaluate it on latest MLIR versions. LOBE discovers 38 previously unknown bugs, including 8 miscompilations and 30 crash bugs, with 25 confirmed/fixed.",
							"pageNumber": 636,
							"isPageNumberRoman": false
						},
						{
							"eid": "CTPp9tH7xHeyveuncnhdK",
							"type": "authorPaper",
							"text": "BinStruct: Binary Structure Recovery Combining Static Analysis and Semantics",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a648/573300a648.pdf",
							"extraLocations": [],
							"authorNames": "Yiran Zhang (Nanyang Technological University, Singapore), Zhengzi Xu (\u2020Imperial Global Singapore, Imperial College London, Singapore), Zhe Lang (Chinese Academy of Sciences, China), Chengyue Liu (Nanyang Technological University, Singapore), Yuqiang Sun (Nanyang Technological University, Singapore), Wenbo Guo (Nanyang Technological University, Singapore), Chengwei Liu (Nanyang Technological University, Singapore; China-Singapore International Joint Research Institute, China), Weisong Sun (Nanyang Technological University, Singapore), Yang Liu (Nanyang Technological University, Singapore; China-Singapore International Joint Research Institute, China)",
							"abstract": "Binary reverse engineering is foundational to various tasks such as malware analysis and vulnerability detection. Traditional binary analysis tools mainly operate at the function level. However, modern software has grown significantly in size, with binaries often containing thousands of functions. Without understanding how these functions are organized into higher-level structures, it becomes difficult to effectively support downstream analysis tasks. Analysts must examine thousands of functions separately, making the process time-consuming and error-prone. Despite these challenges, current research on recovering the higher-level structure of binaries remains limited. To bridge this gap, we propose BinStruct, a novel binary structure recovery framework that recovers both file and module structures from binaries. BinStruct first identifies the file structure by combining data reference patterns, function calls, and semantic understanding from Large Language Models. Then, inspired by software architecture recovery in source code analysis, BinStruct identifies modules by clustering the recovered files using consensus between structural dependency and semantic similarity. Evaluation on 121 real-world stripped binaries demonstrates that BinStruct outperforms state-of-the-art techniques in both file and module recovery accuracy, while requiring only 7.42s and 34.46s on average to recover file and module structures, respectively. Case studies on Libxml2 and PredatorTheStealer demonstrate BinStruct's effectiveness on security tasks like attack surface analysis and malware investigation.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 BinStruct: Binary Structure Recovery Combining Static Analysis and Semantics 1759545645549 10.1109/ASE63991.2025.00060 Yiran Zhang Nanyang Technological University, Singapore yiran002@e.ntu.edu.sg Zhengzi Xu \u2020Imperial Global Singapore, Imperial College London, Singapore z.xu@imperial.ac.uk Zhe Lang Chinese Academy of Sciences, China langzhe@iie.ac.cn Chengyue Liu Nanyang Technological University, Singapore chengyue001@e.ntu.edu.sg Yuqiang Sun Nanyang Technological University, Singapore suny0056@e.ntu.edu.sg Wenbo Guo Nanyang Technological University, Singapore honywenair@gmail.com Chengwei Liu Nanyang Technological University, Singapore; China-Singapore International Joint Research Institute, China chengwei.liu@ntu.edu.sg Weisong Sun Nanyang Technological University, Singapore weisong.sun@ntu.edu.sg Yang Liu Nanyang Technological University, Singapore; China-Singapore International Joint Research Institute, China yangliu@ntu.edu.sg reverse engineering binary analysis program comprehension Binary reverse engineering is foundational to various tasks such as malware analysis and vulnerability detection. Traditional binary analysis tools mainly operate at the function level. However, modern software has grown significantly in size, with binaries often containing thousands of functions. Without understanding how these functions are organized into higher-level structures, it becomes difficult to effectively support downstream analysis tasks. Analysts must examine thousands of functions separately, making the process time-consuming and error-prone. Despite these challenges, current research on recovering the higher-level structure of binaries remains limited. To bridge this gap, we propose BinStruct, a novel binary structure recovery framework that recovers both file and module structures from binaries. BinStruct first identifies the file structure by combining data reference patterns, function calls, and semantic understanding from Large Language Models. Then, inspired by software architecture recovery in source code analysis, BinStruct identifies modules by clustering the recovered files using consensus between structural dependency and semantic similarity. Evaluation on 121 real-world stripped binaries demonstrates that BinStruct outperforms state-of-the-art techniques in both file and module recovery accuracy, while requiring only 7.42s and 34.46s on average to recover file and module structures, respectively. Case studies on Libxml2 and PredatorTheStealer demonstrate BinStruct's effectiveness on security tasks like attack surface analysis and malware investigation.",
							"pageNumber": 648,
							"isPageNumberRoman": false
						},
						{
							"eid": "76zq1kpjoRvBSgHt0d9pJx",
							"type": "authorPaper",
							"text": "United We Stand: Towards End-to-End Log-Based Fault Diagnosis via Interactive Multi-Task Learning",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a661/573300a661.pdf",
							"extraLocations": [],
							"authorNames": "Minghua He (Peking University, China), Chiming Duan (Peking University, China), Pei Xiao (Peking University, China), Tong Jia (Peking University, China; National Key Laboratory of Data Space Technology and System, China), Siyu Yu (Peking University, China), Lingzhe Zhang (Peking University, China), Weijie Hong (Peking University, China), Jin Han (ZTE Corporation, China), Yifan Wu (Peking University, China), Ying Li (Peking University, China), Gang Huang (Peking University, China)",
							"abstract": "Log-based fault diagnosis is essential for maintaining software system availability. However, existing fault diagnosis methods are built using a task-independent manner, which fails to bridge the gap between anomaly detection and root cause localization in terms of data form and diagnostic objectives, resulting in three major issues: 1) Diagnostic bias accumulates in the system; 2) System deployment relies on expensive monitoring data; 3) The collaborative relationship between diagnostic tasks is overlooked. Facing this problems, we propose a novel end-to-end log-based fault diagnosis method, Chimera, whose key idea is to achieve end-to-end fault diagnosis through bidirectional interaction and knowledge transfer between anomaly detection and root cause localization. Chimera is based on interactive multi-task learning, carefully designing interaction strategies between anomaly detection and root cause localization at the data, feature, and diagnostic result levels, thereby achieving both sub-tasks interactively within a unified end-to-end framework. Evaluation on two public datasets and one industrial dataset shows that Chimera outperforms existing methods in both anomaly detection and root cause localization, achieving improvements of over 2.92%~5.00% and 19.01%~37.09%, respectively. It has been successfully deployed in production, serving an industrial cloud platform.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 United We Stand: Towards End-to-End Log-Based Fault Diagnosis via Interactive Multi-Task Learning 1756025232784 10.1109/ASE63991.2025.00061 Minghua He Peking University, China hemh2120@stu.pku.edu.cn Chiming Duan Peking University, China duanchiming@stu.pku.edu.cn Pei Xiao Peking University, China xiaopei@stu.pku.edu.cn Tong Jia Peking University, China; National Key Laboratory of Data Space Technology and System, China jia.tong@pku.edu.cn Siyu Yu Peking University, China yusiyu@stu.pku.edu.cn Lingzhe Zhang Peking University, China zhang.lingzhe@stu.pku.edu.cn Weijie Hong Peking University, China hongwj@stu.pku.edu.cn Jin Han ZTE Corporation, China han.jing28@zte.com.cn Yifan Wu Peking University, China yifanwu@pku.edu.cn Ying Li Peking University, China li.ying@pku.edu.cn Gang Huang Peking University, China hg@pku.edu.cn Fault Diagnosis Log Analysis Root Cause Localization Multi-Task Learning Log-based fault diagnosis is essential for maintaining software system availability. However, existing fault diagnosis methods are built using a task-independent manner, which fails to bridge the gap between anomaly detection and root cause localization in terms of data form and diagnostic objectives, resulting in three major issues: 1) Diagnostic bias accumulates in the system; 2) System deployment relies on expensive monitoring data; 3) The collaborative relationship between diagnostic tasks is overlooked. Facing this problems, we propose a novel end-to-end log-based fault diagnosis method, Chimera, whose key idea is to achieve end-to-end fault diagnosis through bidirectional interaction and knowledge transfer between anomaly detection and root cause localization. Chimera is based on interactive multi-task learning, carefully designing interaction strategies between anomaly detection and root cause localization at the data, feature, and diagnostic result levels, thereby achieving both sub-tasks interactively within a unified end-to-end framework. Evaluation on two public datasets and one industrial dataset shows that Chimera outperforms existing methods in both anomaly detection and root cause localization, achieving improvements of over 2.92%~5.00% and 19.01%~37.09%, respectively. It has been successfully deployed in production, serving an industrial cloud platform.",
							"pageNumber": 661,
							"isPageNumberRoman": false
						},
						{
							"eid": "LjCZLrqujn5w1UQAfM1tN",
							"type": "authorPaper",
							"text": "Triangle: Empowering Incident Triage with Multi-Agent",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a674/573300a674.pdf",
							"extraLocations": [],
							"authorNames": "Zhaoyang Yu (Tsinghua University), Aoyang Fang (The Chinese University of Hong Hong, Shenzhen), Minghua Ma (Microsoft), Jaskaran Singh Walia (Microsoft, Beijing), Chaoyun Zhang (Microsoft, Beijing), Shu Chi (Tsinghua University), Ze Li (Microsoft), Murali Chintalapati (Microsoft), Xuchao  Zhang (Microsoft), Rujia Wang (Microsoft), Chetan Bansal (Microsoft), Saravan Rajmohan (Microsoft), Qingwei Lin (Microsoft, Beijing), Shenglin Zhang (Nankai University), Dan Pei (Tsinghua University), Pinjia  He (The Chinese University of Hong Kong, Shenzhen)",
							"abstract": "As cloud service systems grow in scale and complexity, incidents that indicate unplanned interruptions and outages become unavoidable. Rapid and accurate triage of these incidents to the appropriate responsible teams is crucial to maintain service reliability and prevent significant financial losses. However, existing incident triage methods relying on manual operations and predefined rules often struggle with efficiency and accuracy due to the heterogeneity of incident data and the dynamic nature of domain knowledge across multiple teams. To solve these issues, we propose Triangle, an end-to-end incident triage system based on a Multi-Agent framework. Triangle leverages a semantic distillation mechanism to tackle the issue of semantic heterogeneity in incident data, enhancing the accuracy of incident triage. Additionally, we introduce multi-role agents and a negotiation mechanism to emulate human engineers' workflows, effectively handling decentralized and dynamic domain knowledge from multiple teams. Furthermore, our system incorporates an automated troubleshooting information collection and mitigation mechanism, reducing the reliance on human labor and enabling fully automated end-to-end incident triage. Extensive experiments conducted on a real-world cloud production environment demonstrate that Triangle significantly improved incident triage accuracy (up to 97%) and reduced Time to Engage (TTE) by as much as 91%, demonstrating substantial operational impact across diverse cloud services.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Triangle: Empowering Incident Triage with Multi-Agent 1759297372468 10.1109/ASE63991.2025.00062 Zhaoyang Yu Tsinghua University yu-zy20@mails.tsinghua.edu.cn Aoyang Fang The Chinese University of Hong Hong, Shenzhen aoyangfang@link.cuhk.edu.cn Minghua Ma Microsoft minghuama@microsoft.com Jaskaran Singh Walia Microsoft, Beijing t-jwalia@microsoft.com Chaoyun Zhang Microsoft, Beijing chaoyun.zhang@microsoft.com Shu Chi Tsinghua University chis22@mails.tsinghua.edu.cn Ze Li Microsoft zeli@microsoft.com Murali Chintalapati Microsoft muralic@microsoft.com Xuchao Zhang Microsoft xuchaozhang@microsoft.com Rujia Wang Microsoft rujiawang@microsoft.com Chetan Bansal Microsoft chetanb@microsoft.com Saravan Rajmohan Microsoft saravan.rajmohan@microsoft.com Qingwei Lin Microsoft, Beijing qlin@microsoft.com Shenglin Zhang Nankai University zhangsl@nankai.edu.cn Dan Pei Tsinghua University peidan@tsinghua.edu.cn Pinjia He The Chinese University of Hong Kong, Shenzhen hepinjia@cuhk.edu.cn incident management As cloud service systems grow in scale and complexity, incidents that indicate unplanned interruptions and outages become unavoidable. Rapid and accurate triage of these incidents to the appropriate responsible teams is crucial to maintain service reliability and prevent significant financial losses. However, existing incident triage methods relying on manual operations and predefined rules often struggle with efficiency and accuracy due to the heterogeneity of incident data and the dynamic nature of domain knowledge across multiple teams. To solve these issues, we propose Triangle, an end-to-end incident triage system based on a Multi-Agent framework. Triangle leverages a semantic distillation mechanism to tackle the issue of semantic heterogeneity in incident data, enhancing the accuracy of incident triage. Additionally, we introduce multi-role agents and a negotiation mechanism to emulate human engineers' workflows, effectively handling decentralized and dynamic domain knowledge from multiple teams. Furthermore, our system incorporates an automated troubleshooting information collection and mitigation mechanism, reducing the reliance on human labor and enabling fully automated end-to-end incident triage. Extensive experiments conducted on a real-world cloud production environment demonstrate that Triangle significantly improved incident triage accuracy (up to 97%) and reduced Time to Engage (TTE) by as much as 91%, demonstrating substantial operational impact across diverse cloud services.",
							"pageNumber": 674,
							"isPageNumberRoman": false
						},
						{
							"eid": "7tdmuPiHZSgC90GdJjy0Ks",
							"type": "authorPaper",
							"text": "Navigating the Labyrinth: Path-Sensitive Unit Test Generation with Large Language Models",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a687/573300a687.pdf",
							"extraLocations": [],
							"authorNames": "Dianshu Liao (The Australian National University, Australia), Xin Yin (The State Key Laboratory of Blockchain and Data Security, Zhejiang University, China), Shidong Pan (CSIRO\u2019s Data61, Australia), Chao Ni (Zhejiang University, China), Zhenchang Xing (CSIRO\u2019s Data61, Australia), Xiaoyu Sun (The Australian National University, Australia)",
							"abstract": "Unit testing is essential for software quality assurance, yet writing and maintaining tests remains time-consuming and error-prone. To address this challenge, researchers have proposed various techniques for automating unit test generation, including traditional heuristic-based methods and more recent approaches that leverage large language models (LLMs). However, these existing approaches are inherently path-insensitive because they rely on fixed heuristics or limited contextual information and fail to reason about deep control-flow structures. As a result, they often struggle to achieve adequate coverage, particularly for deep or complex execution paths. In this work, we present a path-sensitive framework, JUnitGenie, to fill this gap by combining code knowledge with the semantic capabilities of LLMs in guiding context-aware unit test generation. After extracting code knowledge from Java projects, JUnitGenie distills this knowledge into structured prompts to guide the generation of high-coverage unit tests. We evaluate JUnitGenie on 2,258 complex focal methods from ten real-world Java projects. The results show that JUnitGenie generates valid tests and improves branch and line coverage by 29.60% and 31.00% on average over both heuristic and LLM-based baselines. We further demonstrate that the generated test cases can uncover real-world bugs, which were later confirmed and fixed by developers.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Navigating the Labyrinth: Path-Sensitive Unit Test Generation with Large Language Models 1759311461960 10.1109/ASE63991.2025.00063 Dianshu Liao The Australian National University, Australia dianshu.liao@anu.edu.au Xin Yin The State Key Laboratory of Blockchain and Data Security, Zhejiang University, China xyin@zju.edu.cn Shidong Pan CSIRO\u2019s Data61, Australia shidong.pan@data61.csiro.au Chao Ni Zhejiang University, China chaoni@zju.edu.cn Zhenchang Xing CSIRO\u2019s Data61, Australia zhenchang.xing@data61.csiro.au Xiaoyu Sun The Australian National University, Australia xiaoyu.sun1@anu.edu.au unit test generation large language models path-sensitive analysis ai for se Unit testing is essential for software quality assurance, yet writing and maintaining tests remains time-consuming and error-prone. To address this challenge, researchers have proposed various techniques for automating unit test generation, including traditional heuristic-based methods and more recent approaches that leverage large language models (LLMs). However, these existing approaches are inherently path-insensitive because they rely on fixed heuristics or limited contextual information and fail to reason about deep control-flow structures. As a result, they often struggle to achieve adequate coverage, particularly for deep or complex execution paths. In this work, we present a path-sensitive framework, JUnitGenie, to fill this gap by combining code knowledge with the semantic capabilities of LLMs in guiding context-aware unit test generation. After extracting code knowledge from Java projects, JUnitGenie distills this knowledge into structured prompts to guide the generation of high-coverage unit tests. We evaluate JUnitGenie on 2,258 complex focal methods from ten real-world Java projects. The results show that JUnitGenie generates valid tests and improves branch and line coverage by 29.60% and 31.00% on average over both heuristic and LLM-based baselines. We further demonstrate that the generated test cases can uncover real-world bugs, which were later confirmed and fixed by developers.",
							"pageNumber": 687,
							"isPageNumberRoman": false
						},
						{
							"eid": "2YUGy3t7vmdnopx6Eq4u5T",
							"type": "authorPaper",
							"text": "LogAction: Consistent Cross-System Anomaly Detection Through Logs via Active Domain Adaptation",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a700/573300a700.pdf",
							"extraLocations": [],
							"authorNames": "Chiming Duan (Peking University, China), Minghua He (Peking University, China), Pei Xiao (Peking University, China), Tong Jia (Peking University, China; National Key Laboratory of Data Space Technology and System, China), Xin Zhang (Bytedance, China), Zhewei Zhong (Bytedance, China), Xiang Luo (Bytedance, China), Yan Niu (Bytedance, China), Lingzhe Zhang (Peking University, China), Siyu Yu (Peking University, China), Yifan Wu (Peking University, China), Weijie Hong (Peking University, China), Ying Li (Peking University, China;), Gang Huang (National Key Laboratory of Data Space Technology and System, China)",
							"abstract": "Log-based anomaly detection is a essential task for ensuring the reliability and performance of software systems. However, the performance of existing anomaly detection methods heavily relies on labeling, while labeling a large volume of logs is highly challenging. To address this issue, many approaches based on transfer learning and active learning have been proposed. Nevertheless, their effectiveness is hindered by issues such as the gap between source and target system data distributions and cold-start problems. In this paper, we propose LogAction, a novel log-based anomaly detection model based on active domain adaptation. LogAction integrates transfer learning and active learning techniques. On one hand, it uses labeled data from a mature system to train a base model, mitigating the cold-start issue in active learning. On the other hand, LogAction utilize free energy-based sampling and uncertainty-based sampling to select logs located at the distribution boundaries for manual labeling, thus addresses the data distribution gap in transfer learning with minimal human labeling efforts. Experimental results on six different combinations of datasets demonstrate that LogAction achieves an average 93.01% F1 score with only 2% of manual labels, outperforming some state-of-the-art methods by 26.28%. Website: https://logaction.github.io",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 LogAction: Consistent Cross-System Anomaly Detection Through Logs via Active Domain Adaptation 1759992672551 10.1109/ASE63991.2025.00064 Chiming Duan Peking University, China duanchiming@stu.pku.edu.cn Minghua He Peking University, China hemh2120@stu.pku.edu.cn Pei Xiao Peking University, China xiaopei@stu.pku.edu.cn Tong Jia Peking University, China; National Key Laboratory of Data Space Technology and System, China jia.tong@pku.edu.cn Xin Zhang Bytedance, China zhangxin.11@bytedance.com Zhewei Zhong Bytedance, China zhongzhewei@bytedance.com Xiang Luo Bytedance, China luoxiang.10@bytedance.com Yan Niu Bytedance, China niuyan.13@bytedance.com Lingzhe Zhang Peking University, China zhang.lingzhe@stu.pku.edu.cn Siyu Yu Peking University, China gaiusyu6@gmail.com Yifan Wu Peking University, China yifanwu@pku.edu.cn Weijie Hong Peking University, China hongwj@stu.pku.edu.cn Ying Li Peking University, China; li.ying@pku.edu.cn Gang Huang National Key Laboratory of Data Space Technology and System, China hg@pku.edu.cn anomaly detection log analysis active learning domain adaptation Log-based anomaly detection is a essential task for ensuring the reliability and performance of software systems. However, the performance of existing anomaly detection methods heavily relies on labeling, while labeling a large volume of logs is highly challenging. To address this issue, many approaches based on transfer learning and active learning have been proposed. Nevertheless, their effectiveness is hindered by issues such as the gap between source and target system data distributions and cold-start problems. In this paper, we propose LogAction, a novel log-based anomaly detection model based on active domain adaptation. LogAction integrates transfer learning and active learning techniques. On one hand, it uses labeled data from a mature system to train a base model, mitigating the cold-start issue in active learning. On the other hand, LogAction utilize free energy-based sampling and uncertainty-based sampling to select logs located at the distribution boundaries for manual labeling, thus addresses the data distribution gap in transfer learning with minimal human labeling efforts. Experimental results on six different combinations of datasets demonstrate that LogAction achieves an average 93.01% F1 score with only 2% of manual labels, outperforming some state-of-the-art methods by 26.28%. Website: https://logaction.github.io",
							"pageNumber": 700,
							"isPageNumberRoman": false
						},
						{
							"eid": "4OvRGhCicCMWdbJT7lNxCw",
							"type": "authorPaper",
							"text": "When Control Flows Deviate: Directed Grey-box Fuzzing with Probabilistic Reachability Analysis",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a713/573300a713.pdf",
							"extraLocations": [],
							"authorNames": "Peihong  Lin (National University of Defense Technology), Pengfei Wang (National University of Defense Technology), Xu Zhou (National University of Defense Technology), Wei Xie (National University of Defense Technology), Xin  Ren (National University of Defense Technology), Kai Lu (National University of Defense Technology)",
							"abstract": "Directed grey-box fuzzing (DGF) steers testing toward high-value targets, but developing effective DGF for commercial off-the-shelf (COTS) binaries is challenging due to the lack of accurate structural information (e.g., control-flow graphs and call graphs), which can cause control flows to deviate and misguide DGF's reachability analysis. In this paper, we introduce BinGo, a tailored binary-level directed grey-box fuzzer, which can accommodate the flawed control-flow graphs (CFGs) of COTS binaries and enable accurate and efficient reachability analysis. First, to quantify the inevitable inaccuracies of uncovered indirect edges and analyze their impact on the reachability of basic blocks, we propose a Bayesian-based method. This method combines prior knowledge from static analysis with dynamic observations from fuzzing to estimate the confidence in correctly recovering indirect edges. Then, we present a new concept called a region, which redefines granularity for efficient reachability analysis by transforming the CFG into a region graph. Using the Bayesian results and region graph, we propose a custom fitness metric for binary-level DGF, termed probabilistic reachability. This metric, based on a dynamically updated region graph and reachability scores, is adaptive, lightweight, and accommodates inaccurate binary-level CFGs. We implemented a prototype tool, BinGo, and evaluated it on the CGC dataset, CVE-Benchmark, and UniBench benchmark. Experimental results show that BinGo surpasses baseline fuzzers (AFL++, AFLGo, PDGF, UAFuzz, and 1dVul) in reaching target locations and exposing known vulnerabilities. Additionally, BinGo discovered three new vulnerabilities in the real-world application cscope-15.9.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 When Control Flows Deviate: Directed Grey-box Fuzzing with Probabilistic Reachability Analysis 1758595479895 10.1109/ASE63991.2025.00065 Peihong Lin National University of Defense Technology phlin22@nudt.edu.cn Pengfei Wang National University of Defense Technology pfwang@nudt.edu.cn Xu Zhou National University of Defense Technology zhouxu@nudt.edu.cn Wei Xie National University of Defense Technology xiewei@nudt.edu.cn Xin Ren National University of Defense Technology renxin@nudt.edu.cn Kai Lu National University of Defense Technology kailu@nudt.edu.cn software security directed grey-box fuzzing region probabilistic reachability Directed grey-box fuzzing (DGF) steers testing toward high-value targets, but developing effective DGF for commercial off-the-shelf (COTS) binaries is challenging due to the lack of accurate structural information (e.g., control-flow graphs and call graphs), which can cause control flows to deviate and misguide DGF's reachability analysis. In this paper, we introduce BinGo, a tailored binary-level directed grey-box fuzzer, which can accommodate the flawed control-flow graphs (CFGs) of COTS binaries and enable accurate and efficient reachability analysis. First, to quantify the inevitable inaccuracies of uncovered indirect edges and analyze their impact on the reachability of basic blocks, we propose a Bayesian-based method. This method combines prior knowledge from static analysis with dynamic observations from fuzzing to estimate the confidence in correctly recovering indirect edges. Then, we present a new concept called a region, which redefines granularity for efficient reachability analysis by transforming the CFG into a region graph. Using the Bayesian results and region graph, we propose a custom fitness metric for binary-level DGF, termed probabilistic reachability. This metric, based on a dynamically updated region graph and reachability scores, is adaptive, lightweight, and accommodates inaccurate binary-level CFGs. We implemented a prototype tool, BinGo, and evaluated it on the CGC dataset, CVE-Benchmark, and UniBench benchmark. Experimental results show that BinGo surpasses baseline fuzzers (AFL++, AFLGo, PDGF, UAFuzz, and 1dVul) in reaching target locations and exposing known vulnerabilities. Additionally, BinGo discovered three new vulnerabilities in the real-world application cscope-15.9.",
							"pageNumber": 713,
							"isPageNumberRoman": false
						},
						{
							"eid": "1tao2paGbXrM7RfTWWHFFO",
							"type": "authorPaper",
							"text": "Improving LLM-Based Log Parsing by Learning from Errors in Reasoning Traces",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a726/573300a726.pdf",
							"extraLocations": [],
							"authorNames": "Jialai Wang (National University of Singapore, Singapore), Juncheng Lu (Southeast University, China), Jie Yang (Wuhan University, China), Junjie Wang (Wuhan University, China), Zeyu Gao (Tsinghua University, China), Chao Zhang (Tsinghua University, China), Zhenkai  Liang (National University of Singapore, Singapore), Ee-Chien  Chang (National University of Singapore, Singapore)",
							"abstract": "Recent advances in reasoning-capable large language models (LLMs) have led to their application in a wide range of tasks, including log parsing. These LLMs generate intermediate reasoning traces during inference, offering a unique opportunity to analyze and improve their performance. In this work, we investigate how reasoning traces can be leveraged to enhance LLM-based log parsers. We propose TraceDoctor, a framework that analyzes reasoning traces associated with parsing errors to understand the causes of failure. We categorize these error causes into high-level error types and design targeted log variant generation strategies guided by these high-level error types. The generated variants are then used to fine-tune the LLMs. We instantiate five state-of-the-art (SOTA) reasoning-capable LLMs as log parsers and identify 29 distinct high-level error types. Our approach improves their average parsing accuracy by up to 17.3% and 16.3% on parsing accuracy (PA) and group accuracy (GA), respectively.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Improving LLM-Based Log Parsing by Learning from Errors in Reasoning Traces 1758890690482 10.1109/ASE63991.2025.00066 Jialai Wang National University of Singapore, Singapore wangjialai97@gmail.com Juncheng Lu Southeast University, China 213221523@seu.edu.cn Jie Yang Wuhan University, China 2022302181128@whu.edu.cn Junjie Wang Wuhan University, China sanowip@gmail.com Zeyu Gao Tsinghua University, China gaozy22@mails.tsinghua.edu.cn Chao Zhang Tsinghua University, China chaoz@tsinghua.edu.cn Zhenkai Liang National University of Singapore, Singapore liangzk@comp.nus.edu.sg Ee-Chien Chang National University of Singapore, Singapore changec@comp.nus.edu.sg log parsing large language models Recent advances in reasoning-capable large language models (LLMs) have led to their application in a wide range of tasks, including log parsing. These LLMs generate intermediate reasoning traces during inference, offering a unique opportunity to analyze and improve their performance. In this work, we investigate how reasoning traces can be leveraged to enhance LLM-based log parsers. We propose TraceDoctor, a framework that analyzes reasoning traces associated with parsing errors to understand the causes of failure. We categorize these error causes into high-level error types and design targeted log variant generation strategies guided by these high-level error types. The generated variants are then used to fine-tune the LLMs. We instantiate five state-of-the-art (SOTA) reasoning-capable LLMs as log parsers and identify 29 distinct high-level error types. Our approach improves their average parsing accuracy by up to 17.3% and 16.3% on parsing accuracy (PA) and group accuracy (GA), respectively.",
							"pageNumber": 726,
							"isPageNumberRoman": false
						},
						{
							"eid": "3ppBhyUmlLgUiNlMyDtEGo",
							"type": "authorPaper",
							"text": "Watson: A Cognitive Observability Framework for the Reasoning of LLM-Powered Agents",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a739/573300a739.pdf",
							"extraLocations": [],
							"authorNames": "Benjamin Rombaut (Centre for Software Excellence, Huawei Canada), Sogol Masoumzadeh (Centre for Software Excellence, Huawei Canada; McGill University, Canada), Kirill Vasilevski (Centre for Software Excellence, Huawei Canada), Dayi Lin (Centre for Software Excellence, Huawei Canada), Ahmed E. Hassan (Queen's University, Canada)",
							"abstract": "Large language models (LLMs) are increasingly integrated into autonomous systems, giving rise to a new class of software known as Agentware, where LLM-powered agents perform complex, open-ended tasks in domains such as software engineering, customer service, and data analysis. However, their high autonomy and opaque reasoning processes pose significant challenges for traditional software observability methods. To address this, we introduce the concept of cognitive observability - the ability to recover and inspect the implicit reasoning behind agent decisions. We present Watson, a general-purpose framework for observing the reasoning processes of fast-thinking LLM agents without altering their behavior. Watson retroactively infers reasoning traces using prompt attribution techniques. We evaluate Watson in both manual debugging and automated correction scenarios across the MMLU benchmark and the AutoCodeRover and OpenHands agents on the SWE-bench-lite dataset. In both static and dynamic settings, Watson surfaces actionable reasoning insights and supports targeted interventions, demonstrating its practical utility for improving transparency and reliability in Agentware systems.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Watson: A Cognitive Observability Framework for the Reasoning of LLM-Powered Agents 1759530824261 10.1109/ASE63991.2025.00067 Benjamin Rombaut Centre for Software Excellence, Huawei Canada ben.rombaut@huawei.com Sogol Masoumzadeh Centre for Software Excellence, Huawei Canada; McGill University, Canada sogol.masoumzadeh@mail.mcgill.ca Kirill Vasilevski Centre for Software Excellence, Huawei Canada kirill.vasilevski@huawei.com Dayi Lin Centre for Software Excellence, Huawei Canada dayi.lin@huawei.com Ahmed E. Hassan Queen's University, Canada ahmed@cs.queensu.ca observability foundation models large language models aiware fmware Large language models (LLMs) are increasingly integrated into autonomous systems, giving rise to a new class of software known as Agentware, where LLM-powered agents perform complex, open-ended tasks in domains such as software engineering, customer service, and data analysis. However, their high autonomy and opaque reasoning processes pose significant challenges for traditional software observability methods. To address this, we introduce the concept of cognitive observability - the ability to recover and inspect the implicit reasoning behind agent decisions. We present Watson, a general-purpose framework for observing the reasoning processes of fast-thinking LLM agents without altering their behavior. Watson retroactively infers reasoning traces using prompt attribution techniques. We evaluate Watson in both manual debugging and automated correction scenarios across the MMLU benchmark and the AutoCodeRover and OpenHands agents on the SWE-bench-lite dataset. In both static and dynamic settings, Watson surfaces actionable reasoning insights and supports targeted interventions, demonstrating its practical utility for improving transparency and reliability in Agentware systems.",
							"pageNumber": 739,
							"isPageNumberRoman": false
						},
						{
							"eid": "15FR62dwVnWROqDEL4NQPT",
							"type": "authorPaper",
							"text": "Speculative Automated Refactoring of Imperative Deep Learning Programs to Graph Execution",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a752/573300a752.pdf",
							"extraLocations": [],
							"authorNames": "Raffi Khatchadourian (City University of New York (CUNY) Hunter College; CUNY Graduate Center), Tatiana Castro V\u00E9lez (CUNY Graduate Center), Mehdi Bagherzadeh (Oakland University), Nan Jia (CUNY Graduate Center), Anita Raja (City University of New York (CUNY) Hunter College; CUNY Graduate Center)",
							"abstract": "Efficiency is essential to support ever-growing datasets, especially for Deep Learning (DL) systems. DL frameworks have traditionally embraced deferred execution-style DL code\u2014supporting symbolic, graph-based Deep Neural Network (DNN) computation. While scalable, such development is error-prone, non-intuitive, and difficult to debug. Consequently, more natural, imperative DL frameworks encouraging eager execution have emerged but at the expense of run-time performance. Though hybrid approaches aim for the \"best of both worlds,\" using them effectively requires subtle considerations. Our key insight is that, while DL programs typically execute sequentially, hybridizing imperative DL code resembles parallelizing sequential code in traditional systems. Inspired by this, we present an automated refactoring approach that assists developers in determining which otherwise eagerly-executed imperative DL functions could be effectively and efficiently executed as graphs. The approach features novel static imperative tensor and side-effect analyses for Python. Due to its inherent dynamism, analyzing Python may be unsound; however, the conservative approach leverages a speculative (keyword-based) analysis for resolving difficult cases that informs developers of any assumptions made. The approach is: (i) implemented as a plug-in to the PyDev Eclipse IDE that integrates the WALA Ariadne analysis framework and (ii) evaluated on nineteen DL projects consisting of 132 KLOC. The results show that 326 of 766 candidate functions (42.56%) were refactorable, and an average relative speedup of 2.16x on performance tests was observed with negligible differences in model accuracy. The results indicate that the approach is useful in optimizing imperative DL code to its full potential.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Speculative Automated Refactoring of Imperative Deep Learning Programs to Graph Execution 1758993598692 10.1109/ASE63991.2025.00068 Raffi Khatchadourian City University of New York (CUNY) Hunter College; CUNY Graduate Center khatchad@hunter.cuny.edu Tatiana Castro V\u00E9lez CUNY Graduate Center tcastrovelez@gradcenter.cuny.edu Mehdi Bagherzadeh Oakland University mbagherzadeh@oakland.edu Nan Jia CUNY Graduate Center njia@gradcenter.cuny.edu Anita Raja City University of New York (CUNY) Hunter College; CUNY Graduate Center anita.raja@hunter.cuny.edu deep learning refactoring imperative programs hybrid programming paradigms graph execution Efficiency is essential to support ever-growing datasets, especially for Deep Learning (DL) systems. DL frameworks have traditionally embraced deferred execution-style DL code\u2014supporting symbolic, graph-based Deep Neural Network (DNN) computation. While scalable, such development is error-prone, non-intuitive, and difficult to debug. Consequently, more natural, imperative DL frameworks encouraging eager execution have emerged but at the expense of run-time performance. Though hybrid approaches aim for the \"best of both worlds,\" using them effectively requires subtle considerations. Our key insight is that, while DL programs typically execute sequentially, hybridizing imperative DL code resembles parallelizing sequential code in traditional systems. Inspired by this, we present an automated refactoring approach that assists developers in determining which otherwise eagerly-executed imperative DL functions could be effectively and efficiently executed as graphs. The approach features novel static imperative tensor and side-effect analyses for Python. Due to its inherent dynamism, analyzing Python may be unsound; however, the conservative approach leverages a speculative (keyword-based) analysis for resolving difficult cases that informs developers of any assumptions made. The approach is: (i) implemented as a plug-in to the PyDev Eclipse IDE that integrates the WALA Ariadne analysis framework and (ii) evaluated on nineteen DL projects consisting of 132 KLOC. The results show that 326 of 766 candidate functions (42.56%) were refactorable, and an average relative speedup of 2.16x on performance tests was observed with negligible differences in model accuracy. The results indicate that the approach is useful in optimizing imperative DL code to its full potential.",
							"pageNumber": 752,
							"isPageNumberRoman": false
						},
						{
							"eid": "QvKzrP753NrQUjzDwSm2C",
							"type": "authorPaper",
							"text": "DualFuzz: Detecting Vulnerability in Wi-Fi NICs through Dual-Directional Fuzzing",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a765/573300a765.pdf",
							"extraLocations": [],
							"authorNames": "Yuanliang Chen (Tsinghua University, China), Fuchen Ma (Tsinghua University, China), Yanyang Zhao (Tsinghua University, China), Yuanyi Li (Tsinghua University, China), Yu Jiang (Tsinghua University, China)",
							"abstract": "Wi-Fi Network Interface Cards (NICs) are vital for enabling wireless connectivity across a wide range of devices. Ensuring their security is critical, as vulnerabilities can expose entire networks to threats. Fuzzing is a promising technique for detecting such flaws. However, existing Wi-Fi fuzzers typically test transmission and reception separately, overlooking their interactions and resulting in inefficient testing. In this work, we present DualFuzz, a dual-directional fuzzing framework designed to simultaneously test both transmission and reception processes in Wi-Fi NICs. First, DualFuzz automatically identifies interaction behaviors within Wi-Fi NICs and constructs a Transmission-Reception Model (TRModel) to characterize Wi-Fi frames that influence these interactions. Leveraging this model, DualFuzz utilizes latency guided fuzzing to efficiently coordinate exploring transmission and reception interaction logics. Finally, we propose liveness and equivalence detectors that enable real-time monitoring to identify abnormal states and uncover potential vulnerabilities in Wi-Fi NICs. We implemented and evaluated DualFuzz on eight widely used Wi-Fi NICs, incorporating chipsets from various manufacturers (e.g., Intel and Realtek). Compared to state-of-the-art Wi-Fi fuzzers like OwFuzz, wpaspy, and Greyhound, DualFuzz detects 75%, 163%, and 250% more vulnerabilities, respectively. In total, it uncovered 21 previously unknown vulnerabilities, 7 of which have been assigned CVEs.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 DualFuzz: Detecting Vulnerability in Wi-Fi NICs through Dual-Directional Fuzzing 1755484476823 10.1109/ASE63991.2025.00069 Yuanliang Chen Tsinghua University, China sard.chen@gmail.com Fuchen Ma Tsinghua University, China fuchenma525@gmail.com Yanyang Zhao Tsinghua University, China zhaoyanyoung@163.com Yuanyi Li Tsinghua University, China liyuanyi@shuimuyulin.com Yu Jiang Tsinghua University, China jiangyu198964@126.com Wi-Fi NIC vulnerability detection fuzzing Wi-Fi Network Interface Cards (NICs) are vital for enabling wireless connectivity across a wide range of devices. Ensuring their security is critical, as vulnerabilities can expose entire networks to threats. Fuzzing is a promising technique for detecting such flaws. However, existing Wi-Fi fuzzers typically test transmission and reception separately, overlooking their interactions and resulting in inefficient testing. In this work, we present DualFuzz, a dual-directional fuzzing framework designed to simultaneously test both transmission and reception processes in Wi-Fi NICs. First, DualFuzz automatically identifies interaction behaviors within Wi-Fi NICs and constructs a Transmission-Reception Model (TRModel) to characterize Wi-Fi frames that influence these interactions. Leveraging this model, DualFuzz utilizes latency guided fuzzing to efficiently coordinate exploring transmission and reception interaction logics. Finally, we propose liveness and equivalence detectors that enable real-time monitoring to identify abnormal states and uncover potential vulnerabilities in Wi-Fi NICs. We implemented and evaluated DualFuzz on eight widely used Wi-Fi NICs, incorporating chipsets from various manufacturers (e.g., Intel and Realtek). Compared to state-of-the-art Wi-Fi fuzzers like OwFuzz, wpaspy, and Greyhound, DualFuzz detects 75%, 163%, and 250% more vulnerabilities, respectively. In total, it uncovered 21 previously unknown vulnerabilities, 7 of which have been assigned CVEs.",
							"pageNumber": 765,
							"isPageNumberRoman": false
						},
						{
							"eid": "1mpWgE7uD28Jq5FXWP1xlg",
							"type": "authorPaper",
							"text": "DrainCode: Stealthy Energy Consumption Attacks on Retrieval-Augmented Code Generation via Context Poisoning",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a778/573300a778.pdf",
							"extraLocations": [],
							"authorNames": "Yanlin Wang (Sun Yat-sen University, China), Jiadong Wu (Sun Yat-sen University, China), Tianyue Jiang (Sun Yat-sen University, China), Mingwei Liu (Sun Yat-sen University, China), Jiachi Chen (Sun Yat-sen University, China), Chong Wang (Nanyang Technological University, Singapore), Ensheng Shi (Huawei Cloud Computing Technologies Co., Ltd., China), Xilin Liu (Huawei Cloud Computing Technologies Co., Ltd, China), Yuchi Ma (Huawei Cloud Computing Technologies Co., Ltd., China), Zibin Zheng (Sun Yat-sen University, China)",
							"abstract": "Large language models (LLMs) have demonstrated impressive capabilities in code generation, by leveraging retrieval-augmented generation (RAG) methods. However, the computational costs associated with LLM inference, particularly in terms of latency and energy consumption, have received limited attention in the security context. This paper introduces DrainCode, the first adversarial attack targeting the computational efficiency of RAG-based code generation systems. By strategically poisoning retrieval contexts through mutation-based approach, DrainCode: forces LLMs to produce significantly longer outputs, thereby increasing GPU latency and energy consumption. We evaluate the effectiveness of DrainCode: across multiple models. Our experiments show that DrainCode achieves up to an 85% increase in latency, a 49% increase in energy consumption, and more than a 3\u00D7 increase in output length compared to the baseline. Furthermore, we demonstrate the generalizability of the attack across different prompting strategies and its effectiveness compared to different defenses. The results highlight DrainCode as a potential method for increasing the computational overhead of LLMs, making it useful for evaluating LLM security in resource-constrained environments. We provide code and data at https://anonymous.4open.science/r/DrainCode-E07.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 DrainCode: Stealthy Energy Consumption Attacks on Retrieval-Augmented Code Generation via Context Poisoning 1759573760771 10.1109/ASE63991.2025.00070 Yanlin Wang Sun Yat-sen University, China wangylin36@mail.sysu.edu.cn Jiadong Wu Sun Yat-sen University, China wujd28@mail.sysu.edu.cn Tianyue Jiang Sun Yat-sen University, China jiangty9@mail.sysu.edu.cn Mingwei Liu Sun Yat-sen University, China liumw2686@mail.sysu.edu.cn Jiachi Chen Sun Yat-sen University, China chenjch86@mail.sysu.edu.cn Chong Wang Nanyang Technological University, Singapore chong.wang@ntu.edu.sg Ensheng Shi Huawei Cloud Computing Technologies Co., Ltd., China shiensheng@huawei.com Xilin Liu Huawei Cloud Computing Technologies Co., Ltd, China liuxilin3@huawei.com Yuchi Ma Huawei Cloud Computing Technologies Co., Ltd., China mayuchi1@huawei.com Zibin Zheng Sun Yat-sen University, China zhzibin@mail.sysu.edu.cn energy consumption attacks code generation large language models Large language models (LLMs) have demonstrated impressive capabilities in code generation, by leveraging retrieval-augmented generation (RAG) methods. However, the computational costs associated with LLM inference, particularly in terms of latency and energy consumption, have received limited attention in the security context. This paper introduces DrainCode, the first adversarial attack targeting the computational efficiency of RAG-based code generation systems. By strategically poisoning retrieval contexts through mutation-based approach, DrainCode: forces LLMs to produce significantly longer outputs, thereby increasing GPU latency and energy consumption. We evaluate the effectiveness of DrainCode: across multiple models. Our experiments show that DrainCode achieves up to an 85% increase in latency, a 49% increase in energy consumption, and more than a 3\u00D7 increase in output length compared to the baseline. Furthermore, we demonstrate the generalizability of the attack across different prompting strategies and its effectiveness compared to different defenses. The results highlight DrainCode as a potential method for increasing the computational overhead of LLMs, making it useful for evaluating LLM security in resource-constrained environments. We provide code and data at https://anonymous.4open.science/r/DrainCode-E07.",
							"pageNumber": 778,
							"isPageNumberRoman": false
						},
						{
							"eid": "1sNOB5xfLhmexxjpPSDtAA",
							"type": "authorPaper",
							"text": "Hit The Bullseye On The First Shot: Improving LLMs Using Multi-Sample Self-Reward Feedback for Vulnerability Repair",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a791/573300a791.pdf",
							"extraLocations": [],
							"authorNames": "Rui Jiao (Xidian University, China), Yue Zhang (Shandong University, China), Jinku Li (Xidian University, China), Jianfeng Ma (Xidian University, China)",
							"abstract": "In recent years, large language models (LLMs) have emerged as powerful tools to assist developers in various coding tasks, including the challenging domain of vulnerability repair. While these models have demonstrated significant potential in generating patches for software vulnerabilities, current approaches often suffer from limitations in precision, requiring multiple attempts to produce accurate fixes. In this paper, we propose MUSSEL (Multi-Sample Self-Reward Feedback), a novel framework designed to address the issue of one-shot vulnerability patching. Inspired by insights from human learning mechanisms, our approach aims to enhance the efficiency and accuracy of LLMs in generating precise patches for software vulnerabilities. We introduce a multi-stage training process, beginning with supervised fine-tuning using domain-specific data to impart foundational knowledge in vulnerability repair to the LLM. Subsequently, we employ self-reward feedback learning to refine the model's patch generation capabilities, leveraging correct and incorrect patches iteratively to improve performance. We also introduce a novel prompt design tailored to better align with the capabilities of LLMs during inference. Our results demonstrate that MUSSEL consistently outperforms state-of-the-art solutions in one-shot queries. Notably, even with a small beam size, MUSSEL exhibits remarkable efficiency, requiring minimal GPU memory resources. Furthermore, MUSSEL's effectiveness across diverse CWEs underscores its significant security implications.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Hit The Bullseye On The First Shot: Improving LLMs Using Multi-Sample Self-Reward Feedback for Vulnerability Repair 1759298709756 10.1109/ASE63991.2025.00071 Rui Jiao Xidian University, China jiaorui@stu.xidian.edu.cn Yue Zhang Shandong University, China zyueinfosec@gmail.com Jinku Li Xidian University, China jkli@xidian.edu.cn Jianfeng Ma Xidian University, China jfma@mail.xidian.edu.cn large language models vulnerability repair In recent years, large language models (LLMs) have emerged as powerful tools to assist developers in various coding tasks, including the challenging domain of vulnerability repair. While these models have demonstrated significant potential in generating patches for software vulnerabilities, current approaches often suffer from limitations in precision, requiring multiple attempts to produce accurate fixes. In this paper, we propose MUSSEL (Multi-Sample Self-Reward Feedback), a novel framework designed to address the issue of one-shot vulnerability patching. Inspired by insights from human learning mechanisms, our approach aims to enhance the efficiency and accuracy of LLMs in generating precise patches for software vulnerabilities. We introduce a multi-stage training process, beginning with supervised fine-tuning using domain-specific data to impart foundational knowledge in vulnerability repair to the LLM. Subsequently, we employ self-reward feedback learning to refine the model's patch generation capabilities, leveraging correct and incorrect patches iteratively to improve performance. We also introduce a novel prompt design tailored to better align with the capabilities of LLMs during inference. Our results demonstrate that MUSSEL consistently outperforms state-of-the-art solutions in one-shot queries. Notably, even with a small beam size, MUSSEL exhibits remarkable efficiency, requiring minimal GPU memory resources. Furthermore, MUSSEL's effectiveness across diverse CWEs underscores its significant security implications.",
							"pageNumber": 791,
							"isPageNumberRoman": false
						},
						{
							"eid": "58TFiokZCUKkm1JVNuhFAA",
							"type": "authorPaper",
							"text": "Let the Code Speak: Incorporating Program Dynamic State for Better Method-Level Fault Localization",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a804/573300a804.pdf",
							"extraLocations": [],
							"authorNames": "Yihao Qin (National University of Defense Technology, China), Shangwen Wang (National University of Defense Technology, China), Bo Lin (National University of Defense Technology, China), Xin Peng (National University of Defense Technology, China), Sheng Ouyang (National University of Defense Technology, China), Liqian Chen (National University of Defense Technology, China), Xiaoguang Mao (National University of Defense Technology, China)",
							"abstract": "Fault localization (FL) is a critical but time-consuming part of software debugging. With the continuous improvement of the Large Language Models (LLMs) in their code capabilities, the increasing demand for automated software development and maintenance has encouraged more researchers to focus on building LLM-based Fault Localization (LLMFL) systems. However, existing LLMFL techniques are typically restricted to predicting bug locations by analyzing static code, while overlooking crucial dynamic program state of the software. This lack of context makes LLMs prone to generating \"hallucinations\", incorrectly identifying bug-free code as suspicious. To address this, this paper introduces PingFL, the first LLMFL system that incorporates print debugging techniques for more accurate fault localization. PingFL comprises a Fault Localization (FL) agent and a Print Debugging (PD) agent. The FL agent is tasked with understanding the root cause through a set of callable tools. When the FL agent nominates a location as suspicious, it would entrust the PD agent to verify the suspected issue through multiple rounds of print debugging. In particular, these two agents communicate and collaborate efficiently by conveying the textual thought generated by the LLM. The evaluation on 812 real-world bugs from the Defects4J benchmark shows that PingFL can localize 450 bugs within Top-1, which significantly outperforms other LLM-based approaches by 41% to 122%. It also consistently surpasses traditional FL techniques in cross-project scenarios. A deeper dive into PingFL's performance reveals that it exhibits specific FL strategies and tool usage patterns even without explicit instructions. Finally, PingFL proves to be cost-effective, spending an average of $0.23 and 104.62 seconds per bug, with the print debugging mechanism accounting for only $0.07 and 48.14 seconds.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Let the Code Speak: Incorporating Program Dynamic State for Better Method-Level Fault Localization 1756545883446 10.1109/ASE63991.2025.00072 Yihao Qin National University of Defense Technology, China yihaoqin@nudt.edu.cn Shangwen Wang National University of Defense Technology, China wangshangwen13@nudt.edu.cn Bo Lin National University of Defense Technology, China linbo19@nudt.edu.cn Xin Peng National University of Defense Technology, China xinpeng@nudt.edu.cn Sheng Ouyang National University of Defense Technology, China ouyangsheng23@nudt.edu.cn Liqian Chen National University of Defense Technology, China lqchen@nudt.edu.cn Xiaoguang Mao National University of Defense Technology, China xgmao@nudt.edu.cn large language model fault localization print debugging Fault localization (FL) is a critical but time-consuming part of software debugging. With the continuous improvement of the Large Language Models (LLMs) in their code capabilities, the increasing demand for automated software development and maintenance has encouraged more researchers to focus on building LLM-based Fault Localization (LLMFL) systems. However, existing LLMFL techniques are typically restricted to predicting bug locations by analyzing static code, while overlooking crucial dynamic program state of the software. This lack of context makes LLMs prone to generating \"hallucinations\", incorrectly identifying bug-free code as suspicious. To address this, this paper introduces PingFL, the first LLMFL system that incorporates print debugging techniques for more accurate fault localization. PingFL comprises a Fault Localization (FL) agent and a Print Debugging (PD) agent. The FL agent is tasked with understanding the root cause through a set of callable tools. When the FL agent nominates a location as suspicious, it would entrust the PD agent to verify the suspected issue through multiple rounds of print debugging. In particular, these two agents communicate and collaborate efficiently by conveying the textual thought generated by the LLM. The evaluation on 812 real-world bugs from the Defects4J benchmark shows that PingFL can localize 450 bugs within Top-1, which significantly outperforms other LLM-based approaches by 41% to 122%. It also consistently surpasses traditional FL techniques in cross-project scenarios. A deeper dive into PingFL's performance reveals that it exhibits specific FL strategies and tool usage patterns even without explicit instructions. Finally, PingFL proves to be cost-effective, spending an average of $0.23 and 104.62 seconds per bug, with the print debugging mechanism accounting for only $0.07 and 48.14 seconds.",
							"pageNumber": 804,
							"isPageNumberRoman": false
						},
						{
							"eid": "FaWe4SfiTARAtpPRO8SlQ",
							"type": "authorPaper",
							"text": "Execution-Aware Program Reduction for WebAssembly via Record and Replay",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a816/573300a816.pdf",
							"extraLocations": [],
							"authorNames": "Doehyun Baek (University of Stuttgart, Germany), Daniel Lehmann (Google Germany GmbH, Germany), Ben L. Titzer (Carnegie Mellon University, USA), Sukyoung Ryu (KAIST, South Korea), Michael Pradel (CISPA Helmholtz Center for Information Security, Germnay)",
							"abstract": "WebAssembly (Wasm) programs may trigger bugs in their engine implementations. To aid debugging, program reduction techniques try to produce a smaller variant of the input program that still triggers the bug. However, existing execution-unaware program reduction techniques struggle with large and complex Wasm programs, because they rely on static information and apply syntactic transformations, while ignoring the valuable information offered by the input program's execution behavior. We present RR-Reduce and Hybrid-Reduce, novel execution-aware program reduction techniques that leverage execution behaviors via record and replay. RR-Reduce identifies a bug-triggering function as the target function, isolates that function from the rest of the program, and generates a reduced program that replays only the interactions between the target function and the rest of the program. Hybrid-Reduce combines a complementary execution-unaware reduction technique with RR-Reduce to further reduce program size. We evaluate RRReduce and Hybrid-Reduce on 28 Wasm programs that trigger a diverse set of bugs in three engines. On average, RR-Reduce reduces the programs to 1.20% of their original size in 14.5 minutes, which outperforms the state of the art by 33.15\u00D7 in terms of reduction time. Hybrid-Reduce reduces the programs to 0.13% of their original size in 3.5 hours, which outperforms the state of the art by 3.42\u00D7 in terms of reduced program size and 2.26\u00D7 in terms of reduction time. We envision RR-Reduce as the go-to tool for rapid, on-demand debugging in minutes, and Hybrid-Reduce for scenarios where developers require the smallest possible programs.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Execution-Aware Program Reduction for WebAssembly via Record and Replay 1759043486782 10.1109/ASE63991.2025.00073 Doehyun Baek University of Stuttgart, Germany doehyunbaek@gmail.com Daniel Lehmann Google Germany GmbH, Germany mail@dlehmann.eu Ben L. Titzer Carnegie Mellon University, USA btitzer@andrew.cmu.edu Sukyoung Ryu KAIST, South Korea sryu.cs@kaist.ac.kr Michael Pradel CISPA Helmholtz Center for Information Security, Germnay michael@binaervarianz.de webassembly program reduction record and replay WebAssembly (Wasm) programs may trigger bugs in their engine implementations. To aid debugging, program reduction techniques try to produce a smaller variant of the input program that still triggers the bug. However, existing execution-unaware program reduction techniques struggle with large and complex Wasm programs, because they rely on static information and apply syntactic transformations, while ignoring the valuable information offered by the input program's execution behavior. We present RR-Reduce and Hybrid-Reduce, novel execution-aware program reduction techniques that leverage execution behaviors via record and replay. RR-Reduce identifies a bug-triggering function as the target function, isolates that function from the rest of the program, and generates a reduced program that replays only the interactions between the target function and the rest of the program. Hybrid-Reduce combines a complementary execution-unaware reduction technique with RR-Reduce to further reduce program size. We evaluate RRReduce and Hybrid-Reduce on 28 Wasm programs that trigger a diverse set of bugs in three engines. On average, RR-Reduce reduces the programs to 1.20% of their original size in 14.5 minutes, which outperforms the state of the art by 33.15\u00D7 in terms of reduction time. Hybrid-Reduce reduces the programs to 0.13% of their original size in 3.5 hours, which outperforms the state of the art by 3.42\u00D7 in terms of reduced program size and 2.26\u00D7 in terms of reduction time. We envision RR-Reduce as the go-to tool for rapid, on-demand debugging in minutes, and Hybrid-Reduce for scenarios where developers require the smallest possible programs.",
							"pageNumber": 816,
							"isPageNumberRoman": false
						},
						{
							"eid": "2VRlwi7nyWO99pSW6dhE3z",
							"type": "authorPaper",
							"text": "Repairing Leaks in Resource Wrappers",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a828/573300a828.pdf",
							"extraLocations": [],
							"authorNames": "Sanjay Malakar (University of California, USA), Michael D. Ernst (University of Washington, USA), Martin Kellogg (New Jersey Institute of Technology, USA), Manu Sridharan (University of California, Riverside, USA)",
							"abstract": "A resource leak occurs when a program fails to release a finite resource like a socket, file descriptor or database connection. While sound static analysis tools can detect all leaks, automatically repairing them remains challenging. Prior work took the output of a detection tool and attempted to repair only leaks from a hard-coded list of library resource types. That approach limits the scope of repairable leaks: real-world code uses resource wrappers that store a resource in a field and must themselves be closed. This paper makes four key contributions to improve resource leak repair in the presence of wrappers. (1) It integrates inference of resource management specifications into the repair pipeline, enabling extant fixing approaches to reason about wrappers. (2) It transforms programs into variants that are easier to analyze, making inference, detection, and fixing tools more effective; for instance, it makes detection tools report problems closer to the root cause, often in a client of a resource wrapper rather than within the wrapper class itself. (3) A novel field containment analysis reasons about resource lifetimes, enabling repair of more leaks involving resources stored in fields. (4) It introduces a new repair pattern and more precise reasoning to better handle resources stored in non-final fields. Prior work fixed 41% of resource leak warnings in the NJR benchmark suite; our implementation Arodnap fixes 68%.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Repairing Leaks in Resource Wrappers 1759341794256 10.1109/ASE63991.2025.00074 Sanjay Malakar University of California, USA smala009@ucr.edu Michael D. Ernst University of Washington, USA mernst@cs.washington Martin Kellogg New Jersey Institute of Technology, USA martin.kellogg@njit.edu Manu Sridharan University of California, Riverside, USA manu@cs.ucr.edu program repair resource leaks A resource leak occurs when a program fails to release a finite resource like a socket, file descriptor or database connection. While sound static analysis tools can detect all leaks, automatically repairing them remains challenging. Prior work took the output of a detection tool and attempted to repair only leaks from a hard-coded list of library resource types. That approach limits the scope of repairable leaks: real-world code uses resource wrappers that store a resource in a field and must themselves be closed. This paper makes four key contributions to improve resource leak repair in the presence of wrappers. (1) It integrates inference of resource management specifications into the repair pipeline, enabling extant fixing approaches to reason about wrappers. (2) It transforms programs into variants that are easier to analyze, making inference, detection, and fixing tools more effective; for instance, it makes detection tools report problems closer to the root cause, often in a client of a resource wrapper rather than within the wrapper class itself. (3) A novel field containment analysis reasons about resource lifetimes, enabling repair of more leaks involving resources stored in fields. (4) It introduces a new repair pattern and more precise reasoning to better handle resources stored in non-final fields. Prior work fixed 41% of resource leak warnings in the NJR benchmark suite; our implementation Arodnap fixes 68%.",
							"pageNumber": 828,
							"isPageNumberRoman": false
						},
						{
							"eid": "50XG3LE1sgdEfiaPqBhLvC",
							"type": "authorPaper",
							"text": "PseudoFix: Refactoring Distorted Structures in Decompiled C Pseudocode",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a841/573300a841.pdf",
							"extraLocations": [],
							"authorNames": "Gangyang Li (University of Science and Technology of China, China), Xiuwei Shang (University of Science and Technology of China, China), Shaoyin Cheng (University of Science and Technology of China, China; Anhui Province Key Laboratory of Digital Security, China), Junqi Zhang (University of Science and Technology of China, China; Anhui Province Key Laboratory of Digital Security, China), Li Hu (University of Science and Technology of China, China), Xu Zhu (University of Science and Technology of China, China), Weiming Zhang (University of Science and Technology of China, China; Anhui Province Key Laboratory of Digital Security, China), NengHai Yu (University of Science and Technology of China, China; Anhui Province Key Laboratory of Digital Security, China)",
							"abstract": "Decompilation can convert binary programs into clear C-style pseudocode, which is of great value in a wide range of security applications. Existing research primarily focuses on recovering symbolic information in pseudocode, such as function names, variable names, and data types, but neglecting structural information. We observe that even when symbolic information is fully preserved, severe and complex structure distortions remain in the pseudocode, greatly impairing code readability and comprehension. In this work, we first systematically investigate structure distortions in decompiled pseudocode, revealing their variation patterns through quantitative analysis. Using open coding, we derive a taxonomy comprising six top-level categories of structure distortions. Building upon this taxonomy, we propose PseudoFix, a novel framework that combines large language models (LLMs) with retrieval-based in-context learning. PseudoFix employs semantic retrieval to select the most relevant few-shot examples that provide structure distortion knowledge, and combines this with the well-structured coding patterns learned by LLMs from vast source code repositories, to efficiently refactor distorted pseudocode. Comprehensive evaluations demonstrate that PseudoFix significantly improves pseudocode readability, achieving up to a 34% reduction in Halstead Complexity Effort and a 105% increase in BLEU-4 score. Notably, it significantly outperforms state-of-the-art approaches in both temporary variable elimination and goto statement removal tasks. Additionally, human evaluations yield consistently positive feedback from users across readability, consistency, and reasonability.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 PseudoFix: Refactoring Distorted Structures in Decompiled C Pseudocode 1759251408336 10.1109/ASE63991.2025.00075 Gangyang Li University of Science and Technology of China, China ligangyang@mail.ustc.edu.cn Xiuwei Shang University of Science and Technology of China, China shangxw@mail.ustc.edu.cn Shaoyin Cheng University of Science and Technology of China, China; Anhui Province Key Laboratory of Digital Security, China sycheng@ustc.edu.cn Junqi Zhang University of Science and Technology of China, China; Anhui Province Key Laboratory of Digital Security, China jqzh@ustc.edu.cn Li Hu University of Science and Technology of China, China pdxbshx@mail.ustc.edu.cn Xu Zhu University of Science and Technology of China, China zhuxu24@mail.ustc.edu.cn Weiming Zhang University of Science and Technology of China, China; Anhui Province Key Laboratory of Digital Security, China zhangwm@ustc.edu.cn NengHai Yu University of Science and Technology of China, China; Anhui Province Key Laboratory of Digital Security, China ynh@ustc.edu.cn decompilation refactor structure distortion taxonomy in-context learning large language models Decompilation can convert binary programs into clear C-style pseudocode, which is of great value in a wide range of security applications. Existing research primarily focuses on recovering symbolic information in pseudocode, such as function names, variable names, and data types, but neglecting structural information. We observe that even when symbolic information is fully preserved, severe and complex structure distortions remain in the pseudocode, greatly impairing code readability and comprehension. In this work, we first systematically investigate structure distortions in decompiled pseudocode, revealing their variation patterns through quantitative analysis. Using open coding, we derive a taxonomy comprising six top-level categories of structure distortions. Building upon this taxonomy, we propose PseudoFix, a novel framework that combines large language models (LLMs) with retrieval-based in-context learning. PseudoFix employs semantic retrieval to select the most relevant few-shot examples that provide structure distortion knowledge, and combines this with the well-structured coding patterns learned by LLMs from vast source code repositories, to efficiently refactor distorted pseudocode. Comprehensive evaluations demonstrate that PseudoFix significantly improves pseudocode readability, achieving up to a 34% reduction in Halstead Complexity Effort and a 105% increase in BLEU-4 score. Notably, it significantly outperforms state-of-the-art approaches in both temporary variable elimination and goto statement removal tasks. Additionally, human evaluations yield consistently positive feedback from users across readability, consistency, and reasonability.",
							"pageNumber": 841,
							"isPageNumberRoman": false
						},
						{
							"eid": "1VAxnucKDMnHlih5PuuP2W",
							"type": "authorPaper",
							"text": "DLBENCH: A Comprehensive Benchmark for SQL Translation with Large Language Models",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a854/573300a854.pdf",
							"extraLocations": [],
							"authorNames": "Li Lin (Xiamen University, China), Hongqiao Chen (Xiamen University, China), Qinglin Zhu (Xiamen University, China), Liehang Chen (Xiamen University, China), Linlong Tang (Xiamen University, China), Rongxin Wu (Xiamen University, China)",
							"abstract": "In recent years, the growing complexity of database management systems (DBMSs) and the proliferation of SQL dialects have created significant challenges for database migration, federation, and integration. These challenges arise from the disparities between SQL dialects across different DBMSs, hindering seamless communication and system interoperability. SQL translation, the process of converting SQL queries from a source dialect DBMS to a target dialect DBMS, plays a crucial role in addressing these challenges. To facilitate this process, we introduce DLBENCH, the first comprehensive benchmark designed to evaluate the SQL translation capabilities of Large Language Models (LLMs). The benchmark includes two datasets: BIRDTRANS, which covers real-world database query scenarios across seven DBMSs, and BUTTERTRANS, which spans a broader spectrum of SQL types and encompasses extensive DBMS dialect features. We collect high-quality databases and SQL statements, applying a rigorous multi-step cleaning process that ensures data quality through SQL-92\u2013based checks and dialect-specific parser validation. Additionally, both LLM-based and human annotations are used to guarantee the correctness and completeness of the dataset. We demonstrate the utility of DLBENCH through extensive experiments, which show that the benchmark effectively evaluates the SQL translation ability of LLMs. The results highlight the potential of LLMs for SQL translation tasks and provide insights into areas for further improvement.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 DLBENCH: A Comprehensive Benchmark for SQL Translation with Large Language Models 1758844753791 10.1109/ASE63991.2025.00076 Li Lin Xiamen University, China linli1210@stu.xmu.edu.cn Hongqiao Chen Xiamen University, China 23020241154371@stu.xmu.edu.cn Qinglin Zhu Xiamen University, China 23020241154481@stu.xmu.edu.cn Liehang Chen Xiamen University, China 2320415112@qq.com Linlong Tang Xiamen University, China Tangll114514@gmail.com Rongxin Wu Xiamen University, China wurongxin@xmu.edu.cn sql translation sql dialect benchmark In recent years, the growing complexity of database management systems (DBMSs) and the proliferation of SQL dialects have created significant challenges for database migration, federation, and integration. These challenges arise from the disparities between SQL dialects across different DBMSs, hindering seamless communication and system interoperability. SQL translation, the process of converting SQL queries from a source dialect DBMS to a target dialect DBMS, plays a crucial role in addressing these challenges. To facilitate this process, we introduce DLBENCH, the first comprehensive benchmark designed to evaluate the SQL translation capabilities of Large Language Models (LLMs). The benchmark includes two datasets: BIRDTRANS, which covers real-world database query scenarios across seven DBMSs, and BUTTERTRANS, which spans a broader spectrum of SQL types and encompasses extensive DBMS dialect features. We collect high-quality databases and SQL statements, applying a rigorous multi-step cleaning process that ensures data quality through SQL-92\u2013based checks and dialect-specific parser validation. Additionally, both LLM-based and human annotations are used to guarantee the correctness and completeness of the dataset. We demonstrate the utility of DLBENCH through extensive experiments, which show that the benchmark effectively evaluates the SQL translation ability of LLMs. The results highlight the potential of LLMs for SQL translation tasks and provide insights into areas for further improvement.",
							"pageNumber": 854,
							"isPageNumberRoman": false
						},
						{
							"eid": "Ibtoce6eOkgIraXBecrYf",
							"type": "authorPaper",
							"text": "An Empirical Study of Python Library Migration Using Large Language Models",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a867/573300a867.pdf",
							"extraLocations": [],
							"authorNames": "Mohayeminul Islam (University of Alberta, Canada), Ajay Kumar  Jha (North Dakota State University, USA), May Mahmoud (New York University Abu Dhabi, United Arab Emirates), Ildar Akhmetov (Northeastern University, Canada), Sarah Nadi (New York University Abu Dhabi, United Arab Emirates)",
							"abstract": "Library migration is the process of replacing one library with another library that provides similar functionality. Manual library migration is time consuming and error prone, as it requires developers to understand the APIs of both libraries, map them, and perform the necessary code transformations. Due to its difficulty, most of the existing automated techniques and tooling stop at the API mapping stage or support a limited set of code transformations. On the other hand, Large Language Models (LLMs) are good at generating and transforming code and finding similar code, which are necessary upstream tasks for library migration. Such capabilities suggest that LLMs may be suitable for library migration. Accordingly, this paper investigates the effectiveness of LLMs for migration between Python libraries. We evaluate three LLMs, LLama 3.1, GPT-4o mini, and GPT-4o on PYMIGBENCH, where we migrate 321 real-world library migrations that include 2,989 migration-related code changes. To measure correctness, we (1) compare the LLM's migrated code with the developers' migrated code in the benchmark and (2) run the unit tests available in the client repositories. We find that LLama 3.1, GPT-4o mini, and GPT-4o correctly migrate 89%, 89%, and 94% of the migration-related code changes, respectively. We also find that 36%, 52% and 64% of the LLama 3.1, GPT-4o mini, and GPT-4o migrations pass the same tests that passed in the developer's migration. To ensure the LLMs are not reciting the migrations, we also evaluate them on 10 new repositories where the migration never happened. Overall, our results suggest that LLMs can be effective in migrating code between libraries, but we also identify some open challenges.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 An Empirical Study of Python Library Migration Using Large Language Models 1759501548177 10.1109/ASE63991.2025.00077 Mohayeminul Islam University of Alberta, Canada mohayemin@ualberta.ca Ajay Kumar Jha North Dakota State University, USA ajay.jha.1@ndsu.edu May Mahmoud New York University Abu Dhabi, United Arab Emirates m.mahmoud@nyu.edu Ildar Akhmetov Northeastern University, Canada i.akhmetov@northeastern.edu Sarah Nadi New York University Abu Dhabi, United Arab Emirates sarah.nadi@nyu.edu library migration python llm Library migration is the process of replacing one library with another library that provides similar functionality. Manual library migration is time consuming and error prone, as it requires developers to understand the APIs of both libraries, map them, and perform the necessary code transformations. Due to its difficulty, most of the existing automated techniques and tooling stop at the API mapping stage or support a limited set of code transformations. On the other hand, Large Language Models (LLMs) are good at generating and transforming code and finding similar code, which are necessary upstream tasks for library migration. Such capabilities suggest that LLMs may be suitable for library migration. Accordingly, this paper investigates the effectiveness of LLMs for migration between Python libraries. We evaluate three LLMs, LLama 3.1, GPT-4o mini, and GPT-4o on PYMIGBENCH, where we migrate 321 real-world library migrations that include 2,989 migration-related code changes. To measure correctness, we (1) compare the LLM's migrated code with the developers' migrated code in the benchmark and (2) run the unit tests available in the client repositories. We find that LLama 3.1, GPT-4o mini, and GPT-4o correctly migrate 89%, 89%, and 94% of the migration-related code changes, respectively. We also find that 36%, 52% and 64% of the LLama 3.1, GPT-4o mini, and GPT-4o migrations pass the same tests that passed in the developer's migration. To ensure the LLMs are not reciting the migrations, we also evaluate them on 10 new repositories where the migration never happened. Overall, our results suggest that LLMs can be effective in migrating code between libraries, but we also identify some open challenges.",
							"pageNumber": 867,
							"isPageNumberRoman": false
						},
						{
							"eid": "56dDTMtVyBqYb8t2Ct9pFM",
							"type": "authorPaper",
							"text": "APPBDS: LLM-Powered Description Synthesis for Sensitive Behaviors in Mobile Apps",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a880/573300a880.pdf",
							"extraLocations": [],
							"authorNames": "Zichen Liu (Arizona State University, USA), Xusheng Xiao (Arizona State University, USA)",
							"abstract": "As mobile applications (i.e., apps) increasingly manage a wide variety of user needs, their access to sensitive data intensifies privacy concerns among users. While app markets employ permissions to regulate private data access, the lack of explanation for permission usage renders this mechanism less effective. Existing techniques that extract explanatory sentences from app descriptions to inform users about sensitive behaviors are also limited. Many app behaviors remain unexplained in app descriptions. To address these issues, we propose APPBDS, a novel approach that integrates program analysis with Large Language Models (LLMs) to process code semantics and UI contexts, further complemented by privacy policies and information from similar apps, in order to generate detailed explanations for apps' sensitive behaviors. Specifically, APPBDS integrates code semantics with UI contexts to build a UI-Fused Call Graph (UCG) for each app. Additionally, APPBDS summarizes permission-related propositions from privacy policies and utilizes similar apps' information from a knowledge base (PP-KB) to improve LLMs' domain knowledge in explaining permission usage. Our evaluation on 270 real-world apps demonstrates that APPBDS significantly outperforms state-of-the-art approaches in richness, specificity, and semantic relatedness, while also proving highly robust against common code obfuscation.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 APPBDS: LLM-Powered Description Synthesis for Sensitive Behaviors in Mobile Apps 1759463464933 10.1109/ASE63991.2025.00078 Zichen Liu Arizona State University, USA zliu396@asu.edu Xusheng Xiao Arizona State University, USA xusheng.xiao@asu.edu As mobile applications (i.e., apps) increasingly manage a wide variety of user needs, their access to sensitive data intensifies privacy concerns among users. While app markets employ permissions to regulate private data access, the lack of explanation for permission usage renders this mechanism less effective. Existing techniques that extract explanatory sentences from app descriptions to inform users about sensitive behaviors are also limited. Many app behaviors remain unexplained in app descriptions. To address these issues, we propose APPBDS, a novel approach that integrates program analysis with Large Language Models (LLMs) to process code semantics and UI contexts, further complemented by privacy policies and information from similar apps, in order to generate detailed explanations for apps' sensitive behaviors. Specifically, APPBDS integrates code semantics with UI contexts to build a UI-Fused Call Graph (UCG) for each app. Additionally, APPBDS summarizes permission-related propositions from privacy policies and utilizes similar apps' information from a knowledge base (PP-KB) to improve LLMs' domain knowledge in explaining permission usage. Our evaluation on 270 real-world apps demonstrates that APPBDS significantly outperforms state-of-the-art approaches in richness, specificity, and semantic relatedness, while also proving highly robust against common code obfuscation.",
							"pageNumber": 880,
							"isPageNumberRoman": false
						},
						{
							"eid": "1uWdMf80KcmbFWkUXGJHuU",
							"type": "authorPaper",
							"text": "LineBreaker: Finding Token-Inconsistency Bugs with Large Language Models",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a893/573300a893.pdf",
							"extraLocations": [],
							"authorNames": "Hongbo Chen (Indiana University Bloomington, USA), Yifan Zhang (San Diego State University, USA ; Samsung Research America), Xing Han (The Hong Kong University of Science and Technology, China), Tianhao Mao (Indiana University Bloomington, USA), Huanyao Rong (Indiana University Bloomington, USA), Yuheng Zhang (Tsinghua University, China), XiaoFeng Wang (Nanyang Technological University, Singapore), Luyi Xing (Indiana University Bloomington, USA; University of Illinois Urbana-Champaign, USA), Xun Chen (Independent researcher; Samsung Research America), Hang Zhang (Indiana University Bloomington, USA)",
							"abstract": "Token-inconsistency bugs (TIBs) involve the misuse of syntactically valid yet incorrect code tokens, such as misused variables and erroneous function invocations, which can often lead to software bugs. Unlike simple syntactic bugs, TIBs occur at the semantic level and are subtle - sometimes remain undetected for years. Traditional detection methods, such as static analysis and dynamic testing, often struggle with TIBs due to their versatile and context-dependent nature. However, advancements in large language models (LLMs) like GPT-4 present new opportunities for automating TIB detection by leveraging these models' semantic understanding capabilities. This paper reports the first systematic measurement of LLMs' capabilities in detecting TIBs, revealing that while GPT-4 shows promise, it exhibits limitations in precision and scalability. Specifically, its detection capability is undermined by the model's tendency to focus on the code snippets that do not contain TIBs; its scalability concern arises from GPT-4's high cost and the massive amount of code requiring inspection. To address these challenges, we introduce LineBreaker, a novel and cascaded TIB detection system. LineBreaker leverages smaller, code-specific, and highly efficient language models to filter out large numbers of code snippets unlikely to contain TIBs, thereby significantly enhancing the system's performance in terms of precision, recall, and scalability. We evaluated LineBreaker on 154 Python and C GitHub repositories, each with over 1,000 stars, uncovering 123 new flaws, 45% of which could be exploited to disrupt program functionalities. Out of our 69 submitted fixes, 41 have already been confirmed or merged.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 LineBreaker: Finding Token-Inconsistency Bugs with Large Language Models 1759462470954 10.1109/ASE63991.2025.00079 Hongbo Chen Indiana University Bloomington, USA hc50@iu.edu Yifan Zhang San Diego State University, USA ; Samsung Research America yzhang24@sdsu.edu Xing Han The Hong Kong University of Science and Technology, China xhanbg@cse.ust.hk Tianhao Mao Indiana University Bloomington, USA tianmao@iu.edu Huanyao Rong Indiana University Bloomington, USA ronghua@iu.edu Yuheng Zhang Tsinghua University, China zhangyuh25@mails.tsinghua.edu.cn XiaoFeng Wang Nanyang Technological University, Singapore xiaofeng.wang@ntu.edu.sg Luyi Xing Indiana University Bloomington, USA; University of Illinois Urbana-Champaign, USA lxing2@illinois.edu Xun Chen Independent researcher; Samsung Research America xunchen@outlook.com Hang Zhang Indiana University Bloomington, USA hz64@iu.edu semantic bug large language model for security token-inconsistency bug logic bug bug detection Token-inconsistency bugs (TIBs) involve the misuse of syntactically valid yet incorrect code tokens, such as misused variables and erroneous function invocations, which can often lead to software bugs. Unlike simple syntactic bugs, TIBs occur at the semantic level and are subtle - sometimes remain undetected for years. Traditional detection methods, such as static analysis and dynamic testing, often struggle with TIBs due to their versatile and context-dependent nature. However, advancements in large language models (LLMs) like GPT-4 present new opportunities for automating TIB detection by leveraging these models' semantic understanding capabilities. This paper reports the first systematic measurement of LLMs' capabilities in detecting TIBs, revealing that while GPT-4 shows promise, it exhibits limitations in precision and scalability. Specifically, its detection capability is undermined by the model's tendency to focus on the code snippets that do not contain TIBs; its scalability concern arises from GPT-4's high cost and the massive amount of code requiring inspection. To address these challenges, we introduce LineBreaker, a novel and cascaded TIB detection system. LineBreaker leverages smaller, code-specific, and highly efficient language models to filter out large numbers of code snippets unlikely to contain TIBs, thereby significantly enhancing the system's performance in terms of precision, recall, and scalability. We evaluated LineBreaker on 154 Python and C GitHub repositories, each with over 1,000 stars, uncovering 123 new flaws, 45% of which could be exploited to disrupt program functionalities. Out of our 69 submitted fixes, 41 have already been confirmed or merged.",
							"pageNumber": 893,
							"isPageNumberRoman": false
						},
						{
							"eid": "kGhrYuqBZjkdABlS8kGW5",
							"type": "authorPaper",
							"text": "Profile Coverage: Using Android Compilation Profiles to Evaluate Dynamic Testing",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a906/573300a906.pdf",
							"extraLocations": [],
							"authorNames": "Jakob Bleier (TU Wien, Austria), Felix Kehrer (TU Wien, Austria), J\u00FCrgen Cito (TU Wien, Austria), Martina Lindorfer (TU Wien, Austria)",
							"abstract": "The rising complexity of Android apps makes comprehensive dynamic testing infeasible, especially for third-party apps. Knowing which methods are exercised by real users typically requires costly user studies or access to usage telemetry. We show that Android's compilation profiles, specifically Cloud Profiles collected by the Google Play Store, offer a readily available, underutilized source of such information. These operational profiles aggregate which methods are commonly executed across users and guide ahead-of-time compilation during app installation. We provide the first in-depth characterization of Baseline Profiles and Cloud Profiles and show that over 99.89% of the top 1000 apps include usage-derived cloud profiles. Based on this insight, we introduce profile coverage, a novel metric that measures how well dynamic testing exercises the methods real users interact with. This metric builds on the idea of operational coverage and enables a more holistic evaluation of automated test input generators. To enable profile coverage measurements, we develop a lightweight tracer, ProfTrace, based on Linux kernel uprobes that requires no app or system modifications. We demonstrate its utility by comparing three tools and a no-interaction baseline on 50 popular apps, showing that profile coverage reveals differences that traditional code coverage misses. For instance, in Candy Crush, automated testing achieves only 2.22% method coverage, but 21.39% profile coverage\u2014indicating better alignment with user behavior than traditional code coverage would suggest.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Profile Coverage: Using Android Compilation Profiles to Evaluate Dynamic Testing 1759495198074 10.1109/ASE63991.2025.00080 Jakob Bleier TU Wien, Austria jakob.bleier@seclab.wien Felix Kehrer TU Wien, Austria felix.kehrer@seclab.wien J\u00FCrgen Cito TU Wien, Austria juergen.cito@tuwien.ac.at Martina Lindorfer TU Wien, Austria martina@seclab.wien android dynamic testing code coverage profile coverage method tracing The rising complexity of Android apps makes comprehensive dynamic testing infeasible, especially for third-party apps. Knowing which methods are exercised by real users typically requires costly user studies or access to usage telemetry. We show that Android's compilation profiles, specifically Cloud Profiles collected by the Google Play Store, offer a readily available, underutilized source of such information. These operational profiles aggregate which methods are commonly executed across users and guide ahead-of-time compilation during app installation. We provide the first in-depth characterization of Baseline Profiles and Cloud Profiles and show that over 99.89% of the top 1000 apps include usage-derived cloud profiles. Based on this insight, we introduce profile coverage, a novel metric that measures how well dynamic testing exercises the methods real users interact with. This metric builds on the idea of operational coverage and enables a more holistic evaluation of automated test input generators. To enable profile coverage measurements, we develop a lightweight tracer, ProfTrace, based on Linux kernel uprobes that requires no app or system modifications. We demonstrate its utility by comparing three tools and a no-interaction baseline on 50 popular apps, showing that profile coverage reveals differences that traditional code coverage misses. For instance, in Candy Crush, automated testing achieves only 2.22% method coverage, but 21.39% profile coverage\u2014indicating better alignment with user behavior than traditional code coverage would suggest.",
							"pageNumber": 906,
							"isPageNumberRoman": false
						},
						{
							"eid": "q2KrhxCzqJQ7d2RrsyYXl",
							"type": "authorPaper",
							"text": "Lares: LLM-Driven Code Slice Semantic Search for Patch Presence Testing",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a919/573300a919.pdf",
							"extraLocations": [],
							"authorNames": "Siyuan Li ( Shandong University, China; Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China), Yaowen Zheng (Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China), Hong Li (Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China), Jingdong Guo (Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China), Chaopeng Dong (Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China), Chunpeng Yan (Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China), Weijie Wang (Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China), Yimo Ren (Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China), Limin Sun (Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China), Hongsong Zhu (Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China)",
							"abstract": "In modern software ecosystems, 1-day vulnerabilities pose significant security risks due to extensive code reuse. Identifying vulnerable functions in target binaries alone is insufficient; it is also crucial to determine whether these functions have been patched. Existing methods, however, suffer from limited usability and accuracy. They often depend on the compilation process to extract features, requiring substantial manual effort and failing for certain software. Moreover, they cannot reliably differentiate between code changes caused by patches or compilation variations. To overcome these limitations, we propose Lares, a scalable and accurate method for patch presence testing. Lares introduces Code Slice Semantic Search, which directly extracts features from the patch source code and identifies semantically equivalent code slices in the pseudocode of the target binary. By eliminating the need for the compilation process, Lares improves usability, while leveraging large language models (LLMs) for code analysis and SMT solvers for logical reasoning to enhance accuracy. Experimental results show that Lares achieves superior precision, recall, and usability. Furthermore, it is the first work to evaluate patch presence testing across optimization levels, architectures, and compilers. The datasets and source code used in this article are available at https://github.com/Siyuan-Li201/Lares.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Lares: LLM-Driven Code Slice Semantic Search for Patch Presence Testing 1759407617584 10.1109/ASE63991.2025.00081 Siyuan Li Shandong University, China; Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China siyuan@sdu.edu.cn Yaowen Zheng Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China zhengyaowen@iie.ac.cn Hong Li Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China lihong@iie.ac.cn Jingdong Guo Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China guojingdong@iie.ac.cn Chaopeng Dong Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China dongchaopeng@iie.ac.cn Chunpeng Yan Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China yanchunpeng@iie.ac.cn Weijie Wang Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China wangweijie@iie.ac.cn Yimo Ren Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China renyimo@iie.ac.cn Limin Sun Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China sunlimin@iie.ac.cn Hongsong Zhu Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China zhuhongsong@iie.ac.cn patch presence testing binary analysis large language model In modern software ecosystems, 1-day vulnerabilities pose significant security risks due to extensive code reuse. Identifying vulnerable functions in target binaries alone is insufficient; it is also crucial to determine whether these functions have been patched. Existing methods, however, suffer from limited usability and accuracy. They often depend on the compilation process to extract features, requiring substantial manual effort and failing for certain software. Moreover, they cannot reliably differentiate between code changes caused by patches or compilation variations. To overcome these limitations, we propose Lares, a scalable and accurate method for patch presence testing. Lares introduces Code Slice Semantic Search, which directly extracts features from the patch source code and identifies semantically equivalent code slices in the pseudocode of the target binary. By eliminating the need for the compilation process, Lares improves usability, while leveraging large language models (LLMs) for code analysis and SMT solvers for logical reasoning to enhance accuracy. Experimental results show that Lares achieves superior precision, recall, and usability. Furthermore, it is the first work to evaluate patch presence testing across optimization levels, architectures, and compilers. The datasets and source code used in this article are available at https://github.com/Siyuan-Li201/Lares.",
							"pageNumber": 919,
							"isPageNumberRoman": false
						},
						{
							"eid": "3RmBAVVMwMhcVTSA5pulB8",
							"type": "authorPaper",
							"text": "Exploring Static Taint Analysis in LLMs: A Dynamic Benchmarking Framework for Measurement and Enhancement",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a932/573300a932.pdf",
							"extraLocations": [],
							"authorNames": "Haoran Zhao (Fudan University), Lei Zhang (Fudan University), Keke Lian (Fudan University), Fute Sun (Fudan University), Bofei Chen (Fudan University), Yongheng Liu (Fudan University), Zhiyu Wu (Fudan University), Yuan Zhang  (Fudan University), Min Yang (Fudan University)",
							"abstract": "LLMs offer a promising avenue to overcome the limitations of traditional taint analysis techniques, with a growing number of studies leveraging LLMs for taint analysis and its downstream applications. However, these studies lack a systematic understanding of LLMs' taint analysis capabilities, limiting their transferability and reliability. To bridge this gap and better apply LLMs to static taint analysis, we aim to comprehensively measure and understand LLMs' taint analysis capabilities. Using existing benchmarks is a straightforward approach, but they are unsuitable due to issues such as training data leakage, not accounting for LLMs' features, and improper assessment criteria. Manually constructing new benchmarks is not only labor-intensive but also struggles to remain effective as LLMs evolve. To address these, we propose LLMCAPLENS, a dynamic benchmark generation framework to systematically measure and enhance LLMs' capabilities. LLMCAPLENS models influencing factors of LLMs' taint analysis capabilities, employing a Basic Unit-Based generation method and a lightweight dynamic taint analysis-based verification method to implement the automated generation of targeted benchmarks, ensuring both diversity and correctness. Furthermore, LLMCAPLENS proposes a measurement-driven, training-free, model-specific enhancement approach. We apply LLMCAPLENS to 10 mainstream LLMs, revealing how they perform under various influencing factors and identifying unique characteristics, such as the underlying error causes for each model. Notably, our enhancement approach significantly improves LLM performance\u2014GPT-4 Turbo, for instance, achieved improvements across 16 out of 19 factors, with an average True Negative Rate increase of 21.29 %. Finally, we validate the real-world impact of our method by applying enhanced LLMs to vulnerability detection, demonstrating a substantial improvement over prior approaches.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Exploring Static Taint Analysis in LLMs: A Dynamic Benchmarking Framework for Measurement and Enhancement 1759048182056 10.1109/ASE63991.2025.00082 Haoran Zhao Fudan University zhaohr23@m.fudan.edu.cn Lei Zhang Fudan University zxl@fudan.edu.cn Keke Lian Fudan University kklian20@fudan.edu.cn Fute Sun Fudan University ftsun22@m.fudan.edu.cn Bofei Chen Fudan University bfchen22@m.fudan.edu.cn Yongheng Liu Fudan University yhliu24@m.fudan.edu.cn Zhiyu Wu Fudan University wuzy24@m.fudan.edu.cn Yuan Zhang Fudan University yuanxzhang@fudan.edu.cn Min Yang Fudan University m_yang@fudan.edu.cn LLMs offer a promising avenue to overcome the limitations of traditional taint analysis techniques, with a growing number of studies leveraging LLMs for taint analysis and its downstream applications. However, these studies lack a systematic understanding of LLMs' taint analysis capabilities, limiting their transferability and reliability. To bridge this gap and better apply LLMs to static taint analysis, we aim to comprehensively measure and understand LLMs' taint analysis capabilities. Using existing benchmarks is a straightforward approach, but they are unsuitable due to issues such as training data leakage, not accounting for LLMs' features, and improper assessment criteria. Manually constructing new benchmarks is not only labor-intensive but also struggles to remain effective as LLMs evolve. To address these, we propose LLMCAPLENS, a dynamic benchmark generation framework to systematically measure and enhance LLMs' capabilities. LLMCAPLENS models influencing factors of LLMs' taint analysis capabilities, employing a Basic Unit-Based generation method and a lightweight dynamic taint analysis-based verification method to implement the automated generation of targeted benchmarks, ensuring both diversity and correctness. Furthermore, LLMCAPLENS proposes a measurement-driven, training-free, model-specific enhancement approach. We apply LLMCAPLENS to 10 mainstream LLMs, revealing how they perform under various influencing factors and identifying unique characteristics, such as the underlying error causes for each model. Notably, our enhancement approach significantly improves LLM performance\u2014GPT-4 Turbo, for instance, achieved improvements across 16 out of 19 factors, with an average True Negative Rate increase of 21.29 %. Finally, we validate the real-world impact of our method by applying enhanced LLMs to vulnerability detection, demonstrating a substantial improvement over prior approaches.",
							"pageNumber": 932,
							"isPageNumberRoman": false
						},
						{
							"eid": "6LkTPTrAAj6SxUT3pnpxLq",
							"type": "authorPaper",
							"text": "Demystifying OpenZeppelin's Own Vulnerabilities and Analyzing Their Propagation in Smart Contracts",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a945/573300a945.pdf",
							"extraLocations": [],
							"authorNames": "Han Liu (The Hong Kong University of Science and Technology, China), Daoyuan Wu (Lingnan University, China), Yuqiang Sun (Nanyang Technological University, Singapore), Shuai Wang (The Hong Kong University of Science and Technology, China), Yang Liu (Nanyang Technological University, Singapore), Yixiang Chen (East China Normal University, China)",
							"abstract": "OpenZeppelin is a building block for many smart contracts on Ethereum-compatible blockchains. It provides modular and reusable libraries for various Ethereum standards (e.g., ERC20 and ERC721) and common functionalities such as upgradeable contracts. Little research has been done on OpenZeppelin security except for a recent study, which focused only on the misuse of OpenZeppelin code, assuming OpenZeppelin itself is secure but contract developers may not follow OpenZeppelin's function checks appropriately. We argue that, despite appearing robust, OpenZeppelin itself could have many vulnerabilities, and these library-level vulnerabilities could inadvertently affect third-party smart contracts, even without misuse from developers. We present ZEPCOMPARE, the first end-to-end system for demystifying OpenZeppelin's own vulnerabilities and analyzing their propagation in third-party smart contracts. ZEPCOMPARE incorporates a manual analysis stage where we review OpenZeppelin's 64 historical releases, identifying 109 vulnerable-fixed code pairs, exposing flaws in cryptographic utilities, access control, etc. Leveraging these pairs, ZEPCOMPARE introduces facts of changes, a novel structure capturing vulnerable and fixed code contexts for flexible matching. Evaluated across 88,605 contracts from three Ethereum-compatible chains, ZEPCOMPARE detects 4,708 instances of OpenZeppelin-derived vulnerabilities. Manual sampling and a ground-truth experiment confirm that ZEPCOMPARE achieves 86.7% precision and 77.1% recall. Our findings reveal significant security risks in both historical and the latest versions of OpenZeppelin libraries, underscoring the urgent need for systematic auditing of foundational contracts components.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Demystifying OpenZeppelin's Own Vulnerabilities and Analyzing Their Propagation in Smart Contracts 1759419413137 10.1109/ASE63991.2025.00083 Han Liu The Hong Kong University of Science and Technology, China liuhan@ust.hk Daoyuan Wu Lingnan University, China daoyuanwu@ln.edu.hk Yuqiang Sun Nanyang Technological University, Singapore suny0056@e.ntu.edu.sg Shuai Wang The Hong Kong University of Science and Technology, China shuaiw@cse.ust.hk Yang Liu Nanyang Technological University, Singapore yangliu@ntu.edu.sg Yixiang Chen East China Normal University, China chenyx61@aliyun.com openzeppelin library smart contracts vulnerability propagation vulnerability detection OpenZeppelin is a building block for many smart contracts on Ethereum-compatible blockchains. It provides modular and reusable libraries for various Ethereum standards (e.g., ERC20 and ERC721) and common functionalities such as upgradeable contracts. Little research has been done on OpenZeppelin security except for a recent study, which focused only on the misuse of OpenZeppelin code, assuming OpenZeppelin itself is secure but contract developers may not follow OpenZeppelin's function checks appropriately. We argue that, despite appearing robust, OpenZeppelin itself could have many vulnerabilities, and these library-level vulnerabilities could inadvertently affect third-party smart contracts, even without misuse from developers. We present ZEPCOMPARE, the first end-to-end system for demystifying OpenZeppelin's own vulnerabilities and analyzing their propagation in third-party smart contracts. ZEPCOMPARE incorporates a manual analysis stage where we review OpenZeppelin's 64 historical releases, identifying 109 vulnerable-fixed code pairs, exposing flaws in cryptographic utilities, access control, etc. Leveraging these pairs, ZEPCOMPARE introduces facts of changes, a novel structure capturing vulnerable and fixed code contexts for flexible matching. Evaluated across 88,605 contracts from three Ethereum-compatible chains, ZEPCOMPARE detects 4,708 instances of OpenZeppelin-derived vulnerabilities. Manual sampling and a ground-truth experiment confirm that ZEPCOMPARE achieves 86.7% precision and 77.1% recall. Our findings reveal significant security risks in both historical and the latest versions of OpenZeppelin libraries, underscoring the urgent need for systematic auditing of foundational contracts components.",
							"pageNumber": 945,
							"isPageNumberRoman": false
						},
						{
							"eid": "5aYPvU11QARovFWyJ1khOM",
							"type": "authorPaper",
							"text": "iKnow: an Intent-Guided Chatbot for Cloud Operations with Retrieval-Augmented Generation",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a958/573300a958.pdf",
							"extraLocations": [],
							"authorNames": "Junjie Huang (The Chinese University of Hong Kong, China), Yuedong Zhong (The Chinese University of Hong Kong, China), Guangba Yu (The Chinese University of Hong Kong, China), Zhihan Jiang (The Chinese University of Hong Kong, China), Minzhi Yan (Huawei Cloud Computing Technology Co., Ltd, China), Wenfei Luan (Huawei Cloud Computing Technology Co., Ltd, China), Tianyu Yang (Huawei Cloud Computing Technology Co., Ltd, China), Rui Ren (Huawei Cloud Computing Technology Co., Ltd, China), Michael R. Lyu (The Chinese University of Hong Kong, China)",
							"abstract": "Managing complex cloud services requires standard operational documentation, but its sheer volume often hinders cloud engineers from efficient knowledge acquisition. Retrieval-Augmented Generation (RAG) can streamline this process by retrieving relevant knowledge and generating concise, referenced answers. However, deploying a reliable RAG-based chatbot for cloud operation remains a challenge. In this experience paper, we analyze the development and deployment of RAG-based chatbots for operational question answering (OpsQA) at a large-scale cloud vendor. Through an empirical study of 2,000 real-world queries across three operational teams, we identify five unique OpsQA intent types (e.g., symptom analysis and terminology explanation) and their corresponding requirements for a satisfactory answer, which differ from general software engineering queries. Our analysis further uncovers six root causes leading to chatbot failures\u2014over half stem from query issues (i.e., incompleteness, out-of-scope, or invalid queries), while others are from retrieval or generation issues. To address these issues, we propose iKonw, an intent-guided RAG-based chatbot that integrates intent detection, query rewriting tailored to each intent, and missing knowledge detection to enhance answer quality. In internal evaluations, iKonw improves average answer accuracy from 65.8% to 81.3% with only a modest increase in latency. iKonw has been deployed for six months at CloudA, supporting thousands of cloud engineers in daily operations. We discuss lessons learned from real-world deployment, providing valuable insights for future research and practical implementations in similar domains.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 iKnow: an Intent-Guided Chatbot for Cloud Operations with Retrieval-Augmented Generation 1759130070593 10.1109/ASE63991.2025.00084 Junjie Huang The Chinese University of Hong Kong, China jjhuang23@cse.cuhk.edu.hk Yuedong Zhong The Chinese University of Hong Kong, China helloherryadeshen@gmai.com Guangba Yu The Chinese University of Hong Kong, China guangbayu@cse.cuhk.edu.hk Zhihan Jiang The Chinese University of Hong Kong, China zhjiang22@cse.cuhk.edu.hk Minzhi Yan Huawei Cloud Computing Technology Co., Ltd, China yanminzhi@huawei.com Wenfei Luan Huawei Cloud Computing Technology Co., Ltd, China luanwenfei@outlook.com Tianyu Yang Huawei Cloud Computing Technology Co., Ltd, China norbertahp@163.com Rui Ren Huawei Cloud Computing Technology Co., Ltd, China renruirui1234@gmail.com Michael R. Lyu The Chinese University of Hong Kong, China lyu@cse.cuhk.edu.hk software operation chatbot retrieval augmented retrieval intent detection Managing complex cloud services requires standard operational documentation, but its sheer volume often hinders cloud engineers from efficient knowledge acquisition. Retrieval-Augmented Generation (RAG) can streamline this process by retrieving relevant knowledge and generating concise, referenced answers. However, deploying a reliable RAG-based chatbot for cloud operation remains a challenge. In this experience paper, we analyze the development and deployment of RAG-based chatbots for operational question answering (OpsQA) at a large-scale cloud vendor. Through an empirical study of 2,000 real-world queries across three operational teams, we identify five unique OpsQA intent types (e.g., symptom analysis and terminology explanation) and their corresponding requirements for a satisfactory answer, which differ from general software engineering queries. Our analysis further uncovers six root causes leading to chatbot failures\u2014over half stem from query issues (i.e., incompleteness, out-of-scope, or invalid queries), while others are from retrieval or generation issues. To address these issues, we propose iKonw, an intent-guided RAG-based chatbot that integrates intent detection, query rewriting tailored to each intent, and missing knowledge detection to enhance answer quality. In internal evaluations, iKonw improves average answer accuracy from 65.8% to 81.3% with only a modest increase in latency. iKonw has been deployed for six months at CloudA, supporting thousands of cloud engineers in daily operations. We discuss lessons learned from real-world deployment, providing valuable insights for future research and practical implementations in similar domains.",
							"pageNumber": 958,
							"isPageNumberRoman": false
						},
						{
							"eid": "5nJUXBIJM0PGsg6uIBR2Xj",
							"type": "authorPaper",
							"text": "AlignCoder: Aligning Retrieval with Target Intent for Repository-Level Code Completion",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a971/573300a971.pdf",
							"extraLocations": [],
							"authorNames": "Tianyue Jiang (Sun Yat-Sen University, China), Yanli Wang (Sun Yat-Sen University, China), Yanlin Wang (Sun Yat-Sen University, China), Daya Guo (Independent Researcher, China), Ensheng Shi (Huawei Cloud Computing Technologies Co., Ltd., China), Yuchi Ma (Huawei Cloud Computing Technologies Co., Ltd., China), Jiachi Chen (Sun Yat-sen University, China), Zibin Zheng (Sun Yat-sen University, China)",
							"abstract": "Repository-level code completion remains a challenging task for existing code large language models (code LLMs) due to their limited understanding of repository-specific context and domain knowledge. While retrieval-augmented generation (RAG) approaches have shown promise by retrieving relevant code snippets as cross-file context, they suffer from two fundamental problems: misalignment between the query and the target code in the retrieval process, and the inability of existing retrieval methods to effectively utilize the inference information. To address these challenges, we propose AlignCoder, a repository-level code completion framework that introduces a query enhancement mechanism and a reinforcement learning based retriever training method. Our approach generates multiple candidate completions to construct an enhanced query that bridges the semantic gap between the initial query and the target code. Additionally, we employ reinforcement learning to train an AlignRetriever that learns to leverage inference information in the enhanced query for more accurate retrieval. We evaluate AlignCoder on two widely-used benchmarks (CrossCodeEval and RepoEval) across five backbone code LLMs, demonstrating an 18.1% improvement in EM score compared to baselines on the CrossCodeEval benchmark. The results show that our framework achieves superior performance and exhibits high generalizability across various code LLMs and programming languages.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 AlignCoder: Aligning Retrieval with Target Intent for Repository-Level Code Completion 1759576014063 10.1109/ASE63991.2025.00085 Tianyue Jiang Sun Yat-Sen University, China jiangty9@mail2.sysu.edu.cn Yanli Wang Sun Yat-Sen University, China wangyli58@mail2.sysu.edu.cn Yanlin Wang Sun Yat-Sen University, China yanlin-wang@outlook.com Daya Guo Independent Researcher, China guody5@mail2.sysu.edu.cn Ensheng Shi Huawei Cloud Computing Technologies Co., Ltd., China shiensheng@huawei.com Yuchi Ma Huawei Cloud Computing Technologies Co., Ltd., China mayuchi1@huawei.com Jiachi Chen Sun Yat-sen University, China chenjch86@mail.sysu.edu.cn Zibin Zheng Sun Yat-sen University, China zhzibin@mail.sysu.edu.cn large language models software development assistant Repository-level code completion remains a challenging task for existing code large language models (code LLMs) due to their limited understanding of repository-specific context and domain knowledge. While retrieval-augmented generation (RAG) approaches have shown promise by retrieving relevant code snippets as cross-file context, they suffer from two fundamental problems: misalignment between the query and the target code in the retrieval process, and the inability of existing retrieval methods to effectively utilize the inference information. To address these challenges, we propose AlignCoder, a repository-level code completion framework that introduces a query enhancement mechanism and a reinforcement learning based retriever training method. Our approach generates multiple candidate completions to construct an enhanced query that bridges the semantic gap between the initial query and the target code. Additionally, we employ reinforcement learning to train an AlignRetriever that learns to leverage inference information in the enhanced query for more accurate retrieval. We evaluate AlignCoder on two widely-used benchmarks (CrossCodeEval and RepoEval) across five backbone code LLMs, demonstrating an 18.1% improvement in EM score compared to baselines on the CrossCodeEval benchmark. The results show that our framework achieves superior performance and exhibits high generalizability across various code LLMs and programming languages.",
							"pageNumber": 971,
							"isPageNumberRoman": false
						},
						{
							"eid": "goV8IWXWwCYUai0iTXFR1",
							"type": "authorPaper",
							"text": "Coverage-Based Harmfulness Testing for LLM Code Transformation",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a983/573300a983.pdf",
							"extraLocations": [],
							"authorNames": "Honghao Tan (Concordia University, Canada), Haibo Wang (Concordia University, Canada), Diany Pressato (Concordia University, Canada), Yisen Xu (Concordia University, Canada), Shin Hwei Tan (Concordia University, Canada)",
							"abstract": "Harmful content embedded in program elements within source code may have detrimental impact on mental health of software developers, and promote harmful behavior. Our key insight is that software developers may introduce harmful content into source code when using Code Large Language Models (Code LLMs) to perform program transformations tasks. To understand the space of program transformations that may be used to introduce harmful content into auto-generated code, we conduct a preliminary study that revealed 32 different types of transformations that can be used to introduce harmful content in source code. Based on our study, we propose CHT, a novel coverage-guided harmfulness testing framework that automatically synthesizes prompts using a set of prompt templates injected with diverse harmful keywords to perform various types of transformations on a set of mined benign programs. Instead of checking if the content moderation has been bypassed as prior approaches, CHT performs output damage measurement to assess potential harm that can be introduced by the generated outputs (i.e., natural language explanation and modified code). By considering output damage, CHT revealed several problems in Code LLMs: (1) bugs in content moderation for code (Code LLMs produce the harmful code without providing any warning), (2) inadequacy in performing code-related task (e.g., Code LLMs may resort to explaining the given code instead of performing the instructed transformation task), and (3) lenient content moderation (gives warning but the modified code with harmful content is still produced). Our evaluations of CHT on four Code LLMs and gpt-4o-mini (general LLM) show that content moderation in Code LLMs is relatively easy to bypass where LLMs may generate harmful keywords embedded within identifier names or code comments without giving any warning (65.93% in our evaluation). To improve the robustness of content moderation in code-related tasks, we propose a two-phrase approach that checks if the prompt contains any harmful content before generating any output. Our evaluation shows that our proposed approach improves the content moderation of Code LLM by 483.76%.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Coverage-Based Harmfulness Testing for LLM Code Transformation 1759177661035 10.1109/ASE63991.2025.00086 Honghao Tan Concordia University, Canada honghao.tan@mail.concordia.ca Haibo Wang Concordia University, Canada haibo.wang@mail.concordia.ca Diany Pressato Concordia University, Canada diany.pressato@mail.concordia.ca Yisen Xu Concordia University, Canada yisen.xu@mail.concordia.ca Shin Hwei Tan Concordia University, Canada shinhwei.tan@concordia.ca large language models code generation harmfulness testing Harmful content embedded in program elements within source code may have detrimental impact on mental health of software developers, and promote harmful behavior. Our key insight is that software developers may introduce harmful content into source code when using Code Large Language Models (Code LLMs) to perform program transformations tasks. To understand the space of program transformations that may be used to introduce harmful content into auto-generated code, we conduct a preliminary study that revealed 32 different types of transformations that can be used to introduce harmful content in source code. Based on our study, we propose CHT, a novel coverage-guided harmfulness testing framework that automatically synthesizes prompts using a set of prompt templates injected with diverse harmful keywords to perform various types of transformations on a set of mined benign programs. Instead of checking if the content moderation has been bypassed as prior approaches, CHT performs output damage measurement to assess potential harm that can be introduced by the generated outputs (i.e., natural language explanation and modified code). By considering output damage, CHT revealed several problems in Code LLMs: (1) bugs in content moderation for code (Code LLMs produce the harmful code without providing any warning), (2) inadequacy in performing code-related task (e.g., Code LLMs may resort to explaining the given code instead of performing the instructed transformation task), and (3) lenient content moderation (gives warning but the modified code with harmful content is still produced). Our evaluations of CHT on four Code LLMs and gpt-4o-mini (general LLM) show that content moderation in Code LLMs is relatively easy to bypass where LLMs may generate harmful keywords embedded within identifier names or code comments without giving any warning (65.93% in our evaluation). To improve the robustness of content moderation in code-related tasks, we propose a two-phrase approach that checks if the prompt contains any harmful content before generating any output. Our evaluation shows that our proposed approach improves the content moderation of Code LLM by 483.76%.",
							"pageNumber": 983,
							"isPageNumberRoman": false
						},
						{
							"eid": "3DY6V8bOSoYjaaqH0Rlw0z",
							"type": "authorPaper",
							"text": "Not Every Patch is an Island: LLM-Enhanced Identification of Multiple Vulnerability Patches",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a996/573300a996.pdf",
							"extraLocations": [],
							"authorNames": "Yi Song (Wuhan University, China), Dongchen Xie (Wuhan University, China), Lin Xu (Wuhan University, China), He Zhang (Wuhan University, China), Chunying Zhou (Wuhan University, China), Xiaoyuan Xie (Wuhan University, China)",
							"abstract": "For a vulnerability reported as an item of platforms such as CVE or NVD, software maintainers need to submit patches (in the form of code commit) to fix it, which is often performed silently for the sake of keeping products' reputation or avoiding malicious attacks. But such a silent practice keeps patches hidden from affected downstream software maintainers, thus they have to identify patches in a large corpus of code commits manually, i.e., silent vulnerability patch identification (SVPI). Existing techniques in this field were often developed under the assumption that a vulnerability is matched to one patch, thus output a ranking list that simply reflects the similarity between one individual patch and the vulnerability. However, previous research has demonstrated that many vulnerabilities correspond to more than one patch in practice, this phenomenon largely threatens the effectiveness of existing SVPI techniques because they typically ignore the correlation between patches. In this paper, we propose SHIP, a Silent vulnerability patcH Identification approach suited for multiPle-patch scenarios, to make patches corresponding to a vulnerability no longer isolated islands. For a vulnerability item, we first obtain several highly-relevant code commits by measuring heuristic features, and then employ a large language model (i.e., DeepSeek-V3) to predict both the link between a code commit and the vulnerability as well as the link between a pair of code commits, and thus deliver candidate groups each containing one or more code commits that could be patches of the vulnerability. Finally, we perform the max-pooling strategy on the features of code commit(s) contained in each candidate group to determine the ranking of groups, the Top-1 group will be output. The experimental results demonstrate the promise of SHIP: on the benchmark consisting of 4,631 vulnerability items, it can achieve 84.30%, 59.14%, and 69.51% of Recall, Precision, and F1-Score, respectively, outperforming the state-of-the-art SVPI technique by 37.54%, 28.71%, and 32.35%, respectively.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Not Every Patch is an Island: LLM-Enhanced Identification of Multiple Vulnerability Patches 1758594469628 10.1109/ASE63991.2025.00087 Yi Song Wuhan University, China yisong@whu.edu.cn Dongchen Xie Wuhan University, China xiedongchen@whu.edu.cn Lin Xu Wuhan University, China xulin_xl@whu.edu.cn He Zhang Wuhan University, China zhanghe@whu.edu.cn Chunying Zhou Wuhan University, China zcy9838@whu.edu.cn Xiaoyuan Xie Wuhan University, China xxie@whu.edu.cn security patches software vulnerability patch identification large language models For a vulnerability reported as an item of platforms such as CVE or NVD, software maintainers need to submit patches (in the form of code commit) to fix it, which is often performed silently for the sake of keeping products' reputation or avoiding malicious attacks. But such a silent practice keeps patches hidden from affected downstream software maintainers, thus they have to identify patches in a large corpus of code commits manually, i.e., silent vulnerability patch identification (SVPI). Existing techniques in this field were often developed under the assumption that a vulnerability is matched to one patch, thus output a ranking list that simply reflects the similarity between one individual patch and the vulnerability. However, previous research has demonstrated that many vulnerabilities correspond to more than one patch in practice, this phenomenon largely threatens the effectiveness of existing SVPI techniques because they typically ignore the correlation between patches. In this paper, we propose SHIP, a Silent vulnerability patcH Identification approach suited for multiPle-patch scenarios, to make patches corresponding to a vulnerability no longer isolated islands. For a vulnerability item, we first obtain several highly-relevant code commits by measuring heuristic features, and then employ a large language model (i.e., DeepSeek-V3) to predict both the link between a code commit and the vulnerability as well as the link between a pair of code commits, and thus deliver candidate groups each containing one or more code commits that could be patches of the vulnerability. Finally, we perform the max-pooling strategy on the features of code commit(s) contained in each candidate group to determine the ranking of groups, the Top-1 group will be output. The experimental results demonstrate the promise of SHIP: on the benchmark consisting of 4,631 vulnerability items, it can achieve 84.30%, 59.14%, and 69.51% of Recall, Precision, and F1-Score, respectively, outperforming the state-of-the-art SVPI technique by 37.54%, 28.71%, and 32.35%, respectively.",
							"pageNumber": 996,
							"isPageNumberRoman": false
						},
						{
							"eid": "7sEQ3sXvJ2GCnw1uKKt9Iq",
							"type": "authorPaper",
							"text": "Automated Inline Comment Smell Detection and Repair with Large Language Models",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b008/573300b008.pdf",
							"extraLocations": [],
							"authorNames": "Hatice K\u00FCbra \u00C7a\u011Flar (Bilkent University, Udemy, Inc, Turkey), Semih \u00C7a\u011Flar (Bilkent University, Turkey), Eray T\u00FCz\u00FCn (Bilkent University, Turkey)",
							"abstract": "Context: Code comments play a critical role in improving code readability, maintainability, and collaborative development. However, comments may deviate from best practices due to software evolution, where code changes are not reflected in comments, as well as practitioner-related issues such as vague descriptions, redundancy, or misaligned intent. These issues lead to various comment smells that degrade software quality. While prior studies have explored comment inconsistencies, most are limited in scope, either addressing a narrow subset of smells or focusing solely on detection without considering repair. Objective: This study evaluates the effectiveness of large language models (LLMs) in both detecting and repairing inline code comment smells, using a comprehensive taxonomy of code comment smell types. Method: We extended a prior data set by incorporating repaired versions of smelly comments, resulting in 2,211 unique instances. Four LLMs\u2014GPT-4o-mini, o3-mini, DeepSeek-V3, and Codestral-2501\u2014are evaluated under zero-shot and few-shot prompting strategies. To account for non-deterministic behavior in LLM outputs and ensure robustness, each configuration is executed five times. Detection performance is measured using accuracy, macro F1 score, and Matthews correlation coefficient (MCC); repair is evaluated using SBERT similarity, METEOR, and ROUGE-L. Our multi-stage pipeline feeds detection outputs into the repair phase, where the detection result with the highest macro F1 score is used to simulate the best possible repair scenario. Median scores across runs are reported for model comparison. Results: o3-mini with few-shot prompting achieves the highest median detection performance: macro F1 of 0.41, MCC of 0.50, and accuracy of 0.72, exceeding the baseline of GPT-4. For repair, Codestral-2501 in the zero-shot setting yields the best results with a median SBERT score of 0.61, followed by DeepSeek-V3 and GPT-4o-mini at 0.53, and o3-mini at 0.46. Few-shot prompts improve detection, while zero-shot prompts are more effective for repair. Conclusion: Lightweight LLMs such as o3-mini can achieve strong detection performance when guided by effective few-shot prompts. For example, o3-mini with few-shot prompting attains the highest median detection results: macro F1 of 0.41, MCC of 0.50, and accuracy of 0.72, surpassing the GPT-4 baseline. In contrast, repair tasks benefit more from zero-shot prompting, though they introduce challenges such as overfitting and the risk of generating new smells. Our findings support the development of practical tools, including a GitHub-integrated comment repair assistant, and motivate future work on dynamic prompt selection and multilingual benchmark construction.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Automated Inline Comment Smell Detection and Repair with Large Language Models 1756451194010 10.1109/ASE63991.2025.00088 Hatice K\u00FCbra \u00C7a\u011Flar Bilkent University, Udemy, Inc, Turkey kubra.caglar@udemy.com Semih \u00C7a\u011Flar Bilkent University, Turkey semih.caglar@ug.bilkent.edu.tr Eray T\u00FCz\u00FCn Bilkent University, Turkey eraytuzun@cs.bilkent.edu.tr comment smells code comment smell detection code comment repair code comment update large language models Context: Code comments play a critical role in improving code readability, maintainability, and collaborative development. However, comments may deviate from best practices due to software evolution, where code changes are not reflected in comments, as well as practitioner-related issues such as vague descriptions, redundancy, or misaligned intent. These issues lead to various comment smells that degrade software quality. While prior studies have explored comment inconsistencies, most are limited in scope, either addressing a narrow subset of smells or focusing solely on detection without considering repair. Objective: This study evaluates the effectiveness of large language models (LLMs) in both detecting and repairing inline code comment smells, using a comprehensive taxonomy of code comment smell types. Method: We extended a prior data set by incorporating repaired versions of smelly comments, resulting in 2,211 unique instances. Four LLMs\u2014GPT-4o-mini, o3-mini, DeepSeek-V3, and Codestral-2501\u2014are evaluated under zero-shot and few-shot prompting strategies. To account for non-deterministic behavior in LLM outputs and ensure robustness, each configuration is executed five times. Detection performance is measured using accuracy, macro F1 score, and Matthews correlation coefficient (MCC); repair is evaluated using SBERT similarity, METEOR, and ROUGE-L. Our multi-stage pipeline feeds detection outputs into the repair phase, where the detection result with the highest macro F1 score is used to simulate the best possible repair scenario. Median scores across runs are reported for model comparison. Results: o3-mini with few-shot prompting achieves the highest median detection performance: macro F1 of 0.41, MCC of 0.50, and accuracy of 0.72, exceeding the baseline of GPT-4. For repair, Codestral-2501 in the zero-shot setting yields the best results with a median SBERT score of 0.61, followed by DeepSeek-V3 and GPT-4o-mini at 0.53, and o3-mini at 0.46. Few-shot prompts improve detection, while zero-shot prompts are more effective for repair. Conclusion: Lightweight LLMs such as o3-mini can achieve strong detection performance when guided by effective few-shot prompts. For example, o3-mini with few-shot prompting attains the highest median detection results: macro F1 of 0.41, MCC of 0.50, and accuracy of 0.72, surpassing the GPT-4 baseline. In contrast, repair tasks benefit more from zero-shot prompting, though they introduce challenges such as overfitting and the risk of generating new smells. Our findings support the development of practical tools, including a GitHub-integrated comment repair assistant, and motivate future work on dynamic prompt selection and multilingual benchmark construction.",
							"pageNumber": 1008,
							"isPageNumberRoman": false
						},
						{
							"eid": "5EKNqXmnbibHzGw8HharLr",
							"type": "authorPaper",
							"text": "Programmers' Visual Attention on Function Call Graphs During Code Summarization",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b020/573300b020.pdf",
							"extraLocations": [],
							"authorNames": "Samantha McLoughlin (Vanderbilt University), Zachary Karas (Vanderbilt University), Robert Wallace (University of Notre Dame), Aakash Bansal (Louisiana State University), Collin McMillan (University of Notre Dame), Yu Huang (Vanderbilt University)",
							"abstract": "This paper studies programmer visual attention on code as it relates to underlying function call graphs during code summarization. Programmer visual attention refers to where people look when performing a software engineering task, and code summarization is the task of writing a natural language description about a section of source code. Prior work has studied programmers' visual attention during code summarization, with the vast majority of research effort placed on details in single functional units of code. There have not been any techniques developed to understand code comprehension at the project level due to the difficulty of this task, despite the nature of most real-world methods as embedded within complex project context. This paper focuses on the visual attention paid to the call graph context in which a method sits. We analyze visual attention coverage of call graphs with graph-based metrics, such as the depth that programmers traverse or the amount of coverage they attain. We use these metrics, among other means, to reevaluate an existing dataset from a previous eye-tracking study of programmers (n=10) that considered basic properties of programmer visual attention in a project context. We then created a new dataset (n=12) using the same procedures specifically for this paper, resulting in a total of 88 hours of recorded visual behavior on source code. We used our proposed metrics to analyze how participants' visual strategies correlated with their code summary quality, and confidence in their summaries. Interestingly, we found that higher coverage of the call graph was associated with decreases in both summary quality and participants' confidence.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Programmers' Visual Attention on Function Call Graphs During Code Summarization 1759508783634 10.1109/ASE63991.2025.00089 Samantha McLoughlin Vanderbilt University samantha.m.mcloughlin@vanderbilt.edu Zachary Karas Vanderbilt University z.karas@vanderbilt.edu Robert Wallace University of Notre Dame rwallac1@nd.edu Aakash Bansal Louisiana State University abansal@lsu.edu Collin McMillan University of Notre Dame cmc@nd.edu Yu Huang Vanderbilt University yu.huang@vanderbilt.edu code comprehension code summarization eye tracking call graph This paper studies programmer visual attention on code as it relates to underlying function call graphs during code summarization. Programmer visual attention refers to where people look when performing a software engineering task, and code summarization is the task of writing a natural language description about a section of source code. Prior work has studied programmers' visual attention during code summarization, with the vast majority of research effort placed on details in single functional units of code. There have not been any techniques developed to understand code comprehension at the project level due to the difficulty of this task, despite the nature of most real-world methods as embedded within complex project context. This paper focuses on the visual attention paid to the call graph context in which a method sits. We analyze visual attention coverage of call graphs with graph-based metrics, such as the depth that programmers traverse or the amount of coverage they attain. We use these metrics, among other means, to reevaluate an existing dataset from a previous eye-tracking study of programmers (n=10) that considered basic properties of programmer visual attention in a project context. We then created a new dataset (n=12) using the same procedures specifically for this paper, resulting in a total of 88 hours of recorded visual behavior on source code. We used our proposed metrics to analyze how participants' visual strategies correlated with their code summary quality, and confidence in their summaries. Interestingly, we found that higher coverage of the call graph was associated with decreases in both summary quality and participants' confidence.",
							"pageNumber": 1020,
							"isPageNumberRoman": false
						},
						{
							"eid": "CrJPIX3caeBKLxoAdQX6Q",
							"type": "authorPaper",
							"text": "An LLM-Based Multi-Agent Framework for Agile Effort Estimation",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b032/573300b032.pdf",
							"extraLocations": [],
							"authorNames": "Thanh-Long Bui (University of Wollongong, Australia), Hoa Khanh Dam (University of Wollongong, Australia), Rashina Hoda (Monash University, Australia)",
							"abstract": "Effort estimation is a crucial activity in agile software development, where teams collaboratively review, discuss, and estimate the effort required to complete user stories in a product backlog. Current practices in agile effort estimation heavily rely on subjective assessments, leading to inaccuracies and inconsistencies in the estimates. While recent machine learning-based methods show promising accuracy, they cannot explain or justify their estimates and lack the capability to interact with human team members. Our paper fills this significant gap by leveraging the powerful capabilities of Large Language Models (LLMs). We propose a novel LLM-based multi-agent framework for agile estimation that not only can produce estimates, but also can coordinate, communicate and discuss with human developers and other agents to reach a consensus. Evaluation results on a real-life dataset show that our approach outperforms state-of-the-art techniques across all evaluation metrics in the majority of the cases. Our human study with software development practitioners also demonstrates an overwhelmingly positive experience in collaborating with our agents in agile effort estimation.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 An LLM-Based Multi-Agent Framework for Agile Effort Estimation 1758674584960 10.1109/ASE63991.2025.00090 Thanh-Long Bui University of Wollongong, Australia tlb959@uowmail.edu.au Hoa Khanh Dam University of Wollongong, Australia hoa@uow.edu.au Rashina Hoda Monash University, Australia rashina.hoda@monash.edu Agile software development effort estimation large language models multi-agent systems planning poker human-AI collaboration Effort estimation is a crucial activity in agile software development, where teams collaboratively review, discuss, and estimate the effort required to complete user stories in a product backlog. Current practices in agile effort estimation heavily rely on subjective assessments, leading to inaccuracies and inconsistencies in the estimates. While recent machine learning-based methods show promising accuracy, they cannot explain or justify their estimates and lack the capability to interact with human team members. Our paper fills this significant gap by leveraging the powerful capabilities of Large Language Models (LLMs). We propose a novel LLM-based multi-agent framework for agile estimation that not only can produce estimates, but also can coordinate, communicate and discuss with human developers and other agents to reach a consensus. Evaluation results on a real-life dataset show that our approach outperforms state-of-the-art techniques across all evaluation metrics in the majority of the cases. Our human study with software development practitioners also demonstrates an overwhelmingly positive experience in collaborating with our agents in agile effort estimation.",
							"pageNumber": 1032,
							"isPageNumberRoman": false
						},
						{
							"eid": "1qmtQ7PEeTvVwx861Daj3X",
							"type": "authorPaper",
							"text": "PROMFUZZ: Leveraging LLM-Driven and Bug-Oriented Composite Analysis for Detecting Functional Bugs in Smart Contracts",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b044/573300b044.pdf",
							"extraLocations": [],
							"authorNames": "Xingshuang Lin (Zhejiang University), Qinge Xie (Georgia Institute of Technology), Binbin Zhao (Zhejiang University; Southeast University, Ministry of Education), Yuan Tian (University of California, Los Angelos), Saman Zonouz (Georgia Institute of Technology), Na Ruan (Shanghai Jiaotong University), Jiliang Li (Xi'an Jiaotong University), Raheem Beyah (Georgia Institute of Technology), Shouling Ji (Zhejiang University)",
							"abstract": "Smart contracts are fundamental pillars of the blockchain, playing a crucial role in facilitating various business transactions. However, these smart contracts are vulnerable to exploitable bugs that can lead to substantial monetary losses. A recent study reveals that over 80% of these exploitable bugs, which are primarily functional bugs, can evade the detection of current tools. Automatically identifying functional bugs in smart contracts presents challenges from multiple perspectives. The primary issue is the significant gap between understanding the high-level logic of the business model and checking the low-level implementations in smart contracts. Furthermore, identifying deeply rooted functional bugs in smart contracts requires the automated generation of effective detection oracles based on various bug features. To address these challenges, we design and implement PROMFUZZ, an automated and scalable system to detect functional bugs in smart contracts. In PROMFUZZ, we first propose a novel Large Language Model (LLM)-driven analysis framework, which leverages a dual-agent prompt engineering strategy to pinpoint potentially vulnerable functions for further scrutiny. We then implement a dual-stage coupling approach, which focuses on generating invariant checkers that leverage logic information extracted from potentially vulnerable functions. Finally, we design a bug-oriented fuzzing engine, which maps the logical information from the high-level business model to the low-level smart contract implementations, and performs the bug-oriented fuzzing on targeted functions. We evaluate PROMFUZZ from 4 perspectives on 5 ground-truth datasets and compare it with multiple state-of-the-art methods. The results show that PROMFUZZ achieves 86.96% recall and 93.02% F1-score in detecting functional bugs, marking at least a 50% improvement in both metrics over state-of-the-art methods. Moreover, we perform an in-depth analysis on 10 real-world DeFi projects and detect 30 zero-day bugs. Our further case studies, the risky first deposit bug and the AMM price oracle manipulation bug on real-world DeFi projects, demonstrate the serious risks of the exploitable functional bugs in smart contracts. Up to now, 24 zero-day bugs have been assigned CVE IDs. Our discoveries have safeguarded assets totaling $18.2 billion from potential monetary losses.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 PROMFUZZ: Leveraging LLM-Driven and Bug-Oriented Composite Analysis for Detecting Functional Bugs in Smart Contracts 1759037499397 10.1109/ASE63991.2025.00091 Xingshuang Lin Zhejiang University cs.xslin@zju.edu.cn Qinge Xie Georgia Institute of Technology qxie47@gatech.edu Binbin Zhao Zhejiang University; Southeast University, Ministry of Education binbinz@zju.edu.cn Yuan Tian University of California, Los Angelos yuant@ucla.edu Saman Zonouz Georgia Institute of Technology szonouz6@gatech.edu Na Ruan Shanghai Jiaotong University naruan@cs.sjtu.edu.cn Jiliang Li Xi'an Jiaotong University jiliang.li@xjtu.edu.cn Raheem Beyah Georgia Institute of Technology rbeyah@coe.gatech.edu Shouling Ji Zhejiang University sji@zju.edu.cn Smart contracts are fundamental pillars of the blockchain, playing a crucial role in facilitating various business transactions. However, these smart contracts are vulnerable to exploitable bugs that can lead to substantial monetary losses. A recent study reveals that over 80% of these exploitable bugs, which are primarily functional bugs, can evade the detection of current tools. Automatically identifying functional bugs in smart contracts presents challenges from multiple perspectives. The primary issue is the significant gap between understanding the high-level logic of the business model and checking the low-level implementations in smart contracts. Furthermore, identifying deeply rooted functional bugs in smart contracts requires the automated generation of effective detection oracles based on various bug features. To address these challenges, we design and implement PROMFUZZ, an automated and scalable system to detect functional bugs in smart contracts. In PROMFUZZ, we first propose a novel Large Language Model (LLM)-driven analysis framework, which leverages a dual-agent prompt engineering strategy to pinpoint potentially vulnerable functions for further scrutiny. We then implement a dual-stage coupling approach, which focuses on generating invariant checkers that leverage logic information extracted from potentially vulnerable functions. Finally, we design a bug-oriented fuzzing engine, which maps the logical information from the high-level business model to the low-level smart contract implementations, and performs the bug-oriented fuzzing on targeted functions. We evaluate PROMFUZZ from 4 perspectives on 5 ground-truth datasets and compare it with multiple state-of-the-art methods. The results show that PROMFUZZ achieves 86.96% recall and 93.02% F1-score in detecting functional bugs, marking at least a 50% improvement in both metrics over state-of-the-art methods. Moreover, we perform an in-depth analysis on 10 real-world DeFi projects and detect 30 zero-day bugs. Our further case studies, the risky first deposit bug and the AMM price oracle manipulation bug on real-world DeFi projects, demonstrate the serious risks of the exploitable functional bugs in smart contracts. Up to now, 24 zero-day bugs have been assigned CVE IDs. Our discoveries have safeguarded assets totaling $18.2 billion from potential monetary losses.",
							"pageNumber": 1044,
							"isPageNumberRoman": false
						},
						{
							"eid": "7hulB9YQqeEinc6oTJWquk",
							"type": "authorPaper",
							"text": "LOSVER: Line-Level Modifiability Signal-Guided Vulnerability Detection and Classification",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b057/573300b057.pdf",
							"extraLocations": [],
							"authorNames": "Doha Nam (KAIST, South Korea), Jongmoon Baik (KAIST, South Korea)",
							"abstract": "The increasing prevalence of software vulnerabilities continues to pose serious threats to system security, underscoring the need for accurate and scalable techniques for vulnerability detection and classification. While Pre-trained Language Models (PLMs) have shown strong potential in vulnerability analysis, most existing methods provide no explicit guidance on which parts of the input code are more likely to be vulnerable. As a result, the model must infer token-level relevance without any indication of which parts are important, making it harder to learn the characteristics of vulnerable code during training. To address this limitation, we propose LOSVER (Line-level mOdifiability Signal-guided VulnERability analyzer), a novel two-stage framework that enhances PLM-based vulnerability analysis by incorporating line-level modifiability signals. In the first stage, LOSVER localizes modifiable lines. These are code segments likely to be changed in the future due to instability or complexity, which are often associated with vulnerabilities. In the second stage, the model assigns greater importance to the predicted modifiable lines, allowing the PLM to focus on potentially vulnerable regions during both training and inference. We evaluated LOSVER with two widely used benchmark datasets: Devign, for function-level vulnerability detection, and Big-Vul, for function-level vulnerability classification with Common Weakness Enumeration (CWE) ID labels. Experimental results show that LOSVER improves detection accuracy on Devign by approximately 4 percentage points and increases the weighted F1-score for CWE ID classification on Big-Vul by over 2 points, when applied on top of the UniXcoder baseline. We also conducted experiments on the PrimeVul dataset, which focuses on vulnerability\u2013patch pairs, and observed meaningful improvements in pair-wise detection. These results demonstrate that integrating line-level modifiability signals significantly enhances the effectiveness of PLM-based software vulnerability analysis across both detection and classification tasks.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 LOSVER: Line-Level Modifiability Signal-Guided Vulnerability Detection and Classification 1759291437704 10.1109/ASE63991.2025.00092 Doha Nam KAIST, South Korea waroad@kaist.ac.kr Jongmoon Baik KAIST, South Korea jbaik@kaist.ac.kr vulnerability detection pre-trained language models line-level vulnerability analysis The increasing prevalence of software vulnerabilities continues to pose serious threats to system security, underscoring the need for accurate and scalable techniques for vulnerability detection and classification. While Pre-trained Language Models (PLMs) have shown strong potential in vulnerability analysis, most existing methods provide no explicit guidance on which parts of the input code are more likely to be vulnerable. As a result, the model must infer token-level relevance without any indication of which parts are important, making it harder to learn the characteristics of vulnerable code during training. To address this limitation, we propose LOSVER (Line-level mOdifiability Signal-guided VulnERability analyzer), a novel two-stage framework that enhances PLM-based vulnerability analysis by incorporating line-level modifiability signals. In the first stage, LOSVER localizes modifiable lines. These are code segments likely to be changed in the future due to instability or complexity, which are often associated with vulnerabilities. In the second stage, the model assigns greater importance to the predicted modifiable lines, allowing the PLM to focus on potentially vulnerable regions during both training and inference. We evaluated LOSVER with two widely used benchmark datasets: Devign, for function-level vulnerability detection, and Big-Vul, for function-level vulnerability classification with Common Weakness Enumeration (CWE) ID labels. Experimental results show that LOSVER improves detection accuracy on Devign by approximately 4 percentage points and increases the weighted F1-score for CWE ID classification on Big-Vul by over 2 points, when applied on top of the UniXcoder baseline. We also conducted experiments on the PrimeVul dataset, which focuses on vulnerability\u2013patch pairs, and observed meaningful improvements in pair-wise detection. These results demonstrate that integrating line-level modifiability signals significantly enhances the effectiveness of PLM-based software vulnerability analysis across both detection and classification tasks.",
							"pageNumber": 1057,
							"isPageNumberRoman": false
						},
						{
							"eid": "602bF75tBRsAUZZknbM2Eg",
							"type": "authorPaper",
							"text": "A Large Scale Study of AI-Based Binary Function Similarity Detection Techniques for Security Researchers and Practitioners",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b069/573300b069.pdf",
							"extraLocations": [],
							"authorNames": "Jingyi Shi (Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China;), Yufeng Chen (Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China;), Yang Xiao (Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China;), Yuekang Li (University of New South Wales, Australia), Zhengzi Xu (Imperial Global Singapore, Singapore), Sihao Qiu (Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China;), Chi Zhang (Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China;), Keyu Qi (Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China;), Yeting Li (Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China;), Xingchu Chen (Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China;), Yanyan Zou (Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China;), Yang Liu (Nanyang Technological University, Singapore), Wei Huo (Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China;)",
							"abstract": "Binary Function Similarity Detection (BFSD) is a foundational technique in software security, underpinning a wide range of applications including vulnerability detection, malware analysis. Recent advances in AI-based BFSD tools have led to significant performance improvements. However, existing evaluations of these tools suffer from three key limitations: a lack of in-depth analysis of performance-influencing factors, an absence of realistic application analysis, and reliance on small-scale or low-quality datasets. In this paper, we present the first large-scale empirical study of AI-based BFSD tools to address these gaps. We construct two high-quality and diverse datasets: BinAtlas, comprising 12,453 binaries and over 7 million functions for capability evaluation; and BinAres, containing 12,291 binaries and 54 real-world 1-day vulnerabilities for evaluating vulnerability detection performance in practical IoT firmware settings. Using these datasets, we evaluate nine representative BFSD tools, analyze the challenges and limitations of existing BFSD tools, and investigate the consistency among BFSD tools. We also propose an actionable strategy for combining BFSD tools to enhance overall performance (an improvement of 13.4%). Our study not only advances the practical adoption of BFSD tools but also provides valuable resources and insights to guide future research in scalable and automated binary similarity detection.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 A Large Scale Study of AI-Based Binary Function Similarity Detection Techniques for Security Researchers and Practitioners 1759136916118 10.1109/ASE63991.2025.00093 Jingyi Shi Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China; shijingyi@iie.ac.cn Yufeng Chen Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China; chenyufeng@iie.ac.cn Yang Xiao Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China; xiaoyang@iie.ac.cn Yuekang Li University of New South Wales, Australia yuekang.li@unsw.edu.au Zhengzi Xu Imperial Global Singapore, Singapore z.xu@imperial.ac.uk Sihao Qiu Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China; qiusihao@iie.ac.cn Chi Zhang Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China; zhangchi2024@iie.ac.cn Keyu Qi Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China; qikeyu@iie.ac.cn Yeting Li Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China; liyeting@iie.ac.cn Xingchu Chen Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China; chenxingchu@iie.ac.cn Yanyan Zou Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China; zouyanyan@iie.ac.cn Yang Liu Nanyang Technological University, Singapore yangliu@ntu.edu.sg Wei Huo Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China; huowei@iie.ac.cn binary function similarity detection artificial intelligence in-practice strategy dataset and evaluation Binary Function Similarity Detection (BFSD) is a foundational technique in software security, underpinning a wide range of applications including vulnerability detection, malware analysis. Recent advances in AI-based BFSD tools have led to significant performance improvements. However, existing evaluations of these tools suffer from three key limitations: a lack of in-depth analysis of performance-influencing factors, an absence of realistic application analysis, and reliance on small-scale or low-quality datasets. In this paper, we present the first large-scale empirical study of AI-based BFSD tools to address these gaps. We construct two high-quality and diverse datasets: BinAtlas, comprising 12,453 binaries and over 7 million functions for capability evaluation; and BinAres, containing 12,291 binaries and 54 real-world 1-day vulnerabilities for evaluating vulnerability detection performance in practical IoT firmware settings. Using these datasets, we evaluate nine representative BFSD tools, analyze the challenges and limitations of existing BFSD tools, and investigate the consistency among BFSD tools. We also propose an actionable strategy for combining BFSD tools to enhance overall performance (an improvement of 13.4%). Our study not only advances the practical adoption of BFSD tools but also provides valuable resources and insights to guide future research in scalable and automated binary similarity detection.",
							"pageNumber": 1069,
							"isPageNumberRoman": false
						},
						{
							"eid": "2uaM73v4EBKI3n8Z69IHQp",
							"type": "authorPaper",
							"text": "DebCovDiff: Differential Testing of Coverage Measurement Tools on Real-World Projects",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b082/573300b082.pdf",
							"extraLocations": [],
							"authorNames": "Wentao Zhang (University of Illinois Urbana-Champaign, USA), Jinghao Jia (University of Illinois Urbana-Champaign, USA), Erkai Yu (University of Illinois Urbana-Champaign, USA), Darko Marinov (University of Illinois Urbana-Champaign, USA), Tianyin Xu (University of Illinois Urbana-Champaign, USA)",
							"abstract": "Measuring code coverage is a critical practice in software testing. Incorrect or misleading coverage information reported by automatic tools can increase the software development cost and lead to negative consequences especially for safety-critical software. Ensuring the correctness of coverage measurement tools is therefore important. Prior studies have applied various techniques to find bugs in Gcov and LLVM-cov, the two most widely used coverage tools for C/C++. However, those studies had two limiting factors. First, they used only small, often synthetic, programs, potentially missing bugs in real-world scenarios. Second, they focused only on basic line coverage, neglecting advanced metrics that are both more complex to implement and commonly required for safety-critical software. This paper presents the first empirical study of coverage measurement tools for real-world projects. We implement DebCovDiff, a testing framework that takes Debian packages as the input programs and performs differential testing of Gcov and LLVM-cov, for line coverage and two advanced coverage metrics. We design robust differential oracles to (1) filter out discrepancies arising from subtle differences in the tool output presentation, (2) overcome the nondeterministic nature of certain packages, and (3) support advanced coverage metrics. From results on 47 Debian packages, we identify 34 new bugs, including 2 crashing bugs and 32 deeper bugs that produce wrong coverage reports.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 DebCovDiff: Differential Testing of Coverage Measurement Tools on Real-World Projects 1759557357001 10.1109/ASE63991.2025.00094 Wentao Zhang University of Illinois Urbana-Champaign, USA wentaoz5@illinois.edu Jinghao Jia University of Illinois Urbana-Champaign, USA jinghao7@illinois.edu Erkai Yu University of Illinois Urbana-Champaign, USA erkaiyu2@illinois.edu Darko Marinov University of Illinois Urbana-Champaign, USA marinov@illinois.edu Tianyin Xu University of Illinois Urbana-Champaign, USA tyxu@illinois.edu Measuring code coverage is a critical practice in software testing. Incorrect or misleading coverage information reported by automatic tools can increase the software development cost and lead to negative consequences especially for safety-critical software. Ensuring the correctness of coverage measurement tools is therefore important. Prior studies have applied various techniques to find bugs in Gcov and LLVM-cov, the two most widely used coverage tools for C/C++. However, those studies had two limiting factors. First, they used only small, often synthetic, programs, potentially missing bugs in real-world scenarios. Second, they focused only on basic line coverage, neglecting advanced metrics that are both more complex to implement and commonly required for safety-critical software. This paper presents the first empirical study of coverage measurement tools for real-world projects. We implement DebCovDiff, a testing framework that takes Debian packages as the input programs and performs differential testing of Gcov and LLVM-cov, for line coverage and two advanced coverage metrics. We design robust differential oracles to (1) filter out discrepancies arising from subtle differences in the tool output presentation, (2) overcome the nondeterministic nature of certain packages, and (3) support advanced coverage metrics. From results on 47 Debian packages, we identify 34 new bugs, including 2 crashing bugs and 32 deeper bugs that produce wrong coverage reports.",
							"pageNumber": 1082,
							"isPageNumberRoman": false
						},
						{
							"eid": "15xAi99CjQTXXsJSEZfSo7",
							"type": "authorPaper",
							"text": "ZendDiff: Differential Testing of PHP Interpreter",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b094/573300b094.pdf",
							"extraLocations": [],
							"authorNames": "Yuancheng Jiang (National University of Singapore, Singapore), Jianing Wang (National University of Singapore, Singapore; Shandong University, China), Qiange Liu (Beihang University, China), Yeqi Fu (National University of Singapore, Singapore), Jian Mao (Beihang University, China), Roland H. C. Yap (National University of Singapore, Singapore), Zhenkai Liang (National University of Singapore, Singapore)",
							"abstract": "The PHP interpreter, powering over 70% of websites on the internet, plays a crucial role in web development. Existing approaches to finding bugs in PHP primarily focus on detecting explicit security issues through crashes or sanitizer-based oracles, but fail to identify logic bugs that can silently lead to incorrect results. We observe that the introduction of Just-In-Time (JIT) compilation mode in PHP presents an opportunity for differential testing, as it provides an alternative implementation of the same language specification. We propose, ZendDiff, an automatic differential testing framework that effectively detects logic bugs in the PHP interpreter by comparing JIT and non-JIT execution results. Our differential testing incorporates three techniques: program state probing for fine-grained execution state comparison, JIT-aware program mutation to sufficiently exercise JIT functionality, and dual verification to handle non-deterministic behaviors in PHP programs. Our experimental results demonstrate that ZendDiff outperforms the official test suite used in PHP's continuous integration, achieving higher code coverage and executing more Zend opcodes. Through ablation studies, we validate the effectiveness of these techniques. To date, ZendDiff has identified 51 previously unknown logic bugs in the PHP interpreter, with 37 already fixed and 3 confirmed by the PHP maintainers. ZendDiff has been acknowledged by the PHP community and offers a practical tool for automatically discovering logic bugs in the PHP interpreter.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 ZendDiff: Differential Testing of PHP Interpreter 1759563336904 10.1109/ASE63991.2025.00095 Yuancheng Jiang National University of Singapore, Singapore yuancheng@comp.nus.edu.sg Jianing Wang National University of Singapore, Singapore; Shandong University, China jianingwang@mail.sdu.edu.cn Qiange Liu Beihang University, China liuqiangebuaa@buaa.edu.cn Yeqi Fu National University of Singapore, Singapore yeqi.fu@comp.nus.edu.sg Jian Mao Beihang University, China maojian@buaa.edu.cn Roland H. C. Yap National University of Singapore, Singapore ryap@comp.nus.edu.sg Zhenkai Liang National University of Singapore, Singapore liangzk@comp.nus.edu.sg differential testing just-in-time compilation logic bug detection php interpreter software testing The PHP interpreter, powering over 70% of websites on the internet, plays a crucial role in web development. Existing approaches to finding bugs in PHP primarily focus on detecting explicit security issues through crashes or sanitizer-based oracles, but fail to identify logic bugs that can silently lead to incorrect results. We observe that the introduction of Just-In-Time (JIT) compilation mode in PHP presents an opportunity for differential testing, as it provides an alternative implementation of the same language specification. We propose, ZendDiff, an automatic differential testing framework that effectively detects logic bugs in the PHP interpreter by comparing JIT and non-JIT execution results. Our differential testing incorporates three techniques: program state probing for fine-grained execution state comparison, JIT-aware program mutation to sufficiently exercise JIT functionality, and dual verification to handle non-deterministic behaviors in PHP programs. Our experimental results demonstrate that ZendDiff outperforms the official test suite used in PHP's continuous integration, achieving higher code coverage and executing more Zend opcodes. Through ablation studies, we validate the effectiveness of these techniques. To date, ZendDiff has identified 51 previously unknown logic bugs in the PHP interpreter, with 37 already fixed and 3 confirmed by the PHP maintainers. ZendDiff has been acknowledged by the PHP community and offers a practical tool for automatically discovering logic bugs in the PHP interpreter.",
							"pageNumber": 1094,
							"isPageNumberRoman": false
						},
						{
							"eid": "2e1vHn7Cqldbl6yUi5wp3M",
							"type": "authorPaper",
							"text": "BCFuzz: Bytecode-Driven Fuzzing for JavaScript Engines",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b106/573300b106.pdf",
							"extraLocations": [],
							"authorNames": "Jiming Wang (Institute of Computing Technology, China; University of Chinese Academy of Sciences), Chenggang Wu (Institute of Computing Technology, China; University of Chinese Academy of Sciences), Jikai Ren (Institute of Computing Technology, China; University of Chinese Academy of Sciences), Yuhao Hu (Institute of Computing Technology, China; University of Chinese Academy of Sciences), Yan Kang (Institute of Computing Technology, China; University of Chinese Academy of Sciences), Xiaojie Wei (Institute of Computing Technology, China), Yuanming Lai (Institute of Computing Technology, China), Mengyao Xie (Institute of Computing Technology, China), Zhe Wang (Institute of Computing Technology, China; University of Chinese Academy of Sciences)",
							"abstract": "The interpreter and the Just-In-Time (JIT) compiler are two core components of modern JavaScript engines, both of which take bytecodes as input. Most bugs in these components are closely related to specific bytecodes. Therefore, effective fuzzing should pay close attention to how bytecode is generated and exercised. However, previous work fails to consider this aspect and instead focuses primarily on the syntactic and semantic validity of test cases. This causes two major issues: 1) certain bytecodes are never exercised during fuzzing; 2) some bytecodes are exercised infrequently. In this paper, we propose BCFuzz, a bytecode-driven fuzzing approach designed to enhance the diversity of generated bytecode and increase testing opportunities for low-frequency bytecodes. Specifically, we introduce a parser-oriented probing technique to identify the necessary conditions for generating specific bytecodes and use this information to enhance the input generation process. To better test low-frequency bytecodes, we propose bytecode-aware seed preservation, scheduling, and mutation strategies. We evaluate BCFuzz on four mainstream JavaScript engines. In 72 hours of testing, BCFuzz discovers 1.73\u00D7 and 1.67\u00D7 more bugs than DIE and Fuzzilli, respectively. In total, BCFuzz uncovered 20 previously unknown bugs. Of these, 17 have already been fixed and one has been assigned a CVE. All the discovered bugs are related to bytecodes.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 BCFuzz: Bytecode-Driven Fuzzing for JavaScript Engines 1756891984508 10.1109/ASE63991.2025.00096 Jiming Wang Institute of Computing Technology, China; University of Chinese Academy of Sciences wangjiming21@mails.ucas.ac.cn Chenggang Wu Institute of Computing Technology, China; University of Chinese Academy of Sciences wucg@ict.ac.cn Jikai Ren Institute of Computing Technology, China; University of Chinese Academy of Sciences renjikai22z@ict.ac.cn Yuhao Hu Institute of Computing Technology, China; University of Chinese Academy of Sciences huyuhao19f@ict.ac.cn Yan Kang Institute of Computing Technology, China; University of Chinese Academy of Sciences kangyan@ict.ac.cn Xiaojie Wei Institute of Computing Technology, China weixiaojie@ict.ac.cn Yuanming Lai Institute of Computing Technology, China laiyuanming@ict.ac.cn Mengyao Xie Institute of Computing Technology, China xiemengyao@ict.ac.cn Zhe Wang Institute of Computing Technology, China; University of Chinese Academy of Sciences wangzhe12@ict.ac.cn javascript engine fuzzing bytecode The interpreter and the Just-In-Time (JIT) compiler are two core components of modern JavaScript engines, both of which take bytecodes as input. Most bugs in these components are closely related to specific bytecodes. Therefore, effective fuzzing should pay close attention to how bytecode is generated and exercised. However, previous work fails to consider this aspect and instead focuses primarily on the syntactic and semantic validity of test cases. This causes two major issues: 1) certain bytecodes are never exercised during fuzzing; 2) some bytecodes are exercised infrequently. In this paper, we propose BCFuzz, a bytecode-driven fuzzing approach designed to enhance the diversity of generated bytecode and increase testing opportunities for low-frequency bytecodes. Specifically, we introduce a parser-oriented probing technique to identify the necessary conditions for generating specific bytecodes and use this information to enhance the input generation process. To better test low-frequency bytecodes, we propose bytecode-aware seed preservation, scheduling, and mutation strategies. We evaluate BCFuzz on four mainstream JavaScript engines. In 72 hours of testing, BCFuzz discovers 1.73\u00D7 and 1.67\u00D7 more bugs than DIE and Fuzzilli, respectively. In total, BCFuzz uncovered 20 previously unknown bugs. Of these, 17 have already been fixed and one has been assigned a CVE. All the discovered bugs are related to bytecodes.",
							"pageNumber": 1106,
							"isPageNumberRoman": false
						},
						{
							"eid": "2JKdARTI0cZhwspcNVejg4",
							"type": "authorPaper",
							"text": "CoorLog: Efficient-Generalizable Log Anomaly Detection via Adaptive Coordinator in Software Evolution",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b118/573300b118.pdf",
							"extraLocations": [],
							"authorNames": "Pei Xiao (Peking University, China), Chiming Duan (Peking University, China), Minghua He (Peking University, China), Tong Jia (Peking University, China; National Key Laboratory of Data Space Technology and System, China), Yifan Wu (Peking University, China), Jing Xu (ByteDance, China), Gege Gao (ByteDance, China), Lingzhe Zhang (Peking University, China), Weijie Hong (Peking University, China), Ying Li (Peking University, China), Gang Huang (National Key Laboratory of Data Space Technology and System, China)",
							"abstract": "Frequent software updates lead to log evolution, posing generalization challenges for current log anomaly detection. Traditional log anomaly detection research focuses on using small deep learning models (SMs), but these models inherently lack generalization due to their closed-world assumption. Large language models (LLMs) exhibit strong semantic understanding and generalization capabilities, making them promising for log anomaly detection. However, they suffer from computational inefficiencies. To balance efficiency and generalization, we propose a collaborative log anomaly detection scheme (CoorLog) that uses an adaptive coordinator to integrate SM and LLM. The coordinator determines if incoming logs have evolved. Non-evolved logs are routed to the SM, while evolved logs are directed to the LLM for detailed inference using the constructed Evol-CoT. To gradually adapt to evolution, we introduce the adaptive evolution mechanism (AEM), which updates the coordinator to redirect evolved logs identified by the LLM to the SM. Simultaneously, the SM is fine-tuned to inherit the LLM's judgment on these logs. Extensive experiments on real-world datasets demonstrate that CoorLog achieves superior F1-scores in both intra-version and inter-version anomaly detection. Additionally, CoorLog reduces processing time by 91.63% and token consumption by 85.59% compared to using an LLM alone.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 CoorLog: Efficient-Generalizable Log Anomaly Detection via Adaptive Coordinator in Software Evolution 1759202511869 10.1109/ASE63991.2025.00097 Pei Xiao Peking University, China xiaopei@stu.pku.edu.cn Chiming Duan Peking University, China duanchiming@stu.pku.edu.cn Minghua He Peking University, China hemh2120@stu.pku.edu.cn Tong Jia Peking University, China; National Key Laboratory of Data Space Technology and System, China jia.tong@pku.edu.cn Yifan Wu Peking University, China yifanwu@pku.edu.cn Jing Xu ByteDance, China xujing.66@bytedance.com Gege Gao ByteDance, China gaogege.1002@bytedance.com Lingzhe Zhang Peking University, China zhang.lingzhe@stu.pku.edu.cn Weijie Hong Peking University, China hongwj@stu.pku.edu.cn Ying Li Peking University, China li.ying@pku.edu.cn Gang Huang National Key Laboratory of Data Space Technology and System, China hg@pku.edu.cn system logs anomaly detection large language models software evolution model collaboration Frequent software updates lead to log evolution, posing generalization challenges for current log anomaly detection. Traditional log anomaly detection research focuses on using small deep learning models (SMs), but these models inherently lack generalization due to their closed-world assumption. Large language models (LLMs) exhibit strong semantic understanding and generalization capabilities, making them promising for log anomaly detection. However, they suffer from computational inefficiencies. To balance efficiency and generalization, we propose a collaborative log anomaly detection scheme (CoorLog) that uses an adaptive coordinator to integrate SM and LLM. The coordinator determines if incoming logs have evolved. Non-evolved logs are routed to the SM, while evolved logs are directed to the LLM for detailed inference using the constructed Evol-CoT. To gradually adapt to evolution, we introduce the adaptive evolution mechanism (AEM), which updates the coordinator to redirect evolved logs identified by the LLM to the SM. Simultaneously, the SM is fine-tuned to inherit the LLM's judgment on these logs. Extensive experiments on real-world datasets demonstrate that CoorLog achieves superior F1-scores in both intra-version and inter-version anomaly detection. Additionally, CoorLog reduces processing time by 91.63% and token consumption by 85.59% compared to using an LLM alone.",
							"pageNumber": 1118,
							"isPageNumberRoman": false
						},
						{
							"eid": "2CpCLAaFRdmpq1DtpCfWi4",
							"type": "authorPaper",
							"text": "GUIFuzz++: Unleashing Grey-box Fuzzing on Desktop Graphical User Interfacing Applications ",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b131/573300b131.pdf",
							"extraLocations": [],
							"authorNames": "Dillon Otto (University of Utah, United States), Tanner Rowlett (University of Utah, United States), Stefan Nagy (University of Utah, United States)",
							"abstract": "Desktop applications represent one of today's largest software ecosystems, accounting for over 96% of workplace computing and supporting essential operations across critical sectors such as healthcare, commerce, industry, and government. Though modern software is increasingly being vetted through fuzzing\u2014an automated testing technique for large-scale bug discovery\u2014a major component of desktop applications remains universally under-vetted: the Graphical User Interface (GUI). Existing desktop-based fuzzers like AFL++ and libFuzzer are limited to non-GUI interfaces (e.g., file- or buffer-based inputs), rendering them wholly incompatible with GUIs. Conversely, mobile app GUI fuzzers like Android's Monkey and iOS's XCMonkey rely on platform-specific SDKs and event-handling, rendering them fundamentally unportable to the broader, more complex landscape of desktop software. For these reasons, desktop GUI code remains largely under-tested, burdening users with numerous GUI-induced errors that should, in principle, be just as discoverable as any other well-fuzzed class of software bugs. This paper introduces GUIFuzz++: the first general-purpose fuzzer for desktop GUI software. Unlike desktop fuzzers that randomly mutate file- or buffer-based inputs, GUIFuzz++ exclusively targets GUI interactions\u2014clicks, scrolls, key presses, window navigation, and more\u2014to uncover complex event sequences triggering GUI-induced program errors. Central to our approach is a novel GUI Interaction Interpreter: a middle-layer translating fuzzer-generated random inputs into distinct GUI operations, enabling successful non-GUI fuzzers like AFL++ to be easily ported to testing GUIs. Beyond supporting today's most popular GUI development frameworks like QT, GTK, and Xorg, we introduce a suite of enhancements capitalizing on ubiquitous Software Accessibility Technologies, significantly boosting GUI fuzzing precision as well as GUI bug-finding effectiveness. We integrate GUIFuzz++ as a prototype atop state-of-the-art GUI-agnostic fuzzer AFL++, and perform a large-scale ablation study of its fundamental components and enhancements. In an evaluation across 12 popular, real-world GUI applications, GUIFuzz++ uncovers 23 previously-unknown GUI-induced bugs\u2014with 14 thus far confirmed or fixed by developers.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 GUIFuzz++: Unleashing Grey-box Fuzzing on Desktop Graphical User Interfacing Applications 1758743276255 10.1109/ASE63991.2025.00098 Dillon Otto University of Utah, United States u1349010@utah.edu Tanner Rowlett University of Utah, United States u1335967@utah.edu Stefan Nagy University of Utah, United States snagy@cs.utah.edu graphical user interfaces gui testing fuzzing Desktop applications represent one of today's largest software ecosystems, accounting for over 96% of workplace computing and supporting essential operations across critical sectors such as healthcare, commerce, industry, and government. Though modern software is increasingly being vetted through fuzzing\u2014an automated testing technique for large-scale bug discovery\u2014a major component of desktop applications remains universally under-vetted: the Graphical User Interface (GUI). Existing desktop-based fuzzers like AFL++ and libFuzzer are limited to non-GUI interfaces (e.g., file- or buffer-based inputs), rendering them wholly incompatible with GUIs. Conversely, mobile app GUI fuzzers like Android's Monkey and iOS's XCMonkey rely on platform-specific SDKs and event-handling, rendering them fundamentally unportable to the broader, more complex landscape of desktop software. For these reasons, desktop GUI code remains largely under-tested, burdening users with numerous GUI-induced errors that should, in principle, be just as discoverable as any other well-fuzzed class of software bugs. This paper introduces GUIFuzz++: the first general-purpose fuzzer for desktop GUI software. Unlike desktop fuzzers that randomly mutate file- or buffer-based inputs, GUIFuzz++ exclusively targets GUI interactions\u2014clicks, scrolls, key presses, window navigation, and more\u2014to uncover complex event sequences triggering GUI-induced program errors. Central to our approach is a novel GUI Interaction Interpreter: a middle-layer translating fuzzer-generated random inputs into distinct GUI operations, enabling successful non-GUI fuzzers like AFL++ to be easily ported to testing GUIs. Beyond supporting today's most popular GUI development frameworks like QT, GTK, and Xorg, we introduce a suite of enhancements capitalizing on ubiquitous Software Accessibility Technologies, significantly boosting GUI fuzzing precision as well as GUI bug-finding effectiveness. We integrate GUIFuzz++ as a prototype atop state-of-the-art GUI-agnostic fuzzer AFL++, and perform a large-scale ablation study of its fundamental components and enhancements. In an evaluation across 12 popular, real-world GUI applications, GUIFuzz++ uncovers 23 previously-unknown GUI-induced bugs\u2014with 14 thus far confirmed or fixed by developers.",
							"pageNumber": 1131,
							"isPageNumberRoman": false
						},
						{
							"eid": "1KgJwCwvcGn4dnV0r2vBtD",
							"type": "authorPaper",
							"text": "Hypergraph Neural Network-Based Multi-Granular Root Cause Localization for Microservice Systems",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b142/573300b142.pdf",
							"extraLocations": [],
							"authorNames": "Yaxiao Li (Xidian University, China), Lu Wang (Xidian University, China), Chenxi Zhang (Xidian University, China), Qingshan Li (Xidian University, China), Siming Rong (Xidian University, China), Baiyang Wen (Xidian University, China), Xuyang Li (Xidian University, China), Kun Ma (Xidian University, China), Quanwei Du (Xidian University, China), Keyang Li (Xidian University, China), Lingfeng Pan (Xidian University, China), Xinyue Li (Peking University, China), Mingxuan Hui (Xidian University, China)",
							"abstract": "Modern enterprises are increasingly adopting microservice architectures to enhance system flexibility and scalability. However, in the face of ever-changing business requirements, the relationships between system components have become increasingly complex, resulting in significant challenges in maintaining system robustness. In recent years, multimodal data-driven approaches based on graph neural networks have emerged as a predominant solution for root cause localization in microservice systems. Our detailed analysis of architectural characteristics and existing research reveals two critical limitations. First, simple graph is insufficient to represent the one-to-many relationships inherent in microservice component interactions, such as deployment, subordinate, and dependency. Second, the current multimodal data-based method has difficulty in performing localization on faults occurring on hosts, services, and instances at the same time. To address these challenges, we propose HyperRCA, a novel multi-granular root cause analysis approach based on hypergraph neural networks. Our approach models system states during faults via a hypergraph with instances as graph nodes, explicitly capturing heterogeneous relationships through three innovative hyperedge designs: deployment hyperedges for infrastructure relationships, subordinate hyperedges for service hierarchies, and dependency hyperedges for inter-component interactions. We used hypergraph neural networks and multi-layer perceptrons to train a root cause localization model based on hyperedge features to achieve multi-granularity root cause localization. Experimental evaluations demonstrate significant performance improvements over state-of-the-art approaches. HyperRCA achieves a maximum HR@5 improvement of 112.62% on single-granularity datasets and 466.43% in multi-granularity scenarios.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Hypergraph Neural Network-Based Multi-Granular Root Cause Localization for Microservice Systems 1759323729453 10.1109/ASE63991.2025.00099 Yaxiao Li Xidian University, China yx_li@stu.xidian.edu.cn Lu Wang Xidian University, China wanglu@xidian.edu.cn Chenxi Zhang Xidian University, China zhangchenxi@xidian.edu.cn Qingshan Li Xidian University, China qshli@mail.xidian.edu.cn Siming Rong Xidian University, China rsm@stu.xidian.edu.cn Baiyang Wen Xidian University, China typemoon@stu.xidian.edu.cn Xuyang Li Xidian University, China whisper@stu.xidian.edu.cn Kun Ma Xidian University, China mk2022@stu.xidian.edu.cn Quanwei Du Xidian University, China du_quanwei@163.com Keyang Li Xidian University, China keyangli@stu.xidian.edu.cn Lingfeng Pan Xidian University, China lfpan@stu.xidian.edu.cn Xinyue Li Peking University, China xinyueli@stu.pku.edu.cn Mingxuan Hui Xidian University, China hmx@stu.xidian.edu.cn microservice system root cause localization hypergraph neural network multi-granular Modern enterprises are increasingly adopting microservice architectures to enhance system flexibility and scalability. However, in the face of ever-changing business requirements, the relationships between system components have become increasingly complex, resulting in significant challenges in maintaining system robustness. In recent years, multimodal data-driven approaches based on graph neural networks have emerged as a predominant solution for root cause localization in microservice systems. Our detailed analysis of architectural characteristics and existing research reveals two critical limitations. First, simple graph is insufficient to represent the one-to-many relationships inherent in microservice component interactions, such as deployment, subordinate, and dependency. Second, the current multimodal data-based method has difficulty in performing localization on faults occurring on hosts, services, and instances at the same time. To address these challenges, we propose HyperRCA, a novel multi-granular root cause analysis approach based on hypergraph neural networks. Our approach models system states during faults via a hypergraph with instances as graph nodes, explicitly capturing heterogeneous relationships through three innovative hyperedge designs: deployment hyperedges for infrastructure relationships, subordinate hyperedges for service hierarchies, and dependency hyperedges for inter-component interactions. We used hypergraph neural networks and multi-layer perceptrons to train a root cause localization model based on hyperedge features to achieve multi-granularity root cause localization. Experimental evaluations demonstrate significant performance improvements over state-of-the-art approaches. HyperRCA achieves a maximum HR@5 improvement of 112.62% on single-granularity datasets and 466.43% in multi-granularity scenarios.",
							"pageNumber": 1142,
							"isPageNumberRoman": false
						},
						{
							"eid": "5jHMMnfwruQmi4Wq8onYk6",
							"type": "authorPaper",
							"text": "Seeing is Fixing: Cross-Modal Reasoning with Multimodal LLMs for Visual Software Issue Repair",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b155/573300b155.pdf",
							"extraLocations": [],
							"authorNames": "Kai Huang (Technical University of Munich), Jian Zhang (Nanyang Technological University), Xiaofei Xie (Singapore Management University), Chunyang Chen (Technical University of Munich)",
							"abstract": "Large language model (LLM)-based automated program repair (APR) techniques have shown promising results in resolving real-world github issue tasks. Existing APR systems are primarily evaluated in unimodal settings (e.g., SWE-bench), relying solely on textual issue descriptions and source code. However, these autonomous systems struggle to resolve multimodal problem scenarios (e.g., SWE-bench M) due to limitations in interpreting and leveraging visual information. In multimodal scenarios, LLMs need to rely on visual information in the graphical user interface (GUI) to understand bugs and generate fixes. To bridge this gap, we propose GUIRepair, a cross-modal reasoning approach for resolving multimodal issue scenarios by understanding and capturing visual information. Specifically, GUIRepair integrates two key components, Image2Code and Code2Image\u2014to enhance fault comprehension and patch validation. Image2Code extracts relevant project documents based on the issue report, then applies these domain knowledge to generate the reproduced code responsible for the visual symptoms, effectively translating GUI images into executable context for better fault comprehension. Code2Image replays the visual issue scenario using the reproduced code and captures GUI renderings of the patched program to assess whether the fix visually resolves the issue, providing feedback for patch validation. We evaluate GUIRepair on SWE bench M, and the approach demonstrates significant effectiveness. When utilizing GPT-4o as the base model, GUIRepair solves 157 instances, outperforming the best open-source baseline by 26 instances. Furthermore, when using o4-mini as the base model, GUIRepair can achieve even better results and solve 175 instances, outperforming the top commercial system by 22 instances. This emphasizes the success of our new perspective on incorporating cross-modal reasoning by understanding and capturing visual information to resolve multimodal issues.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Seeing is Fixing: Cross-Modal Reasoning with Multimodal LLMs for Visual Software Issue Repair 1759242515864 10.1109/ASE63991.2025.00100 Kai Huang Technical University of Munich kai-kevin.huang@tum.de Jian Zhang Nanyang Technological University jian_zhang@ntu.edu.sg Xiaofei Xie Singapore Management University xfxie@smu.edu.sg Chunyang Chen Technical University of Munich chun-yang.chen@tum.de Large Language Model Automated Program Repair Autonomous Programming Multimodal Issue Large language model (LLM)-based automated program repair (APR) techniques have shown promising results in resolving real-world github issue tasks. Existing APR systems are primarily evaluated in unimodal settings (e.g., SWE-bench), relying solely on textual issue descriptions and source code. However, these autonomous systems struggle to resolve multimodal problem scenarios (e.g., SWE-bench M) due to limitations in interpreting and leveraging visual information. In multimodal scenarios, LLMs need to rely on visual information in the graphical user interface (GUI) to understand bugs and generate fixes. To bridge this gap, we propose GUIRepair, a cross-modal reasoning approach for resolving multimodal issue scenarios by understanding and capturing visual information. Specifically, GUIRepair integrates two key components, Image2Code and Code2Image\u2014to enhance fault comprehension and patch validation. Image2Code extracts relevant project documents based on the issue report, then applies these domain knowledge to generate the reproduced code responsible for the visual symptoms, effectively translating GUI images into executable context for better fault comprehension. Code2Image replays the visual issue scenario using the reproduced code and captures GUI renderings of the patched program to assess whether the fix visually resolves the issue, providing feedback for patch validation. We evaluate GUIRepair on SWE bench M, and the approach demonstrates significant effectiveness. When utilizing GPT-4o as the base model, GUIRepair solves 157 instances, outperforming the best open-source baseline by 26 instances. Furthermore, when using o4-mini as the base model, GUIRepair can achieve even better results and solve 175 instances, outperforming the top commercial system by 22 instances. This emphasizes the success of our new perspective on incorporating cross-modal reasoning by understanding and capturing visual information to resolve multimodal issues.",
							"pageNumber": 1155,
							"isPageNumberRoman": false
						},
						{
							"eid": "55N5tLojaJ66szt09P7OVQ",
							"type": "authorPaper",
							"text": "When Autonomous Vehicle Meets V2X Cooperative Perception: How Far Are We?",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b168/573300b168.pdf",
							"extraLocations": [],
							"authorNames": "An Guo (Nanjing University, China), Shuoxiao  Zhang (Nanjing University, China), Enyi  Tang (Nanjing University, China), Xinyu  Gao (Nanjing University, China), Haomin  Pang (Guangzhou University, China), Haoxiang  Tian (Nanyang Technological University, Singapore), Yanzhou  Mu (Nanjing University, China), Wu  Wen (Guangzhou University, China), Chunrong  Fang (Nanjing University, China), Zhenyu  Chen (Shenzhen Research Institute of Nanjing University, China)",
							"abstract": "Perceiving the complex driving environment precisely is crucial to the safe operation of autonomous vehicles. With the tremendous advancement of deep learning and communication technology, Vehicle-to-Everything (V2X) cooperative perception has the potential to address limitations in sensing distant objects and occlusion for a single-agent perception system. V2X cooperative perception systems are software systems characterized by diverse sensor types and cooperative agents, varying fusion schemes, and operation under different communication conditions. Therefore, their complex composition gives rise to numerous operational challenges. Furthermore, when cooperative perception systems produce erroneous predictions, the types of errors and their underlying causes remain insufficiently explored. To bridge this gap, we take an initial step by conducting an empirical study of V2X cooperative perception. To systematically evaluate the impact of cooperative perception on the ego vehicle's perception performance, we identify and analyze six prevalent error patterns in cooperative perception systems. We further conduct a systematic evaluation of the critical components of these systems through our large-scale study and identify the following key findings: (1) The LiDAR-based cooperation configuration exhibits the highest perception performance; (2) Vehicle-to-infrastructure (V2I) and vehicle-to-vehicle (V2V) communication exhibit distinct cooperative perception performance under different fusion schemes; (3) Increased cooperative perception errors may result in a higher frequency of driving violations; (4) Cooperative perception systems are not robust against communication interference when running online. Our results reveal potential risks and vulnerabilities in critical components of cooperative perception systems. We hope that our findings can better promote the design and repair of cooperative perception systems. ",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 When Autonomous Vehicle Meets V2X Cooperative Perception: How Far Are We? 1759131711031 10.1109/ASE63991.2025.00101 An Guo Nanjing University, China guoan218@smail.nju.edu.cn Shuoxiao Zhang Nanjing University, China sx_zhang@smail.nju.edu.cn Enyi Tang Nanjing University, China eytang@nju.edu.cn Xinyu Gao Nanjing University, China xinyugao@smail.nju.edu.cn Haomin Pang Guangzhou University, China panghaomin@e.gzhu.edu.cn Haoxiang Tian Nanyang Technological University, Singapore haoxiang.tian@ntu.edu.sg Yanzhou Mu Nanjing University, China muyanzhou@smail.nju.edu.cn Wu Wen Guangzhou University, China wenwu@gzhu.edu.cn Chunrong Fang Nanjing University, China fangchunrong@nju.edu.cn Zhenyu Chen Shenzhen Research Institute of Nanjing University, China zychen@nju.edu.cn autonomous driving systems cooperative perception offline and online testing Perceiving the complex driving environment precisely is crucial to the safe operation of autonomous vehicles. With the tremendous advancement of deep learning and communication technology, Vehicle-to-Everything (V2X) cooperative perception has the potential to address limitations in sensing distant objects and occlusion for a single-agent perception system. V2X cooperative perception systems are software systems characterized by diverse sensor types and cooperative agents, varying fusion schemes, and operation under different communication conditions. Therefore, their complex composition gives rise to numerous operational challenges. Furthermore, when cooperative perception systems produce erroneous predictions, the types of errors and their underlying causes remain insufficiently explored. To bridge this gap, we take an initial step by conducting an empirical study of V2X cooperative perception. To systematically evaluate the impact of cooperative perception on the ego vehicle's perception performance, we identify and analyze six prevalent error patterns in cooperative perception systems. We further conduct a systematic evaluation of the critical components of these systems through our large-scale study and identify the following key findings: (1) The LiDAR-based cooperation configuration exhibits the highest perception performance; (2) Vehicle-to-infrastructure (V2I) and vehicle-to-vehicle (V2V) communication exhibit distinct cooperative perception performance under different fusion schemes; (3) Increased cooperative perception errors may result in a higher frequency of driving violations; (4) Cooperative perception systems are not robust against communication interference when running online. Our results reveal potential risks and vulnerabilities in critical components of cooperative perception systems. We hope that our findings can better promote the design and repair of cooperative perception systems.",
							"pageNumber": 1168,
							"isPageNumberRoman": false
						},
						{
							"eid": "4PKd78Me1CuMI94uV3TNfz",
							"type": "authorPaper",
							"text": "Backdoors in Code Summarizers: How Bad Is It?",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b181/573300b181.pdf",
							"extraLocations": [],
							"authorNames": "Chenyu Wang (Singapore Management University), Zhou Yang (University of Alberta; Alberta Machine Intelligence Institute), Yaniv Harel (Tel Aviv University), David Lo (Singapore Management University)",
							"abstract": "Large Language Models for Code (Code LLMs) are increasingly employed in software development. However, studies have recently shown that these models are vulnerable to backdoor attacks: when a trigger (a specific input pattern) appears in the input, the backdoor will be activated and cause the model to generate malicious outputs desired by the attacker. Researchers have designed various triggers and demonstrated the feasibility of implanting backdoors by poisoning a fraction of the training data (known as data poisoning). Some basic conclusions have been made, such as backdoors becoming easier to implant when attackers modify more training data. However, existing research has not explored other factors influencing backdoor attacks on Code LLMs, such as training batch size, epoch number, and the broader design space for triggers, e.g., trigger length. To bridge this gap, we use the code summarization task as an example to perform a comprehensive empirical study that systematically investigates the factors affecting backdoor effectiveness and understands the extent of the threat posed by backdoor attacks on Code LLMs. Three categories of factors are considered: data, model, and inference, revealing findings overlooked in previous studies for practitioners to mitigate backdoor threats. For example, Code LLM developers can adopt higher batch sizes with fewer epochs appropriately. Users of code models can adjust inference parameters, such as using a higher temperature or a larger top-k, appropriately. Future backdoor defense can prioritize the inspection of rarer and longer tokens, since they are more effective if they are indeed triggers. Since these non-backdoor design factors can also greatly sway attack performance, future backdoor studies should fully report settings, control key factors, and systematically vary them across configurations. What's more, we find that the prevailing consensus, that attacks are ineffective at extremely low poisoning rates, is incorrect. The absolute number of poisoned samples matters as well. Specifically, poisoning just 20 out of 454,451 samples (0.004% poisoning rate, far below the minimum setting of 0.1% considered in prior Code LLM backdoor attack studies) successfully implants backdoors! Moreover, the common defense is incapable of removing even a single poisoned sample from this poisoned dataset, highlighting the urgent need for defense mechanisms against extremely low poisoning rate settings.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Backdoors in Code Summarizers: How Bad Is It? 1759486483487 10.1109/ASE63991.2025.00102 Chenyu Wang Singapore Management University chenyuwang@smu.edu.sg Zhou Yang University of Alberta; Alberta Machine Intelligence Institute zhou.yang@ualberta.ca Yaniv Harel Tel Aviv University yaniv10@tauex.tau.ac.il David Lo Singapore Management University davidlo@smu.edu.sg adversarial attack data poisoning backdoor attack code llms Large Language Models for Code (Code LLMs) are increasingly employed in software development. However, studies have recently shown that these models are vulnerable to backdoor attacks: when a trigger (a specific input pattern) appears in the input, the backdoor will be activated and cause the model to generate malicious outputs desired by the attacker. Researchers have designed various triggers and demonstrated the feasibility of implanting backdoors by poisoning a fraction of the training data (known as data poisoning). Some basic conclusions have been made, such as backdoors becoming easier to implant when attackers modify more training data. However, existing research has not explored other factors influencing backdoor attacks on Code LLMs, such as training batch size, epoch number, and the broader design space for triggers, e.g., trigger length. To bridge this gap, we use the code summarization task as an example to perform a comprehensive empirical study that systematically investigates the factors affecting backdoor effectiveness and understands the extent of the threat posed by backdoor attacks on Code LLMs. Three categories of factors are considered: data, model, and inference, revealing findings overlooked in previous studies for practitioners to mitigate backdoor threats. For example, Code LLM developers can adopt higher batch sizes with fewer epochs appropriately. Users of code models can adjust inference parameters, such as using a higher temperature or a larger top-k, appropriately. Future backdoor defense can prioritize the inspection of rarer and longer tokens, since they are more effective if they are indeed triggers. Since these non-backdoor design factors can also greatly sway attack performance, future backdoor studies should fully report settings, control key factors, and systematically vary them across configurations. What's more, we find that the prevailing consensus, that attacks are ineffective at extremely low poisoning rates, is incorrect. The absolute number of poisoned samples matters as well. Specifically, poisoning just 20 out of 454,451 samples (0.004% poisoning rate, far below the minimum setting of 0.1% considered in prior Code LLM backdoor attack studies) successfully implants backdoors! Moreover, the common defense is incapable of removing even a single poisoned sample from this poisoned dataset, highlighting the urgent need for defense mechanisms against extremely low poisoning rate settings.",
							"pageNumber": 1181,
							"isPageNumberRoman": false
						},
						{
							"eid": "3af5ekuHRm7uJ1g1DfNsba",
							"type": "authorPaper",
							"text": "AdaptEval: A Benchmark for Evaluating Large Language Models on Code Snippet Adaptation",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b194/573300b194.pdf",
							"extraLocations": [],
							"authorNames": "Tanghaoran Zhang (National University of Defense and Technology, China), Xinjun Mao (National University of Defense and Technology, China), Shangwen Wang (National University of Defense and Technology, China), Yuxin Zhao (National University of Defense and Technology, China), Yao Lu (National University of Defense and Technology, China), Jin Zhang (Changsha University of Science and Technology, China), Zhang Zhang (National University of Defense and Technology, China), Kang Yang (National University of Defense and Technology, China), Yue Yu (National University of Defense and Technology, China; Peng Cheng Laboratory, China)",
							"abstract": "Recent advancements in large language models (LLMs) have automated various software engineering tasks, with benchmarks emerging to evaluate their capabilities. However, for adaptation, a critical activity during code reuse, there is no benchmark to assess LLMs' performance, leaving their practical utility in this area unclear. To fill this gap, we propose AdaptEval, a benchmark designed to evaluate LLMs on code snippet adaptation. Unlike existing benchmarks, AdaptEval incorporates the following three distinctive features: First, practical context. Tasks in AdaptEval are derived from developers' practices, preserving rich contextual information from Stack Overflow and GitHub communities. Second, multi-granularity annotation. Each task is annotated with requirements at both task and adaptation levels, supporting the evaluation of LLMs across diverse adaptation scenarios. Third, fine-grained evaluation. AdaptEval includes a two-tier testing framework combining adaptation-level and function-level tests, which enables evaluating LLMs' performance across various individual adaptations. Based on AdaptEval, we conduct the first empirical study to evaluate six instruction-tuned LLMs and especially three reasoning LLMs on code snippet adaptation. Experimental results demonstrate that AdaptEval enables the assessment of LLMs' adaptation capabilities from various perspectives. It also provides critical insights into their current limitations, particularly their struggle to follow explicit instructions. We hope AdaptEval can facilitate further investigation and enhancement of LLMs' capabilities in code snippet adaptation, supporting their real-world applications.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 AdaptEval: A Benchmark for Evaluating Large Language Models on Code Snippet Adaptation 1758863571169 10.1109/ASE63991.2025.00103 Tanghaoran Zhang National University of Defense and Technology, China zhangthr@nudt.edu.cn Xinjun Mao National University of Defense and Technology, China xjmao@nudt.edu.cn Shangwen Wang National University of Defense and Technology, China wangshangwen13@nudt.edu.cn Yuxin Zhao National University of Defense and Technology, China yuxinzhao@nudt.edu.cn Yao Lu National University of Defense and Technology, China luyao08@nudt.edu.cn Jin Zhang Changsha University of Science and Technology, China mail_zhangjin@163.com Zhang Zhang National University of Defense and Technology, China zhangzhang14@nudt.edu.cn Kang Yang National University of Defense and Technology, China yangkang@nudt.edu.cn Yue Yu National University of Defense and Technology, China; Peng Cheng Laboratory, China yuy@pcl.ac.cn code snippet adaptation large language models benchmark code reuse Recent advancements in large language models (LLMs) have automated various software engineering tasks, with benchmarks emerging to evaluate their capabilities. However, for adaptation, a critical activity during code reuse, there is no benchmark to assess LLMs' performance, leaving their practical utility in this area unclear. To fill this gap, we propose AdaptEval, a benchmark designed to evaluate LLMs on code snippet adaptation. Unlike existing benchmarks, AdaptEval incorporates the following three distinctive features: First, practical context. Tasks in AdaptEval are derived from developers' practices, preserving rich contextual information from Stack Overflow and GitHub communities. Second, multi-granularity annotation. Each task is annotated with requirements at both task and adaptation levels, supporting the evaluation of LLMs across diverse adaptation scenarios. Third, fine-grained evaluation. AdaptEval includes a two-tier testing framework combining adaptation-level and function-level tests, which enables evaluating LLMs' performance across various individual adaptations. Based on AdaptEval, we conduct the first empirical study to evaluate six instruction-tuned LLMs and especially three reasoning LLMs on code snippet adaptation. Experimental results demonstrate that AdaptEval enables the assessment of LLMs' adaptation capabilities from various perspectives. It also provides critical insights into their current limitations, particularly their struggle to follow explicit instructions. We hope AdaptEval can facilitate further investigation and enhancement of LLMs' capabilities in code snippet adaptation, supporting their real-world applications.",
							"pageNumber": 1194,
							"isPageNumberRoman": false
						},
						{
							"eid": "3obb80TbhBzIiesyop8Kf3",
							"type": "authorPaper",
							"text": "Bridging Natural Language and Formal Specification Automated Translation of Software Requirements to LTL via Hierarchical Semantics Decomposition Using LLMs",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b207/573300b207.pdf",
							"extraLocations": [],
							"authorNames": "Zhi Ma (Xidian University, China), Cheng Wen (Guangzhou Institute of Technology of Xidian University, China), Zhexin Su (Xidian University, China), Xiao Liang (Xidian University, China), Cong  Tian (Xidian University, China), Shengchao Qin (Xidian University, China), Mengfei Yang (China Academy of Space Technology, China)",
							"abstract": "Automating the translation of natural language (NL) software requirements into formal specifications remains a critical challenge in scaling formal verification practices to in dustrial settings, particularly in safety-critical domains. Existing approaches, both rule-based and learning-based, face significant limitations. While large language models (LLMs) like GPT 4o demonstrate proficiency in semantic extraction, they still encounter difficulties in addressing the complexity, ambiguity, and logical depth of real-world industrial requirements. In this paper, we propose REQ2LTL, a modular framework that bridges NL and Linear Temporal Logic (LTL) through a hierarchical intermediate representation called OnionL. REQ2LTL leverages LLMsfor semantic decomposition and combines them with deter ministic rule-based synthesis to ensure both syntactic validity and semantic fidelity. Our comprehensive evaluation demonstrates that REQ2LTL achieves 88.4% semantic accuracy and 100% syntactic correctness on real-world aerospace requirements, sig nificantly outperforming existing methods.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Bridging Natural Language and Formal Specification Automated Translation of Software Requirements to LTL via Hierarchical Semantics Decomposition Using LLMs 1758538699185 10.1109/ASE63991.2025.00104 Zhi Ma Xidian University, China mazhi@xidian.edu.cn Cheng Wen Guangzhou Institute of Technology of Xidian University, China wencheng@xidian.edu.cn Zhexin Su Xidian University, China 23031212487@stu.xidian.edu.cn Xiao Liang Xidian University, China xiaoliang@stu.xidian.edu.cn Cong Tian Xidian University, China ctian@mail.xidian.edu.cn Shengchao Qin Xidian University, China qinshengchao@xidian.edu.cn Mengfei Yang China Academy of Space Technology, China yangmf@bice.org.cn formal specifications large language models formal verification linear temporal logic software requirement Automating the translation of natural language (NL) software requirements into formal specifications remains a critical challenge in scaling formal verification practices to in dustrial settings, particularly in safety-critical domains. Existing approaches, both rule-based and learning-based, face significant limitations. While large language models (LLMs) like GPT 4o demonstrate proficiency in semantic extraction, they still encounter difficulties in addressing the complexity, ambiguity, and logical depth of real-world industrial requirements. In this paper, we propose REQ2LTL, a modular framework that bridges NL and Linear Temporal Logic (LTL) through a hierarchical intermediate representation called OnionL. REQ2LTL leverages LLMsfor semantic decomposition and combines them with deter ministic rule-based synthesis to ensure both syntactic validity and semantic fidelity. Our comprehensive evaluation demonstrates that REQ2LTL achieves 88.4% semantic accuracy and 100% syntactic correctness on real-world aerospace requirements, sig nificantly outperforming existing methods.",
							"pageNumber": 1207,
							"isPageNumberRoman": false
						},
						{
							"eid": "5bu3xSpT1uY20TzDezOVXD",
							"type": "authorPaper",
							"text": "RFCAudit: AI Agent for Auditing Protocol Implementations Against RFC Specifications",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b220/573300b220.pdf",
							"extraLocations": [],
							"authorNames": "Mingwei Zheng (Purdue University, USA), Chengpeng Wang (Purdue University, USA), Xuwei Liu (Purdue University, USA), Jinyao Guo (Purdue University, USA), Shiwei Feng (Purdue University, USA), Xiangyu Zhang (Purdue University, USA)",
							"abstract": "Functional correctness is critical for ensuring the reliability and security of network protocol implementations. Functional bugs, instances where implementations diverge from behaviors specified in RFC documents, can lead to severe consequences, including faulty routing, authentication bypasses, and service disruptions. Detecting these bugs requires deep semantic analysis across specification documents and source code, a task beyond the capabilities of traditional static analysis tools. This paper introduces RFCAudit, an autonomous agent that leverages large language models (LLMs) to detect functional bugs by checking conformance between network protocol implementations and their RFC specifications. Inspired by the human auditing procedure, RFCAudit comprises two key components: an indexing agent and a detection agent. The former hierarchically summarizes protocol code semantics, generating semantic indexes that enable the detection agent to narrow down the scanning scope. The latter employs demand-driven retrieval to iteratively collect additional relevant data structures and functions, eventually identifying potential inconsistencies with the RFC specifications effectively. We evaluate RFCAudit across six real-world network protocol implementations. RFCAudit identifies 47 functional bugs with 81.9% precision, of which 20 bugs have been confirmed or fixed by developers.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 RFCAudit: AI Agent for Auditing Protocol Implementations Against RFC Specifications 1759114519179 10.1109/ASE63991.2025.00105 Mingwei Zheng Purdue University, USA zheng618@purdue.edu Chengpeng Wang Purdue University, USA wang6590@purdue.edu Xuwei Liu Purdue University, USA liu2598@purdue.edu Jinyao Guo Purdue University, USA guo846@purdue.edu Shiwei Feng Purdue University, USA feng292@purdue.edu Xiangyu Zhang Purdue University, USA xyzhang@purdue.edu functional bug detection large language model network protocols Functional correctness is critical for ensuring the reliability and security of network protocol implementations. Functional bugs, instances where implementations diverge from behaviors specified in RFC documents, can lead to severe consequences, including faulty routing, authentication bypasses, and service disruptions. Detecting these bugs requires deep semantic analysis across specification documents and source code, a task beyond the capabilities of traditional static analysis tools. This paper introduces RFCAudit, an autonomous agent that leverages large language models (LLMs) to detect functional bugs by checking conformance between network protocol implementations and their RFC specifications. Inspired by the human auditing procedure, RFCAudit comprises two key components: an indexing agent and a detection agent. The former hierarchically summarizes protocol code semantics, generating semantic indexes that enable the detection agent to narrow down the scanning scope. The latter employs demand-driven retrieval to iteratively collect additional relevant data structures and functions, eventually identifying potential inconsistencies with the RFC specifications effectively. We evaluate RFCAudit across six real-world network protocol implementations. RFCAudit identifies 47 functional bugs with 81.9% precision, of which 20 bugs have been confirmed or fixed by developers.",
							"pageNumber": 1220,
							"isPageNumberRoman": false
						},
						{
							"eid": "3xZVRPnoOccrtQNGL7W5CL",
							"type": "authorPaper",
							"text": "RFCScope: Detecting Logical Ambiguities in Internet Protocol Specifications",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b233/573300b233.pdf",
							"extraLocations": [],
							"authorNames": "Mrigank Pawagi (Indian Institute of Science, India), Lize Shao (University of Virginia, USA), Hyeonmin Lee (University of Virginia, USA), Yixin Sun (University of Virginia, USA), Wenxi Wang (University of Virginia, USA)",
							"abstract": "Internet protocol specifications, published as Requests for Comments (RFCs) by the IETF organization, are essential to ensuring the interoperability, security, and reliability of the Internet. However, ambiguities in these specifications, particularly logical ambiguities such as inconsistencies and under-specifications, can lead to critical misinterpretations and implementation errors. Unfortunately, such ambiguities remain largely overlooked and challenging to detect with existing tools. In this paper, we present the first systematic study of verified technical errata from Standards Track RFCs over the past 11 years, identifying seven distinct subtypes of logical ambiguities. Building on these insights, we introduce RFCScope, the first scalable framework for detecting logical ambiguities in RFCs. RFCScope employs large language models (LLMs) through a modular pipeline that constructs targeted cross-document context, partitions specifications to preserve semantic integrity, applies bug-type-aware prompts for detection, and filters out false positives using structured reasoning validation. RFCScope uncovers 31 new logical ambiguities spanning all seven subtypes across 14 recent RFCs. Eight of these have been confirmed by RFC authors, with three officially verified as technical errata. Our results demonstrate that RFCScope offers a practical solution for improving the clarity, consistency, and reliability of protocol standards through ambiguity detection.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 RFCScope: Detecting Logical Ambiguities in Internet Protocol Specifications 1759498447965 10.1109/ASE63991.2025.00106 Mrigank Pawagi Indian Institute of Science, India mrigankp@iisc.ac.in Lize Shao University of Virginia, USA zgr3et@virginia.edu Hyeonmin Lee University of Virginia, USA frv9vh@virginia.edu Yixin Sun University of Virginia, USA ys3kz@virginia.edu Wenxi Wang University of Virginia, USA wenxiw@virginia.edu Internet protocol specifications, published as Requests for Comments (RFCs) by the IETF organization, are essential to ensuring the interoperability, security, and reliability of the Internet. However, ambiguities in these specifications, particularly logical ambiguities such as inconsistencies and under-specifications, can lead to critical misinterpretations and implementation errors. Unfortunately, such ambiguities remain largely overlooked and challenging to detect with existing tools. In this paper, we present the first systematic study of verified technical errata from Standards Track RFCs over the past 11 years, identifying seven distinct subtypes of logical ambiguities. Building on these insights, we introduce RFCScope, the first scalable framework for detecting logical ambiguities in RFCs. RFCScope employs large language models (LLMs) through a modular pipeline that constructs targeted cross-document context, partitions specifications to preserve semantic integrity, applies bug-type-aware prompts for detection, and filters out false positives using structured reasoning validation. RFCScope uncovers 31 new logical ambiguities spanning all seven subtypes across 14 recent RFCs. Eight of these have been confirmed by RFC authors, with three officially verified as technical errata. Our results demonstrate that RFCScope offers a practical solution for improving the clarity, consistency, and reliability of protocol standards through ambiguity detection.",
							"pageNumber": 1233,
							"isPageNumberRoman": false
						},
						{
							"eid": "15eHa6BMMZYgpQxcyfsSiL",
							"type": "authorPaper",
							"text": "Protecting Source Code Privacy When Hunting Memory Bugs",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b246/573300b246.pdf",
							"extraLocations": [],
							"authorNames": "Jielun Wu (Nanjing University, China), Bing Shui (Nanjing University, China), Hongcheng Fan (Nanjing University, China), Shengxin Wu (Nanjing University, China), Rongxin Wu (Xiamen University, China), Yang Feng (Nanjing University, China), Baowen Xu (Nanjing University, China), Qingkai Shi (Nanjing University, China)",
							"abstract": "When proving to a third party that a software system is free from critical memory bugs, software vendors often face the problem of having to reveal their source code, so that the third party can scan the source code using static analysis tools. However, such transparency poses a significant threat to vendors, as the source code typically contains proprietary algorithms, core technical innovations, or trade secrets, exposing them to potential intellectual property risks. In this paper, we present a solution that offers a balance between transparency and code privacy, allowing software vendors to provide minimal source code information while justifying the sufficiency of bug detection. To this end, we propose DIREDUCER, which reduces source code information, a.k.a. debug information, from non-stripped binaries while preserving its utility for memory bug detection. DIREDUCER consists of two components: selective pruning and type minimization. The former eliminates redundant debug information, and the latter is proven to be NP-hard and minimizes type-related debug information by reducing it to the classic set-cover problem, which offers a near-optimal solution. Experimental results show that we can reduce 95% of debug information while maintaining similar bug detection capability compared to using full debug information or the source code.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Protecting Source Code Privacy When Hunting Memory Bugs 1759125291766 10.1109/ASE63991.2025.00107 Jielun Wu Nanjing University, China jielunwu@smail.nju.edu.cn Bing Shui Nanjing University, China bingshui@smail.nju.edu.cn Hongcheng Fan Nanjing University, China hchfan@smail.nju.edu.cn Shengxin Wu Nanjing University, China wsx@smail.nju.edu.cn Rongxin Wu Xiamen University, China wurongxin@xmu.edu.cn Yang Feng Nanjing University, China fengyang@nju.edu.cn Baowen Xu Nanjing University, China bwxu@nju.edu.cn Qingkai Shi Nanjing University, China qingkaishi@nju.edu.cn code privacy protecion static program analysis bug detection debug information When proving to a third party that a software system is free from critical memory bugs, software vendors often face the problem of having to reveal their source code, so that the third party can scan the source code using static analysis tools. However, such transparency poses a significant threat to vendors, as the source code typically contains proprietary algorithms, core technical innovations, or trade secrets, exposing them to potential intellectual property risks. In this paper, we present a solution that offers a balance between transparency and code privacy, allowing software vendors to provide minimal source code information while justifying the sufficiency of bug detection. To this end, we propose DIREDUCER, which reduces source code information, a.k.a. debug information, from non-stripped binaries while preserving its utility for memory bug detection. DIREDUCER consists of two components: selective pruning and type minimization. The former eliminates redundant debug information, and the latter is proven to be NP-hard and minimizes type-related debug information by reducing it to the classic set-cover problem, which offers a near-optimal solution. Experimental results show that we can reduce 95% of debug information while maintaining similar bug detection capability compared to using full debug information or the source code.",
							"pageNumber": 1246,
							"isPageNumberRoman": false
						},
						{
							"eid": "3eGW8q1V1d6aIAhrl25X9J",
							"type": "authorPaper",
							"text": "What's DAT Smell? Untangling and Weaving the Disjoint Assertion Tangle Test Smell",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b259/573300b259.pdf",
							"extraLocations": [],
							"authorNames": "Monil Narang (University of California, Irvine, USA), Hang Du (University of California, Irvine, USA), James A. Jones (University of California, Irvine, USA)",
							"abstract": "In this work, we characterize a novel test-code smell\u2014Disjoint Assertion Tangle (DAT)\u2014which occurs when a test method verifies multiple, logically unrelated behaviors that can be separated. We propose a program analysis-based approach that automatically detects DAT and refactors DAT tests into separate focused test methods. We implemented this approach as a tool called U2W. By separating unrelated testing logic, U2W enhances readability, maintainability, and fault localization, while exposing hidden test clones and duplicated code. It then seizes these opportunities by converting structurally similar tests into compact, parameterized unit tests (PUTs), reducing redundancy and enabling more scalable, extensible test designs. To evaluate our approach and tool, we conducted a number of evaluations: (1) a large-scale, quantitative study to study the prevalence of the test smell and the effects of their refactoring, (2) a user survey to assess developers' opinions and preferences of the unrefactored and refactored test code, and (3) pull requests that were issued to original project maintainers to assess the acceptability of our refactorings. Our quantitative study was conducted on 42,334 tests across 49 open-source projects. We found the DAT smell in 95.9% of the subject projects, affecting an average of 8.59% of analyzed tests. In total, we identified and refactored 3,638 smelly tests, untangled them into 31,837 test-execution logics, and then weaved 14,343 of them into 1,713 extensible PUT methods. These refactorings reduced the executable test-code lines in smelly tests by an average of 36.33%. Our user survey involving 49 industrial and academic participants demonstrated strong preference for our refactored test cases over their original, unrefactored versions. Additionally, we submitted 19 pull requests based on our automated refactorings; 16 of these were accepted by project maintainers. These results suggest that U2W effectively improves test-suite quality, and validate our novel test smell aligns closely with developers' intuitions and practices.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 What's DAT Smell? Untangling and Weaving the Disjoint Assertion Tangle Test Smell 1759532692479 10.1109/ASE63991.2025.00108 Monil Narang University of California, Irvine, USA moniln@uci.edu Hang Du University of California, Irvine, USA hdu5@uci.edu James A. Jones University of California, Irvine, USA jajones@uci.edu test smells disjoint assertion tangle (dat) automated refactoring unit testing parameterized unit tests program analysis In this work, we characterize a novel test-code smell\u2014Disjoint Assertion Tangle (DAT)\u2014which occurs when a test method verifies multiple, logically unrelated behaviors that can be separated. We propose a program analysis-based approach that automatically detects DAT and refactors DAT tests into separate focused test methods. We implemented this approach as a tool called U2W. By separating unrelated testing logic, U2W enhances readability, maintainability, and fault localization, while exposing hidden test clones and duplicated code. It then seizes these opportunities by converting structurally similar tests into compact, parameterized unit tests (PUTs), reducing redundancy and enabling more scalable, extensible test designs. To evaluate our approach and tool, we conducted a number of evaluations: (1) a large-scale, quantitative study to study the prevalence of the test smell and the effects of their refactoring, (2) a user survey to assess developers' opinions and preferences of the unrefactored and refactored test code, and (3) pull requests that were issued to original project maintainers to assess the acceptability of our refactorings. Our quantitative study was conducted on 42,334 tests across 49 open-source projects. We found the DAT smell in 95.9% of the subject projects, affecting an average of 8.59% of analyzed tests. In total, we identified and refactored 3,638 smelly tests, untangled them into 31,837 test-execution logics, and then weaved 14,343 of them into 1,713 extensible PUT methods. These refactorings reduced the executable test-code lines in smelly tests by an average of 36.33%. Our user survey involving 49 industrial and academic participants demonstrated strong preference for our refactored test cases over their original, unrefactored versions. Additionally, we submitted 19 pull requests based on our automated refactorings; 16 of these were accepted by project maintainers. These results suggest that U2W effectively improves test-suite quality, and validate our novel test smell aligns closely with developers' intuitions and practices.",
							"pageNumber": 1259,
							"isPageNumberRoman": false
						},
						{
							"eid": "zWGchj1QM0pP6XZPUaR53",
							"type": "authorPaper",
							"text": "SMTgazer: Learning to Schedule SMT Algorithms via Bayesian Optimization",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b272/573300b272.pdf",
							"extraLocations": [],
							"authorNames": "Chuan Luo (Beihang University, China), Shaoke Cui (Beihang University, China), Jianping Song (Beihang University, China), Xindi Zhang (Chinese Academy of Sciences, China), Wei Wu (Central South University, China), Chanjuan Liu (Dalian University of Technology, China), Shaowei Cai (Chinese Academy of Sciences, China), Chunming Hu (Beihang University, China)",
							"abstract": "Satisfiability Modulo Theories (SMT) plays a critical role in various software engineering applications, including program verification, symbolic execution, and automated test generation. Over the years, a wide range of SMT solvers has been developed, typically designed for general purposes or tailored to specific background theories, such as bit-vectors or nonlinear arithmetic. Due to the diversity and complexity of SMT instances, no single solver consistently outperforms others across all problem domains. This motivates the need for algorithm selection strategies that can adaptively choose solvers based on the characteristics of the instances. To overcome the limitations of single-solver selection, solving SMT as a scheduling problem, enabling a more fault-tolerant and effective use of multiple solvers in sequence. We model algorithm scheduling as a hyperparameter optimization problem, enabling efficient black-box search over solver sequences while treating the dataset as a whole, thus achieving globally optimized and robust scheduling strategies. The resulting scheduler called SMTgazer. To further enhance scheduling efficiency and solver performance, we propose two optimizations: leveraging unsupervised X-means clustering to create semantically coherent instance groups for localized model training, and augmenting the Bayesian optimization surrogate with boosting and bagging ensembles to improve generalization and mitigate overfitting, thereby yielding more reliable performance predictions for the sequential portfolio scheduler. Extensive experiments are conducted to evaluate the performance of SMTgazer, utilizing six SMT benchmarks derived from real-world applications. It shows that our approach consistently outperforms current state-of-the-art methods. Particularly, SMTgazer achieves a 44.65% reduction in PAR-2 score and 69.11% decrease in the number of unsolved instances, compared to the strongest competitor, Sibyl, demonstrating the effectiveness of formulating SMT algorithm scheduling as a hyperparameter optimization problem. We further analyze the generated scheduling sequences to uncover the design principles that explain the success of our method. Finally, we also empirically show that our approach is both robust and generalizable, and the proposed strategies are effective.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 SMTgazer: Learning to Schedule SMT Algorithms via Bayesian Optimization 1759408020794 10.1109/ASE63991.2025.00109 Chuan Luo Beihang University, China chuanluo@buaa.edu.cn Shaoke Cui Beihang University, China cuisk@buaa.edu.cn Jianping Song Beihang University, China jpsong@buaa.edu.cn Xindi Zhang Chinese Academy of Sciences, China zhangxd@ios.ac.cn Wei Wu Central South University, China william.third.wu@gmail.com Chanjuan Liu Dalian University of Technology, China chanjuanliu@dlut.edu.cn Shaowei Cai Chinese Academy of Sciences, China caisw@ios.ac.cn Chunming Hu Beihang University, China hucm@buaa.edu.cn smt solver scheduling bayesian optimization Satisfiability Modulo Theories (SMT) plays a critical role in various software engineering applications, including program verification, symbolic execution, and automated test generation. Over the years, a wide range of SMT solvers has been developed, typically designed for general purposes or tailored to specific background theories, such as bit-vectors or nonlinear arithmetic. Due to the diversity and complexity of SMT instances, no single solver consistently outperforms others across all problem domains. This motivates the need for algorithm selection strategies that can adaptively choose solvers based on the characteristics of the instances. To overcome the limitations of single-solver selection, solving SMT as a scheduling problem, enabling a more fault-tolerant and effective use of multiple solvers in sequence. We model algorithm scheduling as a hyperparameter optimization problem, enabling efficient black-box search over solver sequences while treating the dataset as a whole, thus achieving globally optimized and robust scheduling strategies. The resulting scheduler called SMTgazer. To further enhance scheduling efficiency and solver performance, we propose two optimizations: leveraging unsupervised X-means clustering to create semantically coherent instance groups for localized model training, and augmenting the Bayesian optimization surrogate with boosting and bagging ensembles to improve generalization and mitigate overfitting, thereby yielding more reliable performance predictions for the sequential portfolio scheduler. Extensive experiments are conducted to evaluate the performance of SMTgazer, utilizing six SMT benchmarks derived from real-world applications. It shows that our approach consistently outperforms current state-of-the-art methods. Particularly, SMTgazer achieves a 44.65% reduction in PAR-2 score and 69.11% decrease in the number of unsolved instances, compared to the strongest competitor, Sibyl, demonstrating the effectiveness of formulating SMT algorithm scheduling as a hyperparameter optimization problem. We further analyze the generated scheduling sequences to uncover the design principles that explain the success of our method. Finally, we also empirically show that our approach is both robust and generalizable, and the proposed strategies are effective.",
							"pageNumber": 1272,
							"isPageNumberRoman": false
						},
						{
							"eid": "49bXWPbUlZKQXjZPszHlF2",
							"type": "authorPaper",
							"text": "Agentic Specification Generator for Move Programs",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b285/573300b285.pdf",
							"extraLocations": [],
							"authorNames": "Yu-Fu Fu (Georgia Institute of Technology), Meng Xu (University of Waterloo), Taesoo Kim (Georgia Institute of Technology)",
							"abstract": "While LLM-based specification generation is gaining traction, existing tools primarily focus on mainstream programming languages like C, Java, and even Solidity, leaving emerging and yet verification-oriented languages like Move underexplored. In this paper, we introduce MSG, an automated specification generation tool designed for Move smart contracts. MSG aims to highlight key insights that uniquely present when applying LLM-based specification generation to a new ecosystem. Specifically, MSG demonstrates that LLMs exhibit robust code comprehension and generation capabilities even for non-mainstream languages. MSG successfully generates verifiable specifications for 84% of tested Move functions and even identifies clauses previously overlooked by experts. Additionally, MSG shows that explicitly leveraging specification language features through an agentic, modular design improves specification quality substantially (generating 57% more verifiable clauses than conventional designs). Incorporating feedback from the verification toolchain further enhances the effectiveness of MSG, leading to a 30% increase in generated verifiable specifications. ",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Agentic Specification Generator for Move Programs 1759256287298 10.1109/ASE63991.2025.00110 Yu-Fu Fu Georgia Institute of Technology yufu@gatech.edu Meng Xu University of Waterloo meng.xu.cs@uwaterloo.ca Taesoo Kim Georgia Institute of Technology taesoo@gatech.edu llm specification verification move While LLM-based specification generation is gaining traction, existing tools primarily focus on mainstream programming languages like C, Java, and even Solidity, leaving emerging and yet verification-oriented languages like Move underexplored. In this paper, we introduce MSG, an automated specification generation tool designed for Move smart contracts. MSG aims to highlight key insights that uniquely present when applying LLM-based specification generation to a new ecosystem. Specifically, MSG demonstrates that LLMs exhibit robust code comprehension and generation capabilities even for non-mainstream languages. MSG successfully generates verifiable specifications for 84% of tested Move functions and even identifies clauses previously overlooked by experts. Additionally, MSG shows that explicitly leveraging specification language features through an agentic, modular design improves specification quality substantially (generating 57% more verifiable clauses than conventional designs). Incorporating feedback from the verification toolchain further enhances the effectiveness of MSG, leading to a 30% increase in generated verifiable specifications.",
							"pageNumber": 1285,
							"isPageNumberRoman": false
						},
						{
							"eid": "3JIBgHLNws2dVH1ORfYfza",
							"type": "authorPaper",
							"text": "AMPLE: Fine-Grained File Access Policies for Server Applications",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b298/573300b298.pdf",
							"extraLocations": [],
							"authorNames": "Seyedhamed Ghavamnia (Bloomberg, United States), Julien Vanegue (Bloomberg, United States)",
							"abstract": "Userspace programs depend heavily on operating system resources to execute correctly, with file access being one of the most common and critical use cases. Modern Linux distributions include a vast number of files, many of which are unnecessary for the operation of most programs. However, existing access control mechanisms typically enforce coarse-grained policies that allow programs to access far more files than they actually require. This over-permissiveness significantly increases the system's attack surface, exposing sensitive resources to potential exploitation. In this paper, we introduce AMPLE (Automated MAC PoLicy Extraction), a versatile tool that integrates both static and dynamic analysis to identify the files required by server applications. Ample accomplishes this by leveraging the distinct phases of server application execution, extracting runtime-dependent file paths by executing only the program's initialization phase. This novel approach addresses the limitations of relying exclusively on static analysis, which fails to identify runtime-dependent file paths, as well as the shortcomings of purely dynamic analysis, which overlooks file paths accessed in non-executed code paths. To demonstrate its effectiveness, we evaluated Ample on ten widely-used server applications. The results show that Ample significantly reduces the number of accessible files, achieving an average reduction of over 99%, and limiting access to an average of fewer than 254 files per application. This substantial reduction helps restrict access to numerous security-critical files and mitigates 13 Linux kernel CVEs.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 AMPLE: Fine-Grained File Access Policies for Server Applications 1759332037431 10.1109/ASE63991.2025.00111 Seyedhamed Ghavamnia Bloomberg, United States sghavamnia@bloomberg.net Julien Vanegue Bloomberg, United States jvanegue@bloomberg.net Userspace programs depend heavily on operating system resources to execute correctly, with file access being one of the most common and critical use cases. Modern Linux distributions include a vast number of files, many of which are unnecessary for the operation of most programs. However, existing access control mechanisms typically enforce coarse-grained policies that allow programs to access far more files than they actually require. This over-permissiveness significantly increases the system's attack surface, exposing sensitive resources to potential exploitation. In this paper, we introduce AMPLE (Automated MAC PoLicy Extraction), a versatile tool that integrates both static and dynamic analysis to identify the files required by server applications. Ample accomplishes this by leveraging the distinct phases of server application execution, extracting runtime-dependent file paths by executing only the program's initialization phase. This novel approach addresses the limitations of relying exclusively on static analysis, which fails to identify runtime-dependent file paths, as well as the shortcomings of purely dynamic analysis, which overlooks file paths accessed in non-executed code paths. To demonstrate its effectiveness, we evaluated Ample on ten widely-used server applications. The results show that Ample significantly reduces the number of accessible files, achieving an average reduction of over 99%, and limiting access to an average of fewer than 254 files per application. This substantial reduction helps restrict access to numerous security-critical files and mitigates 13 Linux kernel CVEs.",
							"pageNumber": 1298,
							"isPageNumberRoman": false
						},
						{
							"eid": "4lLIxpbmjmltuU7as9R3oQ",
							"type": "authorPaper",
							"text": "Detecting Semantic Clones of Unseen Functionality",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b311/573300b311.pdf",
							"extraLocations": [],
							"authorNames": "Konstantinos Kitsios (University of Zurich, Switzerland), Francesco Sovrano (University of Zurich, Switzerland), Earl T. Barr (University College London, UK), Alberto Bacchelli (University of Zurich, Switzerland)",
							"abstract": "Semantic code clone detection is the task of detecting whether two snippets of code implement the same functionality (e.g., Sort Array). Recently, many neural models achieved near-perfect performance on this task. These models seek to make inferences based on their training data. Consequently, they better detect clones similar to those they have seen during training and may struggle to detect those they have not. Developers seeking clones are, of course, interested in both types of clones. We confirm this claim through a literature review, identifying three practical clone detection tasks in which the model's goal is to detect clones of a functionality even if it was trained on clones of different functionalities. In light of this finding, we re-evaluate six state-of-the-art models, including both task-specific models and generative LLMs, on the task of detecting clones of unseen functionality. Our experiments reveal a drop in F1 of up to 48% (average 31%) for task-specific models. LLMs perform on par with task-specific models without explicit training for clone detection, but generalize better to unseen functionalities, where F1 drops up to 5% (average 3%) instead. We propose and evaluate the use of contrastive learning to improve the performance of existing models on clones of unseen functionality. We draw inspiration from the computer vision and natural language processing fields where contrastive learning excels at measuring similarity between two objects, even if they come from classes unseen during training. We replace the final classifier of the task-specific models with a contrastive classifier, while for the generative LLMs we propose contrastive in-context learning, guiding the LLMs to focus on the differences between clones and non-clones. The F1 on clones of unseen functionality is improved by up to 26% (average 9%) for task-specific models and up to 5% (average 3%) for LLMs.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Detecting Semantic Clones of Unseen Functionality 1759267482788 10.1109/ASE63991.2025.00112 Konstantinos Kitsios University of Zurich, Switzerland konstantinos.kitsios@uzh.ch Francesco Sovrano University of Zurich, Switzerland francesco.sovrano@uzh.ch Earl T. Barr University College London, UK e.barr@ucl.ac.uk Alberto Bacchelli University of Zurich, Switzerland bacchelli@ifi.uzh.ch clone detection ai4se Semantic code clone detection is the task of detecting whether two snippets of code implement the same functionality (e.g., Sort Array). Recently, many neural models achieved near-perfect performance on this task. These models seek to make inferences based on their training data. Consequently, they better detect clones similar to those they have seen during training and may struggle to detect those they have not. Developers seeking clones are, of course, interested in both types of clones. We confirm this claim through a literature review, identifying three practical clone detection tasks in which the model's goal is to detect clones of a functionality even if it was trained on clones of different functionalities. In light of this finding, we re-evaluate six state-of-the-art models, including both task-specific models and generative LLMs, on the task of detecting clones of unseen functionality. Our experiments reveal a drop in F1 of up to 48% (average 31%) for task-specific models. LLMs perform on par with task-specific models without explicit training for clone detection, but generalize better to unseen functionalities, where F1 drops up to 5% (average 3%) instead. We propose and evaluate the use of contrastive learning to improve the performance of existing models on clones of unseen functionality. We draw inspiration from the computer vision and natural language processing fields where contrastive learning excels at measuring similarity between two objects, even if they come from classes unseen during training. We replace the final classifier of the task-specific models with a contrastive classifier, while for the generative LLMs we propose contrastive in-context learning, guiding the LLMs to focus on the differences between clones and non-clones. The F1 on clones of unseen functionality is improved by up to 26% (average 9%) for task-specific models and up to 5% (average 3%) for LLMs.",
							"pageNumber": 1311,
							"isPageNumberRoman": false
						},
						{
							"eid": "76RuBO3M8F09CYF42gZ9tB",
							"type": "authorPaper",
							"text": "Efficient and Verifiable Proof Logging for MaxSAT Solving",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b324/573300b324.pdf",
							"extraLocations": [],
							"authorNames": "Raoul van Doren (ETH Zurich, Switzerland), Timos Antonopoulos (Yale University, USA), Ruzica Piskac (Yale University, USA)",
							"abstract": "MaxSAT solvers are increasingly used as back-ends in software engineering tools. Yet their results have lacked automatically checkable certificates of optimality. While SAT solvers emit DRAT proofs of (un) satisfiability, MaxSAT must additionally prove that no lower-cost solution exists. Existing approaches either cover only isolated solving paradigms or reduce MaxSAT reasoning to heavyweight pseudo-Boolean proofs, yielding impractical verification overhead. We present the first MaxSAT-specific proof-logging framework for core-guided OLL solvers. We formalize native inference rules for cores, cliques, hardenings, totalizer updates, and bound adjustments, and implement both a human-readable logger and a compact binary DAG logger in EvalMaxSAT. Evaluation on the 2024 MaxSAT competition dataset confirm the practicality and scalability of our certification pipeline, paving the way for trustworthy, solver use.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Efficient and Verifiable Proof Logging for MaxSAT Solving 1759425040551 10.1109/ASE63991.2025.00113 Raoul van Doren ETH Zurich, Switzerland rvandoren@student.ethz.ch Timos Antonopoulos Yale University, USA timos.antonopoulos@yale.edu Ruzica Piskac Yale University, USA ruzica.piskac@yale.edu MaxSAT proof logging solver verification coreguided OLL debugging MaxSAT solvers are increasingly used as back-ends in software engineering tools. Yet their results have lacked automatically checkable certificates of optimality. While SAT solvers emit DRAT proofs of (un) satisfiability, MaxSAT must additionally prove that no lower-cost solution exists. Existing approaches either cover only isolated solving paradigms or reduce MaxSAT reasoning to heavyweight pseudo-Boolean proofs, yielding impractical verification overhead. We present the first MaxSAT-specific proof-logging framework for core-guided OLL solvers. We formalize native inference rules for cores, cliques, hardenings, totalizer updates, and bound adjustments, and implement both a human-readable logger and a compact binary DAG logger in EvalMaxSAT. Evaluation on the 2024 MaxSAT competition dataset confirm the practicality and scalability of our certification pipeline, paving the way for trustworthy, solver use.",
							"pageNumber": 1324,
							"isPageNumberRoman": false
						},
						{
							"eid": "492ZHDiAMrrbQag9b8LAYN",
							"type": "authorPaper",
							"text": "FGIT: Fault-Guided Fine-Tuning for Code Generation",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b337/573300b337.pdf",
							"extraLocations": [],
							"authorNames": "Lishui Fan (Zhejiang University, China), Zhongxin Liu (Zhejiang University, China), Haoye Wang (Hangzhou City University, China), Lingfeng Bao (Zhejiang University, China), Xin Xia (Zhejiang University, China), Shanping Li (Zhejiang University, China)",
							"abstract": "Modern instruction-tuned large language models (LLMs) have made remarkable progress in code generation. However, these LLMs fine-tuned with standard supervised fine-tuning (SFT) sometimes generate plausible-looking but functionally incorrect code variants. This issue likely stems from the limitation of standard SFT, which treats all tokens equally during optimization and fails to emphasize the error-sensitive segments\u2014specific code differences between correct implementations and similar incorrect variants. To address this problem, we propose Fault-Guided Fine-Tuning (FGIT), a novel fine-tuning technique that enhances LLMs' code generation by (1) extracting multi-granularity (line/token-level) differences between correct and incorrect yet similar implementations to identify error-sensitive segments, and (2) dynamically prioritizing those segments during training via dynamic loss weighting. Through extensive experiments on seven LLMs across three widely-used benchmarks, our method achieves an average relative improvement of 6.9% on pass@1, with some enhanced 6.7B LLMs outperforming closed-source models, e.g., GPT-3.5-Turbo. Furthermore, our fine-tuning technique demonstrates strong generalization with performance improvements ranging from 3.8% to 19.1% across diverse instruction-tuned LLMs, and our ablation studies confirm the contributions of different granularities of differences and hyperparameters.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 FGIT: Fault-Guided Fine-Tuning for Code Generation 1758852474371 10.1109/ASE63991.2025.00114 Lishui Fan Zhejiang University, China flscode@zju.edu.cn Zhongxin Liu Zhejiang University, China liu_zx@zju.edu.cn Haoye Wang Hangzhou City University, China wanghaoye@hzcu.edu.cn Lingfeng Bao Zhejiang University, China lingfengbao@zju.edu.cn Xin Xia Zhejiang University, China xin.xia@acm.org Shanping Li Zhejiang University, China shan@zju.edu.cn large language model code generation software engineering Modern instruction-tuned large language models (LLMs) have made remarkable progress in code generation. However, these LLMs fine-tuned with standard supervised fine-tuning (SFT) sometimes generate plausible-looking but functionally incorrect code variants. This issue likely stems from the limitation of standard SFT, which treats all tokens equally during optimization and fails to emphasize the error-sensitive segments\u2014specific code differences between correct implementations and similar incorrect variants. To address this problem, we propose Fault-Guided Fine-Tuning (FGIT), a novel fine-tuning technique that enhances LLMs' code generation by (1) extracting multi-granularity (line/token-level) differences between correct and incorrect yet similar implementations to identify error-sensitive segments, and (2) dynamically prioritizing those segments during training via dynamic loss weighting. Through extensive experiments on seven LLMs across three widely-used benchmarks, our method achieves an average relative improvement of 6.9% on pass@1, with some enhanced 6.7B LLMs outperforming closed-source models, e.g., GPT-3.5-Turbo. Furthermore, our fine-tuning technique demonstrates strong generalization with performance improvements ranging from 3.8% to 19.1% across diverse instruction-tuned LLMs, and our ablation studies confirm the contributions of different granularities of differences and hyperparameters.",
							"pageNumber": 1337,
							"isPageNumberRoman": false
						},
						{
							"eid": "2W8VbvumHhOYt4JnpiodPS",
							"type": "authorPaper",
							"text": "Destabilizing Neurons to Generate Challenging Neural Network Verification Benchmarks",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b350/573300b350.pdf",
							"extraLocations": [],
							"authorNames": "Linhan Li (George Mason University, USA), ThanhVu Nguyen (George Mason University, USA)",
							"abstract": "Neural Network Verification has made significant progress in recent years, with the development of numerous verification techniques and tools. However, the field still lacks high-quality benchmarks for systematically evaluating and improving these tools. As verification techniques advance, many existing benchmarks have become too trivial, while the harder ones often remain unsolvable. Several recent efforts have attempted to address this gap, typically by retraining or distilling neural networks to create new benchmarks. However, such approaches are computationally expensive and often produce benchmarks with unknown or unverifiable ground truth. In this paper, we introduce ReluSplitter, an automatic benchmark generation tool for DNN verifiers. ReluSplitter takes existing verification benchmarks as input and strategically destabilizes stable neurons to increase verification difficulty. This transformation is semantics-preserving by construction: every ReluSplitter-generated benchmark is guaranteed to have exactly the same ground truth as the original benchmark. This makes ReluSplitter particularly valuable for assessing verifier correctness and performance. Our evaluation demonstrates that ReluSplitter can significantly increase the difficulty of existing benchmarks, effectively challenging state-of-the-art DNN verifiers. We believe ReluSplitter offers a practical and principled way to generate benchmarks with tunable difficulty and verifiable ground truth, contributing a much-needed resource for the neural network verification community.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Destabilizing Neurons to Generate Challenging Neural Network Verification Benchmarks 1759192252716 10.1109/ASE63991.2025.00115 Linhan Li George Mason University, USA lli34@gmu.edu ThanhVu Nguyen George Mason University, USA tvn@gmu.edu neural network verification benchmark generation Neural Network Verification has made significant progress in recent years, with the development of numerous verification techniques and tools. However, the field still lacks high-quality benchmarks for systematically evaluating and improving these tools. As verification techniques advance, many existing benchmarks have become too trivial, while the harder ones often remain unsolvable. Several recent efforts have attempted to address this gap, typically by retraining or distilling neural networks to create new benchmarks. However, such approaches are computationally expensive and often produce benchmarks with unknown or unverifiable ground truth. In this paper, we introduce ReluSplitter, an automatic benchmark generation tool for DNN verifiers. ReluSplitter takes existing verification benchmarks as input and strategically destabilizes stable neurons to increase verification difficulty. This transformation is semantics-preserving by construction: every ReluSplitter-generated benchmark is guaranteed to have exactly the same ground truth as the original benchmark. This makes ReluSplitter particularly valuable for assessing verifier correctness and performance. Our evaluation demonstrates that ReluSplitter can significantly increase the difficulty of existing benchmarks, effectively challenging state-of-the-art DNN verifiers. We believe ReluSplitter offers a practical and principled way to generate benchmarks with tunable difficulty and verifiable ground truth, contributing a much-needed resource for the neural network verification community.",
							"pageNumber": 1350,
							"isPageNumberRoman": false
						},
						{
							"eid": "4kE0U4ZUDO8McvGAI0yxol",
							"type": "authorPaper",
							"text": "SATORI: Static Test Oracle Generation for REST APIs",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b363/573300b363.pdf",
							"extraLocations": [],
							"authorNames": "Juan C. Alonso (Universidad de Sevilla, Spain), Alberto Martin-Lopez (Universit\u00E0 della Svizzera Italiana, Switzerland), Sergio Segura (Universidad de Sevilla, Spain), Gabriele Bavota (Universit\u00E0 della Svizzera Italiana, Switzerland), Antonio Ruiz-Cort\u00E9s (Universidad de Sevilla, Spain)",
							"abstract": "REST API test case generation tools are evolving rapidly, with growing capabilities for the automated generation of complex tests. However, despite their strengths in test data generation, these tools are constrained by the types of test oracles they support, often limited to crashes, regressions, and non-compliance with API specifications or design standards. This paper introduces SATORI (Static API Test ORacle Inference), a black-box approach for generating test oracles for REST APIs by analyzing their OpenAPI Specification. SATORI uses large language models to infer the expected behavior of an API by analyzing the properties of the response fields of its operations, such as their name and descriptions. To foster its adoption, we extended the PostmanAssertify tool to automatically convert the test oracles reported by SATORI into executable assertions. Evaluation results on 17 operations from 12 industrial APIs show that SATORI can automatically generate up to hundreds of valid test oracles per operation. SATORI achieved an F1-score of 74.3%, outperforming the state-of-the-art dynamic approach AGORA+ (69.3%)\u2014which requires executing the API\u2014when generating comparable oracle types. Moreover, our findings show that static and dynamic oracle inference methods are complementary: together, SATORI and AGORA+ found 90% of the oracles in our annotated ground-truth dataset. Notably, SATORI uncovered 18 bugs in popular APIs (Amadeus Hotel, Deutschebahn, FDIC, GitLab, Marvel, OMDb and Vimeo) leading to documentation updates by the API maintainers.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 SATORI: Static Test Oracle Generation for REST APIs 1759241342698 10.1109/ASE63991.2025.00116 Juan C. Alonso Universidad de Sevilla, Spain javalenzuela@us.es Alberto Martin-Lopez Universit\u00E0 della Svizzera Italiana, Switzerland alberto.martin@usi.ch Sergio Segura Universidad de Sevilla, Spain sergiosegura@us.es Gabriele Bavota Universit\u00E0 della Svizzera Italiana, Switzerland gabriele.bavota@usi.ch Antonio Ruiz-Cort\u00E9s Universidad de Sevilla, Spain aruiz@us.es rest apis test oracle llm automated testing REST API test case generation tools are evolving rapidly, with growing capabilities for the automated generation of complex tests. However, despite their strengths in test data generation, these tools are constrained by the types of test oracles they support, often limited to crashes, regressions, and non-compliance with API specifications or design standards. This paper introduces SATORI (Static API Test ORacle Inference), a black-box approach for generating test oracles for REST APIs by analyzing their OpenAPI Specification. SATORI uses large language models to infer the expected behavior of an API by analyzing the properties of the response fields of its operations, such as their name and descriptions. To foster its adoption, we extended the PostmanAssertify tool to automatically convert the test oracles reported by SATORI into executable assertions. Evaluation results on 17 operations from 12 industrial APIs show that SATORI can automatically generate up to hundreds of valid test oracles per operation. SATORI achieved an F1-score of 74.3%, outperforming the state-of-the-art dynamic approach AGORA+ (69.3%)\u2014which requires executing the API\u2014when generating comparable oracle types. Moreover, our findings show that static and dynamic oracle inference methods are complementary: together, SATORI and AGORA+ found 90% of the oracles in our annotated ground-truth dataset. Notably, SATORI uncovered 18 bugs in popular APIs (Amadeus Hotel, Deutschebahn, FDIC, GitLab, Marvel, OMDb and Vimeo) leading to documentation updates by the API maintainers.",
							"pageNumber": 1363,
							"isPageNumberRoman": false
						},
						{
							"eid": "2oLy9lZvP5WiTeC2RJjXB8",
							"type": "authorPaper",
							"text": "Learning Project-Wise Subsequent Code Edits via Interleaving Neural-Based Induction and Tool-Based Deduction",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b376/573300b376.pdf",
							"extraLocations": [],
							"authorNames": "Chenyan Liu (Shanghai Jiao Tong University, China; National University of Singapore, Singapore), Yun Lin (Shanghai Jiao Tong University, China), Yuhuan Huang (Shanghai Jiao Tong University, China), Jiaxin Chang (Shanghai Jiao Tong University, China), Binhang Qi (National University of Singapore, Singapore), Bo  Jiang (Bytedance Network Technology, China), Zhiyong  Huang (National University of Singapore, Singapore), Jin Song  Dong (National University of Singapore, Singapore)",
							"abstract": "In industrial and open-source software engineering tasks, developers often perform project-wise code editing tasks, including feature enhancement, refactoring, and bug fixing, where the leading AI models are expected to support the productivity. Hence, researchers and practitioners have proposed and adopted many LLM-based solutions to facilitate their realworld development. However, they largely suffer from the balance among predicting scope, accuracy, and efficiency. For example, solutions like Cursor achieve high accuracy only in a local editing scope while its performance drops on cross-file edits. In contrast, solutions like CoEdPilot exhibit efficiency limitations when used to predict project-wise edits. In this work, we propose TRACE (Tool-integrated RecommendAtion for Code Editing), a novel subsequent code editing solution to push the boundary of scope, accuracy, and efficiency. Our rationale lies in that code edits are triggered for either semantic or syntactic reasons. Therefore, TRACE predicts subsequent edits by interleaving neural-based induction for semantic edit prediction and tool-based deduction for syntactic edit prediction. The tools can be any IDE facilities, such as refactoring tools (e.g., rename) or linting tools (e.g., use-def), providing decent performance of deducing edit-location and editgeneration. Technically, we address the challenge of (1) when to interleave between neural-based and tool-based prediction and (2) how to further improve the performance of neural-based prediction. As for the former, we learn a neural model to detect when to invoke IDE editing tools. As for the latter, we propose a novel and fine-grained editing representation to further boost the performance of neural editing models. Our extensive experiments show that, in comparison to the state-of-the-arts such as CoEdPilot, GrACE, and CCT5, TRACE significantly improves the performance of edit location (by 43.76%) and edit generation (by 11.16%). Our simulation experiment on an interactive editing setting shows that TRACE achieves an acceptance rate 6.15% higher than Cursor. Moreover, our user study consists of 24 participants on Cursor, CoEdPilot, and TRACE, on three code editing tasks. The results show that the experimental group with TRACE achieves leading performance on cross-file global edits. In addition, we observe concerning user behaviours on how participants deal with false predictions by the tools, shedding light on the design of future code-editing tools.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Learning Project-Wise Subsequent Code Edits via Interleaving Neural-Based Induction and Tool-Based Deduction 1758849475491 10.1109/ASE63991.2025.00117 Chenyan Liu Shanghai Jiao Tong University, China; National University of Singapore, Singapore chenyan@u.nus.edu Yun Lin Shanghai Jiao Tong University, China lin_yun@sjtu.edu.cn Yuhuan Huang Shanghai Jiao Tong University, China hyh0u0@sjtu.edu.cn Jiaxin Chang Shanghai Jiao Tong University, China cjx001234@sjtu.edu.cn Binhang Qi National University of Singapore, Singapore qibh@nus.edu.sg Bo Jiang Bytedance Network Technology, China jiangbo.jacob@bytedance.com Zhiyong Huang National University of Singapore, Singapore huangzy@comp.nus.edu.sg Jin Song Dong National University of Singapore, Singapore dcsdjs@nus.edu.sg code editing subsequent edit prediction neural based induction tool-based deduction In industrial and open-source software engineering tasks, developers often perform project-wise code editing tasks, including feature enhancement, refactoring, and bug fixing, where the leading AI models are expected to support the productivity. Hence, researchers and practitioners have proposed and adopted many LLM-based solutions to facilitate their realworld development. However, they largely suffer from the balance among predicting scope, accuracy, and efficiency. For example, solutions like Cursor achieve high accuracy only in a local editing scope while its performance drops on cross-file edits. In contrast, solutions like CoEdPilot exhibit efficiency limitations when used to predict project-wise edits. In this work, we propose TRACE (Tool-integrated RecommendAtion for Code Editing), a novel subsequent code editing solution to push the boundary of scope, accuracy, and efficiency. Our rationale lies in that code edits are triggered for either semantic or syntactic reasons. Therefore, TRACE predicts subsequent edits by interleaving neural-based induction for semantic edit prediction and tool-based deduction for syntactic edit prediction. The tools can be any IDE facilities, such as refactoring tools (e.g., rename) or linting tools (e.g., use-def), providing decent performance of deducing edit-location and editgeneration. Technically, we address the challenge of (1) when to interleave between neural-based and tool-based prediction and (2) how to further improve the performance of neural-based prediction. As for the former, we learn a neural model to detect when to invoke IDE editing tools. As for the latter, we propose a novel and fine-grained editing representation to further boost the performance of neural editing models. Our extensive experiments show that, in comparison to the state-of-the-arts such as CoEdPilot, GrACE, and CCT5, TRACE significantly improves the performance of edit location (by 43.76%) and edit generation (by 11.16%). Our simulation experiment on an interactive editing setting shows that TRACE achieves an acceptance rate 6.15% higher than Cursor. Moreover, our user study consists of 24 participants on Cursor, CoEdPilot, and TRACE, on three code editing tasks. The results show that the experimental group with TRACE achieves leading performance on cross-file global edits. In addition, we observe concerning user behaviours on how participants deal with false predictions by the tools, shedding light on the design of future code-editing tools.",
							"pageNumber": 1376,
							"isPageNumberRoman": false
						},
						{
							"eid": "4qaBBCgi7swW39tDmrbrfF",
							"type": "authorPaper",
							"text": "NATE: A Network-Aware Testing Enhancer for Network-Related Fault Detection in Android Apps",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b389/573300b389.pdf",
							"extraLocations": [],
							"authorNames": "Yuanhong Lan (Nanjing University, China), Shaoheng Cao (Nanjing University, China), Yifei Lu (Nanjing University, China), Minxue Pan (Nanjing University, China), Xuandong Li (Nanjing University, China)",
							"abstract": "As Android apps become increasingly dependent on network services, Network-Related Faults (NRFs) are gradually more prevalent and severely degrade user experience. These faults are typically scattered across apps and require complex, often non-trivial network patterns to trigger, which makes their detection challenging. To date, we still lack a general and in-depth understanding of NRFs in real-world Android apps. To fill this gap, we conduct the first empirical study on 154 real-world network-related bugs collected from 42 diverse, representative Android apps, investigating their characteristics, influences, triggering patterns, and origins. Our study reveals several notable findings and practical implications to guide future research on detecting and mitigating NRFs. Motivated by the empirical results and the limitations of existing Android testing approaches\u2014namely, the lack of targeted network events and efficient injection mechanisms\u2014we propose NATE, a novel Network-Aware Testing Enhancer that augments existing general Android testing approaches for NRF detection. NATE leverages curiosity-driven reinforcement learning to provide network-aware guidance and to inject effective network events, enabling testing approaches to explore network-related extra app functionalities and detect NRFs. When integrated with two state-of-the-art general Android testing approaches, experiments conducted on 12 large, active apps demonstrate the effectiveness and efficiency of NATE, with 1.7-5.7\u00D7 as many faults detected, as well as 8.8% and 12.5% more code covered. Among the network-related faults detected by NATE, 21 have been explicitly confirmed as real-world bugs by the developers (six of which have already been fixed), where 16 of them were first reported by NATE. Notably, none of the 21 bugs were detected by the original general testing approaches, demonstrating the unique contributions of NATE.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 NATE: A Network-Aware Testing Enhancer for Network-Related Fault Detection in Android Apps 1759390286467 10.1109/ASE63991.2025.00118 Yuanhong Lan Nanjing University, China yhlan@smail.nju.edu.cn Shaoheng Cao Nanjing University, China shaohengcao@smail.nju.edu.cn Yifei Lu Nanjing University, China lyf@nju.edu.cn Minxue Pan Nanjing University, China mxp@nju.edu.cn Xuandong Li Nanjing University, China lxd@nju.edu.cn android app mobile testing network-related fault reinforcement learning As Android apps become increasingly dependent on network services, Network-Related Faults (NRFs) are gradually more prevalent and severely degrade user experience. These faults are typically scattered across apps and require complex, often non-trivial network patterns to trigger, which makes their detection challenging. To date, we still lack a general and in-depth understanding of NRFs in real-world Android apps. To fill this gap, we conduct the first empirical study on 154 real-world network-related bugs collected from 42 diverse, representative Android apps, investigating their characteristics, influences, triggering patterns, and origins. Our study reveals several notable findings and practical implications to guide future research on detecting and mitigating NRFs. Motivated by the empirical results and the limitations of existing Android testing approaches\u2014namely, the lack of targeted network events and efficient injection mechanisms\u2014we propose NATE, a novel Network-Aware Testing Enhancer that augments existing general Android testing approaches for NRF detection. NATE leverages curiosity-driven reinforcement learning to provide network-aware guidance and to inject effective network events, enabling testing approaches to explore network-related extra app functionalities and detect NRFs. When integrated with two state-of-the-art general Android testing approaches, experiments conducted on 12 large, active apps demonstrate the effectiveness and efficiency of NATE, with 1.7-5.7\u00D7 as many faults detected, as well as 8.8% and 12.5% more code covered. Among the network-related faults detected by NATE, 21 have been explicitly confirmed as real-world bugs by the developers (six of which have already been fixed), where 16 of them were first reported by NATE. Notably, none of the 21 bugs were detected by the original general testing approaches, demonstrating the unique contributions of NATE.",
							"pageNumber": 1389,
							"isPageNumberRoman": false
						},
						{
							"eid": "3VE7mrnG7ZZEdaZKGvqdYh",
							"type": "authorPaper",
							"text": "WEST: Specification-Based Test Generation for WebAssembly",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b402/573300b402.pdf",
							"extraLocations": [],
							"authorNames": "Dongjun Youn (KAIST, South Korea), Wonho Shin (KAIST, South Korea), Sukyoung Ryu (KAIST, South Korea)",
							"abstract": "WebAssembly (Wasm) is a low-level binary instruction format designed for safe and high-performance execution across diverse computing environments and runtimes. As Wasm evolves with new features and proposals, testing the correctness and conformance of Wasm runtimes has become increasingly complex. Manually constructing test suites is labor-intensive and difficult to scale, especially as the specification grows in complexity. While fuzzing-based approaches offer partial automation, they often lack a principled connection to the formal specification, and adapting to evolving or restricted subsets of the specification typically requires manual intervention. In this paper, we present WEST, a specification-based test generation framework that automatically produces Wasm test cases from mechanized specifications written in SpecTec, a Wasm-specific specification language. Given any full or subset variant of the Wasm specification as input, WEST aims to systematically generate test programs that conform to the input grammar and validation rules, and capture the runtime behavior defined by its execution semantics. The framework allows flexible integration of different test generation strategies. For instance, we demonstrate both top-down and bottom-up approaches for generating Wasm modules, but the architecture is compatible with other generation techniques as well. The framework enables the creation of customized test cases for engines that support only subsets of the Wasm specification. We evaluate WEST across multiple specification variants and engine configurations, demonstrating that it produces valid and diverse test cases. As a result, it reveals 16 bugs across four Wasm engine implementations, 11 of which are confirmed and fixed. We believe that this work provides a solid foundation for future specification-driven test generation.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 WEST: Specification-Based Test Generation for WebAssembly 1759304340365 10.1109/ASE63991.2025.00119 Dongjun Youn KAIST, South Korea f52985@kaist.ac.kr Wonho Shin KAIST, South Korea new170527@kaist.ac.kr Sukyoung Ryu KAIST, South Korea sryu.cs@kaist.ac.kr webassembly test generation language specification mechanized specification WebAssembly (Wasm) is a low-level binary instruction format designed for safe and high-performance execution across diverse computing environments and runtimes. As Wasm evolves with new features and proposals, testing the correctness and conformance of Wasm runtimes has become increasingly complex. Manually constructing test suites is labor-intensive and difficult to scale, especially as the specification grows in complexity. While fuzzing-based approaches offer partial automation, they often lack a principled connection to the formal specification, and adapting to evolving or restricted subsets of the specification typically requires manual intervention. In this paper, we present WEST, a specification-based test generation framework that automatically produces Wasm test cases from mechanized specifications written in SpecTec, a Wasm-specific specification language. Given any full or subset variant of the Wasm specification as input, WEST aims to systematically generate test programs that conform to the input grammar and validation rules, and capture the runtime behavior defined by its execution semantics. The framework allows flexible integration of different test generation strategies. For instance, we demonstrate both top-down and bottom-up approaches for generating Wasm modules, but the architecture is compatible with other generation techniques as well. The framework enables the creation of customized test cases for engines that support only subsets of the Wasm specification. We evaluate WEST across multiple specification variants and engine configurations, demonstrating that it produces valid and diverse test cases. As a result, it reveals 16 bugs across four Wasm engine implementations, 11 of which are confirmed and fixed. We believe that this work provides a solid foundation for future specification-driven test generation.",
							"pageNumber": 1402,
							"isPageNumberRoman": false
						},
						{
							"eid": "7EB9dsDxJT13O0xZ8kLTFF",
							"type": "authorPaper",
							"text": "VeriExploit: Automatic Bug Reproduction in Smart Contracts via LLMs and Formal Methods",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b414/573300b414.pdf",
							"extraLocations": [],
							"authorNames": "Chenfeng Wei (The University of Manchester, United Kingdom), Shiyu Cai (The University of Manchester, United Kingdom), Yiannis Charalambous (The University of Manchester, United Kingdom), Tong Wu (The University of Manchester, United Kingdom), Sangharatna Godboley (National Institute of Technology Warangal, India), Lucas Cordeiro (The University of Manchester, United Kingdom)",
							"abstract": "Bug reproduction is becoming an important task in the security analysis of Solidity smart contracts. By simulating attacks, developers and auditors can better understand how a vulnerability is triggered in practice. To reproduce a bug, one often needs to define an attacker contract and a specific sequence of interactions that exploit the vulnerability. However, in smart contracts, there are rarely automated tools that can generate such contracts and sequences and validate their correctness. Existing security tools, such as formal verifiers, are effective at detecting bugs, but they are not designed for bug reproduction. They often omit execution traces or produce incomplete ones. Moreover, their reports rarely reflect the behaviour patterns of attacker contracts. This gap motivates our work. We propose VeriExploit, a framework that combines formal methods and large language models to automatically generate, validate, and refine reproduction contracts and execution steps. Given a vulnerable contract and its counterexample, VeriExploit produces a contract that re-triggers the same bug and outputs a concrete trace showing how the exploit works. Experiments show that VeriExploit is effective at automating bug reproduction, achieving a success rate of 85.60% on our benchmark dataset.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 VeriExploit: Automatic Bug Reproduction in Smart Contracts via LLMs and Formal Methods 1759333037296 10.1109/ASE63991.2025.00120 Chenfeng Wei The University of Manchester, United Kingdom chenfeng.wei@manchester.ac.uk Shiyu Cai The University of Manchester, United Kingdom shiyu.cai@manchester.ac.uk Yiannis Charalambous The University of Manchester, United Kingdom yiannis.charalambous-4@postgrad.manchester.ac.uk Tong Wu The University of Manchester, United Kingdom tong.wu-11@postgrad.manchester.ac.uk Sangharatna Godboley National Institute of Technology Warangal, India sanghu@nitw.ac.in Lucas Cordeiro The University of Manchester, United Kingdom lucas.cordeiro@manchester.ac.uk smart contract formal verification large language model Bug reproduction is becoming an important task in the security analysis of Solidity smart contracts. By simulating attacks, developers and auditors can better understand how a vulnerability is triggered in practice. To reproduce a bug, one often needs to define an attacker contract and a specific sequence of interactions that exploit the vulnerability. However, in smart contracts, there are rarely automated tools that can generate such contracts and sequences and validate their correctness. Existing security tools, such as formal verifiers, are effective at detecting bugs, but they are not designed for bug reproduction. They often omit execution traces or produce incomplete ones. Moreover, their reports rarely reflect the behaviour patterns of attacker contracts. This gap motivates our work. We propose VeriExploit, a framework that combines formal methods and large language models to automatically generate, validate, and refine reproduction contracts and execution steps. Given a vulnerable contract and its counterexample, VeriExploit produces a contract that re-triggers the same bug and outputs a concrete trace showing how the exploit works. Experiments show that VeriExploit is effective at automating bug reproduction, achieving a success rate of 85.60% on our benchmark dataset.",
							"pageNumber": 1414,
							"isPageNumberRoman": false
						},
						{
							"eid": "1e9KjiKlK2KN2ILE10tet6",
							"type": "authorPaper",
							"text": "Rechecking Recheck Requests in Continuous Integration: An Empirical Study of OpenStack",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b426/573300b426.pdf",
							"extraLocations": [],
							"authorNames": "Yelizaveta Brus (University of Waterloo, Canada), Rungroj Maipradit (University of Waterloo, Canada), Earl T. Barr (University of Waterloo, Canada; University College London, UK), Shane McIntosh (University of Waterloo, Canada)",
							"abstract": "Continuous Integration (CI) is a process for automatically checking patch sets for errors. CI periodically fails due to non-deterministic (a.k.a., \"flaky\") behaviour. Since a patch set may not be the cause of a flaky failure, developers can issue a \"recheck\" command to request retesting a patch set. Developers waste time considering whether or not to issue a recheck after a CI failure. Prior work also shows that rechecks are issued liberally, wasting up to 187.4 compute years when CI continues to fail. To save developer time and avoid wasteful rechecks, we fit and analyze statistical models that discriminate between successful and failing rechecks, i.e., those rechecks that will change a failing CI run into a successful one and those that will fail again. Through an empirical study of 314,947 recheck requests from OpenStack, we find that our model can differentiate successful and failed rechecks well, outperforming baseline approaches by 23.6 percentage points in terms of AUROC (0.736). Analysis of our model suggests that, in terms of explanatory power, past behaviour of jobs, bots, and users dominate static characteristics of patch sets. Applying our model to automatically request rechecks for those predicted to succeed would have saved roughly 247 years of elapsed developer time for OpenStack. Applying our model to skip recheck requests when they are predicted to fail would avoid 86.49% of wasted rechecks, saving roughly 262 years of compute time.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Rechecking Recheck Requests in Continuous Integration: An Empirical Study of OpenStack 1759460427144 10.1109/ASE63991.2025.00121 Yelizaveta Brus University of Waterloo, Canada ybrus@uwaterloo.ca Rungroj Maipradit University of Waterloo, Canada rungroj.maipradit@uwaterloo.ca Earl T. Barr University of Waterloo, Canada; University College London, UK e.barr@ucl.ac.uk Shane McIntosh University of Waterloo, Canada shane.mcintosh@uwaterloo.ca code review continuous integration Continuous Integration (CI) is a process for automatically checking patch sets for errors. CI periodically fails due to non-deterministic (a.k.a., \"flaky\") behaviour. Since a patch set may not be the cause of a flaky failure, developers can issue a \"recheck\" command to request retesting a patch set. Developers waste time considering whether or not to issue a recheck after a CI failure. Prior work also shows that rechecks are issued liberally, wasting up to 187.4 compute years when CI continues to fail. To save developer time and avoid wasteful rechecks, we fit and analyze statistical models that discriminate between successful and failing rechecks, i.e., those rechecks that will change a failing CI run into a successful one and those that will fail again. Through an empirical study of 314,947 recheck requests from OpenStack, we find that our model can differentiate successful and failed rechecks well, outperforming baseline approaches by 23.6 percentage points in terms of AUROC (0.736). Analysis of our model suggests that, in terms of explanatory power, past behaviour of jobs, bots, and users dominate static characteristics of patch sets. Applying our model to automatically request rechecks for those predicted to succeed would have saved roughly 247 years of elapsed developer time for OpenStack. Applying our model to skip recheck requests when they are predicted to fail would avoid 86.49% of wasted rechecks, saving roughly 262 years of compute time.",
							"pageNumber": 1426,
							"isPageNumberRoman": false
						},
						{
							"eid": "1k1voH9cCwrzb2YRf7v1DS",
							"type": "authorPaper",
							"text": "Hierarchical Knowledge Injection for Improving LLM-Based Program Repair",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b439/573300b439.pdf",
							"extraLocations": [],
							"authorNames": "Ramtin Ehsani (Drexel University, USA), Esteban Parra (Belmont University, USA), Sonia Haiduc (Florida State University, USA), Preetha Chatterjee (Drexel University, USA)",
							"abstract": "Prompting LLMs with bug-related context (e.g., error messages, stack traces) improves automated program repair, but many bugs still remain unresolved. In real-world projects, developers often rely on broader repository and project-level context beyond the local code to resolve such bugs. In this paper, we investigate how automatically extracting and providing such knowledge can improve LLM-based program repair. We propose a layered knowledge injection framework that incrementally augments LLMs with structured context. It starts with the Bug Knowledge Layer, which includes information such as the buggy function and failing tests; expands to the Repository Knowledge Layer, which adds structural dependencies, related files, and commit history; and finally injects the Project Knowledge Layer, which incorporates relevant details from documentation and previously fixed bugs. We evaluate this framework on a dataset of 314 bugs from BugsInPy using two LLMs (Llama 3.3 and GPT-4o-mini), and analyze fix rates across six bug types. By progressively injecting knowledge across layers, our approach achieves a fix rate of 79% (250/314) using Llama 3.3, a significant improvement of 23% over previous work. All bug types show improvement with the addition of repository-level context, while only a subset benefit further from project-level knowledge, highlighting that different bug types require different levels of contextual information for effective repair. We also analyze the remaining unresolved bugs and find that more complex and structurally isolated bugs, such as Program Anomaly and GUI bugs, remain difficult even after injecting all available information. Our results show that layered context injection improves program repair and suggest the need for interactive and adaptive APR systems.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Hierarchical Knowledge Injection for Improving LLM-Based Program Repair 1759498258526 10.1109/ASE63991.2025.00122 Ramtin Ehsani Drexel University, USA ramtin.ehsani@drexel.edu Esteban Parra Belmont University, USA esteban.parrarodriguez@belmont.edu Sonia Haiduc Florida State University, USA shaiduc@fsu.edu Preetha Chatterjee Drexel University, USA preetha.chatterjee@drexel.edu automated program repair large language models knowledge injection in-context learning Prompting LLMs with bug-related context (e.g., error messages, stack traces) improves automated program repair, but many bugs still remain unresolved. In real-world projects, developers often rely on broader repository and project-level context beyond the local code to resolve such bugs. In this paper, we investigate how automatically extracting and providing such knowledge can improve LLM-based program repair. We propose a layered knowledge injection framework that incrementally augments LLMs with structured context. It starts with the Bug Knowledge Layer, which includes information such as the buggy function and failing tests; expands to the Repository Knowledge Layer, which adds structural dependencies, related files, and commit history; and finally injects the Project Knowledge Layer, which incorporates relevant details from documentation and previously fixed bugs. We evaluate this framework on a dataset of 314 bugs from BugsInPy using two LLMs (Llama 3.3 and GPT-4o-mini), and analyze fix rates across six bug types. By progressively injecting knowledge across layers, our approach achieves a fix rate of 79% (250/314) using Llama 3.3, a significant improvement of 23% over previous work. All bug types show improvement with the addition of repository-level context, while only a subset benefit further from project-level knowledge, highlighting that different bug types require different levels of contextual information for effective repair. We also analyze the remaining unresolved bugs and find that more complex and structurally isolated bugs, such as Program Anomaly and GUI bugs, remain difficult even after injecting all available information. Our results show that layered context injection improves program repair and suggest the need for interactive and adaptive APR systems.",
							"pageNumber": 1439,
							"isPageNumberRoman": false
						},
						{
							"eid": "7mnZYaKuO8buluoOXS14Vb",
							"type": "authorPaper",
							"text": "VERT: Polyglot Verified Equivalent Rust Transpilation with Large Language Models",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b452/573300b452.pdf",
							"extraLocations": [],
							"authorNames": "Aidan Z.H. Yang (Amazon Web Services), Yoshiki Takashima (Yale Law School), Brandon Paulsen (Amazon Web Services), Josiah Dodds (Amazon Web Services), Daniel Kroening (Amazon Web Services)",
							"abstract": "Rust is a programming language that combines memory safety and low-level control, providing C-like performance while guaranteeing the absence of undefined behaviors by default. Rust's growing popularity has prompted research on correct and idiomatic transpiling of existing code-bases to Rust. Existing work falls into two categories: rule-based and large language model (LLM)-based. While rule-based approaches are theoretically sound, they often yield unidiomatic and unsafe Rust code while targeting a few source languages, hindering maintainability and industrial application. In contrast, LLM-based approaches, while providing no guarantees, are polyglot and typically produce more idiomatic and safe Rust code. In this work, we present VERT, a formally correct, polyglot Rust translator with more idiomatic outputs. VERT supports any language that compiles to Web Assembly. Using the Web Assembly compiler, VERT obtains an oracle Rust program. Leveraging the LLM, VERT generates an idiomatic candidate Rust program. This candidate is verified against the oracle with model-checking to ensure equivalence.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 VERT: Polyglot Verified Equivalent Rust Transpilation with Large Language Models 1759273369094 10.1109/ASE63991.2025.00123 Aidan Z.H. Yang Amazon Web Services aidayang@amazon.com Yoshiki Takashima Yale Law School yoshiki.takashima@yale.edu Brandon Paulsen Amazon Web Services bpaulse@amazon.com Josiah Dodds Amazon Web Services jldodds@amazon.com Daniel Kroening Amazon Web Services dkr@amazon.com large language models rust program transpilation program verification Rust is a programming language that combines memory safety and low-level control, providing C-like performance while guaranteeing the absence of undefined behaviors by default. Rust's growing popularity has prompted research on correct and idiomatic transpiling of existing code-bases to Rust. Existing work falls into two categories: rule-based and large language model (LLM)-based. While rule-based approaches are theoretically sound, they often yield unidiomatic and unsafe Rust code while targeting a few source languages, hindering maintainability and industrial application. In contrast, LLM-based approaches, while providing no guarantees, are polyglot and typically produce more idiomatic and safe Rust code. In this work, we present VERT, a formally correct, polyglot Rust translator with more idiomatic outputs. VERT supports any language that compiles to Web Assembly. Using the Web Assembly compiler, VERT obtains an oracle Rust program. Leveraging the LLM, VERT generates an idiomatic candidate Rust program. This candidate is verified against the oracle with model-checking to ensure equivalence.",
							"pageNumber": 1452,
							"isPageNumberRoman": false
						},
						{
							"eid": "3LEtJX2Rxx2l0zQlyb4hRQ",
							"type": "authorPaper",
							"text": "ScaleCirc: Scaling the Analysis over Circom Circuits",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b463/573300b463.pdf",
							"extraLocations": [],
							"authorNames": "Jinan Jiang (Hong Kong Polytechnic University, China), Haoran Qin (Hong Kong Polytechnic University, China), Xiapu Luo (Hong Kong Polytechnic University, China)",
							"abstract": "Zero-knowledge proof (ZKP) circuits implemented in programming languages like Circom are fundamental to blockchain and privacy-preserving applications. These code often suffer from constraint-related issues where constraints fail to accurately specify intended computations. While existing analysis tools have been proposed, they struggle with large-scale circuits containing complex template embeddings. We present SCALECIRC, a novel framework that addresses such limitations through: 1) systematic management of analysis redundancy via circuit deduplication strategies; 2) constrainedness propagation methods leveraging source code semantic information; and 3) a generalizable framework for different circuit analysis tasks. Evaluation on 691 real-world circuits shows SCALECIRC demonstrates higher efficiency, and successfully analyzes many Circom programs that existing works failed on.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 ScaleCirc: Scaling the Analysis over Circom Circuits 1759300988390 10.1109/ASE63991.2025.00124 Jinan Jiang Hong Kong Polytechnic University, China jinan.jiang@connect.polyu.hk Haoran Qin Hong Kong Polytechnic University, China hao-ran.qin@connect.polyu.hk Xiapu Luo Hong Kong Polytechnic University, China csxluo@comp.polyu.edu.hk Zero-knowledge proof (ZKP) circuits implemented in programming languages like Circom are fundamental to blockchain and privacy-preserving applications. These code often suffer from constraint-related issues where constraints fail to accurately specify intended computations. While existing analysis tools have been proposed, they struggle with large-scale circuits containing complex template embeddings. We present SCALECIRC, a novel framework that addresses such limitations through: 1) systematic management of analysis redundancy via circuit deduplication strategies; 2) constrainedness propagation methods leveraging source code semantic information; and 3) a generalizable framework for different circuit analysis tasks. Evaluation on 691 real-world circuits shows SCALECIRC demonstrates higher efficiency, and successfully analyzes many Circom programs that existing works failed on.",
							"pageNumber": 1463,
							"isPageNumberRoman": false
						},
						{
							"eid": "4ztG3MUG0If5Tf2BvyHaUA",
							"type": "authorPaper",
							"text": "Aligning LLMs to Fully Utilize the Cross-File Context in Repository-Level Code Completion",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b476/573300b476.pdf",
							"extraLocations": [],
							"authorNames": "O Jia Li (Peking University, China), Hao Zhu (Peking University, China), Huanyu Liu (Peking University, China), Xianjie Shi (Peking University, China), He Zong (aiXcoder, China), Yihong Dong (Peking University, China), Kechi Zhang (Peking University, China), Siyuan Jiang (aiXcoder, China), Zhi Jin (Peking University, China), Ge Li (Peking University, China)",
							"abstract": "Large Language Models (LLMs) have shown promising results in repository-level code completion, which completes code based on the in-file and cross-file context of a repository. The cross-file context typically contains different types of information (e.g., relevant APIs and similar code) and is lengthy. In this paper, we found that LLMs struggle to fully utilize the information in the cross-file context. We hypothesize that one of the root causes of the limitation is the misalignment between pre-training (i.e., relying on nearby context) and repo-level code completion (i.e., frequently attending to long-range cross-file context). To address the above misalignment, we propose Code Long-context Alignment - COLA, a purely data-driven approach to explicitly teach LLMs to focus on the cross-file context. Specifically, COLA constructs a large-scale repo-level code completion dataset - COLA-132K, where each sample contains the long cross-file context (up to 128K tokens) and requires generating context-aware code (i.e., cross-file API invocations and code spans similar to cross-file context). Through a two-stage training pipeline upon COLA-132K, LLMs learn the capability of finding relevant information in the cross-file context, thus aligning LLMs with repo-level code completion. We apply COLA to multiple popular LLMs (e.g., aiXcoder-7B) and extensive experiments on COLA-132K and a public benchmark - CrossCodeEval. Our experiments yield the following results. (1) Effectiveness. COLA substantially improves the performance of multiple LLMs in repo-level code completion. For example, it improves aiXcoder-7B by up to 19.7% in exact match. (2) Generalizability. The capability learned by COLA can generalize to new languages (i.e., languages not in training data). (3) Enhanced Context Utilization Capability. We design two probing experiments, which show COLA improves the capability of LLMs in utilizing the information (i.e., relevant APIs and similar code) in cross-file context. Our datasets and model weights are released in https://anonymous.4open.science/r/aiXcoder-7B-v2/README.md.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Aligning LLMs to Fully Utilize the Cross-File Context in Repository-Level Code Completion 1759477435830 10.1109/ASE63991.2025.00125 O Jia Li Peking University, China jia_li@mail.tsinghua.edu.cn Hao Zhu Peking University, China zhuhao@stu.pku.edu.cn Huanyu Liu Peking University, China huanyuliu@stu.pku.edu.cn Xianjie Shi Peking University, China 2100013180@stu.pku.edu.cn He Zong aiXcoder, China zonghe@aixcoder.com Yihong Dong Peking University, China dongyh@stu.pku.edu.cn Kechi Zhang Peking University, China zhangkechi@stu.pku.edu.cn Siyuan Jiang aiXcoder, China jiangsiyuan@aixcoder.com Zhi Jin Peking University, China zhijin@pku.edu.cn Ge Li Peking University, China lige@pku.edu.cn repository-level code completion large language models reinforcement learning Large Language Models (LLMs) have shown promising results in repository-level code completion, which completes code based on the in-file and cross-file context of a repository. The cross-file context typically contains different types of information (e.g., relevant APIs and similar code) and is lengthy. In this paper, we found that LLMs struggle to fully utilize the information in the cross-file context. We hypothesize that one of the root causes of the limitation is the misalignment between pre-training (i.e., relying on nearby context) and repo-level code completion (i.e., frequently attending to long-range cross-file context). To address the above misalignment, we propose Code Long-context Alignment - COLA, a purely data-driven approach to explicitly teach LLMs to focus on the cross-file context. Specifically, COLA constructs a large-scale repo-level code completion dataset - COLA-132K, where each sample contains the long cross-file context (up to 128K tokens) and requires generating context-aware code (i.e., cross-file API invocations and code spans similar to cross-file context). Through a two-stage training pipeline upon COLA-132K, LLMs learn the capability of finding relevant information in the cross-file context, thus aligning LLMs with repo-level code completion. We apply COLA to multiple popular LLMs (e.g., aiXcoder-7B) and extensive experiments on COLA-132K and a public benchmark - CrossCodeEval. Our experiments yield the following results. (1) Effectiveness. COLA substantially improves the performance of multiple LLMs in repo-level code completion. For example, it improves aiXcoder-7B by up to 19.7% in exact match. (2) Generalizability. The capability learned by COLA can generalize to new languages (i.e., languages not in training data). (3) Enhanced Context Utilization Capability. We design two probing experiments, which show COLA improves the capability of LLMs in utilizing the information (i.e., relevant APIs and similar code) in cross-file context. Our datasets and model weights are released in https://anonymous.4open.science/r/aiXcoder-7B-v2/README.md.",
							"pageNumber": 1476,
							"isPageNumberRoman": false
						},
						{
							"eid": "2LWuhFVGUvYpUtNG65v6HS",
							"type": "authorPaper",
							"text": "CoTune: Co-Evolutionary Configuration Tuning",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b489/573300b489.pdf",
							"extraLocations": [],
							"authorNames": "Gangda Xiong (University of Electronic Science and Technology of China, China), Tao Chen (University of Birmingham, United Kingdom)",
							"abstract": "To automatically tune configurations for the best possible system performance (e.g., runtime or throughput), much work has been focused on designing intelligent heuristics in a tuner. However, existing tuner designs have mostly ignored the presence of complex performance requirements (e.g., the latency shall ideally be 2 seconds), but simply assume that better performance is always more preferred. This would not only waste valuable information in a requirement but might also consume extensive resources to tune for a goal with little gain. Yet, prior studies have shown that simply incorporating the requirement as a tuning objective is problematic since the requirement might be too strict, harming convergence; or its highly diverse satisfactions might lead to premature convergence. In this paper, we propose CoTune, a tool that takes the information of a given target performance requirement into account through co-evolution. CoTune is unique in the sense that it creates an auxiliary performance requirement to be co-evolved with the configurations, which assists the target performance requirement when it becomes ineffective or even misleading, hence allowing the tuning to be guided by the requirement while being robust to its harm. Experiment results on 162 cases (nine systems and 18 requirements) reveal that CoTune considerably outperforms existing tuners, ranking as the best for \u224890% cases (against the 0%-35% for other tuners) with up to 2.9x overall improvements, while doing so under a much better efficiency.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 CoTune: Co-Evolutionary Configuration Tuning 1759146632649 10.1109/ASE63991.2025.00126 Gangda Xiong University of Electronic Science and Technology of China, China gangdaxiong0207@gmail.com Tao Chen University of Birmingham, United Kingdom t.chen@bham.ac.uk sbse compiler/database optimization performance/hyperparameter optimization requirement satisfactions To automatically tune configurations for the best possible system performance (e.g., runtime or throughput), much work has been focused on designing intelligent heuristics in a tuner. However, existing tuner designs have mostly ignored the presence of complex performance requirements (e.g., the latency shall ideally be 2 seconds), but simply assume that better performance is always more preferred. This would not only waste valuable information in a requirement but might also consume extensive resources to tune for a goal with little gain. Yet, prior studies have shown that simply incorporating the requirement as a tuning objective is problematic since the requirement might be too strict, harming convergence; or its highly diverse satisfactions might lead to premature convergence. In this paper, we propose CoTune, a tool that takes the information of a given target performance requirement into account through co-evolution. CoTune is unique in the sense that it creates an auxiliary performance requirement to be co-evolved with the configurations, which assists the target performance requirement when it becomes ineffective or even misleading, hence allowing the tuning to be guided by the requirement while being robust to its harm. Experiment results on 162 cases (nine systems and 18 requirements) reveal that CoTune considerably outperforms existing tuners, ranking as the best for \u224890% cases (against the 0%-35% for other tuners) with up to 2.9x overall improvements, while doing so under a much better efficiency.",
							"pageNumber": 1489,
							"isPageNumberRoman": false
						},
						{
							"eid": "1Xr9GjUdOsplou5s0YtAPb",
							"type": "authorPaper",
							"text": "Sifting Truth from Coincidences: A Two-Stage Positive and Unlabeled Learning Model for Coincidental Correctness Detection",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b502/573300b502.pdf",
							"extraLocations": [],
							"authorNames": "Chunyan Liu (Chongqing University, China), Huan Xie (Chongqing University, China), Yan  Lei (Chongqing University, China), Zhenyu  Wu (Chongqing University, China), Jinping  Wang (Chongqing University, China)",
							"abstract": "Fault localization (FL) can identify the fault's location by analyzing the execution information from test cases in the program. This execution information serves as the foundation for FL to infer latent causal relationships between fault entities and failed results. However, this execution information contains coincidental correctness (CC), which reduces the accuracy of FL. CC arises when a test case executes faulty program entities but still produces the correct output, leading to misleading FL inferences. In widely used datasets, the presence of CC compromises the reliability of passed test cases (i.e., negative labels). In contrast, failed test cases (i.e., positive labels) remain definitive. In FL scenarios, unlabeled data is typically abundant and primarily consists of passed test cases. Therefore, systematically leveraging positive and unlabeled data for accurate CC detection is essential, which is beneficial to FL. To tackle the problem, we propose a two-stagE positiVe and unlAbeled learning model for coiNcidental correctneSs detection, EVANS. EVANS defines failed test cases as positive samples and treats the remaining ones as unlabeled data. It comprises two core modules: (1) A module for selecting high-quality pseudo-negative samples. This module leverages vector distance metrics to identify high-quality pseudo-negative test cases, using inter-class distances computed via a pre-trained model. (2) A weakly supervised contrastive learning module. This module utilizes the labeled samples from Stage (1) to train a contrastive learning model, which then detects CC in unlabeled test cases. Experimental results demonstrate that EVANS significantly outperforms current CC detection methods.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Sifting Truth from Coincidences: A Two-Stage Positive and Unlabeled Learning Model for Coincidental Correctness Detection 1759042916270 10.1109/ASE63991.2025.00127 Chunyan Liu Chongqing University, China chunyanliu@cqu.edu.cn Huan Xie Chongqing University, China huanxie@cqu.edu.cn Yan Lei Chongqing University, China yanlei@cqu.edu.cn Zhenyu Wu Chongqing University, China zhenyu_wu@stu.cqu.edu.cn Jinping Wang Chongqing University, China jpwang@stu.cqu.edu.cn coincidental correctness detection positive and unlabeled learning contrastive learning Fault localization (FL) can identify the fault's location by analyzing the execution information from test cases in the program. This execution information serves as the foundation for FL to infer latent causal relationships between fault entities and failed results. However, this execution information contains coincidental correctness (CC), which reduces the accuracy of FL. CC arises when a test case executes faulty program entities but still produces the correct output, leading to misleading FL inferences. In widely used datasets, the presence of CC compromises the reliability of passed test cases (i.e., negative labels). In contrast, failed test cases (i.e., positive labels) remain definitive. In FL scenarios, unlabeled data is typically abundant and primarily consists of passed test cases. Therefore, systematically leveraging positive and unlabeled data for accurate CC detection is essential, which is beneficial to FL. To tackle the problem, we propose a two-stagE positiVe and unlAbeled learning model for coiNcidental correctneSs detection, EVANS. EVANS defines failed test cases as positive samples and treats the remaining ones as unlabeled data. It comprises two core modules: (1) A module for selecting high-quality pseudo-negative samples. This module leverages vector distance metrics to identify high-quality pseudo-negative test cases, using inter-class distances computed via a pre-trained model. (2) A weakly supervised contrastive learning module. This module utilizes the labeled samples from Stage (1) to train a contrastive learning model, which then detects CC in unlabeled test cases. Experimental results demonstrate that EVANS significantly outperforms current CC detection methods.",
							"pageNumber": 1502,
							"isPageNumberRoman": false
						},
						{
							"eid": "1aLvHS82fLZh5R8hY0hYC4",
							"type": "authorPaper",
							"text": "Improving NLSAT for Nonlinear Real Arithmetic",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b515/573300b515.pdf",
							"extraLocations": [],
							"authorNames": "Zhonghan Wang (Institute of Software, Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China)",
							"abstract": "The Model-Constructing Satisfiability Calculus (MCSAT) framework has been applied to SMT problems over various arithmetic theories. NLSAT, an implementation using cylindrical algebraic decomposition (CAD) for explanation, is especially competitive for nonlinear real arithmetic (NRA) constraints. However, current Conflict-Driven Clause Learning (CDCL)-style algorithms only consider literal information when making decisions, and thus ignore the influence of clauses on arithmetic variables. This limitation may lead NLSAT to encounter unnecessary conflicts due to suboptimal literal choices. To address this issue, we analyze conflicts caused by literal decisions and incorporate clause-level information that directly affects arithmetic variables. We propose two main algorithmic improvements: a clause-level feasible-set-based look-ahead mechanism and an arithmetic propagation-based branching heuristic. We implement our solver, named clauseSMT, based on a dynamic variable ordering framework. Experiments indicate that clauseSMT is competitive on nonlinear real arithmetic problems compared with existing SMT solvers (CVC5, Z3, YICES2), and it outperforms all of them on satisfiable instances of SMT(QF_NRA) in SMT-LIB. We also evaluate the effectiveness of our proposed methods.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Improving NLSAT for Nonlinear Real Arithmetic 1758914406599 10.1109/ASE63991.2025.00128 Zhonghan Wang Institute of Software, Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China wangzhonghan272@gmail.com nlsat nonlinear real arithmetic smt clause level The Model-Constructing Satisfiability Calculus (MCSAT) framework has been applied to SMT problems over various arithmetic theories. NLSAT, an implementation using cylindrical algebraic decomposition (CAD) for explanation, is especially competitive for nonlinear real arithmetic (NRA) constraints. However, current Conflict-Driven Clause Learning (CDCL)-style algorithms only consider literal information when making decisions, and thus ignore the influence of clauses on arithmetic variables. This limitation may lead NLSAT to encounter unnecessary conflicts due to suboptimal literal choices. To address this issue, we analyze conflicts caused by literal decisions and incorporate clause-level information that directly affects arithmetic variables. We propose two main algorithmic improvements: a clause-level feasible-set-based look-ahead mechanism and an arithmetic propagation-based branching heuristic. We implement our solver, named clauseSMT, based on a dynamic variable ordering framework. Experiments indicate that clauseSMT is competitive on nonlinear real arithmetic problems compared with existing SMT solvers (CVC5, Z3, YICES2), and it outperforms all of them on satisfiable instances of SMT(QF_NRA) in SMT-LIB. We also evaluate the effectiveness of our proposed methods.",
							"pageNumber": 1515,
							"isPageNumberRoman": false
						},
						{
							"eid": "dF57QSHTNYwbg3hsxA4Ze",
							"type": "authorPaper",
							"text": "Finding Insecure State Dependency in DApps via Multi-Source Tracing and Semantic Enrichment",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b528/573300b528.pdf",
							"extraLocations": [],
							"authorNames": "Jingwen Zhang (Sun Yat-sen University, China; Peng Cheng Laboratory, China), Yuhong Nan (Sun Yat-sen University, China), Wei Li (Sun Yat-sen University, China), Kaiwen Ning (Sun Yat-sen University, China; Peng Cheng Laboratory, China), Zewei Lin (Sun Yat-sen University, China; Peng Cheng Laboratory, China), Zitong Yao (Sun Yat-sen University, China), Yuming Feng (Peng Cheng Laboratory, China), Weizhe Zhang (Harbin Institute of Technology; Peng Cheng Laboratory, China), Zibin Zheng (Sun Yat-sen University, China)",
							"abstract": "Decentralized Applications (DApps) serve as the gateway to utilizing blockchain technology. As their prevalence continues to grow, DApps are becoming increasingly interconnected. For instance, a DApp does not need to manage the prices of various tokens internally, as it can retrieve this information from other DApps that provide more up-to-date data. However, such deep reliance also introduces more attack surfaces, posing greater risks to both DApps and their users. In this paper, we refer to the security threat arising from the interdependence of DApps as Insecure State Dependency (ISD). Public reports indicate that ISD has led to losses exceeding 340 million USD. Existing ISDs are mostly found by extensive manual auditing and lucky incidents, as automated discovery of such issues is extremely difficult. More specifically, it is by no means trivial to (1) achieve precise data tracking in the intertwined and invisible interactions of DApps, (2) obtain fine-grained semantic information in low semantic bytecode. In this paper, we propose a novel framework, called InsFinder, for detecting ISD in DApps. Specifically, InsFinder consists of three unique modules to overcome the aforementioned challenges. (1) InsFinder employs dynamic cross-DApp taint analysis to achieve accurate multi-source data tracking in heavily coupled DApp interactions. (2) InsFinder uses source mapping to map bytecode identifiers into meaningful source code, such as variable names or statements, enabling a deeper understanding of bytecode. (3) InsFinder implements fine-grained access control and static analysis for ISD entry point detection. Evaluation on a manually annotated dataset with 93 real-world ISDs shows that InsFinder successfully detects 72 of them, achieving a precision of 84.7% and a recall of 77.4%. Furthermore, InsFinder successfully uncovers 165 previously unreported ISDs across 122 DApp projects. These ISDs collectively impact over 2 million USD.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Finding Insecure State Dependency in DApps via Multi-Source Tracing and Semantic Enrichment 1758073106849 10.1109/ASE63991.2025.00129 Jingwen Zhang Sun Yat-sen University, China; Peng Cheng Laboratory, China zhangjw273@mail2.sysu.edu.cn Yuhong Nan Sun Yat-sen University, China nanyh@mail.sysu.edu.cn Wei Li Sun Yat-sen University, China liwei378@mail2.sysu.edu.cn Kaiwen Ning Sun Yat-sen University, China; Peng Cheng Laboratory, China ningkw@mail2.sysu.edu.cn Zewei Lin Sun Yat-sen University, China; Peng Cheng Laboratory, China linzw3@mail2.sysu.edu.cn Zitong Yao Sun Yat-sen University, China yaozt@mail2.sysu.edu.cn Yuming Feng Peng Cheng Laboratory, China fengym@pcl.ac.cn Weizhe Zhang Harbin Institute of Technology; Peng Cheng Laboratory, China wzzhang@hit.edu.cn Zibin Zheng Sun Yat-sen University, China zhzibin@mail.sysu.edu.cn smart contract dynamic taint analysis source mapping vulnerability detection Decentralized Applications (DApps) serve as the gateway to utilizing blockchain technology. As their prevalence continues to grow, DApps are becoming increasingly interconnected. For instance, a DApp does not need to manage the prices of various tokens internally, as it can retrieve this information from other DApps that provide more up-to-date data. However, such deep reliance also introduces more attack surfaces, posing greater risks to both DApps and their users. In this paper, we refer to the security threat arising from the interdependence of DApps as Insecure State Dependency (ISD). Public reports indicate that ISD has led to losses exceeding 340 million USD. Existing ISDs are mostly found by extensive manual auditing and lucky incidents, as automated discovery of such issues is extremely difficult. More specifically, it is by no means trivial to (1) achieve precise data tracking in the intertwined and invisible interactions of DApps, (2) obtain fine-grained semantic information in low semantic bytecode. In this paper, we propose a novel framework, called InsFinder, for detecting ISD in DApps. Specifically, InsFinder consists of three unique modules to overcome the aforementioned challenges. (1) InsFinder employs dynamic cross-DApp taint analysis to achieve accurate multi-source data tracking in heavily coupled DApp interactions. (2) InsFinder uses source mapping to map bytecode identifiers into meaningful source code, such as variable names or statements, enabling a deeper understanding of bytecode. (3) InsFinder implements fine-grained access control and static analysis for ISD entry point detection. Evaluation on a manually annotated dataset with 93 real-world ISDs shows that InsFinder successfully detects 72 of them, achieving a precision of 84.7% and a recall of 77.4%. Furthermore, InsFinder successfully uncovers 165 previously unreported ISDs across 122 DApp projects. These ISDs collectively impact over 2 million USD.",
							"pageNumber": 1528,
							"isPageNumberRoman": false
						},
						{
							"eid": "1mET1rpjmbwccmSg8rKfRu",
							"type": "authorPaper",
							"text": "Forcrat: Automatic I/O API Translation from C to Rust via Origin and Capability Analysis",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b540/573300b540.pdf",
							"extraLocations": [],
							"authorNames": "Jaemin Hong (KAIST, South Korea), Sukyoung Ryu (KAIST, South Korea)",
							"abstract": "Translating C to Rust is a promising way to enhance the reliability of legacy system programs. Although the industry has developed an automatic C-to-Rust translator, C2Rust, its translation remains unsatisfactory. One major reason is that C2Rust retains C standard library (libc) function calls instead of replacing them with functions from the Rust standard library (Rust std). However, little work has been done on replacing library functions in C2Rust-generated code. In this work, we focus on replacing the I/O API, an important subset of library functions. This poses challenges due to the semantically different designs of I/O APIs in libc and Rust std. First, the two APIs offer different sets of types that represent the origins (e.g., standard input, files) and capabilities (e.g., read, write) of streams used for I/O. Second, they use different error-checking mechanisms: libc uses internal indicators, while Rust std uses return values. To address these challenges, we propose two static analysis techniques, origin and capability analysis and error source analysis, and use their results to replace the I/O API. Our evaluation shows that the proposed approach is (1) correct, with all 32 programs that have test suites passing the tests after transformation, (2) efficient, analyzing and transforming 422k LOC in 14 seconds, and (3) widely applicable, replacing 82% of I/O API calls.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Forcrat: Automatic I/O API Translation from C to Rust via Origin and Capability Analysis 1759107893676 10.1109/ASE63991.2025.00130 Jaemin Hong KAIST, South Korea jaemin.hong@kaist.ac.kr Sukyoung Ryu KAIST, South Korea sryu.cs@kaist.ac.kr Translating C to Rust is a promising way to enhance the reliability of legacy system programs. Although the industry has developed an automatic C-to-Rust translator, C2Rust, its translation remains unsatisfactory. One major reason is that C2Rust retains C standard library (libc) function calls instead of replacing them with functions from the Rust standard library (Rust std). However, little work has been done on replacing library functions in C2Rust-generated code. In this work, we focus on replacing the I/O API, an important subset of library functions. This poses challenges due to the semantically different designs of I/O APIs in libc and Rust std. First, the two APIs offer different sets of types that represent the origins (e.g., standard input, files) and capabilities (e.g., read, write) of streams used for I/O. Second, they use different error-checking mechanisms: libc uses internal indicators, while Rust std uses return values. To address these challenges, we propose two static analysis techniques, origin and capability analysis and error source analysis, and use their results to replace the I/O API. Our evaluation shows that the proposed approach is (1) correct, with all 32 programs that have test suites passing the tests after transformation, (2) efficient, analyzing and transforming 422k LOC in 14 seconds, and (3) widely applicable, replacing 82% of I/O API calls.",
							"pageNumber": 1540,
							"isPageNumberRoman": false
						},
						{
							"eid": "4sQr7FJrPM0Lszhl9q3hvu",
							"type": "authorPaper",
							"text": "It's Not Easy Being Green: On the Energy Efficiency of Programming Languages",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b552/573300b552.pdf",
							"extraLocations": [],
							"authorNames": "Nicolas van Kempen (University of Massachusetts Amherst, USA), Hyuk-Je Kwon (Unaffiliated, USA), Dung Tuan Nguyen (Eureka Robotics, Vietnam), Emery D. Berger (University of Massachusetts Amherst USA; Amazon Web Services, USA)",
							"abstract": "Does the choice of programming language affect energy consumption? Previous highly visible studies have established associations between certain programming languages and energy consumption. A causal misinterpretation of this work has led academics and industry leaders to use or support certain languages based on their claimed impact on energy consumption. This paper tackles this causal question directly: it develops a detailed causal model capturing the complex relationship between programming language choice and energy consumption. This model identifies and incorporates several critical but previously overlooked factors that affect energy usage. These factors, such as distinguishing programming languages from their implementations, the impact of the application implementations themselves, the number of active cores, and memory activity, can significantly skew energy consumption measurements if not accounted for. We show\u2014via empirical experiments, improved methodology, and careful examination of anomalies\u2014that when these factors are controlled for, notable discrepancies in prior work vanish. Our analysis suggests that the choice of programming language implementation has no significant impact on energy consumption beyond execution time.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 It's Not Easy Being Green: On the Energy Efficiency of Programming Languages 1758840445990 10.1109/ASE63991.2025.00131 Nicolas van Kempen University of Massachusetts Amherst, USA nvankempen@cs.umass.edu Hyuk-Je Kwon Unaffiliated, USA hyukjekwon@gmail.com Dung Tuan Nguyen Eureka Robotics, Vietnam ntddebugger@gmail.com Emery D. Berger University of Massachusetts Amherst USA; Amazon Web Services, USA emery@cs.umass.edu programming languages performance sustainability Does the choice of programming language affect energy consumption? Previous highly visible studies have established associations between certain programming languages and energy consumption. A causal misinterpretation of this work has led academics and industry leaders to use or support certain languages based on their claimed impact on energy consumption. This paper tackles this causal question directly: it develops a detailed causal model capturing the complex relationship between programming language choice and energy consumption. This model identifies and incorporates several critical but previously overlooked factors that affect energy usage. These factors, such as distinguishing programming languages from their implementations, the impact of the application implementations themselves, the number of active cores, and memory activity, can significantly skew energy consumption measurements if not accounted for. We show\u2014via empirical experiments, improved methodology, and careful examination of anomalies\u2014that when these factors are controlled for, notable discrepancies in prior work vanish. Our analysis suggests that the choice of programming language implementation has no significant impact on energy consumption beyond execution time.",
							"pageNumber": 1552,
							"isPageNumberRoman": false
						},
						{
							"eid": "YLdHFqRCyRhWoXjZYzP9c",
							"type": "authorPaper",
							"text": "Belief Propagation with Local Structure and Its Applications in Program Analysis",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b565/573300b565.pdf",
							"extraLocations": [],
							"authorNames": "Yiqian Wu (Peking University, China), Yifan Chen (Peking University, China), Yingfei  Xiong (Peking University, China), Xin Zhang (Peking University, China)",
							"abstract": "In program analysis, there is an emerging trend to apply probabilistic reasoning. In general, these approaches build their models based on probabilistic graphical models because they can express local correlations through factors in a compositional manner, which is suitable for program analysis. These models commonly use the loopy belief propagation algorithm to infer the marginal probability distribution for efficiency. However, the efficiency of loopy belief propagation is still affected by large factors. To address this challenge, our insight is that we can exploit the local structure of probabilistic constraints to speed up the inference. To realize this idea, we use if-then rules to encode the factors with local structures and propose an efficient loopy belief propagation algorithm based on it. We also discuss the inference algorithm complexity and prove some applicable conditions of our approach. Our approach is evaluated on two existing program analysis works based on probabilistic graphical models. The results show that our approach can be 5.11 and 2.31 times faster than the original loopy belief propagation algorithm on average, respectively.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Belief Propagation with Local Structure and Its Applications in Program Analysis 1759042112148 10.1109/ASE63991.2025.00132 Yiqian Wu Peking University, China wuyiqian@pku.edu.cn Yifan Chen Peking University, China yf_chen@pku.edu.cn Yingfei Xiong Peking University, China xiongyf@pku.edu.cn Xin Zhang Peking University, China xin@pku.edu.cn program analysis probabilistic graphical model belief propagation In program analysis, there is an emerging trend to apply probabilistic reasoning. In general, these approaches build their models based on probabilistic graphical models because they can express local correlations through factors in a compositional manner, which is suitable for program analysis. These models commonly use the loopy belief propagation algorithm to infer the marginal probability distribution for efficiency. However, the efficiency of loopy belief propagation is still affected by large factors. To address this challenge, our insight is that we can exploit the local structure of probabilistic constraints to speed up the inference. To realize this idea, we use if-then rules to encode the factors with local structures and propose an efficient loopy belief propagation algorithm based on it. We also discuss the inference algorithm complexity and prove some applicable conditions of our approach. Our approach is evaluated on two existing program analysis works based on probabilistic graphical models. The results show that our approach can be 5.11 and 2.31 times faster than the original loopy belief propagation algorithm on average, respectively.",
							"pageNumber": 1565,
							"isPageNumberRoman": false
						},
						{
							"eid": "2xV4mu5M1rjt9HaVfYGJK",
							"type": "authorPaper",
							"text": "CRYPTBARA: Dependency-Guided Detection of Python Cryptographic API Misuses",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b577/573300b577.pdf",
							"extraLocations": [],
							"authorNames": "Seogyeong Cho (Korea University, Republic of Korea), Seungeun Yu (Korea University, Republic of Korea), Seunghoon Woo (Korea University, Republic of Korea)",
							"abstract": "We present CRYPTBARA, a precise approach for detecting Python cryptographic API misuses. Cryptographic APIs are widely used to ensure data security, but their improper use can inadvertently compromise the security of entire systems. Existing approaches often fail to capture how cryptographic objects are initialized and used across inter-procedural contexts, limiting their ability to detect context-dependent misuses. In contrast, the key innovation of CRYPTBARA lies in synergistically combining static dependency analysis with LLM reasoning guided by dependency context, enabling context-sensitive misuse detection. To this end, CRYPTBARA extracts intra- and inter-procedural dependencies from Python code and encodes them into context-rich prompts, allowing the LLM to perform semantically-aware analysis despite syntactic complexity. We evaluated CRYPTBARA on two benchmarks containing real-world cryptographic API misuses. CRYPTBARA achieved F1 scores of 95.43% and 84%, outperforming existing approaches that achieved at most 73.68% and 70.59% F1 scores, respectively. CRYPTBARA further demonstrated its practical impact by discovering previously unknown misuses in popular Python repositories, with 22 representative cases reported to and confirmed by maintainers.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 CRYPTBARA: Dependency-Guided Detection of Python Cryptographic API Misuses 1759123595860 10.1109/ASE63991.2025.00133 Seogyeong Cho Korea University, Republic of Korea jsg8777@korea.ac.kr Seungeun Yu Korea University, Republic of Korea spblue4422@korea.ac.kr Seunghoon Woo Korea University, Republic of Korea seunghoonwoo@korea.ac.kr python cryptographic api misuse dependency analysis misuse detection We present CRYPTBARA, a precise approach for detecting Python cryptographic API misuses. Cryptographic APIs are widely used to ensure data security, but their improper use can inadvertently compromise the security of entire systems. Existing approaches often fail to capture how cryptographic objects are initialized and used across inter-procedural contexts, limiting their ability to detect context-dependent misuses. In contrast, the key innovation of CRYPTBARA lies in synergistically combining static dependency analysis with LLM reasoning guided by dependency context, enabling context-sensitive misuse detection. To this end, CRYPTBARA extracts intra- and inter-procedural dependencies from Python code and encodes them into context-rich prompts, allowing the LLM to perform semantically-aware analysis despite syntactic complexity. We evaluated CRYPTBARA on two benchmarks containing real-world cryptographic API misuses. CRYPTBARA achieved F1 scores of 95.43% and 84%, outperforming existing approaches that achieved at most 73.68% and 70.59% F1 scores, respectively. CRYPTBARA further demonstrated its practical impact by discovering previously unknown misuses in popular Python repositories, with 22 representative cases reported to and confirmed by maintainers.",
							"pageNumber": 1577,
							"isPageNumberRoman": false
						},
						{
							"eid": "3KJnynzkKIyptImf659u9H",
							"type": "authorPaper",
							"text": "IMUFUZZER: Resilience-Based Discovery of Signal Injection Attacks on Robotic Aerial Vehicles",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b590/573300b590.pdf",
							"extraLocations": [],
							"authorNames": "Sudharssan Mohan (University of Texas at Dallas), Kyeongseok Yang (Korea University), Zelun Kong (University of Texas at Dallas), Yonghwi Kwon (University of Maryland), Junghwan Rhee (University of Central Oklahoma), Tyler Summers (University of Texas at Dallas), Hongjun Choi (DGIST), Heejo Lee (Korea University), Chung Hwan Kim (University of Texas at Dallas)",
							"abstract": "Robotic aerial vehicles (RAVs), particularly drones, are crucial in civil and military sectors. However, researchers have found that adversaries can inject noise into sensor measurements and cause physical impacts on the RAVs like crashes. Although identifying such signal injection attacks is essential to evaluate and improve the robustness of an RAV, it is challenging to discover them since their impact depends on the RAV's physical states and the search space of noise signals and physical states is vast due to its dynamic nature. This paper proposes IMUFUZZER, a feedback-driven fuzzing framework, to automatically test an RAV system and discover signal injection attacks. IMUFUZZER generates realistic noise signals for various inertial measurement unit (IMU) sensors, and monitors their impact on RAV control to detect mission failures, leveraging a high-fidelity RAV simulator. To find the physical states that attacks depend on, IMUFUZZER generates various mission paths that the RAV will fly through. We develop a novel feedback mechanism to quantify the resilience of the RAV against attacks and efficiently guide the fuzzing process to find signal injection attacks. Using IMUFUZZER, we have discovered 23 successful signal injection attacks on popular RAV control software (ArduPilot). We evaluate the correctness and effectiveness of our feedback-based sensor fuzzing and demonstrate the feasibility of the discovered attacks through physical experiments.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 IMUFUZZER: Resilience-Based Discovery of Signal Injection Attacks on Robotic Aerial Vehicles 1758909932977 10.1109/ASE63991.2025.00134 Sudharssan Mohan University of Texas at Dallas sudharssan.mohan@utdallas.edu Kyeongseok Yang Korea University ks8171235@korea.ac.kr Zelun Kong University of Texas at Dallas zelun.kong@utdallas.edu Yonghwi Kwon University of Maryland yongkwon@umd.edu Junghwan Rhee University of Central Oklahoma jrhee2@uco.edu Tyler Summers University of Texas at Dallas tyler.summers@utdallas.edu Hongjun Choi DGIST hongjun@dgist.ac.kr Heejo Lee Korea University heejo@korea.ac.kr Chung Hwan Kim University of Texas at Dallas chungkim@utdallas.edu robotic aerial vehicle sensor fuzzing resilience Robotic aerial vehicles (RAVs), particularly drones, are crucial in civil and military sectors. However, researchers have found that adversaries can inject noise into sensor measurements and cause physical impacts on the RAVs like crashes. Although identifying such signal injection attacks is essential to evaluate and improve the robustness of an RAV, it is challenging to discover them since their impact depends on the RAV's physical states and the search space of noise signals and physical states is vast due to its dynamic nature. This paper proposes IMUFUZZER, a feedback-driven fuzzing framework, to automatically test an RAV system and discover signal injection attacks. IMUFUZZER generates realistic noise signals for various inertial measurement unit (IMU) sensors, and monitors their impact on RAV control to detect mission failures, leveraging a high-fidelity RAV simulator. To find the physical states that attacks depend on, IMUFUZZER generates various mission paths that the RAV will fly through. We develop a novel feedback mechanism to quantify the resilience of the RAV against attacks and efficiently guide the fuzzing process to find signal injection attacks. Using IMUFUZZER, we have discovered 23 successful signal injection attacks on popular RAV control software (ArduPilot). We evaluate the correctness and effectiveness of our feedback-based sensor fuzzing and demonstrate the feasibility of the discovered attacks through physical experiments.",
							"pageNumber": 1590,
							"isPageNumberRoman": false
						},
						{
							"eid": "54T76efGCPgHzKRZOnURfS",
							"type": "authorPaper",
							"text": "Beyond Static GUI Agent: Evolving LLM-Based GUI Testing via Dynamic Memory",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b602/573300b602.pdf",
							"extraLocations": [],
							"authorNames": "Mengzhuo Chen (Chinese Academy of Sciences, Beijing, China; University of Chinese Academy of Sciences, China; State Key Laboratory of Complex System Modeling and Simulation Technology ISCAS, China), Zhe Liu (Chinese Academy of Sciences, Beijing, China; University of Chinese Academy of Sciences, China; State Key Laboratory of Complex System Modeling and Simulation Technology ISCAS, China), Chunyang Chen (Technical University of Munich, Germany), Junjie Wang (Chinese Academy of Sciences, Beijing, China; University of Chinese Academy of Sciences, China; State Key Laboratory of Complex System Modeling and Simulation Technology ISCAS, China), Yangguang Xue (Chinese Academy of Sciences, Beijing, China; University of Chinese Academy of Sciences, China; State Key Laboratory of Complex System Modeling and Simulation Technology ISCAS, China), Boyu Wu (Chinese Academy of Sciences, Beijing, China; University of Chinese Academy of Sciences, China), Yuekai Huang (Chinese Academy of Sciences, Beijing, China; University of Chinese Academy of Sciences, China; State Key Laboratory of Complex System Modeling and Simulation Technology ISCAS, China), Libin Wu (Chinese Academy of Sciences, Beijing, China; University of Chinese Academy of Sciences, China; State Key Laboratory of Complex System Modeling and Simulation Technology ISCAS, China), Qing Wang (Chinese Academy of Sciences, Beijing, China; University of Chinese Academy of Sciences, China; State Key Laboratory of Complex System Modeling and Simulation Technology ISCAS, China)",
							"abstract": "The development of Large Language Models (LLMs) enables LLM-based GUI testing to interact with graphical user interfaces by understanding GUI screenshots and generating actions, which are widely applied in industry and academia. However, current approaches test each app in isolation, lacking mechanisms for experience accumulation and reuse. This limitation often causes GUI testing approaches to miss deeper exploration and fail to trigger bug-prone functionalities. To address this, we propose MemoDroid, a three-layer memory mechanism that augments LLM-based GUI testing with the ability to evolve through repeated interaction. MemoDroid designs episodic memory to capture functional-level testing traces, reflective memory to summarize issue patterns and redundant behaviors, and strategic memory to synthesize cross-app exploration strategies. These memory layers are dynamically retrieved and injected into LLM prompts at runtime, enabling the agent to reuse successful behaviors, avoid ineffective actions, and prioritize bug-prone paths. We implement MemoDroid as a lightweight plugin, which can be integrated into existing LLM-based GUI testing approaches. We evaluate MemoDroid on real-world apps from 15 diverse app categories. Results show that MemoDroid enhances GUI testing performance across five baselines, with activity and code coverage increasing by 79% - 96% and 81% - 97%, and bug detection improving by 57% - 198%. Ablation studies confirm the contributions of each memory layer. Furthermore, MemoDroid detects 49 new bugs in 200 popular apps, with 35 confirmed fixes and 14 acknowledged by developers, showing its practical value in memory-driven GUI testing.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Beyond Static GUI Agent: Evolving LLM-Based GUI Testing via Dynamic Memory 1759133615052 10.1109/ASE63991.2025.00135 Mengzhuo Chen Chinese Academy of Sciences, Beijing, China; University of Chinese Academy of Sciences, China; State Key Laboratory of Complex System Modeling and Simulation Technology ISCAS, China chenmengzhuo23@mails.ucas.edu.cn Zhe Liu Chinese Academy of Sciences, Beijing, China; University of Chinese Academy of Sciences, China; State Key Laboratory of Complex System Modeling and Simulation Technology ISCAS, China liuzhe181@mails.ucas.edu.cn Chunyang Chen Technical University of Munich, Germany chun-yang.chen@tum.de Junjie Wang Chinese Academy of Sciences, Beijing, China; University of Chinese Academy of Sciences, China; State Key Laboratory of Complex System Modeling and Simulation Technology ISCAS, China junjie@iscas.ac.cn Yangguang Xue Chinese Academy of Sciences, Beijing, China; University of Chinese Academy of Sciences, China; State Key Laboratory of Complex System Modeling and Simulation Technology ISCAS, China xueyangguang24@mails.ucas.ac.cn Boyu Wu Chinese Academy of Sciences, Beijing, China; University of Chinese Academy of Sciences, China boyu_wu2021@163.com Yuekai Huang Chinese Academy of Sciences, Beijing, China; University of Chinese Academy of Sciences, China; State Key Laboratory of Complex System Modeling and Simulation Technology ISCAS, China huangyuekai18@mails.ucas.ac.cn Libin Wu Chinese Academy of Sciences, Beijing, China; University of Chinese Academy of Sciences, China; State Key Laboratory of Complex System Modeling and Simulation Technology ISCAS, China libinwu@yeah.net Qing Wang Chinese Academy of Sciences, Beijing, China; University of Chinese Academy of Sciences, China; State Key Laboratory of Complex System Modeling and Simulation Technology ISCAS, China wq@iscas.ac.cn large language model android app memory mechanism automated gui testing gui agent The development of Large Language Models (LLMs) enables LLM-based GUI testing to interact with graphical user interfaces by understanding GUI screenshots and generating actions, which are widely applied in industry and academia. However, current approaches test each app in isolation, lacking mechanisms for experience accumulation and reuse. This limitation often causes GUI testing approaches to miss deeper exploration and fail to trigger bug-prone functionalities. To address this, we propose MemoDroid, a three-layer memory mechanism that augments LLM-based GUI testing with the ability to evolve through repeated interaction. MemoDroid designs episodic memory to capture functional-level testing traces, reflective memory to summarize issue patterns and redundant behaviors, and strategic memory to synthesize cross-app exploration strategies. These memory layers are dynamically retrieved and injected into LLM prompts at runtime, enabling the agent to reuse successful behaviors, avoid ineffective actions, and prioritize bug-prone paths. We implement MemoDroid as a lightweight plugin, which can be integrated into existing LLM-based GUI testing approaches. We evaluate MemoDroid on real-world apps from 15 diverse app categories. Results show that MemoDroid enhances GUI testing performance across five baselines, with activity and code coverage increasing by 79% - 96% and 81% - 97%, and bug detection improving by 57% - 198%. Ablation studies confirm the contributions of each memory layer. Furthermore, MemoDroid detects 49 new bugs in 200 popular apps, with 35 confirmed fixes and 14 acknowledged by developers, showing its practical value in memory-driven GUI testing.",
							"pageNumber": 1602,
							"isPageNumberRoman": false
						},
						{
							"eid": "50fKZjZgy5bAlNIZ0feTL2",
							"type": "authorPaper",
							"text": "Terminator: Enabling Efficient Fuzzing of Closed-Source GUI Programs by Automatic Coverage-Guided Termination",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b615/573300b615.pdf",
							"extraLocations": [],
							"authorNames": "Jonas Zabel (Fraunhofer SIT, Germany), Philip Kolvenbach (DZ Bank, Germany), Steven Arzt (Fraunhofer SIT, Germany)",
							"abstract": "When fuzzing a proprietary file-processing program, one typically executes the whole program repeatedly with sampled input files, and distinguishes between normal and abnormal termination. While this works well for many command-line utilities, it is more complicated for programs that usually do not terminate after input file processing. Many real-world applications are examples of such programs, in particular, those with a graphical user interface (GUI), such as image editors, media players and document viewers. In these cases, the fuzzer has to define the scope of the execution and forcefully terminate the program under test. In order to efficiently fuzz test file-processing programs with a GUI, a standard approach is to define a dedicated testing harness, which executes the file processing in isolation and strips irrelevant program parts. However, this either requires the source code of the program or an expert's effort in reverse engineering. Alternative approaches work on the unmodified binary of the program, and use a heuristic to decide when the input processing is likely done. For example, one can terminate the program after a fixed timeout or once its CPU usage has dropped below a threshold. We show that these heuristics, while simple to implement, are inefficient and ineffective. We present TERMINATOR, a fully-automated approach to facilitate efficient fuzzing of closed-source file-processing programs with a GUI. TERMINATOR modifies the binary of the program under test so that it automatically terminates when code coverage stops increasing without user interaction. Consequently, TERMINATOR (1) ensures that the program terminates soon after the input processing instead of waiting for user interaction, and, at the same time, (2) prevents premature termination during input processing. We show that TERMINATOR outperforms the timeout and CPU usage heuristics and significantly increases fuzzing efficiency. ",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Terminator: Enabling Efficient Fuzzing of Closed-Source GUI Programs by Automatic Coverage-Guided Termination 1759776334322 10.1109/ASE63991.2025.00136 Jonas Zabel Fraunhofer SIT, Germany jonas.zabel@sit.fraunhofer.de Philip Kolvenbach DZ Bank, Germany philip.kolvenbach@dzbank.de Steven Arzt Fraunhofer SIT, Germany steven.arzt@sit.fraunhofer.de fuzzing gui dynamic instrumentation windows closed-source software When fuzzing a proprietary file-processing program, one typically executes the whole program repeatedly with sampled input files, and distinguishes between normal and abnormal termination. While this works well for many command-line utilities, it is more complicated for programs that usually do not terminate after input file processing. Many real-world applications are examples of such programs, in particular, those with a graphical user interface (GUI), such as image editors, media players and document viewers. In these cases, the fuzzer has to define the scope of the execution and forcefully terminate the program under test. In order to efficiently fuzz test file-processing programs with a GUI, a standard approach is to define a dedicated testing harness, which executes the file processing in isolation and strips irrelevant program parts. However, this either requires the source code of the program or an expert's effort in reverse engineering. Alternative approaches work on the unmodified binary of the program, and use a heuristic to decide when the input processing is likely done. For example, one can terminate the program after a fixed timeout or once its CPU usage has dropped below a threshold. We show that these heuristics, while simple to implement, are inefficient and ineffective. We present TERMINATOR, a fully-automated approach to facilitate efficient fuzzing of closed-source file-processing programs with a GUI. TERMINATOR modifies the binary of the program under test so that it automatically terminates when code coverage stops increasing without user interaction. Consequently, TERMINATOR (1) ensures that the program terminates soon after the input processing instead of waiting for user interaction, and, at the same time, (2) prevents premature termination during input processing. We show that TERMINATOR outperforms the timeout and CPU usage heuristics and significantly increases fuzzing efficiency.",
							"pageNumber": 1615,
							"isPageNumberRoman": false
						},
						{
							"eid": "7HTESAQuaeRwdktrj66oCL",
							"type": "authorPaper",
							"text": "Characterizing Multi-Hunk Patches: Divergence, Proximity, and LLM Repair Challenges",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b628/573300b628.pdf",
							"extraLocations": [],
							"authorNames": "Noor Nashid (University of British Columbia, Canada), Daniel Ding (University of British Columbia, Canada), Keheliya Gallaba (Queen's University, Canada), Ahmed E. Hassan (Queen's University, Canada), Ali Mesbah (University of British Columbia, Canada)",
							"abstract": "Multi-hunk bugs, where fixes span disjoint regions of code, are common in practice, yet remain underrepresented in automated repair. Existing techniques and benchmarks pre-dominantly target single-hunk scenarios, overlooking the added complexity of coordinating semantically related changes across the codebase. In this work, we characterize HUNK4J, a dataset of multi-hunk patches derived from 372 real-world defects. We propose hunk divergence, a metric that quantifies the variation among edits in a patch by capturing lexical, structural, and file-level differences, while incorporating the number of hunks involved. We further define spatial proximity, a classification that models how hunks are spatially distributed across the program hierarchy. Our empirical study spanning six LLMs reveals that model success rates decline with increased divergence and spatial dispersion. Notably, when using the LLM alone, no model succeeds in the most dispersed Fragment class. These findings highlight a critical gap in LLM capabilities and motivate divergence-aware repair strategies.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Characterizing Multi-Hunk Patches: Divergence, Proximity, and LLM Repair Challenges 1759528677905 10.1109/ASE63991.2025.00137 Noor Nashid University of British Columbia, Canada nashid@ece.ubc.ca Daniel Ding University of British Columbia, Canada dyxd2003@ece.ubc.ca Keheliya Gallaba Queen's University, Canada gallabak@sigsoft.org Ahmed E. Hassan Queen's University, Canada ahmed@cs.queensu.ca Ali Mesbah University of British Columbia, Canada amesbah@ece.ubc.ca multi-hunk benchmark program repair hunk divergence spatial proximity large language model Multi-hunk bugs, where fixes span disjoint regions of code, are common in practice, yet remain underrepresented in automated repair. Existing techniques and benchmarks pre-dominantly target single-hunk scenarios, overlooking the added complexity of coordinating semantically related changes across the codebase. In this work, we characterize HUNK4J, a dataset of multi-hunk patches derived from 372 real-world defects. We propose hunk divergence, a metric that quantifies the variation among edits in a patch by capturing lexical, structural, and file-level differences, while incorporating the number of hunks involved. We further define spatial proximity, a classification that models how hunks are spatially distributed across the program hierarchy. Our empirical study spanning six LLMs reveals that model success rates decline with increased divergence and spatial dispersion. Notably, when using the LLM alone, no model succeeds in the most dispersed Fragment class. These findings highlight a critical gap in LLM capabilities and motivate divergence-aware repair strategies.",
							"pageNumber": 1628,
							"isPageNumberRoman": false
						},
						{
							"eid": "75rUioJqcMGFNLsJlSDXum",
							"type": "authorPaper",
							"text": "Fact-Aligned and Template-Constrained Static Analyzer Rule Enhancement with LLMs",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b641/573300b641.pdf",
							"extraLocations": [],
							"authorNames": "Zongze Jiang (National Engineering Research Center for Big Data Technology and System, Services Computing Technology and System Lab; Hubei Engineering Research Center on Big Data Security, Hubei Key Laboratory of Distributed System Security; Huazhong University of Science and Technology (HUST), China), Ming Wen (National Engineering Research Center for Big Data Technology and System, Services Computing Technology and System Lab; Hubei Engineering Research Center on Big Data Security, Hubei Key Laboratory of Distributed System Security; Huazhong University of Science and Technology (HUST), China), Ge Wen (Huazhong University of Science and Technology, China), Hai Jin (National Engineering Research Center for Big Data Technology and System, Services Computing Technology and System Lab; Cluster and Grid Computing Lab, School of Computer Science and Technology, China)",
							"abstract": "Static analyzers are vital to ensure software quality, but often produce false alarms. In this paper, we focus on the challenging task, directly refining defective static detection rules in the analyzer with Large Language Models to mitigate false positives/negatives fundamentally. This paper introduces RuleRefiner, a novel multi-stage framework for static analyzer rule refinement. Specifically, RuleRefiner systematically employs LLMs by integrating dynamic profiling information for fact-based rule-code alignment, performing differential fault localization to accurately pinpoint error sources, and utilizing targeted templates to guide and constrain LLM-based modifications for precise and minimally disruptive enhancements. Evaluated on 218 real-world refinement tasks, RuleRefiner achieved a pass@5 score of 80.28%, significantly outperforming all selected LLM-based baselines under the same settings. Moreover, the rules refined by RuleRefiner demonstrated high generalization capability comparable to those written by human experts.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Fact-Aligned and Template-Constrained Static Analyzer Rule Enhancement with LLMs 1759563961258 10.1109/ASE63991.2025.00138 Zongze Jiang National Engineering Research Center for Big Data Technology and System, Services Computing Technology and System Lab; Hubei Engineering Research Center on Big Data Security, Hubei Key Laboratory of Distributed System Security; Huazhong University of Science and Technology (HUST), China jiangzongze@hust.edu.cn Ming Wen National Engineering Research Center for Big Data Technology and System, Services Computing Technology and System Lab; Hubei Engineering Research Center on Big Data Security, Hubei Key Laboratory of Distributed System Security; Huazhong University of Science and Technology (HUST), China mwenaa@hust.edu.cn Ge Wen Huazhong University of Science and Technology, China gwen@hust.edu.cn Hai Jin National Engineering Research Center for Big Data Technology and System, Services Computing Technology and System Lab; Cluster and Grid Computing Lab, School of Computer Science and Technology, China hjin@hust.edu.cn Static analyzers are vital to ensure software quality, but often produce false alarms. In this paper, we focus on the challenging task, directly refining defective static detection rules in the analyzer with Large Language Models to mitigate false positives/negatives fundamentally. This paper introduces RuleRefiner, a novel multi-stage framework for static analyzer rule refinement. Specifically, RuleRefiner systematically employs LLMs by integrating dynamic profiling information for fact-based rule-code alignment, performing differential fault localization to accurately pinpoint error sources, and utilizing targeted templates to guide and constrain LLM-based modifications for precise and minimally disruptive enhancements. Evaluated on 218 real-world refinement tasks, RuleRefiner achieved a pass@5 score of 80.28%, significantly outperforming all selected LLM-based baselines under the same settings. Moreover, the rules refined by RuleRefiner demonstrated high generalization capability comparable to those written by human experts.",
							"pageNumber": 1641,
							"isPageNumberRoman": false
						},
						{
							"eid": "1EBMFiqeq8w0kS9QmT7pWm",
							"type": "authorPaper",
							"text": "When Faster Isn't Greener: The Hidden Costs of LLM-Based Code Optimization",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b654/573300b654.pdf",
							"extraLocations": [],
							"authorNames": "Tristan Coignion (Univ. Lille, CNRS, France), Cl\u00E9ment Quinton (Univ. Lille, CNRS, France), Romain Rouvoy (Univ. Lille, CNRS, France)",
							"abstract": "Large Language Models (LLMs) are increasingly adopted to optimize source code, offering the promise of faster, more efficient programs without manual tuning. This capability is particularly appealing in the context of sustainable computing, where enhanced performance is often assumed to correspond to reduced energy consumption. However, LLMs themselves are energy- and resource-intensive, raising critical questions about whether their use for code optimization is energetically justified. Prior work mainly focused on runtime performance gains, leaving a gap in our understanding of the broader energy implications of LLM-based code optimization. In this paper, we report on a systematic, energy-focused evaluation of LLM-based code optimization methods. Relying on 118 tasks from the EvalPerf benchmark, we assess the trade-offs between code performance, correctness, and energy consumption of multiple optimization methods across multiple families of LLMs. We introduce the Break-Even Point (BEP) as a key metric to quantify the number of executions required for an optimized program to outweigh the energy consumed when generating the optimization itself. Our results show that, while certain configurations achieve substantial speedups and energy reductions, these benefits often demand from hundreds to hundreds of thousands of executions to become energetically profitable. Moreover, the optimization process often yields incorrect or less efficient code. Importantly, we identify a weak negative correlation between performance gains and actual energy savings, challenging assumptions that faster code automatically equates to a smaller energy footprint. This work underscores the necessity of energy-aware optimization strategies. Practitioners should carefully target LLM-based optimization efforts to high-frequency, high-impact workloads, while monitoring energy consumption across the entire life-cycle of development and deployment.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 When Faster Isn't Greener: The Hidden Costs of LLM-Based Code Optimization 1756215090232 10.1109/ASE63991.2025.00139 Tristan Coignion Univ. Lille, CNRS, France tristan.coignion@inria.fr Cl\u00E9ment Quinton Univ. Lille, CNRS, France clement.quinton@inria.fr Romain Rouvoy Univ. Lille, CNRS, France romain.rouvoy@inria.fr large language model code efficiency code optimization energy consumption Large Language Models (LLMs) are increasingly adopted to optimize source code, offering the promise of faster, more efficient programs without manual tuning. This capability is particularly appealing in the context of sustainable computing, where enhanced performance is often assumed to correspond to reduced energy consumption. However, LLMs themselves are energy- and resource-intensive, raising critical questions about whether their use for code optimization is energetically justified. Prior work mainly focused on runtime performance gains, leaving a gap in our understanding of the broader energy implications of LLM-based code optimization. In this paper, we report on a systematic, energy-focused evaluation of LLM-based code optimization methods. Relying on 118 tasks from the EvalPerf benchmark, we assess the trade-offs between code performance, correctness, and energy consumption of multiple optimization methods across multiple families of LLMs. We introduce the Break-Even Point (BEP) as a key metric to quantify the number of executions required for an optimized program to outweigh the energy consumed when generating the optimization itself. Our results show that, while certain configurations achieve substantial speedups and energy reductions, these benefits often demand from hundreds to hundreds of thousands of executions to become energetically profitable. Moreover, the optimization process often yields incorrect or less efficient code. Importantly, we identify a weak negative correlation between performance gains and actual energy savings, challenging assumptions that faster code automatically equates to a smaller energy footprint. This work underscores the necessity of energy-aware optimization strategies. Practitioners should carefully target LLM-based optimization efforts to high-frequency, high-impact workloads, while monitoring energy consumption across the entire life-cycle of development and deployment.",
							"pageNumber": 1654,
							"isPageNumberRoman": false
						},
						{
							"eid": "6GLhftkBkjqA8dX9abuSLg",
							"type": "authorPaper",
							"text": "Leveraging Mixture-of-Experts Framework for Smart Contract Vulnerability Repair with Large Language Model",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b666/573300b666.pdf",
							"extraLocations": [],
							"authorNames": "Hang Yuan (Chinese Academy of Science, China; University of Chinese Academy of Sciences, China), Xizhi Hou (Chinese Academy of Science, China; University of Chinese Academy of Sciences, China), Lei Yu (Chinese Academy of Science, China; University of Chinese Academy of Sciences, China), Li Yang (Chinese Academy of Science, China; University of Chinese Academy of Sciences, China), Jiayue  Tang (Chinese Academy of Science, China; University of Chinese Academy of Sciences, China), Jiadong  Xu  (Chinese Academy of Science, China; University of Chinese Academy of Sciences, China), Yifei Liu (Chinese Academy of Science, China; University of Chinese Academy of Sciences, China), Fengjun Zhang (Chinese Academy of Sciences, China), Chun Zuo (Sinosoft Co., Ltd., China)",
							"abstract": "Smart contracts are a core component of blockchain ecosystems, but their transparency and immutability make them vulnerable to attacks, leading to significant financial losses. Thus, repairing vulnerabilities in smart contracts is crucial for establishing a trustworthy blockchain environment. Existing smart contract vulnerability repair methods suffer from a critical \"one-for-all\" design limitation, where a single model is tasked with fixing diverse vulnerability types, leading to suboptimal performance due to insufficient specialization. To address this, we propose MoEFix, a novel framework leveraging a Mixture-of-Experts (MoE) architecture tailored for smart contract characteristics. MoEFix partitions vulnerabilities into subspaces, trains specialized experts for each type (e.g., reentrancy, integer overflow), and employs a vulnerability-aware router to dynamically allocate repairs. We further redesign the repair workflow to align with large language models, enabling end-to-end secure contract generation instead of partial patches, and to achieve this, we curated a dataset of 1,391 contracts covering five critical vulnerability types. To validate our approach, we extend the benchmark PVD test suite. Experiments demonstrate that MoEFix outperforms state-of-the-art methods by 21.64% in overall accuracy, achieving improvements of 26.19% (reentrancy) and 23.08% (delegatecall) for specific vulnerabilities. ",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Leveraging Mixture-of-Experts Framework for Smart Contract Vulnerability Repair with Large Language Model 1759320647065 10.1109/ASE63991.2025.00140 Hang Yuan Chinese Academy of Science, China; University of Chinese Academy of Sciences, China yuanhang2023@iscas.ac.cn Xizhi Hou Chinese Academy of Science, China; University of Chinese Academy of Sciences, China houxizhi24@mails.ucas.ac.cn Lei Yu Chinese Academy of Science, China; University of Chinese Academy of Sciences, China yulei2022@iscas.ac.cn Li Yang Chinese Academy of Science, China; University of Chinese Academy of Sciences, China yangli2017@iscas.ac.cn Jiayue Tang Chinese Academy of Science, China; University of Chinese Academy of Sciences, China tangjiayue23@mails.ucas.ac.cn Jiadong Xu Chinese Academy of Science, China; University of Chinese Academy of Sciences, China xujiadong24@mails.ucas.ac.cn Yifei Liu Chinese Academy of Science, China; University of Chinese Academy of Sciences, China liuyifei241@mails.ucas.ac.cn Fengjun Zhang Chinese Academy of Sciences, China fengjun@iscas.ac.cn Chun Zuo Sinosoft Co., Ltd., China zuochun@sinosoft.com.cn Smart Contract Large Language Models Mixture of Experts Smart contracts are a core component of blockchain ecosystems, but their transparency and immutability make them vulnerable to attacks, leading to significant financial losses. Thus, repairing vulnerabilities in smart contracts is crucial for establishing a trustworthy blockchain environment. Existing smart contract vulnerability repair methods suffer from a critical \"one-for-all\" design limitation, where a single model is tasked with fixing diverse vulnerability types, leading to suboptimal performance due to insufficient specialization. To address this, we propose MoEFix, a novel framework leveraging a Mixture-of-Experts (MoE) architecture tailored for smart contract characteristics. MoEFix partitions vulnerabilities into subspaces, trains specialized experts for each type (e.g., reentrancy, integer overflow), and employs a vulnerability-aware router to dynamically allocate repairs. We further redesign the repair workflow to align with large language models, enabling end-to-end secure contract generation instead of partial patches, and to achieve this, we curated a dataset of 1,391 contracts covering five critical vulnerability types. To validate our approach, we extend the benchmark PVD test suite. Experiments demonstrate that MoEFix outperforms state-of-the-art methods by 21.64% in overall accuracy, achieving improvements of 26.19% (reentrancy) and 23.08% (delegatecall) for specific vulnerabilities.",
							"pageNumber": 1666,
							"isPageNumberRoman": false
						},
						{
							"eid": "2tGyrBZjOyPaP7iRjxH5qX",
							"type": "authorPaper",
							"text": "Uncovering Discrimination Clusters: Quantifying and Explaining Systematic Fairness Violations",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b679/573300b679.pdf",
							"extraLocations": [],
							"authorNames": "Ranit D. Akash (University of Illinois Chicago, USA), Ashish Kumar (Pennsylvania State University, USA), Verya Monjezi (University of Illinois Chicago, USA), Ashutosh Trivedi (University of Colorado Boulder, USA), Gang Tan (State University, USA), Saeid Tizpaz-Niari (University of Illinois Chicago, USA)",
							"abstract": "Fairness in algorithmic decision-making is often framed in terms of individual fairness, which requires that similar individuals receive similar outcomes. A system violates individual fairness if there exists a pair of inputs differing only in protected attributes (such as race or gender) that lead to significantly different outcomes\u2014for example, one favorable and the other unfavorable. While this notion highlights isolated instances of unfairness, it fails to capture broader patterns of systematic or clustered discrimination that may affect entire subgroups. We introduce and motivate the concept of discrimination clustering, a generalization of individual fairness violations. Rather than detecting single counterfactual disparities, we seek to uncover regions of the input space where small perturbations in protected features lead to k-significantly distinct clusters of outcomes. That is, for a given input, we identify a local neighborhood\u2014differing only in protected attributes\u2014whose members' outputs separate into many distinct clusters. These clusters reveal significant arbitrariness in treatment solely based on protected attributes that help expose patterns of algorithmic bias that elude pairwise fairness checks. We present HyFair, a hybrid technique that combines formal symbolic analysis (via SMT and MILP solvers) to certify individual fairness with randomized search to discover discriminatory clusters. This combination enables both formal guarantees\u2014when no counterexamples exist\u2014and the detection of severe violations that are computationally challenging for symbolic methods alone. Given a set of inputs exhibiting high k-discrimination, we introduce a novel explanation method to generate interpretable, decision-tree-style artifacts. Our experiments demonstrate that HyFair outperforms state-of-the-art fairness verification and local explanation methods. In particular, HyFair reveals that some benchmarks exhibit significant discrimination clustering, while others show limited or no disparities with respect to protected attributes. It also provides intuitive explanations to support understanding and mitigation of unfairness.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Uncovering Discrimination Clusters: Quantifying and Explaining Systematic Fairness Violations 1759458140485 10.1109/ASE63991.2025.00141 Ranit D. Akash University of Illinois Chicago, USA rakas@uic.edu Ashish Kumar Pennsylvania State University, USA azk640@psu.edu Verya Monjezi University of Illinois Chicago, USA vmonj@uic.edu Ashutosh Trivedi University of Colorado Boulder, USA ashutosh.trivedi@colorado.edu Gang Tan State University, USA gtan@psu.edu Saeid Tizpaz-Niari University of Illinois Chicago, USA saeid@uic.edu Fairness in algorithmic decision-making is often framed in terms of individual fairness, which requires that similar individuals receive similar outcomes. A system violates individual fairness if there exists a pair of inputs differing only in protected attributes (such as race or gender) that lead to significantly different outcomes\u2014for example, one favorable and the other unfavorable. While this notion highlights isolated instances of unfairness, it fails to capture broader patterns of systematic or clustered discrimination that may affect entire subgroups. We introduce and motivate the concept of discrimination clustering, a generalization of individual fairness violations. Rather than detecting single counterfactual disparities, we seek to uncover regions of the input space where small perturbations in protected features lead to k-significantly distinct clusters of outcomes. That is, for a given input, we identify a local neighborhood\u2014differing only in protected attributes\u2014whose members' outputs separate into many distinct clusters. These clusters reveal significant arbitrariness in treatment solely based on protected attributes that help expose patterns of algorithmic bias that elude pairwise fairness checks. We present HyFair, a hybrid technique that combines formal symbolic analysis (via SMT and MILP solvers) to certify individual fairness with randomized search to discover discriminatory clusters. This combination enables both formal guarantees\u2014when no counterexamples exist\u2014and the detection of severe violations that are computationally challenging for symbolic methods alone. Given a set of inputs exhibiting high k-discrimination, we introduce a novel explanation method to generate interpretable, decision-tree-style artifacts. Our experiments demonstrate that HyFair outperforms state-of-the-art fairness verification and local explanation methods. In particular, HyFair reveals that some benchmarks exhibit significant discrimination clustering, while others show limited or no disparities with respect to protected attributes. It also provides intuitive explanations to support understanding and mitigation of unfairness.",
							"pageNumber": 1679,
							"isPageNumberRoman": false
						},
						{
							"eid": "4DPw64SFACif2KKOIjtByF",
							"type": "authorPaper",
							"text": "Demystifying Cookie Sharing Risks in WebView-Based Mobile App-in-app Ecosystems",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b692/573300b692.pdf",
							"extraLocations": [],
							"authorNames": "Miao Zhang (Beijing University of Posts and Telecommunications, China), Shenao Wang (Huazhong University of Science and Technology, China), Guilin Zheng (Beijing University of Posts and Telecommunications, China), Yanjie Zhao (Huazhong University of Science and Technology, China), Haoyu Wang (Huazhong University of Science and Technology, China)",
							"abstract": "Mini-programs, an emerging mobile application paradigm within super-apps, offer a seamless and installation-free experience. However, the adoption of the web-view component has disrupted their isolation mechanisms, exposing new attack surfaces and vulnerabilities. In this paper, we introduce a novel vulnerability called Cross Mini-program Cookie Sharing (CMCS), which arises from the shared web-view environment across mini-programs. This vulnerability allows unauthorized data exchange across mini-programs by enabling one mini-program to access cookies set by another within the same web-view context, violating isolation principles. As a preliminary step, we analyzed the web-view mechanisms of four major platforms, including WeChat, AliPay, TikTok, and Baidu, and found that all of them are affected by CMCS vulnerabilities. These findings were responsibly disclosed and acknowledged with two CVEs. Furthermore, we demonstrate the collusion attack enabled by CMCS, where privileged mini-programs exfiltrate sensitive user data via cookies accessible to unprivileged mini-programs. To measure the impact of collusion attacks enabled by CMCS vulnerabilities in the wild, we developed MiCoScan, a static analysis tool that detects mini-programs affected by CMCS vulnerabilities. MiCoScan employs web-view context modeling to identify clusters of mini-programs sharing the same web-view domain and cross-webview data flow analysis to detect sensitive data transmissions to/from web-views. Using MiCoScan, we conducted a large-scale analysis of 351,483 mini-programs, identifying 45,448 clusters sharing web-view domains, 7,965 instances of privileged data transmission, and 9,877 mini-programs vulnerable to collusion attacks. Our findings highlight the widespread prevalence and significant security risks posed by CMCS vulnerabilities, underscoring the urgent need for improved isolation mechanisms in mini-program ecosystems.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Demystifying Cookie Sharing Risks in WebView-Based Mobile App-in-app Ecosystems 1759568331490 10.1109/ASE63991.2025.00142 Miao Zhang Beijing University of Posts and Telecommunications, China zhangmiao@bupt.edu.cn Shenao Wang Huazhong University of Science and Technology, China shenaowang@hust.edu.cn Guilin Zheng Beijing University of Posts and Telecommunications, China zhengguilin1818@bupt.edu.cn Yanjie Zhao Huazhong University of Science and Technology, China Yanjie_Zhao@hust.edu.cn Haoyu Wang Huazhong University of Science and Technology, China haoyuwang@hust.edu.cn mini-program cookie management collusion attack Mini-programs, an emerging mobile application paradigm within super-apps, offer a seamless and installation-free experience. However, the adoption of the web-view component has disrupted their isolation mechanisms, exposing new attack surfaces and vulnerabilities. In this paper, we introduce a novel vulnerability called Cross Mini-program Cookie Sharing (CMCS), which arises from the shared web-view environment across mini-programs. This vulnerability allows unauthorized data exchange across mini-programs by enabling one mini-program to access cookies set by another within the same web-view context, violating isolation principles. As a preliminary step, we analyzed the web-view mechanisms of four major platforms, including WeChat, AliPay, TikTok, and Baidu, and found that all of them are affected by CMCS vulnerabilities. These findings were responsibly disclosed and acknowledged with two CVEs. Furthermore, we demonstrate the collusion attack enabled by CMCS, where privileged mini-programs exfiltrate sensitive user data via cookies accessible to unprivileged mini-programs. To measure the impact of collusion attacks enabled by CMCS vulnerabilities in the wild, we developed MiCoScan, a static analysis tool that detects mini-programs affected by CMCS vulnerabilities. MiCoScan employs web-view context modeling to identify clusters of mini-programs sharing the same web-view domain and cross-webview data flow analysis to detect sensitive data transmissions to/from web-views. Using MiCoScan, we conducted a large-scale analysis of 351,483 mini-programs, identifying 45,448 clusters sharing web-view domains, 7,965 instances of privileged data transmission, and 9,877 mini-programs vulnerable to collusion attacks. Our findings highlight the widespread prevalence and significant security risks posed by CMCS vulnerabilities, underscoring the urgent need for improved isolation mechanisms in mini-program ecosystems.",
							"pageNumber": 1692,
							"isPageNumberRoman": false
						},
						{
							"eid": "42RbZTnApNcz3v4U3E6dmB",
							"type": "authorPaper",
							"text": "ADPerf: Investigating and Testing Performance in Autonomous Driving Systems",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b704/573300b704.pdf",
							"extraLocations": [],
							"authorNames": "Tri Minh-Triet Pham (Concordia University, Canada), Diego Elias Costa (Concordia University, Canada), Weiyi Shang (University of Waterloo, Canada), Jinqiu Yang (Concordia University, Canada)",
							"abstract": "Obstacle detection is crucial to the operation of autonomous driving systems, which rely on multiple sensors, such as cameras and LiDARs, combined with code logic and deep learning models to detect obstacles for time-sensitive decisions. Consequently, obstacle detection latency is critical to the safety and effectiveness of autonomous driving systems. However, the latency of the obstacle detection module and its resilience to various changes in the LiDAR point cloud data are not yet fully understood. In this work, we present the first comprehensive investigation on measuring and modeling the performance of the obstacle detection modules in two industry-grade autonomous driving systems, i.e., Apollo and Autoware. Learning from this investigation, we introduce ADPerf, a tool that aims to generate realistic point cloud data test cases that can expose increased detection latency. Increasing latency decreases the availability of the detected obstacles and stresses the capabilities of subsequent modules in autonomous driving systems, i.e., the modules may be negatively impacted by the increased latency in obstacle detection. We applied ADPerf to stress-test the performance of widely used 3D obstacle detection modules in autonomous driving systems, as well as the propagation of such tests on trajectory prediction modules. Our evaluation highlights the need to conduct performance testing of obstacle detection components, especially 3D obstacle detection, as they can be a major bottleneck to increased latency of the autonomous driving system. Such an adverse outcome will also further propagate to other modules, reducing the overall reliability of autonomous driving systems.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 ADPerf: Investigating and Testing Performance in Autonomous Driving Systems 1759554734784 10.1109/ASE63991.2025.00143 Tri Minh-Triet Pham Concordia University, Canada p_triet@encs.concordia.ca Diego Elias Costa Concordia University, Canada diego.costa@concordia.ca Weiyi Shang University of Waterloo, Canada wshang@uwaterloo.ca Jinqiu Yang Concordia University, Canada jinqiu.yang@concordia.ca autonomous vehicles lidar software testing system testing simulation performance evaluation Obstacle detection is crucial to the operation of autonomous driving systems, which rely on multiple sensors, such as cameras and LiDARs, combined with code logic and deep learning models to detect obstacles for time-sensitive decisions. Consequently, obstacle detection latency is critical to the safety and effectiveness of autonomous driving systems. However, the latency of the obstacle detection module and its resilience to various changes in the LiDAR point cloud data are not yet fully understood. In this work, we present the first comprehensive investigation on measuring and modeling the performance of the obstacle detection modules in two industry-grade autonomous driving systems, i.e., Apollo and Autoware. Learning from this investigation, we introduce ADPerf, a tool that aims to generate realistic point cloud data test cases that can expose increased detection latency. Increasing latency decreases the availability of the detected obstacles and stresses the capabilities of subsequent modules in autonomous driving systems, i.e., the modules may be negatively impacted by the increased latency in obstacle detection. We applied ADPerf to stress-test the performance of widely used 3D obstacle detection modules in autonomous driving systems, as well as the propagation of such tests on trajectory prediction modules. Our evaluation highlights the need to conduct performance testing of obstacle detection components, especially 3D obstacle detection, as they can be a major bottleneck to increased latency of the autonomous driving system. Such an adverse outcome will also further propagate to other modules, reducing the overall reliability of autonomous driving systems.",
							"pageNumber": 1704,
							"isPageNumberRoman": false
						},
						{
							"eid": "1ZNCBjUDa8MdxoqZKJSSNp",
							"type": "authorPaper",
							"text": "Fixing Broken Graphs: LLM-Powered Automatic Code Optimization for DNN Programs",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b717/573300b717.pdf",
							"extraLocations": [],
							"authorNames": "Haotian Wang (Nankai University, China), Yicheng Sui (Nankai University, China), Yudong Xie (Nankai University, China), Yicong Liu (Nankai University, China), Yufei Sun (Nankai University, China), Changqing Shi (Nankai University, China), Yuzhi Zhang (Nankai University, China)",
							"abstract": "Deep learning compilers optimize DNN program execution by capturing them as operator-based computation graphs. However, developers' deep learning programs often contain complex Python language features that prevent compilers from recognizing the entire program as a complete computation graph, resulting in sub-optimal performance. Our analysis reveals that actual capture failures involve only a few lines of code, we believe this problem can be addressed through code repair rather than extensive compiler improvements. To address this challenge, we introduce GraphGlue, a multi-agent system that leverages LLMs to repair and optimize DNN programs for compiler requirements, thereby maximizing the performance benefits of deep learning compilers in inference scenarios. GraphGlue employs (1) graph-break cause mining (GCM) to identify hidden causes of computation graph breaks and facilitate LLM-based repair, and (2) self-correction with reject sampling (SRS) to alternate between code debugging and regeneration, effectively avoiding ineffective feedback attempts caused by incorrect initial optimization strategies. Experimental results demonstrate that programs optimized by GraphGlue achieve up to 2.19x (1.23x on average) speedup compared to using TorchDynamo directly, and deliver up to 15.77x (8.74x on average) memory savings compared to state-of-the-art AI compiler frontends. GraphGlue exhibits strong generalization capabilities across 1,411 real-world user programs, successfully optimizing 92.63% of them. Code is available at https://github.com/Jamesswang/GraphGlue.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Fixing Broken Graphs: LLM-Powered Automatic Code Optimization for DNN Programs 1759301553630 10.1109/ASE63991.2025.00144 Haotian Wang Nankai University, China wanght@mail.nankai.edu.cn Yicheng Sui Nankai University, China suiyicheng@nankai.edu.cn Yudong Xie Nankai University, China 2120240856@mail.nankai.edu.cn Yicong Liu Nankai University, China liuyicong@mail.nankai.edu.cn Yufei Sun Nankai University, China yufei_sun@sina.com Changqing Shi Nankai University, China sccq@mail.nankai.edu.cn Yuzhi Zhang Nankai University, China zyz@nankai.edu.cn computation graph llm code optimization Deep learning compilers optimize DNN program execution by capturing them as operator-based computation graphs. However, developers' deep learning programs often contain complex Python language features that prevent compilers from recognizing the entire program as a complete computation graph, resulting in sub-optimal performance. Our analysis reveals that actual capture failures involve only a few lines of code, we believe this problem can be addressed through code repair rather than extensive compiler improvements. To address this challenge, we introduce GraphGlue, a multi-agent system that leverages LLMs to repair and optimize DNN programs for compiler requirements, thereby maximizing the performance benefits of deep learning compilers in inference scenarios. GraphGlue employs (1) graph-break cause mining (GCM) to identify hidden causes of computation graph breaks and facilitate LLM-based repair, and (2) self-correction with reject sampling (SRS) to alternate between code debugging and regeneration, effectively avoiding ineffective feedback attempts caused by incorrect initial optimization strategies. Experimental results demonstrate that programs optimized by GraphGlue achieve up to 2.19x (1.23x on average) speedup compared to using TorchDynamo directly, and deliver up to 15.77x (8.74x on average) memory savings compared to state-of-the-art AI compiler frontends. GraphGlue exhibits strong generalization capabilities across 1,411 real-world user programs, successfully optimizing 92.63% of them. Code is available at https://github.com/Jamesswang/GraphGlue.",
							"pageNumber": 1717,
							"isPageNumberRoman": false
						},
						{
							"eid": "5yER5XApkmuAbFgFSvOqwG",
							"type": "authorPaper",
							"text": "Function Clustering-Based Fuzzing Termination: Toward Smarter Early Stopping",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b730/573300b730.pdf",
							"extraLocations": [],
							"authorNames": "Liang Ding (University of Science and Technology of China, China), Wenzhang Yang (Institute of AI for industries, China), Yinxing Xue (Institute of AI for industries, China)",
							"abstract": "Fuzzing is a testing technique that generates a large number of inputs to cause program crashes. As software development accelerates and projects scale, the demand for fuzz testing in software assurance has increased. Performing comprehensive fuzz testing on all functions has become increasingly challenging and resource-intensive. Current methods for determining when to stop fuzz testing activities rely on metrics such as function coverage, potential vulnerability function coverage or crash count. However, these metrics fail to account for the scale of the functions under test. For example, function coverage may lead to excessive testing on non-critical functions, while vulnerability function coverage can result in premature termination if the estimated number of vulnerability functions is too low. This paper introduces a novel fuzzing testing termination criterion based on function clustering. We compare our criterion with three existing methods. First, by leveraging language model for function encoding and a multi-metric fusion algorithm for determining the number of clusters, we establish a relationship between function clustering and vulnerability distribution. Second, our experiments on eight function libraries demonstrate that the proposed termination criterion significantly improves testing efficiency, reducing fuzzing time by 1.4\u20137.2 hours (5\u201330%) across different configurations while maintaining minimal bug loss (averaging 0.25 bugs), outperforming existing criteria like potential vulnerability function coverage-based approaches.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Function Clustering-Based Fuzzing Termination: Toward Smarter Early Stopping 1759319916475 10.1109/ASE63991.2025.00145 Liang Ding University of Science and Technology of China, China dingliang@mail.ustc.edu.cn Wenzhang Yang Institute of AI for industries, China wzhyang@iaii.ac.cn Yinxing Xue Institute of AI for industries, China yxxue@iaii.ac.cn fuzzing function clustering stopping criterion Fuzzing is a testing technique that generates a large number of inputs to cause program crashes. As software development accelerates and projects scale, the demand for fuzz testing in software assurance has increased. Performing comprehensive fuzz testing on all functions has become increasingly challenging and resource-intensive. Current methods for determining when to stop fuzz testing activities rely on metrics such as function coverage, potential vulnerability function coverage or crash count. However, these metrics fail to account for the scale of the functions under test. For example, function coverage may lead to excessive testing on non-critical functions, while vulnerability function coverage can result in premature termination if the estimated number of vulnerability functions is too low. This paper introduces a novel fuzzing testing termination criterion based on function clustering. We compare our criterion with three existing methods. First, by leveraging language model for function encoding and a multi-metric fusion algorithm for determining the number of clusters, we establish a relationship between function clustering and vulnerability distribution. Second, our experiments on eight function libraries demonstrate that the proposed termination criterion significantly improves testing efficiency, reducing fuzzing time by 1.4\u20137.2 hours (5\u201330%) across different configurations while maintaining minimal bug loss (averaging 0.25 bugs), outperforming existing criteria like potential vulnerability function coverage-based approaches.",
							"pageNumber": 1730,
							"isPageNumberRoman": false
						},
						{
							"eid": "3FoEbIEp776727QHV0r4ub",
							"type": "authorPaper",
							"text": "CROSS2OH: Enabling Seamless Porting of C/C++ Software Libraries to OpenHarmony",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b743/573300b743.pdf",
							"extraLocations": [],
							"authorNames": "Qian Zhang (Northeastern University, China), Tsz-On Li (The Hong Kong University of Science and Technology, China; Guangzhou HKUST Fok Ying Tung Research Institute, China), Ying Wang (Northeastern University, China), Li Li (Beihang University, China), Shing-Chi Cheung (The Hong Kong University of Science and Technology, China; Guangzhou HKUST Fok Ying Tung Research Institute, China)",
							"abstract": "OpenHarmony is a new mobile operating system that offers a popular alternative to Android and iOS. To support its adoption, significant efforts have been devoted to porting C/C++ libraries from Linux to OpenHarmony. However, this porting process presents unique challenges due to the fundamental architectural differences in system libraries, runtime environments, and build systems between the two platforms. These discrepancies manifest as Cross-platform Incompatibility (CPI) issues during cross-compilation, which are particularly difficult to resolve for two key reasons. First, conventional cross-compilation toolchains provide only brief error messages that offer inadequate diagnostic information for CPI issues. Second, resolving these issues requires a deep understanding of cross-platform discrepancies, yet comprehensive documentation or systematic guidelines about such Linux-to-OpenHarmony differences remain largely unavailable. To assist developers in addressing these challenges, we conducted an empirical study on 92 C/C++ libraries successfully ported to OpenHarmony. Through manual step-by-step reproduction of all CPI issues, our study reveals that discrepancies between Linux and OpenHarmony can be divided into three categories, and CPI issues can manifest through eight dimensions. Furthermore, we identified eight common adaptation strategies for resolving CPI issues. Based on these findings, we present CROSS2OH, an automated technique for porting Linux-based software to OpenHarmony. Our approach combines: (1) an adaptation knowledge base (derived from RQ1 and RQ2 findings) and (2) a static analysis approach to detect and patch eight types of CPI issues. Evaluation using real developer patches shows CROSS2OH achieves 0.94 recall and 0.91 precision in resolving CPI issues. Notably, CROSS2OH enables successful cross-compilation for 40 critical libraries (including dependencies for popular Android apps such as WeChat, Microsoft Excel), with 29 of them passed OpenHarmony review. The evaluation results demonstrate CROSS2OH's potential to streamline the porting process and foster the growth of the OpenHarmony software ecosystem.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 CROSS2OH: Enabling Seamless Porting of C/C++ Software Libraries to OpenHarmony 1759500766132 10.1109/ASE63991.2025.00146 Qian Zhang Northeastern University, China 2371418@stu.neu.edu.cn Tsz-On Li The Hong Kong University of Science and Technology, China; Guangzhou HKUST Fok Ying Tung Research Institute, China toli@connect.ust.hk Ying Wang Northeastern University, China wangying@swc.neu.edu.cn Li Li Beihang University, China lilicoding@ieee.org Shing-Chi Cheung The Hong Kong University of Science and Technology, China; Guangzhou HKUST Fok Ying Tung Research Institute, China scc@cse.ust.hk openharmony software porting OpenHarmony is a new mobile operating system that offers a popular alternative to Android and iOS. To support its adoption, significant efforts have been devoted to porting C/C++ libraries from Linux to OpenHarmony. However, this porting process presents unique challenges due to the fundamental architectural differences in system libraries, runtime environments, and build systems between the two platforms. These discrepancies manifest as Cross-platform Incompatibility (CPI) issues during cross-compilation, which are particularly difficult to resolve for two key reasons. First, conventional cross-compilation toolchains provide only brief error messages that offer inadequate diagnostic information for CPI issues. Second, resolving these issues requires a deep understanding of cross-platform discrepancies, yet comprehensive documentation or systematic guidelines about such Linux-to-OpenHarmony differences remain largely unavailable. To assist developers in addressing these challenges, we conducted an empirical study on 92 C/C++ libraries successfully ported to OpenHarmony. Through manual step-by-step reproduction of all CPI issues, our study reveals that discrepancies between Linux and OpenHarmony can be divided into three categories, and CPI issues can manifest through eight dimensions. Furthermore, we identified eight common adaptation strategies for resolving CPI issues. Based on these findings, we present CROSS2OH, an automated technique for porting Linux-based software to OpenHarmony. Our approach combines: (1) an adaptation knowledge base (derived from RQ1 and RQ2 findings) and (2) a static analysis approach to detect and patch eight types of CPI issues. Evaluation using real developer patches shows CROSS2OH achieves 0.94 recall and 0.91 precision in resolving CPI issues. Notably, CROSS2OH enables successful cross-compilation for 40 critical libraries (including dependencies for popular Android apps such as WeChat, Microsoft Excel), with 29 of them passed OpenHarmony review. The evaluation results demonstrate CROSS2OH's potential to streamline the porting process and foster the growth of the OpenHarmony software ecosystem.",
							"pageNumber": 1743,
							"isPageNumberRoman": false
						},
						{
							"eid": "5ebwTnLjjxfJXtAPTOvJWH",
							"type": "authorPaper",
							"text": "HybridSIMD: A Super C++ SIMD Library with Integrated Auto-Tuning Capabilities",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b755/573300b755.pdf",
							"extraLocations": [],
							"authorNames": "Haolin Pan (Institute of Software, Chinese Academy of Sciences, China; Hangzhou Institute for Advanced Study at University of Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China), Xulin Zhou (Institute of Software, Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China), Mingjie Xing (Institute of Software, Chinese Academy of Sciences, China), Yanjun Wu (Institute of Software, Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China)",
							"abstract": "Single Instruction, Multiple Data (SIMD) technology is crucial for enhancing computational efficiency in High-Performance Computing (HPC). While C++ SIMD libraries abstract away low-level complexities, their proliferation has led to a fragmented set of libraries, creating significant challenges in both performance and usability for developers. To overcome these library-level limitations, this paper introduces a new collaborative concept for SIMD library design. We present HybridSIMD, a C++ library to embody this principle, resolving fragmentation through a unified interface and an operator-level collaborative back-end that leverages the collective strengths of existing libraries. A built-in auto-tuning engine, featuring a hierarchical search strategy, automatically navigates the rich optimization space created by this collaborative approach to deliver maximum performance without manual intervention. Experimental results across six real-world HPC benchmarks on AVX2, AVX512, and NEON architectures demonstrate HybridSIMD's superiority. Notably, the highest speedups achieved are 185.34x on AVX2, 97.80x on AVX512, and 71.32x on NEON, showcasing its effectiveness in resolving fragmentation while delivering state-of-the-art performance. Our artifact is available at https://github.com/Panhaolin2001/HybridSIMD/.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 HybridSIMD: A Super C++ SIMD Library with Integrated Auto-Tuning Capabilities 1759124335216 10.1109/ASE63991.2025.00147 Haolin Pan Institute of Software, Chinese Academy of Sciences, China; Hangzhou Institute for Advanced Study at University of Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China panhaolin21@mails.ucas.ac.cn Xulin Zhou Institute of Software, Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China zhouxulin2023@iscas.ac.cn Mingjie Xing Institute of Software, Chinese Academy of Sciences, China mingjie@iscas.ac.cn Yanjun Wu Institute of Software, Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China yanjun@iscas.ac.cn Single Instruction, Multiple Data (SIMD) technology is crucial for enhancing computational efficiency in High-Performance Computing (HPC). While C++ SIMD libraries abstract away low-level complexities, their proliferation has led to a fragmented set of libraries, creating significant challenges in both performance and usability for developers. To overcome these library-level limitations, this paper introduces a new collaborative concept for SIMD library design. We present HybridSIMD, a C++ library to embody this principle, resolving fragmentation through a unified interface and an operator-level collaborative back-end that leverages the collective strengths of existing libraries. A built-in auto-tuning engine, featuring a hierarchical search strategy, automatically navigates the rich optimization space created by this collaborative approach to deliver maximum performance without manual intervention. Experimental results across six real-world HPC benchmarks on AVX2, AVX512, and NEON architectures demonstrate HybridSIMD's superiority. Notably, the highest speedups achieved are 185.34x on AVX2, 97.80x on AVX512, and 71.32x on NEON, showcasing its effectiveness in resolving fragmentation while delivering state-of-the-art performance. Our artifact is available at https://github.com/Panhaolin2001/HybridSIMD/.",
							"pageNumber": 1755,
							"isPageNumberRoman": false
						},
						{
							"eid": "2OiEbLL80Ihtc9HfiFeYWD",
							"type": "authorPaper",
							"text": "Demystifying Cross-Language C/C++ Binaries: A Robust Software Component Analysis Approach",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b767/573300b767.pdf",
							"extraLocations": [],
							"authorNames": "Meiqiu Xu (Northeastern University, China), Ying Wang (Northeastern University, China), Wei Tang (Huawei Technologies Co., Ltd., China), Xian Zhan (Huawei Technologies Co., Ltd., China), Shing-Chi Cheung (The Hong Kong University of Science and Technology, China), Hai Yu (Northeastern University, China), Zhiliang Zhu (Northeastern University, China)",
							"abstract": "Binary Software Composition Analysis (BSCA) is a technique for identifying the versions of third-party libraries (TPLs) used in compiled binaries, thereby tracing the dependencies and vulnerabilities of software components without access to their source code. However, existing BSCA techniques struggle with cross-language invoked C/C++ binaries in polyglot projects due to two key challenges: (1) interference from heterogeneous Foreign Function Interface (FFI) bindings that obscure distinctive TPL features and generate false positives during matching processes, and (2) the inherent complexity of composite binaries (fused binaries), particularly prevalent in polyglot development where multiple TPLs are frequently compiled into single executable units, resulting in blurred boundaries between libraries and substantially compromising version identification precision. We propose DeeperBin, a BSCA technique that addresses these challenges through a high-quality, large-scale feature database with four key advantages: (1) high scalability that is capable of analyzing 74,647 C/C++ TPL versions, (2) efficient noise filtering to remove FFI bindings and common functions, (3) automated extraction of version string regexes for 31,855 TPL versions, and (4) generation of distinctive version features using the Minimum Description Length (MDL) principle. Evaluated on 418 cross-language binaries, DeeperBin achieves 81.2% precision and 84.6% recall for TPL detection, outperforming state-of-the-art (SOTA) techniques by 14.1% and 23.2%, respectively. For version identification, it achieves 70.3% precision, a 12.6% improvement over state-of-the-art techniques. Ablation studies confirm the usefulness of FFI filtering and MDL-based features, boosting precision and recall by 17.1% and 18.8%. DeeperBin also maintains competitive efficiency, processing binaries in 364.3 seconds while supporting the largest feature database.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Demystifying Cross-Language C/C++ Binaries: A Robust Software Component Analysis Approach 1758425725887 10.1109/ASE63991.2025.00148 Meiqiu Xu Northeastern University, China xumeiqiu@outlook.com Ying Wang Northeastern University, China wangying@swc.neu.edu.cn Wei Tang Huawei Technologies Co., Ltd., China tangwei119@huawei.com Xian Zhan Huawei Technologies Co., Ltd., China zhanxian2@huawei.com Shing-Chi Cheung The Hong Kong University of Science and Technology, China scc@cse.ust.hk Hai Yu Northeastern University, China yuhai@mail.neu.edu.cn Zhiliang Zhu Northeastern University, China zhuzhiliang_neu@163.com Binary Software Composition Analysis Third Party Libraries Polyglot Projects Binary Software Composition Analysis (BSCA) is a technique for identifying the versions of third-party libraries (TPLs) used in compiled binaries, thereby tracing the dependencies and vulnerabilities of software components without access to their source code. However, existing BSCA techniques struggle with cross-language invoked C/C++ binaries in polyglot projects due to two key challenges: (1) interference from heterogeneous Foreign Function Interface (FFI) bindings that obscure distinctive TPL features and generate false positives during matching processes, and (2) the inherent complexity of composite binaries (fused binaries), particularly prevalent in polyglot development where multiple TPLs are frequently compiled into single executable units, resulting in blurred boundaries between libraries and substantially compromising version identification precision. We propose DeeperBin, a BSCA technique that addresses these challenges through a high-quality, large-scale feature database with four key advantages: (1) high scalability that is capable of analyzing 74,647 C/C++ TPL versions, (2) efficient noise filtering to remove FFI bindings and common functions, (3) automated extraction of version string regexes for 31,855 TPL versions, and (4) generation of distinctive version features using the Minimum Description Length (MDL) principle. Evaluated on 418 cross-language binaries, DeeperBin achieves 81.2% precision and 84.6% recall for TPL detection, outperforming state-of-the-art (SOTA) techniques by 14.1% and 23.2%, respectively. For version identification, it achieves 70.3% precision, a 12.6% improvement over state-of-the-art techniques. Ablation studies confirm the usefulness of FFI filtering and MDL-based features, boosting precision and recall by 17.1% and 18.8%. DeeperBin also maintains competitive efficiency, processing binaries in 364.3 seconds while supporting the largest feature database.",
							"pageNumber": 1767,
							"isPageNumberRoman": false
						},
						{
							"eid": "1thUnUpRmDPDkG6aq9dbT1",
							"type": "authorPaper",
							"text": "Detecting Various DeFi Price Manipulations with LLM Reasoning",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b780/573300b780.pdf",
							"extraLocations": [],
							"authorNames": "Juantao Zhong (Lingnan University, China), Daoyuan Wu (Lingnan University, China), Ye Liu (Singapore Management University, Singapore), Maoyi Xie (Nanyang Technological University, Singapore), Yang Liu (Nanyang Technological University, Singapore), Yi Li (Nanyang Technological University, Singapore), Ning Liu (City University of Hong Kong, China)",
							"abstract": "DeFi (Decentralized Finance) is one of the most important applications of today's cryptocurrencies and smart contracts. It manages hundreds of billions in Total Value Locked (TVL) on-chain, yet it remains susceptible to common DeFi price manipulation attacks. Despite state-of-the-art (SOTA) systems like DeFiRanger and DeFort, we found that they are less effective to non-standard price models in custom DeFi protocols, which account for 44.2% of the 95 DeFi price manipulation attacks reported over the past three years. In this paper, we introduce the first LLM-based approach, DeFiScope, for detecting DeFi price manipulation attacks in both standard and custom price models. Our insight is that large language models (LLMs) have certain intelligence to abstract price calculation from code and infer the trend of token price changes based on the extracted price models. To further strengthen LLMs in this aspect, we leverage Foundry to synthesize on-chain data and use it to fine-tune a DeFi price specific LLM. Together with the high-level DeFi operations recovered from low-level transaction data, DeFiScope detects various DeFi price manipulations according to systematically mined patterns. Experimental results show that DeFiScope achieves a high precision of 96% and a recall rate of 80%, significantly outperforming SOTA approaches. Moreover, we evaluate DeFiScope's cost-effectiveness and demonstrate its practicality by helping our industry partner confirm 147 real-world price manipulation attacks, including discovering 81 previously unknown historical incidents.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Detecting Various DeFi Price Manipulations with LLM Reasoning 1759163093069 10.1109/ASE63991.2025.00149 Juantao Zhong Lingnan University, China ericzhong@ln.edu.hk Daoyuan Wu Lingnan University, China daoyuanwu@ln.edu.hk Ye Liu Singapore Management University, Singapore yeliu@smu.edu.sg Maoyi Xie Nanyang Technological University, Singapore maoyi001@e.ntu.edu.sg Yang Liu Nanyang Technological University, Singapore yangliu@ntu.edu.sg Yi Li Nanyang Technological University, Singapore yi_li@ntu.edu.sg Ning Liu City University of Hong Kong, China ninliu@cityu.edu.hk large language model smart contract defi price manipulation vulnerability detection DeFi (Decentralized Finance) is one of the most important applications of today's cryptocurrencies and smart contracts. It manages hundreds of billions in Total Value Locked (TVL) on-chain, yet it remains susceptible to common DeFi price manipulation attacks. Despite state-of-the-art (SOTA) systems like DeFiRanger and DeFort, we found that they are less effective to non-standard price models in custom DeFi protocols, which account for 44.2% of the 95 DeFi price manipulation attacks reported over the past three years. In this paper, we introduce the first LLM-based approach, DeFiScope, for detecting DeFi price manipulation attacks in both standard and custom price models. Our insight is that large language models (LLMs) have certain intelligence to abstract price calculation from code and infer the trend of token price changes based on the extracted price models. To further strengthen LLMs in this aspect, we leverage Foundry to synthesize on-chain data and use it to fine-tune a DeFi price specific LLM. Together with the high-level DeFi operations recovered from low-level transaction data, DeFiScope detects various DeFi price manipulations according to systematically mined patterns. Experimental results show that DeFiScope achieves a high precision of 96% and a recall rate of 80%, significantly outperforming SOTA approaches. Moreover, we evaluate DeFiScope's cost-effectiveness and demonstrate its practicality by helping our industry partner confirm 147 real-world price manipulation attacks, including discovering 81 previously unknown historical incidents.",
							"pageNumber": 1780,
							"isPageNumberRoman": false
						},
						{
							"eid": "6QPGDLn2Vy9EJwOvec9hcq",
							"type": "authorPaper",
							"text": "Multi-Dimensional Assessment of Crowdsourced Testing Reports via LLMs",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b793/573300b793.pdf",
							"extraLocations": [],
							"authorNames": "Yue Wang (Nanjing University, China), Yuan Zhao (Nanjing University, China), Shengcheng Yu (Technical University of Munich, Germany), Zhenyu Chen (Nanjing University, China)",
							"abstract": "Crowdsourced testing can markedly enhance test coverage and the discovery rate of potential defects compared to traditional software testing, making it increasingly popular. However, with the widespread use of crowdsourced testing, more and more crowdworkers from various backgrounds are submitting a large number of testing reports to crowdsourced testing platforms, which hinders developers from effectively reviewing the reports. Facing a vast amount of reports with varying quality, manual review is not only time-consuming and labor-intensive but also increases costs. Therefore, how to efficiently review crowdsourced testing reports has become a major challenge. To address this challenge, we propose a multi-dimensional assessment method for crowdsourced testing reports based on large language models. This method not only inherits the textuality dimension widely used in traditional report assessment but also innovatively introduces two new dimensions: adequacy and competitiveness. It comprehensively assesses the quality of crowdsourced testing reports from multiple perspectives, aiming to better screen for high-quality crowdsourced testing reports. Through experimental analysis conducted on three different applications, we have proven the consistency of our method with human raters across various dimensions, and we have also observed an enhancement in the efficiency of report assessment.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Multi-Dimensional Assessment of Crowdsourced Testing Reports via LLMs 1759412463236 10.1109/ASE63991.2025.00150 Yue Wang Nanjing University, China yue_wang@smail.nju.edu.cn Yuan Zhao Nanjing University, China zhaoyuan@nju.edu.cn Shengcheng Yu Technical University of Munich, Germany shengcheng.yu@tum.de Zhenyu Chen Nanjing University, China zychen@nju.edu.cn crowdsourced testing report assessment llm-as-a-judge large language models autograding Crowdsourced testing can markedly enhance test coverage and the discovery rate of potential defects compared to traditional software testing, making it increasingly popular. However, with the widespread use of crowdsourced testing, more and more crowdworkers from various backgrounds are submitting a large number of testing reports to crowdsourced testing platforms, which hinders developers from effectively reviewing the reports. Facing a vast amount of reports with varying quality, manual review is not only time-consuming and labor-intensive but also increases costs. Therefore, how to efficiently review crowdsourced testing reports has become a major challenge. To address this challenge, we propose a multi-dimensional assessment method for crowdsourced testing reports based on large language models. This method not only inherits the textuality dimension widely used in traditional report assessment but also innovatively introduces two new dimensions: adequacy and competitiveness. It comprehensively assesses the quality of crowdsourced testing reports from multiple perspectives, aiming to better screen for high-quality crowdsourced testing reports. Through experimental analysis conducted on three different applications, we have proven the consistency of our method with human raters across various dimensions, and we have also observed an enhancement in the efficiency of report assessment.",
							"pageNumber": 1793,
							"isPageNumberRoman": false
						},
						{
							"eid": "4noYoKsoR9Q25q5ty0Ac7l",
							"type": "authorPaper",
							"text": "ARG: Testing Query Rewriters via Abstract Rule Guided Fuzzing",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b806/573300b806.pdf",
							"extraLocations": [],
							"authorNames": "Dawei Li (Beihang University, China), Yuxiao Guo (Beihang University, China), Qifan Liu (Beihang University, China), Jie Liang (Beihang University, China), Zhiyong Wu (Tsinghua University, China), Jingzhou Fu (Tsinghua University, China), Chi Zhang ( Tsinghua University, China), Yu Jiang (Tsinghua University, China)",
							"abstract": "Query rewriters transform a query into a more efficient yet semantically equivalent form, which is vital for optimizing query execution. Despite its importance, query rewriting is inherently complex, influenced by factors including rewrite rule design, rule interactions, and semantic preservation. Consequently, its implementation struggles to prevent problems, which may result in system crashes or incorrect query results. Existing DBMS testing approaches are generally designed for broad bug detection. However, due to the diversity of rewrite rules, they cover only a limited subset of rewrite scenarios, potentially overlooking critical bugs. In this paper, we propose Abstract Rule Guided (ARG) fuzzing to detect bugs in query rewrites. The key idea is to use feedback from abstract rules to guide query generation, thereby activating more rewriting logic and enhancing bug detection. Abstract rules provide a unified representation of the patterns (e.g., AST structures and related constraints) that trigger rewrites, as well as the resulting transformations. We track abstract rules to identify which patterns have been covered. This feedback is then used to dynamically adjust query generation, prioritizing unexplored patterns to avoid redundancy and expose more rewriting logic. We implemented ARG to test four popular query rewrites, namely Calcite, WeTune, SQLSolver, and LearnedRewrite. ARG discovered 38 previously unknown bugs, consisting of 4 crashes, 13 invalid SQL outputs, and 21 semantic deviations. Among them, 19 have been confirmed, while the remaining cases are still under investigation. We also compared ARG against popular DBMS testing tools. In 24 hours, ARG triggered 76% and 1017% more written rules, triggered 13 and 15 more bugs than SQLsmith and SQLancer, respectively.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 ARG: Testing Query Rewriters via Abstract Rule Guided Fuzzing 1758813033916 10.1109/ASE63991.2025.00151 Dawei Li Beihang University, China lidawei@buaa.edu.cn Yuxiao Guo Beihang University, China yuxiaoguo@buaa.edu.cn Qifan Liu Beihang University, China imchifan@buaa.edu.cn Jie Liang Beihang University, China liangjie.mailbox.cn@gmail.com Zhiyong Wu Tsinghua University, China 253540651@qq.com Jingzhou Fu Tsinghua University, China fuboat@outlook.com Chi Zhang Tsinghua University, China chi-zhang@mail.tsinghua.edu.cn Yu Jiang Tsinghua University, China jiangyu198964@126.com query rewriter rule feedback bug detection Query rewriters transform a query into a more efficient yet semantically equivalent form, which is vital for optimizing query execution. Despite its importance, query rewriting is inherently complex, influenced by factors including rewrite rule design, rule interactions, and semantic preservation. Consequently, its implementation struggles to prevent problems, which may result in system crashes or incorrect query results. Existing DBMS testing approaches are generally designed for broad bug detection. However, due to the diversity of rewrite rules, they cover only a limited subset of rewrite scenarios, potentially overlooking critical bugs. In this paper, we propose Abstract Rule Guided (ARG) fuzzing to detect bugs in query rewrites. The key idea is to use feedback from abstract rules to guide query generation, thereby activating more rewriting logic and enhancing bug detection. Abstract rules provide a unified representation of the patterns (e.g., AST structures and related constraints) that trigger rewrites, as well as the resulting transformations. We track abstract rules to identify which patterns have been covered. This feedback is then used to dynamically adjust query generation, prioritizing unexplored patterns to avoid redundancy and expose more rewriting logic. We implemented ARG to test four popular query rewrites, namely Calcite, WeTune, SQLSolver, and LearnedRewrite. ARG discovered 38 previously unknown bugs, consisting of 4 crashes, 13 invalid SQL outputs, and 21 semantic deviations. Among them, 19 have been confirmed, while the remaining cases are still under investigation. We also compared ARG against popular DBMS testing tools. In 24 hours, ARG triggered 76% and 1017% more written rules, triggered 13 and 15 more bugs than SQLsmith and SQLancer, respectively.",
							"pageNumber": 1806,
							"isPageNumberRoman": false
						},
						{
							"eid": "28u6nJGKosgranMaeLPcAc",
							"type": "authorPaper",
							"text": "On the (In)Security of Non-Resettable Device Identifiers in Custom Android Systems",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b818/573300b818.pdf",
							"extraLocations": [],
							"authorNames": "Zikan Dong (Huazhong University of Science and Technology, China), Liu Wang (Huazhong University of Science and Technology, China), Guoai Xu (Harbin Institute of Technology, China), Haoyu Wang (Huazhong University of Science and Technology, China)",
							"abstract": "User tracking is critical in the mobile ecosystem and relies on device identifiers to build user profiles. Early versions of Android allowed third-party apps to easily access non-resettable identifiers such as serial numbers and IMEI. As privacy concerns grew, Google has tightened identifier access in native Android. In response, stakeholders in custom Android systems introduced covert channels (e.g., system properties and settings) to maintain consistent and stable identifier access across systems and devices, which undoubtedly increases privacy risks. This paper examines the introduction of such channels through system customization and their vulnerability due to poor access control. We present IDRadar, a scalable and accurate approach for identifying vulnerable properties and settings in custom Android systems. Applying our approach to 1,814 custom ROMs, we identified 8,192 system properties and 3,620 settings that store non-resettable device identifiers. Among these, 3,477 properties and 1,336 settings lack adequate access control and could be exploited by third-party apps to track users without permissions. Further validation on real devices demonstrates the effectiveness of our approach. Compared to state-of-the-art, IDRadar offers improved scalability and analytical capabilities. Additionally, we investigate the root causes of the access control deficiencies and observe that such vulnerabilities frequently recur across devices from the same OEMs. We have reported our findings to the respective vendors and received positive confirmations. Our work underscores the need for greater scrutiny of covert access to device identifiers and better solutions to safeguard user privacy during system customizations.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 On the (In)Security of Non-Resettable Device Identifiers in Custom Android Systems 1759544193804 10.1109/ASE63991.2025.00152 Zikan Dong Huazhong University of Science and Technology, China zikandong@hust.edu.cn Liu Wang Huazhong University of Science and Technology, China wwillow324@gmail.com Guoai Xu Harbin Institute of Technology, China xga@hit.edu.cn Haoyu Wang Huazhong University of Science and Technology, China haoyuwang@hust.edu.cn device identifiers android security privacy User tracking is critical in the mobile ecosystem and relies on device identifiers to build user profiles. Early versions of Android allowed third-party apps to easily access non-resettable identifiers such as serial numbers and IMEI. As privacy concerns grew, Google has tightened identifier access in native Android. In response, stakeholders in custom Android systems introduced covert channels (e.g., system properties and settings) to maintain consistent and stable identifier access across systems and devices, which undoubtedly increases privacy risks. This paper examines the introduction of such channels through system customization and their vulnerability due to poor access control. We present IDRadar, a scalable and accurate approach for identifying vulnerable properties and settings in custom Android systems. Applying our approach to 1,814 custom ROMs, we identified 8,192 system properties and 3,620 settings that store non-resettable device identifiers. Among these, 3,477 properties and 1,336 settings lack adequate access control and could be exploited by third-party apps to track users without permissions. Further validation on real devices demonstrates the effectiveness of our approach. Compared to state-of-the-art, IDRadar offers improved scalability and analytical capabilities. Additionally, we investigate the root causes of the access control deficiencies and observe that such vulnerabilities frequently recur across devices from the same OEMs. We have reported our findings to the respective vendors and received positive confirmations. Our work underscores the need for greater scrutiny of covert access to device identifiers and better solutions to safeguard user privacy during system customizations.",
							"pageNumber": 1818,
							"isPageNumberRoman": false
						},
						{
							"eid": "1Sl3bBuPNAG2rB7K0qzQey",
							"type": "authorPaper",
							"text": "PEACE: Towards Efficient Project-Level Efficiency Optimization via Hybrid Code Editing",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b830/573300b830.pdf",
							"extraLocations": [],
							"authorNames": "Xiaoxue Ren (Zhejiang University, China), Jun Wan (Zhejiang University, China), Yun Peng (The Chinese University of Hong Kong, China), Zhongxin Liu (Zhejiang University, China), Ming Liang (Ant Group, China), Dajun Chen (Ant Group, China), Wei Jiang (Ant Group, China), Yong Li (Ant Group, China)",
							"abstract": "Large Language Models (LLMs) have demonstrated significant capability in code generation, but their potential in code efficiency optimization remains underexplored. Previous LLM-based code efficiency optimization approaches exclusively focus on function-level optimization and overlook interaction between functions, failing to generalize to real-world development scenarios. Code editing techniques show great potential for conducting project-level optimization, yet they face challenges associated with invalid edits and suboptimal internal functions. To address these gaps, we propose PEACE, a novel hybrid framework for Project-level code Efficiency optimization through Automatic Code Editing, which also ensures the overall correctness and integrity of the project. PEACE integrates three key phases: dependency-aware optimizing function sequence construction, valid associated edits identification, and efficiency optimization editing iteration. To rigorously evaluate the effectiveness of PEACE, we construct PEACExec, the first benchmark comprising 146 real-world optimization tasks from 47 high-impact GitHub Python projects, along with highly qualified test cases and executable environments. Extensive experiments demonstrate PEACE's superiority over the state-of-the-art baselines, achieving a 69.2% correctness rate (pass@1), +46.9% opt rate, and 0.840 speedup in execution efficiency. Notably, our PEACE outperforms all baselines by significant margins, particularly in complex optimization tasks with multiple functions. Moreover, extensive experiments are also conducted to validate the contributions of each component in PEACE, as well as the rationale and effectiveness of our hybrid framework design.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 PEACE: Towards Efficient Project-Level Efficiency Optimization via Hybrid Code Editing 1759506395955 10.1109/ASE63991.2025.00153 Xiaoxue Ren Zhejiang University, China xxren@zju.edu.cn Jun Wan Zhejiang University, China 22451014@zju.edu.cn Yun Peng The Chinese University of Hong Kong, China ypeng@cse.cuhk.edu.hk Zhongxin Liu Zhejiang University, China liu_zx@zju.edu.cn Ming Liang Ant Group, China liangming.liang@antgroup.com Dajun Chen Ant Group, China chendajun.cdj@antgroup.com Wei Jiang Ant Group, China jonny.jw@antgroup.com Yong Li Ant Group, China liyong.liy@antgroup.com code optimization code editing large language model Large Language Models (LLMs) have demonstrated significant capability in code generation, but their potential in code efficiency optimization remains underexplored. Previous LLM-based code efficiency optimization approaches exclusively focus on function-level optimization and overlook interaction between functions, failing to generalize to real-world development scenarios. Code editing techniques show great potential for conducting project-level optimization, yet they face challenges associated with invalid edits and suboptimal internal functions. To address these gaps, we propose PEACE, a novel hybrid framework for Project-level code Efficiency optimization through Automatic Code Editing, which also ensures the overall correctness and integrity of the project. PEACE integrates three key phases: dependency-aware optimizing function sequence construction, valid associated edits identification, and efficiency optimization editing iteration. To rigorously evaluate the effectiveness of PEACE, we construct PEACExec, the first benchmark comprising 146 real-world optimization tasks from 47 high-impact GitHub Python projects, along with highly qualified test cases and executable environments. Extensive experiments demonstrate PEACE's superiority over the state-of-the-art baselines, achieving a 69.2% correctness rate (pass@1), +46.9% opt rate, and 0.840 speedup in execution efficiency. Notably, our PEACE outperforms all baselines by significant margins, particularly in complex optimization tasks with multiple functions. Moreover, extensive experiments are also conducted to validate the contributions of each component in PEACE, as well as the rationale and effectiveness of our hybrid framework design.",
							"pageNumber": 1830,
							"isPageNumberRoman": false
						},
						{
							"eid": "7e5gDrCzBSLUwSNUUfpDZX",
							"type": "authorPaper",
							"text": "MCTS-Refined CoT: High-Quality Fine-Tuning Data for LLM-Based Repository Issue Resolution",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b843/573300b843.pdf",
							"extraLocations": [],
							"authorNames": "Yibo Wang (Northeastern University, China), Zhihao Peng (Northeastern University, China), Ying Wang (Northeastern University, China), Zhao Wei (Tencent, China), Hai Yu (Northeastern University, China), Zhiliang Zhu (Northeastern University, China)",
							"abstract": "LLMs demonstrate strong performance in automated software engineering, particularly for code generation and issue resolution. While proprietary models like GPT-4o achieve high benchmarks scores on SWE-bench, their API dependence, cost, and privacy concerns limit adoption. Open-source alternatives offer transparency but underperform in complex tasks, especially sub-100B parameter models. Although quality Chain-of-Thought (CoT) data can enhance reasoning, current methods face two critical flaws: (1) weak rejection sampling reduces data quality, and (2) inadequate step validation causes error accumulation. These limitations lead to flawed reasoning chains that impair LLMs' ability to learn reliable issue resolution. The paper proposes MCTS-Refine, an enhanced Monte Carlo Tree Search (MCTS)-based algorithm that dynamically validates and optimizes intermediate reasoning steps through a rigorous rejection sampling strategy, generating high-quality CoT data to improve LLM performance in issue resolution tasks. Key innovations include: (1) augmenting MCTS with a reflection mechanism that corrects errors via rejection sampling and refinement, (2) decomposing issue resolution into three subtasks\u2014File Localization, Fault Localization, and Patch Generation\u2014each with clear ground-truth criteria, and (3) enforcing a strict sampling protocol where intermediate outputs must exactly match verified developer patches, ensuring correctness across reasoning paths. Experiments on SWE-bench Lite and SWE-bench Verified demonstrate that LLMs fine-tuned with our CoT dataset achieve substantial improvements over baselines. Notably, Qwen2.5-72B-Instruct achieves black 28.3%(Lite) and black 35.0%(Verified) resolution rates, surpassing SOTA baseline SWE-Fixer-Qwen-72B with the same parameter scale, which only reached black 24.7%(Lite) and black 32.8%(Verified). Given precise issue locations as input, our fine-tuned Qwen2.5-72B-Instruct model achieves an impressive issue resolution rate of 43.8%(Verified), comparable to the performance of Deepseek-v3. We open-source our MCTS-Refine framework, CoT dataset, and fine-tuned models to advance research in AI-driven software engineering.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 MCTS-Refined CoT: High-Quality Fine-Tuning Data for LLM-Based Repository Issue Resolution 1759333033740 10.1109/ASE63991.2025.00154 Yibo Wang Northeastern University, China yibowangcz@outlook.com Zhihao Peng Northeastern University, China 2471378@stu.neu.edu.cn Ying Wang Northeastern University, China wangying@swc.neu.edu.cn Zhao Wei Tencent, China zachwei@tencent.com Hai Yu Northeastern University, China yuhai@mail.neu.edu.cn Zhiliang Zhu Northeastern University, China ZHUZhiLiang_NEU@163.com MCTS CoT Fine-Tuning Issue Resolution LLMs demonstrate strong performance in automated software engineering, particularly for code generation and issue resolution. While proprietary models like GPT-4o achieve high benchmarks scores on SWE-bench, their API dependence, cost, and privacy concerns limit adoption. Open-source alternatives offer transparency but underperform in complex tasks, especially sub-100B parameter models. Although quality Chain-of-Thought (CoT) data can enhance reasoning, current methods face two critical flaws: (1) weak rejection sampling reduces data quality, and (2) inadequate step validation causes error accumulation. These limitations lead to flawed reasoning chains that impair LLMs' ability to learn reliable issue resolution. The paper proposes MCTS-Refine, an enhanced Monte Carlo Tree Search (MCTS)-based algorithm that dynamically validates and optimizes intermediate reasoning steps through a rigorous rejection sampling strategy, generating high-quality CoT data to improve LLM performance in issue resolution tasks. Key innovations include: (1) augmenting MCTS with a reflection mechanism that corrects errors via rejection sampling and refinement, (2) decomposing issue resolution into three subtasks\u2014File Localization, Fault Localization, and Patch Generation\u2014each with clear ground-truth criteria, and (3) enforcing a strict sampling protocol where intermediate outputs must exactly match verified developer patches, ensuring correctness across reasoning paths. Experiments on SWE-bench Lite and SWE-bench Verified demonstrate that LLMs fine-tuned with our CoT dataset achieve substantial improvements over baselines. Notably, Qwen2.5-72B-Instruct achieves black 28.3%(Lite) and black 35.0%(Verified) resolution rates, surpassing SOTA baseline SWE-Fixer-Qwen-72B with the same parameter scale, which only reached black 24.7%(Lite) and black 32.8%(Verified). Given precise issue locations as input, our fine-tuned Qwen2.5-72B-Instruct model achieves an impressive issue resolution rate of 43.8%(Verified), comparable to the performance of Deepseek-v3. We open-source our MCTS-Refine framework, CoT dataset, and fine-tuned models to advance research in AI-driven software engineering.",
							"pageNumber": 1843,
							"isPageNumberRoman": false
						},
						{
							"eid": "436FF3CgkOmbc8DIQT5gFb",
							"type": "authorPaper",
							"text": "Can Mamba Be Better? An Experimental Evaluation of Mamba in Code Intelligence",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b855/573300b855.pdf",
							"extraLocations": [],
							"authorNames": "Shuo Liu (City University of Hong Kong, China), Jacky Keung (City University of Hong Kong, China), Zhen Yang (Shandong University, China), Zhenyu Mao (City University of Hong Kong, China), Yicheng Sun (City University of Hong Kong, China)",
							"abstract": "The Transformer architecture and its core attention mechanism form the foundation of Pre-trained Language Models (PLMs) and have driven their remarkable progress across a wide range of code intelligence tasks. However, the quadratic complexity inherent in the attention mechanism poses scalability challenges. Recently, sub-quadratic architectures such as Mamba and Mamba-2 have emerged as compelling alternatives to the Transformer. While they have shown promising results and attracted increasing academic interest, their effectiveness in code intelligence tasks has not yet been fully explored. To fill this gap, we present the first systematic empirical study of Mamba-based PLMs on three typical code tasks (i.e., code completion, code generation, and code clone detection), covering both the code comprehension and generation categories to delve into their effectiveness and efficiency. We first pre-train two Mamba-based PLMs on code based on Mamba and Mamba-2, respectively. Subsequently, we evaluate these four PLMs against typical Transformer-based PLMs (e.g., CodeGPT) with Full fine-Tuning (FT) and Parameter-Efficient Fine-Tuning (PEFT) settings, demonstrating the overall superiority of Mamba-based PLMs across all code tasks. Subsequent experiments involve the architecture analysis via pre-training from scratch to isolate the influence of the training corpora and low-resource analysis via deliberately limiting the fine-tuning data volume. All demonstrate the superiority of Mamba-based PLMs in both efficacy and efficiency. Finally, we also extend the sizes of PLMs to larger scales (7B at most) and make comparisons with more diverse PLMs/LLMs. Experimental results demonstrate that pre-training corpora and tasks also heavily affect the code modeling performance, apart from architectures. This work provides a comprehensive investigation into Mamba-based PLMs in the context of code intelligence, uncovering their strengths, limitations, and potential for future applications.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Can Mamba Be Better? An Experimental Evaluation of Mamba in Code Intelligence 1759498191367 10.1109/ASE63991.2025.00155 Shuo Liu City University of Hong Kong, China sliu273-c@my.cityu.edu.hk Jacky Keung City University of Hong Kong, China jacky.keung@cityu.edu.hk Zhen Yang Shandong University, China zhenyang@sdu.edu.cn Zhenyu Mao City University of Hong Kong, China zhenyumao2-c@my.cityu.edu.hk Yicheng Sun City University of Hong Kong, China yicsun2-c@my.cityu.edu.hk code language models transformer mamba parameter-efficient fine-tuning The Transformer architecture and its core attention mechanism form the foundation of Pre-trained Language Models (PLMs) and have driven their remarkable progress across a wide range of code intelligence tasks. However, the quadratic complexity inherent in the attention mechanism poses scalability challenges. Recently, sub-quadratic architectures such as Mamba and Mamba-2 have emerged as compelling alternatives to the Transformer. While they have shown promising results and attracted increasing academic interest, their effectiveness in code intelligence tasks has not yet been fully explored. To fill this gap, we present the first systematic empirical study of Mamba-based PLMs on three typical code tasks (i.e., code completion, code generation, and code clone detection), covering both the code comprehension and generation categories to delve into their effectiveness and efficiency. We first pre-train two Mamba-based PLMs on code based on Mamba and Mamba-2, respectively. Subsequently, we evaluate these four PLMs against typical Transformer-based PLMs (e.g., CodeGPT) with Full fine-Tuning (FT) and Parameter-Efficient Fine-Tuning (PEFT) settings, demonstrating the overall superiority of Mamba-based PLMs across all code tasks. Subsequent experiments involve the architecture analysis via pre-training from scratch to isolate the influence of the training corpora and low-resource analysis via deliberately limiting the fine-tuning data volume. All demonstrate the superiority of Mamba-based PLMs in both efficacy and efficiency. Finally, we also extend the sizes of PLMs to larger scales (7B at most) and make comparisons with more diverse PLMs/LLMs. Experimental results demonstrate that pre-training corpora and tasks also heavily affect the code modeling performance, apart from architectures. This work provides a comprehensive investigation into Mamba-based PLMs in the context of code intelligence, uncovering their strengths, limitations, and potential for future applications.",
							"pageNumber": 1855,
							"isPageNumberRoman": false
						},
						{
							"eid": "5BpMEaJIUgIPbrjBJD42xf",
							"type": "authorPaper",
							"text": "ORFUZZ: Fuzzing the \"Other Side\" of LLM Safety \u2013 Testing Over-Refusal",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b868/573300b868.pdf",
							"extraLocations": [],
							"authorNames": "Haonan Zhang (Zhejiang University, China), Dongxia Wang (Zhejiang University, China), Yi Liu (Quantstamp, Singapore), Kexin Chen (Zhejiang University, China), Jiashui Wang (Zhejiang University, China), Xinlei Ying (n/a), Long Liu (n/a), Wenhai Wang (Zhejiang University, China)",
							"abstract": "Large Language Models (LLMs) have been found to show over-refusal problems-erroneously rejecting benign queries due to overly conservative safety measures-a critical functional flaw that undermines their reliability and usability. Current methods for testing this behavior are demonstrably inadequate, suffering from flawed benchmarks and limited test generation capabilities, as highlighted by our empirical user study. To the best of our knowledge, this paper introduces the first evolutionary testing framework, ORFUZZ, for the systematic detection and analysis of LLM over-refusals. ORFUZZ uniquely integrates three core components: (1) safety category-aware seed selection for comprehensive test coverage, (2) adaptive mutator optimization using reasoning LLMs to generate effective test cases, and (3) OR-JUDGE, a human-aligned judge model validated to accurately reflect user perception of toxicity and refusal. Our extensive evaluations demonstrate that ORFUZZ generates diverse, validated over-refusal instances at a rate (6.98% average) more than double that of leading baselines, effectively uncovering vulnerabilities. Furthermore, ORFUZZ's outputs form the basis of ORFUZZSET, a new benchmark of 1,786 highly transferable test cases that achieves a superior 57.37% average over-refusal rate across 14 diverse LLMs, significantly outperforming existing datasets. ORFUZZ and ORFUZZSET provide a robust automated testing framework and a valuable community resource, paving the way for developing more reliable and trustworthy LLM-based software systems. The code of this paper is available at: https://github.com/HotBento/ORFuzz.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 ORFUZZ: Fuzzing the \"Other Side\" of LLM Safety \u2013 Testing Over-Refusal 1759219573279 10.1109/ASE63991.2025.00156 Haonan Zhang Zhejiang University, China haonanzhang@zju.edu.cn Dongxia Wang Zhejiang University, China dxwang@zju.edu.cn Yi Liu Quantstamp, Singapore yi009@e.ntu.edu.sg Kexin Chen Zhejiang University, China kxchen@zju.edu.cn Jiashui Wang Zhejiang University, China 12221251@zju.edu.cn Xinlei Ying n/a xinlei.yxl@antgroup.com Long Liu n/a ll280345@antgroup.com Wenhai Wang Zhejiang University, China zdzzlab@zju.edu.cn over-refusal llm fuzz test Large Language Models (LLMs) have been found to show over-refusal problems-erroneously rejecting benign queries due to overly conservative safety measures-a critical functional flaw that undermines their reliability and usability. Current methods for testing this behavior are demonstrably inadequate, suffering from flawed benchmarks and limited test generation capabilities, as highlighted by our empirical user study. To the best of our knowledge, this paper introduces the first evolutionary testing framework, ORFUZZ, for the systematic detection and analysis of LLM over-refusals. ORFUZZ uniquely integrates three core components: (1) safety category-aware seed selection for comprehensive test coverage, (2) adaptive mutator optimization using reasoning LLMs to generate effective test cases, and (3) OR-JUDGE, a human-aligned judge model validated to accurately reflect user perception of toxicity and refusal. Our extensive evaluations demonstrate that ORFUZZ generates diverse, validated over-refusal instances at a rate (6.98% average) more than double that of leading baselines, effectively uncovering vulnerabilities. Furthermore, ORFUZZ's outputs form the basis of ORFUZZSET, a new benchmark of 1,786 highly transferable test cases that achieves a superior 57.37% average over-refusal rate across 14 diverse LLMs, significantly outperforming existing datasets. ORFUZZ and ORFUZZSET provide a robust automated testing framework and a valuable community resource, paving the way for developing more reliable and trustworthy LLM-based software systems. The code of this paper is available at: https://github.com/HotBento/ORFuzz.",
							"pageNumber": 1868,
							"isPageNumberRoman": false
						},
						{
							"eid": "4K39RuSMsQ15y0WCNbEOCN",
							"type": "authorPaper",
							"text": "Coding-Fuse: Efficient Fusion of Code Pre-Trained Models for Classification Tasks",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b880/573300b880.pdf",
							"extraLocations": [],
							"authorNames": "Yu Zhao (Nanjing University of Aeronautics and Astronautics, China; Ministry of Industry and Information Technology), Lina Gong (Nanjing University of Aeronautics and Astronautics, China; Ministry of Industry and Information Technology), Zhiqiu Huang (Nanjing University of Aeronautics and Astronautics, China; Ministry of Industry and Information Technology), Yuchen Jin (Nanjing University of Aeronautics and Astronautics, China; Key Laboratory of Brain-Machine Intelligence Technology), Mingqiang Wei (Nanjing University of Aeronautics and Astronautics, China; Key Laboratory of Brain-Machine Intelligence Technology)",
							"abstract": "Software engineering (SE) classification tasks play a vital role in improving software quality. Nevertheless, SE researchers and practitioners tend to rely on a single code pre-trained model (PTM) for downstream classification tasks. Previous studies have found that different code PTMs yield different performance in SE classification tasks, which triggers our thinking of whether the integration of multiple code PTMs improves the performance of classification tasks. Therefore, we first conduct preliminary exploratory research to analyze the impact of fusing multiple PTMs on code classification tasks. The result shows that compared to the single code PTM, the fusion of multiple code PTMs can improve the performance of SE classification tasks. However, the performance improvement also brings about the problem of increased finetuning resources and reduced application efficiency, which does not meet the greenness requirements. In order to address these issues, we propose Coding-Fuse, a framework of efficient fusion of code PTMs for SE classification tasks. Coding-Fuse first introduces evidence theory to evaluate the adaptability of the output features of each layer of code PTMs and data labels, and locates the potential best performance layer of different code PTMs. Then, Coding-Fuse uses a soft voting strategy to fuse the outputs of these layers to obtain a new model. We conduct experiments for effectiveness by comparing Coding-Fuse with the full PTM fusion method and the original single PTM using five different code PTMs on three different SE classification tasks and two task scenarios. The results show that Coding-Fuse can achieve better performance than the full PTM fusion method with higher efficiency and fewer hardware resources, and can achieve better performance than the original single PTM at the same efficiency and hardware resource level. We encourage SE practitioners to use our Coding-Fuse method in practice to fully utilize the advantages of each code PTM in the PTM repository according to task requirements to easily create new SE intelligent PTMs to achieve performance and greenness improvements.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Coding-Fuse: Efficient Fusion of Code Pre-Trained Models for Classification Tasks 1757934771632 10.1109/ASE63991.2025.00157 Yu Zhao Nanjing University of Aeronautics and Astronautics, China; Ministry of Industry and Information Technology zhao_yu@nuaa.edu.cn Lina Gong Nanjing University of Aeronautics and Astronautics, China; Ministry of Industry and Information Technology gonglina@nuaa.edu.cn Zhiqiu Huang Nanjing University of Aeronautics and Astronautics, China; Ministry of Industry and Information Technology zqhuang@nuaa.edu.cn Yuchen Jin Nanjing University of Aeronautics and Astronautics, China; Key Laboratory of Brain-Machine Intelligence Technology jin_yuchen@nuaa.edu.cn Mingqiang Wei Nanjing University of Aeronautics and Astronautics, China; Key Laboratory of Brain-Machine Intelligence Technology mqwei@nuaa.edu.cn coding-fuse code pre-trained model fusion maximum evidence layer fusion soft vote performance and greenness Software engineering (SE) classification tasks play a vital role in improving software quality. Nevertheless, SE researchers and practitioners tend to rely on a single code pre-trained model (PTM) for downstream classification tasks. Previous studies have found that different code PTMs yield different performance in SE classification tasks, which triggers our thinking of whether the integration of multiple code PTMs improves the performance of classification tasks. Therefore, we first conduct preliminary exploratory research to analyze the impact of fusing multiple PTMs on code classification tasks. The result shows that compared to the single code PTM, the fusion of multiple code PTMs can improve the performance of SE classification tasks. However, the performance improvement also brings about the problem of increased finetuning resources and reduced application efficiency, which does not meet the greenness requirements. In order to address these issues, we propose Coding-Fuse, a framework of efficient fusion of code PTMs for SE classification tasks. Coding-Fuse first introduces evidence theory to evaluate the adaptability of the output features of each layer of code PTMs and data labels, and locates the potential best performance layer of different code PTMs. Then, Coding-Fuse uses a soft voting strategy to fuse the outputs of these layers to obtain a new model. We conduct experiments for effectiveness by comparing Coding-Fuse with the full PTM fusion method and the original single PTM using five different code PTMs on three different SE classification tasks and two task scenarios. The results show that Coding-Fuse can achieve better performance than the full PTM fusion method with higher efficiency and fewer hardware resources, and can achieve better performance than the original single PTM at the same efficiency and hardware resource level. We encourage SE practitioners to use our Coding-Fuse method in practice to fully utilize the advantages of each code PTM in the PTM repository according to task requirements to easily create new SE intelligent PTMs to achieve performance and greenness improvements.",
							"pageNumber": 1880,
							"isPageNumberRoman": false
						},
						{
							"eid": "DXkWhFbBwXFMgb1HArGsq",
							"type": "authorPaper",
							"text": "Diplomatist: What Do Cross-Language Dependencies Reflect Software Ecosystem Health?",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b893/573300b893.pdf",
							"extraLocations": [],
							"authorNames": "Fanyi Meng (Shenyang University of Technology, China), Ying  Wang (Northeastern University, China), Chun Yong  Chong (Monash University Malaysia, Malaysia), Hai  Yu (Northeastern University, China), Zhiliang  Zhu ( Northeastern University, China )",
							"abstract": "In large-scale software development, multilingual projects, those involving multiple interacting programming languages, have become increasingly common in both industry and the open-source community. Research indicates that cross-language dependencies in these projects can increase the likelihood of risks, such as functionality defects and security vulnerabilities. While most existing studies focus on cross-language dependencies between host languages and specific guest languages (e.g., C/C++), interactions between host languages and a broader range of guest languages, as well as the broader impact of such dependencies on software ecosystems, remain underexplored. To address the above limitations, in this paper, we develop a technique, Diplomatist, to identify and analyze cross-language dependencies between host languages, such as Java, and guest languages, including JavaScript, Python, Ruby, PHP, and C/C++. Diplomatist automatically analyzes cross-language invocation APIs and constructs a large-scale knowledge repository to standardize code features for identifying library versions across various guest languages, enabling host languages to trace the guest language libraries they invoke. Evaluation shows that Diplomatist achieved an average precision of 88.9% and a recall of 91.5% on a high-quality benchmark, indicating its high accuracy in detecting cross-language dependencies. Using Diplomatist, we identified 435,258 Java libraries that indirectly or transitively depend on libraries from other ecosystems. Diplomatist provides a list of cross-language pivotal libraries that contribute to preserving the long-term health and sustainability of software ecosystems. Moreover, we conduct a case study to examine the impact of the risks introduced due to cross-language dependencies on programming language ecosystems, by analyzing a full-picture of the cross-language dependency graph. Our findings show that fragile projects or libraries can propagate security issues across ecosystems via these dependencies, impacting 13,739 downstream projects in the Maven ecosystem. We utilized Diplomatist to provide remediation suggestions to relevant project developers. Issue reports of some subjects have been confirmed by developers.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Diplomatist: What Do Cross-Language Dependencies Reflect Software Ecosystem Health? 1758720281758 10.1109/ASE63991.2025.00158 Fanyi Meng Shenyang University of Technology, China mengfanyineu@163.com Ying Wang Northeastern University, China wangying@swc.neu.edu.cn Chun Yong Chong Monash University Malaysia, Malaysia chong.chunyong@monash.edu Hai Yu Northeastern University, China yuhai@mail.neu.edu.cn Zhiliang Zhu Northeastern University, China zhuzhiliang_neu@163.com Cross-language Dependency Software Ecosys tem Empirical Study In large-scale software development, multilingual projects, those involving multiple interacting programming languages, have become increasingly common in both industry and the open-source community. Research indicates that cross-language dependencies in these projects can increase the likelihood of risks, such as functionality defects and security vulnerabilities. While most existing studies focus on cross-language dependencies between host languages and specific guest languages (e.g., C/C++), interactions between host languages and a broader range of guest languages, as well as the broader impact of such dependencies on software ecosystems, remain underexplored. To address the above limitations, in this paper, we develop a technique, Diplomatist, to identify and analyze cross-language dependencies between host languages, such as Java, and guest languages, including JavaScript, Python, Ruby, PHP, and C/C++. Diplomatist automatically analyzes cross-language invocation APIs and constructs a large-scale knowledge repository to standardize code features for identifying library versions across various guest languages, enabling host languages to trace the guest language libraries they invoke. Evaluation shows that Diplomatist achieved an average precision of 88.9% and a recall of 91.5% on a high-quality benchmark, indicating its high accuracy in detecting cross-language dependencies. Using Diplomatist, we identified 435,258 Java libraries that indirectly or transitively depend on libraries from other ecosystems. Diplomatist provides a list of cross-language pivotal libraries that contribute to preserving the long-term health and sustainability of software ecosystems. Moreover, we conduct a case study to examine the impact of the risks introduced due to cross-language dependencies on programming language ecosystems, by analyzing a full-picture of the cross-language dependency graph. Our findings show that fragile projects or libraries can propagate security issues across ecosystems via these dependencies, impacting 13,739 downstream projects in the Maven ecosystem. We utilized Diplomatist to provide remediation suggestions to relevant project developers. Issue reports of some subjects have been confirmed by developers.",
							"pageNumber": 1893,
							"isPageNumberRoman": false
						},
						{
							"eid": "66TextM2h8NdRHgflXg6Uo",
							"type": "authorPaper",
							"text": "Automated Detection of Web Application Navigation Barriers for Screen Reader Users",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b905/573300b905.pdf",
							"extraLocations": [],
							"authorNames": "Shubhi Jain (University of California, Irvine, USA), Syed Fatiul Huq (University of California, Irvine, USA), Ziyao He (University of California, Irvine, USA), Sam Malek (University of California, Irvine, USA)",
							"abstract": "An estimated 43.3 million people worldwide live with blindness and rely on screen readers (SRs) to access the web. To support accessible development, software teams often rely on automated tools like WAVE and Lighthouse to detect accessibility issues. However, these tools primarily rely on static rule-based analysis and are largely limited to detecting labeling errors relevant to screen reader users. They fail to capture dynamic accessibility issues\u2014specifically, whether user interface (UI) elements can be located and activated using a screen reader, which is essential for accessing core webpage functionality. To address this gap, we present A11yNavigator, an automated accessibility testing tool that simulates screen reader navigation to detect UI elements that cannot be either (1) located or (2) activated via the screen reader. A11yNavigator leverages NVDA, one of the most widely used screen readers, and supports three common navigation strategies: Tab, Arrow, and Quick Navigation keys. We evaluate A11yNavigator across 26 real-world websites and demonstrate its effectiveness in uncovering issues missed by existing tools. Our results highlight its high precision and recall in detecting barriers that go beyond static analysis.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Automated Detection of Web Application Navigation Barriers for Screen Reader Users 1759035650834 10.1109/ASE63991.2025.00159 Shubhi Jain University of California, Irvine, USA shubhij1@uci.edu Syed Fatiul Huq University of California, Irvine, USA fsyedhuq@uci.edu Ziyao He University of California, Irvine, USA ziyaoh5@uci.edu Sam Malek University of California, Irvine, USA malek@uci.edu web software accessibility software testing assistive technologies blind users An estimated 43.3 million people worldwide live with blindness and rely on screen readers (SRs) to access the web. To support accessible development, software teams often rely on automated tools like WAVE and Lighthouse to detect accessibility issues. However, these tools primarily rely on static rule-based analysis and are largely limited to detecting labeling errors relevant to screen reader users. They fail to capture dynamic accessibility issues\u2014specifically, whether user interface (UI) elements can be located and activated using a screen reader, which is essential for accessing core webpage functionality. To address this gap, we present A11yNavigator, an automated accessibility testing tool that simulates screen reader navigation to detect UI elements that cannot be either (1) located or (2) activated via the screen reader. A11yNavigator leverages NVDA, one of the most widely used screen readers, and supports three common navigation strategies: Tab, Arrow, and Quick Navigation keys. We evaluate A11yNavigator across 26 real-world websites and demonstrate its effectiveness in uncovering issues missed by existing tools. Our results highlight its high precision and recall in detecting barriers that go beyond static analysis.",
							"pageNumber": 1905,
							"isPageNumberRoman": false
						},
						{
							"eid": "swjN48oZvKmp6hMorZOpu",
							"type": "authorPaper",
							"text": "SemGuard: Real-Time Semantic Evaluator for Correcting LLM-Generated Code",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b918/573300b918.pdf",
							"extraLocations": [],
							"authorNames": "Qinglin Wang (Shandong Normal University, China), Zhihong Sun (Shandong Normal University, China), Ruyun Wang (Institute of Information Engineering, Chinese Academy of Sciences, China), Tao Huang (Shandong Normal University, China), Zhi Jin (Key Lab of HCST (PKU); SCS, China), Ge Li (Key Lab of HCST (PKU); SCS, China), Chen Lyu (Shandong Normal University, China)",
							"abstract": "Large Language Models (LLMs) can translate natural language requirements into code, yet empirical analyses of representative models reveal that semantic errors\u2014programs that compile but behave incorrectly\u2014constitute the majority of observed faults (e.g., >60% on DeepSeek-Coder-6.7B and QwenCoder-7B). Post-hoc repair pipelines detect such faults only after execution, incurring latency, relying on incomplete test suites, and often mis-localizing the defect. Since semantic drift originates in the autoregressive decoding process, intervening while the code is being generated is a direct way to stop error propagation. Constrained-decoding approaches such as ROCODE attempt this, but still wait until the entire program runs to obtain feedback and use entropy heuristics that do not truly capture semantics. A more effective solution must inject semantic signals\u2014early and precisely\u2014into the decoding process. We present SemGuard, a semantic-evaluator-driven framework that performs real-time, line-level semantic supervision. To train the evaluator, we build SemDiff, the first dataset with fine-grained annotations that mark the exact line where a correct and an incorrect implementation diverge. The evaluator, once embedded in the LLM's decoder, flags deviations on partial code, rolls back to the faulty line, and guides regeneration\u2014without executing the program or requiring test cases. Across four benchmarks, SemGuard consistently outperforms state-of-the-art baselines. It lowers the semantic error rate by 19.86% on SemDiff relative to ROCODE, and lifts Pass@1 by 48.92% on the real-world LiveCodeBench with CodeLlama-7B. Similar gains hold for StarCoder2-7B on MBPP and for DeepSeekCoder-6.7B on the Java benchmark SemDiff-Java, demonstrating model- and language-agnostic effectiveness.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 SemGuard: Real-Time Semantic Evaluator for Correcting LLM-Generated Code 1759138103112 10.1109/ASE63991.2025.00160 Qinglin Wang Shandong Normal University, China 2023317094@stu.sdnu.edu.cn Zhihong Sun Shandong Normal University, China 2022021002@stu.sdnu.edu.cn Ruyun Wang Institute of Information Engineering, Chinese Academy of Sciences, China wangruyun@iie.ac.cn Tao Huang Shandong Normal University, China 2022317095@stu.sdnu.edu.cn Zhi Jin Key Lab of HCST (PKU); SCS, China zhijin@pku.edu.cn Ge Li Key Lab of HCST (PKU); SCS, China lige@pku.edu.cn Chen Lyu Shandong Normal University, China lvchen@sdnu.edu.cn semantic supervision large language models code generation Large Language Models (LLMs) can translate natural language requirements into code, yet empirical analyses of representative models reveal that semantic errors\u2014programs that compile but behave incorrectly\u2014constitute the majority of observed faults (e.g., >60% on DeepSeek-Coder-6.7B and QwenCoder-7B). Post-hoc repair pipelines detect such faults only after execution, incurring latency, relying on incomplete test suites, and often mis-localizing the defect. Since semantic drift originates in the autoregressive decoding process, intervening while the code is being generated is a direct way to stop error propagation. Constrained-decoding approaches such as ROCODE attempt this, but still wait until the entire program runs to obtain feedback and use entropy heuristics that do not truly capture semantics. A more effective solution must inject semantic signals\u2014early and precisely\u2014into the decoding process. We present SemGuard, a semantic-evaluator-driven framework that performs real-time, line-level semantic supervision. To train the evaluator, we build SemDiff, the first dataset with fine-grained annotations that mark the exact line where a correct and an incorrect implementation diverge. The evaluator, once embedded in the LLM's decoder, flags deviations on partial code, rolls back to the faulty line, and guides regeneration\u2014without executing the program or requiring test cases. Across four benchmarks, SemGuard consistently outperforms state-of-the-art baselines. It lowers the semantic error rate by 19.86% on SemDiff relative to ROCODE, and lifts Pass@1 by 48.92% on the real-world LiveCodeBench with CodeLlama-7B. Similar gains hold for StarCoder2-7B on MBPP and for DeepSeekCoder-6.7B on the Java benchmark SemDiff-Java, demonstrating model- and language-agnostic effectiveness.",
							"pageNumber": 1918,
							"isPageNumberRoman": false
						},
						{
							"eid": "5IxoM4bBgTjaYGCZEtaS3c",
							"type": "authorPaper",
							"text": "Defects4Log: Benchmarking LLMs for Logging Code Defect Detection and Reasoning",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b930/573300b930.pdf",
							"extraLocations": [],
							"authorNames": "Xin Wang (The Hong Kong University of Science and Technology (Guangzhou), China), Zhenhao Li (York University, Canada), Zishuo Ding (The Hong Kong University of Science and Technology (Guangzhou), China)",
							"abstract": "Logging code is written by developers to capture system runtime behavior and plays a vital role in debugging, performance analysis, and system monitoring. However, defects in logging code can undermine the usefulness of logs and lead to misinterpretations. Although prior work has identified several logging defect patterns and provided valuable insights into logging practices, these studies often focus on a narrow range of defect patterns derived from limited sources (e.g., commit histories) and lack a systematic and comprehensive analysis. Moreover, large language models (LLMs) have demonstrated promising generalization and reasoning capabilities across a variety of code-related tasks, yet their potential for detecting logging code defects remains largely unexplored. In this paper, we derive a comprehensive taxonomy of logging code defects, which encompasses seven defect patterns with 14 detailed scenarios. We further construct a benchmark dataset, Defects4Log, consisting of 164 developer-verified real-world logging defects. Based on this dataset, we propose an automated framework that leverages various prompting strategies and contextual information to evaluate LLMs' capability in detecting and reasoning about logging code defects. Experimental results reveal that LLMs generally struggle to accurately detect and reason about logging code defects when relying solely on source code. However, incorporating proper knowledge (e.g., detailed scenarios of defect patterns) can lead to a 10.9% improvement in detection accuracy. Overall, our findings provide actionable guidance for practitioners to avoid common defect patterns and establish a foundation for improving LLM-based reasoning in logging code defect detection.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Defects4Log: Benchmarking LLMs for Logging Code Defect Detection and Reasoning 1759445246611 10.1109/ASE63991.2025.00161 Xin Wang The Hong Kong University of Science and Technology (Guangzhou), China xwang496@connect.hkust-gz.edu.cn Zhenhao Li York University, Canada lzhenhao@yorku.ca Zishuo Ding The Hong Kong University of Science and Technology (Guangzhou), China zishuoding@hkust-gz.edu.cn logging code defects large language models Logging code is written by developers to capture system runtime behavior and plays a vital role in debugging, performance analysis, and system monitoring. However, defects in logging code can undermine the usefulness of logs and lead to misinterpretations. Although prior work has identified several logging defect patterns and provided valuable insights into logging practices, these studies often focus on a narrow range of defect patterns derived from limited sources (e.g., commit histories) and lack a systematic and comprehensive analysis. Moreover, large language models (LLMs) have demonstrated promising generalization and reasoning capabilities across a variety of code-related tasks, yet their potential for detecting logging code defects remains largely unexplored. In this paper, we derive a comprehensive taxonomy of logging code defects, which encompasses seven defect patterns with 14 detailed scenarios. We further construct a benchmark dataset, Defects4Log, consisting of 164 developer-verified real-world logging defects. Based on this dataset, we propose an automated framework that leverages various prompting strategies and contextual information to evaluate LLMs' capability in detecting and reasoning about logging code defects. Experimental results reveal that LLMs generally struggle to accurately detect and reason about logging code defects when relying solely on source code. However, incorporating proper knowledge (e.g., detailed scenarios of defect patterns) can lead to a 10.9% improvement in detection accuracy. Overall, our findings provide actionable guidance for practitioners to avoid common defect patterns and establish a foundation for improving LLM-based reasoning in logging code defect detection.",
							"pageNumber": 1930,
							"isPageNumberRoman": false
						},
						{
							"eid": "dzI5r2JfWl1Nc64KgGyS0",
							"type": "authorPaper",
							"text": "Efficient Understanding of Machine Learning Model Mispredictions",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b942/573300b942.pdf",
							"extraLocations": [],
							"authorNames": "Martin Eberlein (Humboldt-Universit\u00E4t zu Berlin, Germany), J\u00FCrgen Cito (TU Wien, Austria), Lars Grunske (Humboldt-Universit\u00E4t zu Berlin, Germany)",
							"abstract": "Mispredictions by machine learning components can have severe consequences, especially in safety-critical and mission-critical software systems. Therefore, understanding and debugging these mispredictions is a crucial part of the development process for systems that use machine learning components. Previous research has successfully applied methods that identify when a model's predictions may be unreliable by generating a rule set that links feature values to prediction errors. However, current state-of-the-art rule set approaches require significant computational resources, particularly for large data sets. To address these high computational demands, we propose a strategy to identify and focus only on the most influential features that lead to mispredictions. Additionally, to improve the accuracy of mispredictions diagnosis, we replace traditional rule-based approaches with decision tree learning. We evaluate our tool MMDFast across 11 diverse real-world data sets. The results show that focusing on influential features with decision trees improves the accuracy of misprediction explanations, while significantly reducing computational demands in all scenarios. Thus, MMDFast produces better results much faster, making it more efficient and effective for generating misprediction explanations.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Efficient Understanding of Machine Learning Model Mispredictions 1759146436847 10.1109/ASE63991.2025.00162 Martin Eberlein Humboldt-Universit\u00E4t zu Berlin, Germany martin.eberlein@hu-berlin.de J\u00FCrgen Cito TU Wien, Austria juergen.cito@tuwien.ac.at Lars Grunske Humboldt-Universit\u00E4t zu Berlin, Germany grunske@informatik.hu-berlin.de explainability rule induction machine learning Mispredictions by machine learning components can have severe consequences, especially in safety-critical and mission-critical software systems. Therefore, understanding and debugging these mispredictions is a crucial part of the development process for systems that use machine learning components. Previous research has successfully applied methods that identify when a model's predictions may be unreliable by generating a rule set that links feature values to prediction errors. However, current state-of-the-art rule set approaches require significant computational resources, particularly for large data sets. To address these high computational demands, we propose a strategy to identify and focus only on the most influential features that lead to mispredictions. Additionally, to improve the accuracy of mispredictions diagnosis, we replace traditional rule-based approaches with decision tree learning. We evaluate our tool MMDFast across 11 diverse real-world data sets. The results show that focusing on influential features with decision trees improves the accuracy of misprediction explanations, while significantly reducing computational demands in all scenarios. Thus, MMDFast produces better results much faster, making it more efficient and effective for generating misprediction explanations.",
							"pageNumber": 1942,
							"isPageNumberRoman": false
						},
						{
							"eid": "7HWfCLOMju6D1Wq84JTy7y",
							"type": "authorPaper",
							"text": "VRTestSniffer: Test Smell Detector for Virtual Reality (VR) Software Projects",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b955/573300b955.pdf",
							"extraLocations": [],
							"authorNames": "Faraz Gurramkonda (University of Michigan-Dearborn, USA), Avishak Chakroborty (University of Michigan-Dearborn, USA), Bruce Maxim (University of Michigan-Dearborn, USA), Mohamed Wiem Mkaouer (University of Michigan-Flint, USA), Foyzul Hassan (University of Michigan-Dearborn, USA)",
							"abstract": "Virtual Reality (VR) is an emerging technology increasingly adopted in sectors such as gaming, education, border security, and industrial training. However, testing VR applications presents unique challenges due to factors like active user interaction, hardware dependencies, and immersive environments. Recent studies suggest that developers often write fewer test cases for VR applications, and these limited test cases frequently exhibit test smells. Current research on VR test smell detection can only identify a small subset of test smells and often lacks the necessary context for comprehensive detection. This highlights a critical gap in current testing practices for VR applications and underscores the need for approaches tailored to detecting and addressing quality issues in VR test cases. To address this research gap, we developed VRTestSniffer, a static analysis-based tool that extends test smell detection capabilities specifically for Unity-based VR applications. VRTestSniffer can detect 17 test smell categories, building upon those identified by the state-of-the-art tool tsDetect, and achieves an F1-score of 95.61%. It leverages abstract syntax trees (ASTs), control flow graphs (CFGs), and data flow graphs (DFGs) to enhance detection accuracy by capturing both control and data dependencies specific to VR testing patterns. In parallel, we conducted an empirical analysis of real-world VR projects to examine the prevalence and characteristics of these test smells. Our findings reveal that a few smelly test categories are associated with design issues such as Blob and Complex Class in functional code. We believe that VRTestSniffer, along with the empirical insights derived from this study, can help VR developers write more effective, reliable, and maintainable test cases. To support further research and replication, our tool, dataset, and analysis results are publicly available at [1].",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 VRTestSniffer: Test Smell Detector for Virtual Reality (VR) Software Projects 1759464597365 10.1109/ASE63991.2025.00163 Faraz Gurramkonda University of Michigan-Dearborn, USA gfaraz@umich.edu Avishak Chakroborty University of Michigan-Dearborn, USA avishak@umich.edu Bruce Maxim University of Michigan-Dearborn, USA bmaxim@umich.edu Mohamed Wiem Mkaouer University of Michigan-Flint, USA mmkaouer@umich.edu Foyzul Hassan University of Michigan-Dearborn, USA foyzul@umich.edu virtual reality program analysis test smell Virtual Reality (VR) is an emerging technology increasingly adopted in sectors such as gaming, education, border security, and industrial training. However, testing VR applications presents unique challenges due to factors like active user interaction, hardware dependencies, and immersive environments. Recent studies suggest that developers often write fewer test cases for VR applications, and these limited test cases frequently exhibit test smells. Current research on VR test smell detection can only identify a small subset of test smells and often lacks the necessary context for comprehensive detection. This highlights a critical gap in current testing practices for VR applications and underscores the need for approaches tailored to detecting and addressing quality issues in VR test cases. To address this research gap, we developed VRTestSniffer, a static analysis-based tool that extends test smell detection capabilities specifically for Unity-based VR applications. VRTestSniffer can detect 17 test smell categories, building upon those identified by the state-of-the-art tool tsDetect, and achieves an F1-score of 95.61%. It leverages abstract syntax trees (ASTs), control flow graphs (CFGs), and data flow graphs (DFGs) to enhance detection accuracy by capturing both control and data dependencies specific to VR testing patterns. In parallel, we conducted an empirical analysis of real-world VR projects to examine the prevalence and characteristics of these test smells. Our findings reveal that a few smelly test categories are associated with design issues such as Blob and Complex Class in functional code. We believe that VRTestSniffer, along with the empirical insights derived from this study, can help VR developers write more effective, reliable, and maintainable test cases. To support further research and replication, our tool, dataset, and analysis results are publicly available at [1].",
							"pageNumber": 1955,
							"isPageNumberRoman": false
						},
						{
							"eid": "706fKtDsW0fDrUX3yefVe1",
							"type": "authorPaper",
							"text": "Non-Termination Witnesses and Their Validation",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b968/573300b968.pdf",
							"extraLocations": [],
							"authorNames": "Zs\u00F3fia \u00C1d\u00E1m (Budapest University of Technology and Economics, Hungary), Paul\u00EDna Ayaziov\u00E1 (Masaryk University, Czech Republic), Levente Bajczi (Budapest University of Technology and Economics, Hungary), Dirk Beyer (LMU Munich, Germany), Marek Jankola (LMU Munich, Germany), Marian Lingsch-Rosenfeld (LMU Munich, Germany), Jan Strej\u010Dek (Masaryk University, Czech Republic)",
							"abstract": "Designing algorithms for complex problems as certifying algorithms is an important approach to ensure correctness of computational results. Instead of producing an output y for an input x, a certifying algorithm produces as output for x not only y but also a witness w. The witness w (also called certificate) can now be used to check that y is indeed the correct output for input x. Witnesses and their validation also exist in the area of automatic software verification, and a large number of tools support verification witnesses. SV-COMP 2025 reports 62 verifiers producing witnesses and 18 tools for witness validation. In 2023, a new version 2.0 of the witness format for software verification was introduced to overcome several problems with the previous format, and this new format is now widely supported. However, there is no format with a clear definition and semantics for witnesses of non-termination. This paper closes this gap by presenting an extension of the witness format 2.0 to support program non-termination. Besides explaining the design of this extension, we describe various approaches to generate and validate non-termination witnesses. We also give an overview of current tool support of the extended format, i.e., the verifiers that can generate non-termination witnesses and the witness validators able to analyze these witnesses. Finally, we present an experimental evaluation showing the performance of these tools on program-termination tasks of SV-COMP 2025.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Non-Termination Witnesses and Their Validation 1759134231966 10.1109/ASE63991.2025.00164 Zs\u00F3fia \u00C1d\u00E1m Budapest University of Technology and Economics, Hungary adamzsofi@edu.bme.hu Paul\u00EDna Ayaziov\u00E1 Masaryk University, Czech Republic ayazi@mail.muni.cz Levente Bajczi Budapest University of Technology and Economics, Hungary levente.bajczi@edu.bme.hu Dirk Beyer LMU Munich, Germany dirk.beyer@sosy.ifi.lmu.de Marek Jankola LMU Munich, Germany marek.jankola@sosy.ifi.lmu.de Marian Lingsch-Rosenfeld LMU Munich, Germany marian.lingsch@sosy.ifi.lmu.de Jan Strej\u010Dek Masaryk University, Czech Republic xstrejc@fi.muni.cz verification witness software verification validation exchange format non-termination counterexample Designing algorithms for complex problems as certifying algorithms is an important approach to ensure correctness of computational results. Instead of producing an output y for an input x, a certifying algorithm produces as output for x not only y but also a witness w. The witness w (also called certificate) can now be used to check that y is indeed the correct output for input x. Witnesses and their validation also exist in the area of automatic software verification, and a large number of tools support verification witnesses. SV-COMP 2025 reports 62 verifiers producing witnesses and 18 tools for witness validation. In 2023, a new version 2.0 of the witness format for software verification was introduced to overcome several problems with the previous format, and this new format is now widely supported. However, there is no format with a clear definition and semantics for witnesses of non-termination. This paper closes this gap by presenting an extension of the witness format 2.0 to support program non-termination. Besides explaining the design of this extension, we describe various approaches to generate and validate non-termination witnesses. We also give an overview of current tool support of the extended format, i.e., the verifiers that can generate non-termination witnesses and the witness validators able to analyze these witnesses. Finally, we present an experimental evaluation showing the performance of these tools on program-termination tasks of SV-COMP 2025.",
							"pageNumber": 1968,
							"isPageNumberRoman": false
						},
						{
							"eid": "4snIdjooKe7b5zSUOMNV5q",
							"type": "authorPaper",
							"text": "Automated Generation of Issue-Reproducing Tests by Combining LLMs and Search-Based Testing",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b981/573300b981.pdf",
							"extraLocations": [],
							"authorNames": "Konstantinos Kitsios (University of Zurich, Switzerland), Marco Castelluccio (Mozilla Corporation, UK), Alberto Bacchelli (University of Zurich, Switzerland)",
							"abstract": "Issue-reproducing tests fail on buggy code and pass once a patch is applied, thus increasing developers' confidence that the issue has been resolved and will not be re-introduced. However, past research has shown that developers often commit patches without such tests, making the automated generation of issue-reproducing tests an area of interest. We propose BLAST, a tool for automatically generating issue-reproducing tests from issue-patch pairs by combining LLMs and search-based software testing (SBST). For the LLM part, we complement the issue description and the patch by extracting relevant context through git history analysis, static analysis, and SBST-generated tests. For the SBST part, we adapt SBST for generating issue-reproducing tests; the issue description and the patch are fed into the SBST optimization through an intermediate LLM-generated seed, which we deserialize into SBST-compatible form. BLAST successfully generates issue-reproducing tests for 151/426 (35.4%) of the issues from a curated Python benchmark, outperforming the state-of-the-art (23.5%). Additionally, to measure the real-world impact of BLAST, we built a GitHub bot that runs BLAST whenever a new pull request (PR) linked to an issue is opened, and if BLAST generates an issue-reproducing test, the bot proposes it as a comment in the PR. We deployed the bot in three open-source repositories for three months, gathering data from 32 PRs-issue pairs. BLAST generated an issue-reproducing test in 11 of these cases, which we proposed to the developers. By analyzing the developers' feedback, we discuss challenges and opportunities for researchers and tool builders.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Automated Generation of Issue-Reproducing Tests by Combining LLMs and Search-Based Testing 1758899910093 10.1109/ASE63991.2025.00165 Konstantinos Kitsios University of Zurich, Switzerland konstantinos.kitsios@uzh.ch Marco Castelluccio Mozilla Corporation, UK mcastelluccio@mozilla.com Alberto Bacchelli University of Zurich, Switzerland bacchelli@ifi.uzh.ch test generation search-based software testing Issue-reproducing tests fail on buggy code and pass once a patch is applied, thus increasing developers' confidence that the issue has been resolved and will not be re-introduced. However, past research has shown that developers often commit patches without such tests, making the automated generation of issue-reproducing tests an area of interest. We propose BLAST, a tool for automatically generating issue-reproducing tests from issue-patch pairs by combining LLMs and search-based software testing (SBST). For the LLM part, we complement the issue description and the patch by extracting relevant context through git history analysis, static analysis, and SBST-generated tests. For the SBST part, we adapt SBST for generating issue-reproducing tests; the issue description and the patch are fed into the SBST optimization through an intermediate LLM-generated seed, which we deserialize into SBST-compatible form. BLAST successfully generates issue-reproducing tests for 151/426 (35.4%) of the issues from a curated Python benchmark, outperforming the state-of-the-art (23.5%). Additionally, to measure the real-world impact of BLAST, we built a GitHub bot that runs BLAST whenever a new pull request (PR) linked to an issue is opened, and if BLAST generates an issue-reproducing test, the bot proposes it as a comment in the PR. We deployed the bot in three open-source repositories for three months, gathering data from 32 PRs-issue pairs. BLAST generated an issue-reproducing test in 11 of these cases, which we proposed to the developers. By analyzing the developers' feedback, we discuss challenges and opportunities for researchers and tool builders.",
							"pageNumber": 1981,
							"isPageNumberRoman": false
						},
						{
							"eid": "6RImGVW9oYfqIQsgplCJGo",
							"type": "authorPaper",
							"text": "Have We Solved Access Control Vulnerability Detection in Smart Contracts? A Benchmark Study",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b994/573300b994.pdf",
							"extraLocations": [],
							"authorNames": "Han Liu (The Hong Kong University of Science and Technology, China), Daoyuan Wu (Lingnan University, China), Yuqiang Sun (Nanyang Technological University, Singapore), Shuai Wang (The Hong Kong University of Science and Technology, China), Yang Liu (Nanyang Technological University, Singapore)",
							"abstract": "Access control (AC) vulnerabilities are among the most critical security threats to smart contracts. Despite extensive research, they remain widespread and damaging in the Ethereum ecosystem. To understand and advance the current state-of-the-art (SOTA) in AC vulnerability detection, we first curate a diverse dataset of 180 real-world AC vulnerabilities from CVE entries, DeFiHackLabs incidents, and Code4rena audit reports. Using this dataset, we conduct a systematic benchmark study along three dimensions. First, we develop a cause-based taxonomy and analyze the prevalence and evolution of AC vulnerabilities. Second, we evaluate six SOTA tools, including two from industry and four from academia, revealing low recall (3% to 8%) and significant blind spots. To understand these failures, we examine 1.2 million deployed contracts and uncover practical gaps in AC protection mechanisms overlooked by existing tools. Finally, we assess the potential of large language models (LLMs) for AC vulnerability detection and show that LLMs detect 53\u201375% of vulnerabilities, outperforming traditional tools but facing challenges such as hallucinations and scalability. Our findings highlight the need for hybrid approaches that combine static analysis with LLM-based semantic reasoning to address the complexity of modern AC vulnerabilities.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Have We Solved Access Control Vulnerability Detection in Smart Contracts? A Benchmark Study 1759424299985 10.1109/ASE63991.2025.00166 Han Liu The Hong Kong University of Science and Technology, China liuhan@ust.hk Daoyuan Wu Lingnan University, China daoyuanwu@ln.edu.hk Yuqiang Sun Nanyang Technological University, Singapore suny0056@e.ntu.edu.sg Shuai Wang The Hong Kong University of Science and Technology, China shuaiw@cse.ust.hk Yang Liu Nanyang Technological University, Singapore yangliu@ntu.edu.sg smart contracts access control vulnerability detection large language models Access control (AC) vulnerabilities are among the most critical security threats to smart contracts. Despite extensive research, they remain widespread and damaging in the Ethereum ecosystem. To understand and advance the current state-of-the-art (SOTA) in AC vulnerability detection, we first curate a diverse dataset of 180 real-world AC vulnerabilities from CVE entries, DeFiHackLabs incidents, and Code4rena audit reports. Using this dataset, we conduct a systematic benchmark study along three dimensions. First, we develop a cause-based taxonomy and analyze the prevalence and evolution of AC vulnerabilities. Second, we evaluate six SOTA tools, including two from industry and four from academia, revealing low recall (3% to 8%) and significant blind spots. To understand these failures, we examine 1.2 million deployed contracts and uncover practical gaps in AC protection mechanisms overlooked by existing tools. Finally, we assess the potential of large language models (LLMs) for AC vulnerability detection and show that LLMs detect 53\u201375% of vulnerabilities, outperforming traditional tools but facing challenges such as hallucinations and scalability. Our findings highlight the need for hybrid approaches that combine static analysis with LLM-based semantic reasoning to address the complexity of modern AC vulnerabilities.",
							"pageNumber": 1994,
							"isPageNumberRoman": false
						},
						{
							"eid": "3ssiXMs90QXcbE2r2oNCVu",
							"type": "authorPaper",
							"text": "Explainable Fault Localization for Programming Assignments via LLM-Guided Annotation",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c007/573300c007.pdf",
							"extraLocations": [],
							"authorNames": "Fang Liu (Beihang University, China), Tianze Wang (Beihang University, China), Li Zhang (Beihang University, China), Zheyu Yang (Beihang University, China), Jing Jiang (Beihang University, China), Zian Sun (Beihang University, China)",
							"abstract": "Providing timely and personalized guidance for students' programming assignments, particularly by indicating fine-grained error locations with explanations, offers significant practical value for helping students complete assignments and enhance their learning outcomes. In recent years, various automated Fault Localization (FL) techniques, particularly those leveraging Large Language Models (LLMs), have demonstrated promising results in identifying errors in programs. However, existing fault localization techniques face challenges when applied to educational contexts. Most approaches operate at the method level without explanatory feedback, resulting in granularity too coarse for students who need actionable insights to identify and fix their errors. While some approaches attempt line-level fault localization, they often depend on predicting line numbers directly in numerical form, which is ill-suited to LLMs. To address these challenges, we propose FLAME, a fine-grained, explainable Fault Localization method tailored for programming assignments via LLM-guided Annotation and Model Ensemble. FLAME leverages rich contextual information specific to programming assignments to guide LLMs in identifying faulty code lines. Instead of directly predicting line numbers, we prompt the LLM to annotate faulty code lines with detailed explanations, enhancing both localization accuracy and educational value. To further improve reliability, we introduce a weighted multi-model voting strategy that aggregates results from multiple LLMs to determine the suspiciousness of each code line. Extensive experimental results demonstrate that FLAME outperforms state-of-the-art fault localization baselines on programming assignments, successfully localizing 207 more faults at top-1 over the best-performing baseline. Beyond educational contexts, FLAME also generalizes effectively to general-purpose software codebases, outperforming all baselines on the Defects4J benchmark.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Explainable Fault Localization for Programming Assignments via LLM-Guided Annotation 1758505727044 10.1109/ASE63991.2025.00167 Fang Liu Beihang University, China fangliu@buaa.edu.cn Tianze Wang Beihang University, China wangtz@buaa.edu.cn Li Zhang Beihang University, China lily@buaa.edu.cn Zheyu Yang Beihang University, China yangzheyu00@hotmail.com Jing Jiang Beihang University, China jiangjing@buaa.edu.cn Zian Sun Beihang University, China sza@buaa.edu.cn automated fault localization programming education large language models Providing timely and personalized guidance for students' programming assignments, particularly by indicating fine-grained error locations with explanations, offers significant practical value for helping students complete assignments and enhance their learning outcomes. In recent years, various automated Fault Localization (FL) techniques, particularly those leveraging Large Language Models (LLMs), have demonstrated promising results in identifying errors in programs. However, existing fault localization techniques face challenges when applied to educational contexts. Most approaches operate at the method level without explanatory feedback, resulting in granularity too coarse for students who need actionable insights to identify and fix their errors. While some approaches attempt line-level fault localization, they often depend on predicting line numbers directly in numerical form, which is ill-suited to LLMs. To address these challenges, we propose FLAME, a fine-grained, explainable Fault Localization method tailored for programming assignments via LLM-guided Annotation and Model Ensemble. FLAME leverages rich contextual information specific to programming assignments to guide LLMs in identifying faulty code lines. Instead of directly predicting line numbers, we prompt the LLM to annotate faulty code lines with detailed explanations, enhancing both localization accuracy and educational value. To further improve reliability, we introduce a weighted multi-model voting strategy that aggregates results from multiple LLMs to determine the suspiciousness of each code line. Extensive experimental results demonstrate that FLAME outperforms state-of-the-art fault localization baselines on programming assignments, successfully localizing 207 more faults at top-1 over the best-performing baseline. Beyond educational contexts, FLAME also generalizes effectively to general-purpose software codebases, outperforming all baselines on the Defects4J benchmark.",
							"pageNumber": 2007,
							"isPageNumberRoman": false
						},
						{
							"eid": "2MxmGnZJ4bfdtOm6R2B5er",
							"type": "authorPaper",
							"text": "Interpretable Vulnerability Detection Reports",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c020/573300c020.pdf",
							"extraLocations": [],
							"authorNames": "Claudia Mamede (Carnegie Mellon University; Faculty of Engineering of University of Porto, Portugal), Jos\u00E9 Campos (Faculty of Engineering of University of Porto, Portugal; Universidade de Lisboa, Portugal), Claire Le Goues (Carnegie Mellon University), Rui Abreu (Faculty of Engineering of University of Porto, Portugal; INESC-ID, Portugal)",
							"abstract": "Software security faces a persistent gap: static analysis tools detect vulnerabilities effectively, but their technical outputs remain inaccessible to most developers. This leads to mounting security debt, as organizations must rely on security specialists for remediation, creating bottlenecks that delay fixes. This paper proposes an interpretability convention and a modular workflow that transforms raw static analyzer outputs into clear, actionable vulnerability reports for all developers, not just security experts. Our tool, SECGen, automates the workflow by parsing static analyzer outputs and restructuring them into clear, developer-friendly reports based on our convention, and enforcing compliance through automated validation. We validated our approach through a user study with 25 developers, comparing our interpretable reports to other state-of-the-art static analyzer outputs. The results suggest that developers using interpretable reports detect, understand and fix vulnerabilities more effectively, requiring only 67% of the time typically spent with traditional reports while writing more correct fixes. Key reasons for this include participants' preference for structured reports, with clear vulnerability descriptions and actionable fix suggestions.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Interpretable Vulnerability Detection Reports 1759516653534 10.1109/ASE63991.2025.00168 Claudia Mamede Carnegie Mellon University; Faculty of Engineering of University of Porto, Portugal cmamede@andrew.cmu.edu Jos\u00E9 Campos Faculty of Engineering of University of Porto, Portugal; Universidade de Lisboa, Portugal jcmc@fe.up.pt Claire Le Goues Carnegie Mellon University clegoues@andrew.cmu.edu Rui Abreu Faculty of Engineering of University of Porto, Portugal; INESC-ID, Portugal rui@computer.org interpretable vulnerability reports static analysis Software security faces a persistent gap: static analysis tools detect vulnerabilities effectively, but their technical outputs remain inaccessible to most developers. This leads to mounting security debt, as organizations must rely on security specialists for remediation, creating bottlenecks that delay fixes. This paper proposes an interpretability convention and a modular workflow that transforms raw static analyzer outputs into clear, actionable vulnerability reports for all developers, not just security experts. Our tool, SECGen, automates the workflow by parsing static analyzer outputs and restructuring them into clear, developer-friendly reports based on our convention, and enforcing compliance through automated validation. We validated our approach through a user study with 25 developers, comparing our interpretable reports to other state-of-the-art static analyzer outputs. The results suggest that developers using interpretable reports detect, understand and fix vulnerabilities more effectively, requiring only 67% of the time typically spent with traditional reports while writing more correct fixes. Key reasons for this include participants' preference for structured reports, with clear vulnerability descriptions and actionable fix suggestions.",
							"pageNumber": 2020,
							"isPageNumberRoman": false
						},
						{
							"eid": "6qdE7MT0Tc82bwECe0T7f3",
							"type": "authorPaper",
							"text": "Characterizing and Repairing Color-Related Accessibility Issues in Android Apps",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c032/573300c032.pdf",
							"extraLocations": [],
							"authorNames": "Jiahao Gu (Xiamen University, China), Huaxun Huang (Xiamen University, China)",
							"abstract": "As Android apps become increasingly prevalent in daily life, a common issue in the development process is the configuration of UI colors, leading to color-related accessibility issues that make the text or images on the app's UI difficult to see due to low color contrast. Such color-related accessibility issues are among the top issues in apps, having a negative impact on vision and user experience. However, state-of-the-art approaches are based on predefined rules and lack an understanding of strategies for alternative colors, therefore failing to generate patches acceptable to both app users and developers. To address this research gap, we first conducted an empirical study to explore common strategies used by app developers when fixing real-world color-related accessibility issues. Based on these findings, we proposed DroidPalette, an automated approach for repairing color-related accessibility issues in Android apps. DroidPalette encodes the common strategies used by app developers for selecting issue-fixing colors, as identified in our empirical study, and combines this with the candidate issue-fixing attributes identified from the Android framework and third-party libraries to generate patches. We evaluated DroidPalette on 316 color-related accessibility issues across 105 real-world Android apps, achieving a success rate of 67.72%. Encouragingly, out of 13 patches submitted to GitHub repositories, 8 have received positive feedback from app developers.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Characterizing and Repairing Color-Related Accessibility Issues in Android Apps 1759457818582 10.1109/ASE63991.2025.00169 Jiahao Gu Xiamen University, China gujiahao@stu.xmu.edu.cn Huaxun Huang Xiamen University, China huanghuaxun@xmu.edu.cn android automated repair color-related accessibility issues As Android apps become increasingly prevalent in daily life, a common issue in the development process is the configuration of UI colors, leading to color-related accessibility issues that make the text or images on the app's UI difficult to see due to low color contrast. Such color-related accessibility issues are among the top issues in apps, having a negative impact on vision and user experience. However, state-of-the-art approaches are based on predefined rules and lack an understanding of strategies for alternative colors, therefore failing to generate patches acceptable to both app users and developers. To address this research gap, we first conducted an empirical study to explore common strategies used by app developers when fixing real-world color-related accessibility issues. Based on these findings, we proposed DroidPalette, an automated approach for repairing color-related accessibility issues in Android apps. DroidPalette encodes the common strategies used by app developers for selecting issue-fixing colors, as identified in our empirical study, and combines this with the candidate issue-fixing attributes identified from the Android framework and third-party libraries to generate patches. We evaluated DroidPalette on 316 color-related accessibility issues across 105 real-world Android apps, achieving a success rate of 67.72%. Encouragingly, out of 13 patches submitted to GitHub repositories, 8 have received positive feedback from app developers.",
							"pageNumber": 2032,
							"isPageNumberRoman": false
						},
						{
							"eid": "30jiOy4M70X5RbIYcoq3So",
							"type": "authorPaper",
							"text": "Demystifying the Evolution of Neural Networks with BOM Analysis: Insights from a Large-Scale Study of 55,997 GitHub Repositories",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c045/573300c045.pdf",
							"extraLocations": [],
							"authorNames": "Xiaoning Ren (University of Science and Technology of China, China), Yuhang Ye (University of Science and Technology of China, China), Xiongfei Wu (University of Luxembourg, Luxembourg), Yueming Wu (Huazhong University of Science and Technology, China), Yinxing Xue (Institute of AI for Industries, China)",
							"abstract": "Neural networks have become integral to many fields due to their exceptional performance. The open-source community has witnessed a rapid influx of neural network (NN) repositories with fast-paced iterations, making it crucial for practitioners to analyze their evolution to guide development and stay ahead of trends. While extensive research has explored traditional software evolution using Software Bill of Materials (SBOMs), these are ill-suited for NN software, which relies on pre-defined modules and pre-trained models (PTMs) with distinct component structures and reuse patterns. Conceptual AI Bills of Materials (AIBOMs) also lack practical implementations for large-scale evolutionary analysis. To fill this gap, we introduce the Neural Network Bill of Material (NNBOM), a comprehensive dataset construct tailored for NN software. We create a large-scale NNBOM database from 55,997 curated PyTorch GitHub repositories, cataloging their TPLs, PTMs, and modules. Leveraging this database, we conduct a comprehensive empirical study of neural network software evolution across software scale, component reuse, and inter-domain dependency, providing maintainers and developers with a holistic view of its long-term trends. Building on these findings, we develop two prototype applications, Multi repository Evolution Analyzer and Single repository Component Assessor and Recommender, to demonstrate the practical value of our analysis.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Demystifying the Evolution of Neural Networks with BOM Analysis: Insights from a Large-Scale Study of 55,997 GitHub Repositories 1757832098255 10.1109/ASE63991.2025.00170 Xiaoning Ren University of Science and Technology of China, China hnurxn@mail.ustc.edu.cn Yuhang Ye University of Science and Technology of China, China yyh834771838@mail.ustc.edu.cn Xiongfei Wu University of Luxembourg, Luxembourg xiongfei.wu@uni.lu Yueming Wu Huazhong University of Science and Technology, China wuyueming21@gmail.com Yinxing Xue Institute of AI for Industries, China yxxue@iaii.ac.cn neural network software evolution analysis bill of material Neural networks have become integral to many fields due to their exceptional performance. The open-source community has witnessed a rapid influx of neural network (NN) repositories with fast-paced iterations, making it crucial for practitioners to analyze their evolution to guide development and stay ahead of trends. While extensive research has explored traditional software evolution using Software Bill of Materials (SBOMs), these are ill-suited for NN software, which relies on pre-defined modules and pre-trained models (PTMs) with distinct component structures and reuse patterns. Conceptual AI Bills of Materials (AIBOMs) also lack practical implementations for large-scale evolutionary analysis. To fill this gap, we introduce the Neural Network Bill of Material (NNBOM), a comprehensive dataset construct tailored for NN software. We create a large-scale NNBOM database from 55,997 curated PyTorch GitHub repositories, cataloging their TPLs, PTMs, and modules. Leveraging this database, we conduct a comprehensive empirical study of neural network software evolution across software scale, component reuse, and inter-domain dependency, providing maintainers and developers with a holistic view of its long-term trends. Building on these findings, we develop two prototype applications, Multi repository Evolution Analyzer and Single repository Component Assessor and Recommender, to demonstrate the practical value of our analysis.",
							"pageNumber": 2045,
							"isPageNumberRoman": false
						},
						{
							"eid": "63oBxyY61WkQDYlt2ZTBDI",
							"type": "authorPaper",
							"text": "FirmProj: Detecting Firmware Leakage in IoT Update Processes via Companion App Analysis",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c057/573300c057.pdf",
							"extraLocations": [],
							"authorNames": "Wenzhi Li (Shandong University, China), Jialong Guo (Shandong University, China), Jiongyi Chen (National University of Defense Technology, China), Fan Li (Shandong University, China), Yujie Xing (Shandong University, China), Yanbo Xu (Shanghai Jiao Tong University, China), Shishuai Yang (Shandong University, China), Wenrui Diao (Shandong University, China)",
							"abstract": "The rapid growth of the Internet of Things (IoT) has led to the widespread use of companion apps for device management. However, these apps expose a critical vulnerability in the IoT ecosystem: insufficient verification procedures during device firmware updates (DFU), often resulting in firmware leakage. Once leaked, the firmware reveals sensitive design details, creating a straightforward path for attackers to reverse-engineer devices. To address this issue, we designed an automated analysis tool called FirmProj. It systematically evaluates firmware leakage risks by examining IoT companion apps. FirmProj combines advanced static analysis techniques with large language models to identify DFU modules, extract firmware files, and detect security vulnerabilities. In a large-scale study involving 10,047 IoT companion apps, FirmProj successfully retrieved 3,434 firmware files, uncovering severe flaws in DFU implementations that can lead to firmware leakage. These findings resulted in the assignment of 35 CVE IDs. Our results highlight the urgent need to strengthen firmware protection mechanisms throughout the IoT ecosystem.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 FirmProj: Detecting Firmware Leakage in IoT Update Processes via Companion App Analysis 1759398894017 10.1109/ASE63991.2025.00171 Wenzhi Li Shandong University, China wzl2022@mail.sdu.edu.cn Jialong Guo Shandong University, China guoxb@mail.sdu.edu.cn Jiongyi Chen National University of Defense Technology, China chenjiongyi@nudt.edu.cn Fan Li Shandong University, China fl2022@mail.sdu.edu.cn Yujie Xing Shandong University, China xyj0920@mail.sdu.edu.cn Yanbo Xu Shanghai Jiao Tong University, China yanbo_xu@sjtu.edu.cn Shishuai Yang Shandong University, China shishuai@mail.sdu.edu.cn Wenrui Diao Shandong University, China diaowenrui@link.cuhk.edu.hk firmware leakage iot update companion app analysis vulnerability discovery The rapid growth of the Internet of Things (IoT) has led to the widespread use of companion apps for device management. However, these apps expose a critical vulnerability in the IoT ecosystem: insufficient verification procedures during device firmware updates (DFU), often resulting in firmware leakage. Once leaked, the firmware reveals sensitive design details, creating a straightforward path for attackers to reverse-engineer devices. To address this issue, we designed an automated analysis tool called FirmProj. It systematically evaluates firmware leakage risks by examining IoT companion apps. FirmProj combines advanced static analysis techniques with large language models to identify DFU modules, extract firmware files, and detect security vulnerabilities. In a large-scale study involving 10,047 IoT companion apps, FirmProj successfully retrieved 3,434 firmware files, uncovering severe flaws in DFU implementations that can lead to firmware leakage. These findings resulted in the assignment of 35 CVE IDs. Our results highlight the urgent need to strengthen firmware protection mechanisms throughout the IoT ecosystem.",
							"pageNumber": 2057,
							"isPageNumberRoman": false
						},
						{
							"eid": "3QmAReeYXy9XdxPwwawvFK",
							"type": "authorPaper",
							"text": "Why Is My Transaction Risky? Understanding Smart Contract Semantics and Interactions in the NFT Ecosystem",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c070/573300c070.pdf",
							"extraLocations": [],
							"authorNames": "Yujing Chen (Zhejiang University), Xuanming Liu (Zhejiang University), Zhiyuan Wan (Zhejiang University), Zuobin Wang (Zhejiang University), David Lo (Singapore Management University), Difan Xie (Hangzhou High-Tech Zone (Binjiang) Institute of Blockchain and Data Security), Xiaohu Yang (Zhejiang University, China)",
							"abstract": "The NFT ecosystem represents an interconnected, decentralized environment that encompasses the creation, distribution, and trading of Non-Fungible Tokens (NFTs), where key actors, such as marketplaces, sellers, and buyers, utilize smart contracts to facilitate secure, transparent, and trustless transactions. Scam tokens are deliberately created to mislead users and facilitate financial exploitation, posing significant risks in the NFT ecosystem. Prior work has explored the NFT ecosystem from various perspectives, including security challenges, actor behaviors, and risks from scams and wash trading, leaving a gap in understanding the semantics and interactions of smart contracts during transactions, and how the risks associated with scam tokens manifest in relation to the semantics and interactions of contracts. To bridge this gap, we conducted a large-scale empirical study on smart contract semantics and interactions in the NFT ecosystem, using a curated dataset of nearly 100 million transactions across 20 million blocks on Ethereum. We observe a limited semantic diversity among smart contracts in the NFT ecosystem, dominated by proxy, token, and DeFi contracts. Marketplace and proxy registry contracts are the most frequently involved in smart contract interactions during transactions, engaging with a broad spectrum of contracts in the ecosystem. Token contracts exhibit bytecode-level diversity, whereas scam tokens exhibit bytecode convergence. Certain interaction patterns between smart contracts are common to both risky and non-risky transactions, while others are predominantly associated with risky transactions. Based on our findings, we provide recommendations to mitigate risks in the blockchain ecosystem, and outline future research directions.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Why Is My Transaction Risky? Understanding Smart Contract Semantics and Interactions in the NFT Ecosystem 1759122911831 10.1109/ASE63991.2025.00172 Yujing Chen Zhejiang University chenyujing@zju.edu.cn Xuanming Liu Zhejiang University hinsliu@zju.edu.cn Zhiyuan Wan Zhejiang University wanzhiyuan@zju.edu.cn Zuobin Wang Zhejiang University wangzuobin@zju.edu.cn David Lo Singapore Management University davidlo@smu.edu.sg Difan Xie Hangzhou High-Tech Zone (Binjiang) Institute of Blockchain and Data Security xiedifan@bcds.org.cn Xiaohu Yang Zhejiang University, China yangxh@zju.edu.cn ethereum blockchain transaction smart contract scam nft The NFT ecosystem represents an interconnected, decentralized environment that encompasses the creation, distribution, and trading of Non-Fungible Tokens (NFTs), where key actors, such as marketplaces, sellers, and buyers, utilize smart contracts to facilitate secure, transparent, and trustless transactions. Scam tokens are deliberately created to mislead users and facilitate financial exploitation, posing significant risks in the NFT ecosystem. Prior work has explored the NFT ecosystem from various perspectives, including security challenges, actor behaviors, and risks from scams and wash trading, leaving a gap in understanding the semantics and interactions of smart contracts during transactions, and how the risks associated with scam tokens manifest in relation to the semantics and interactions of contracts. To bridge this gap, we conducted a large-scale empirical study on smart contract semantics and interactions in the NFT ecosystem, using a curated dataset of nearly 100 million transactions across 20 million blocks on Ethereum. We observe a limited semantic diversity among smart contracts in the NFT ecosystem, dominated by proxy, token, and DeFi contracts. Marketplace and proxy registry contracts are the most frequently involved in smart contract interactions during transactions, engaging with a broad spectrum of contracts in the ecosystem. Token contracts exhibit bytecode-level diversity, whereas scam tokens exhibit bytecode convergence. Certain interaction patterns between smart contracts are common to both risky and non-risky transactions, while others are predominantly associated with risky transactions. Based on our findings, we provide recommendations to mitigate risks in the blockchain ecosystem, and outline future research directions.",
							"pageNumber": 2070,
							"isPageNumberRoman": false
						},
						{
							"eid": "6tkjvfNpStNUu3IwntHQQd",
							"type": "authorPaper",
							"text": "Breaking the Traffic Barrier: Unveiling Multi-Format of Protocols via Autonomous Program Exploration",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c082/573300c082.pdf",
							"extraLocations": [],
							"authorNames": "Dingzhao Xue (Institute of Information Engineering of CAS, China; College of Cyberspace Security, Chinese Academy of Sciences, China), Yibo Qu (Institute of Information Engineering of CAS, China; College of Cyberspace Security, Chinese Academy of Sciences, China), Bowen Jiang (Institute of Information Engineering of CAS, China; College of Cyberspace Security, Chinese Academy of Sciences, China), Xin Chen (Institute of Information Engineering of CAS, China; College of Cyberspace Security, Chinese Academy of Sciences, China), Shuaizong Si (Institute of Information Engineering of CAS, China; College of Cyberspace Security, Chinese Academy of Sciences, China), Shichao Lv (Institute of Information Engineering of CAS, China; College of Cyberspace Security, Chinese Academy of Sciences, China), Zhiqiang Shi (Institute of Information Engineering of CAS, China; College of Cyberspace Security, Chinese Academy of Sciences, China), Limin Sun (Institute of Information Engineering of CAS, China; College of Cyberspace Security, Chinese Academy of Sciences, China)",
							"abstract": "Protocol reverse engineering (PRE) aims to infer the protocol formats of unknown protocols. Existing techniques, whether Network-trace based or Execution-trace based methods, face two main limitations: a reliance on the quality and scale of traffic datasets, which often leads to low accuracy and poor generalization; and a failure to adequately consider the multi-format characteristic prevalent in real-world protocols (i.e., the same protocol may support multiple different formats). To address these challenges, we propose ProbePRE\u2014a PRE tool that performs multi-format extraction on protocol handlers by autonomously generating packets. ProbePRE employs three key techniques: (1) an execution tracing strategy enhanced with implicit data flow analysis to obtain more detailed execution information; (2) constraint extraction methods tailored for different program structures to pass protocol validation; and (3) an innovative constraint combination algorithm to construct effective packets that guide the protocol handler to execute diverse protocol parsing paths. In our experimental evaluation, we compared ProbePRE with 4 state-of-the-art PRE tools in terms of field segmentation accuracy. The results demonstrated that ProbePRE achieved an F1 score of 0.88, significantly outperforming existing methods. Furthermore, evaluations on 6 protocol handlers indicated that ProbePRE attained 83% completeness in multi-format extraction tasks. Notably, in basic block coverage tests, ProbePRE achieved a 67% improvement over traditional traffic dataset methods, which fully validates the effectiveness of its path exploration capabilities.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Breaking the Traffic Barrier: Unveiling Multi-Format of Protocols via Autonomous Program Exploration 1759065228106 10.1109/ASE63991.2025.00173 Dingzhao Xue Institute of Information Engineering of CAS, China; College of Cyberspace Security, Chinese Academy of Sciences, China xuedingzhao@iie.ac.cn Yibo Qu Institute of Information Engineering of CAS, China; College of Cyberspace Security, Chinese Academy of Sciences, China quyibo@iie.ac.cn Bowen Jiang Institute of Information Engineering of CAS, China; College of Cyberspace Security, Chinese Academy of Sciences, China jiangbowen@iie.ac.cn Xin Chen Institute of Information Engineering of CAS, China; College of Cyberspace Security, Chinese Academy of Sciences, China chenxin1990@iie.ac.cn Shuaizong Si Institute of Information Engineering of CAS, China; College of Cyberspace Security, Chinese Academy of Sciences, China sishuaizong@iie.ac.cn Shichao Lv Institute of Information Engineering of CAS, China; College of Cyberspace Security, Chinese Academy of Sciences, China lvshichao@iie.ac.cn Zhiqiang Shi Institute of Information Engineering of CAS, China; College of Cyberspace Security, Chinese Academy of Sciences, China shizhiqiang@iie.ac.cn Limin Sun Institute of Information Engineering of CAS, China; College of Cyberspace Security, Chinese Academy of Sciences, China sunlimin@iie.ac.cn protocol reverse engineering data flow analysis taint analysis Protocol reverse engineering (PRE) aims to infer the protocol formats of unknown protocols. Existing techniques, whether Network-trace based or Execution-trace based methods, face two main limitations: a reliance on the quality and scale of traffic datasets, which often leads to low accuracy and poor generalization; and a failure to adequately consider the multi-format characteristic prevalent in real-world protocols (i.e., the same protocol may support multiple different formats). To address these challenges, we propose ProbePRE\u2014a PRE tool that performs multi-format extraction on protocol handlers by autonomously generating packets. ProbePRE employs three key techniques: (1) an execution tracing strategy enhanced with implicit data flow analysis to obtain more detailed execution information; (2) constraint extraction methods tailored for different program structures to pass protocol validation; and (3) an innovative constraint combination algorithm to construct effective packets that guide the protocol handler to execute diverse protocol parsing paths. In our experimental evaluation, we compared ProbePRE with 4 state-of-the-art PRE tools in terms of field segmentation accuracy. The results demonstrated that ProbePRE achieved an F1 score of 0.88, significantly outperforming existing methods. Furthermore, evaluations on 6 protocol handlers indicated that ProbePRE attained 83% completeness in multi-format extraction tasks. Notably, in basic block coverage tests, ProbePRE achieved a 67% improvement over traditional traffic dataset methods, which fully validates the effectiveness of its path exploration capabilities.",
							"pageNumber": 2082,
							"isPageNumberRoman": false
						},
						{
							"eid": "2KVm2Q4aOXqkavlP39fa3S",
							"type": "authorPaper",
							"text": "SPEC2CODE: Mapping Protocol Specification to Function-Level Code Implementation",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c095/573300c095.pdf",
							"extraLocations": [],
							"authorNames": "Yuekun Wang (Singapore Management University, Singapore), Lili Quan (Singapore Management University, Singapore), Xiaofei Xie (Singapore Management University, Singapore), Junjie Wang (Tianjin University, China), Jianjun Chen (Tsinghua University, China)",
							"abstract": "Protocol specifications, which defined in Request for Comments (RFCs), play a critical role in ensuring the correctness of protocol software systems. To check consistency, specification\u2013implementation pairs are essential for testing and verification. However, existing efforts in specification-to-code mapping remain largely manual and are typically limited to the file level, lacking the fine-grained granularity needed for function-level analysis, which is crucial for effective consistency checking. To address this gap, we present SPEC2CODE, the first LLM-driven framework that automates fine-grained mapping from protocol specifications to function implementations. Given a RFC document and a protocol codebase, SPEC2CODE first performs preprocessing to extract structured specification requirements (SRs) and function-level code representations, along with contextual and dependency information. To ensure scalability, SPEC2CODE employs a two-stage process comprising relevance filtering and clustering-based SR organization to reduce the candidate pairs. For accuracy, SPEC2CODE performs finegrained constraint-level matching on each candidate SR\u2013function pair using LLMs, leveraging enriched context to determine whether a function fully, partially, or does not relate to an SR. We evaluate SPEC2CODE on real-world implementations of HTTP, TLS and BFD protocols, including Apache Httpd, Nginx, OpenSSL, BoringSSL, FRRouting, and BIRD. Experimental results show that SPEC2CODE outperforms four state-of-the-art baselines, achieving up to 49%, 66%, and 66% improvement in precision, recall, and F1, respectively. Additionally, SPEC2CODE successfully recovers the mappings for 16 known inconsistency bugs and discovers 11 previously unreported inconsistencies using an integrated lightweight consistency verifier, 5 of which have been confirmed by project developers.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 SPEC2CODE: Mapping Protocol Specification to Function-Level Code Implementation 1759237105196 10.1109/ASE63991.2025.00174 Yuekun Wang Singapore Management University, Singapore ykwang@smu.edu.sg Lili Quan Singapore Management University, Singapore quanlili2022@163.com Xiaofei Xie Singapore Management University, Singapore xfxie@smu.edu.sg Junjie Wang Tianjin University, China junjie.wang@tju.edu.cn Jianjun Chen Tsinghua University, China jianjun@tsinghua.edu.cn software verification protocol compliance large language models Protocol specifications, which defined in Request for Comments (RFCs), play a critical role in ensuring the correctness of protocol software systems. To check consistency, specification\u2013implementation pairs are essential for testing and verification. However, existing efforts in specification-to-code mapping remain largely manual and are typically limited to the file level, lacking the fine-grained granularity needed for function-level analysis, which is crucial for effective consistency checking. To address this gap, we present SPEC2CODE, the first LLM-driven framework that automates fine-grained mapping from protocol specifications to function implementations. Given a RFC document and a protocol codebase, SPEC2CODE first performs preprocessing to extract structured specification requirements (SRs) and function-level code representations, along with contextual and dependency information. To ensure scalability, SPEC2CODE employs a two-stage process comprising relevance filtering and clustering-based SR organization to reduce the candidate pairs. For accuracy, SPEC2CODE performs finegrained constraint-level matching on each candidate SR\u2013function pair using LLMs, leveraging enriched context to determine whether a function fully, partially, or does not relate to an SR. We evaluate SPEC2CODE on real-world implementations of HTTP, TLS and BFD protocols, including Apache Httpd, Nginx, OpenSSL, BoringSSL, FRRouting, and BIRD. Experimental results show that SPEC2CODE outperforms four state-of-the-art baselines, achieving up to 49%, 66%, and 66% improvement in precision, recall, and F1, respectively. Additionally, SPEC2CODE successfully recovers the mappings for 16 known inconsistency bugs and discovers 11 previously unreported inconsistencies using an integrated lightweight consistency verifier, 5 of which have been confirmed by project developers.",
							"pageNumber": 2095,
							"isPageNumberRoman": false
						},
						{
							"eid": "4owjkeCpDkoUvlWVjzpDJJ",
							"type": "authorPaper",
							"text": "Using Fourier Analysis and Mutant Clustering to Accelerate DNN Mutation Testing",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c108/573300c108.pdf",
							"extraLocations": [],
							"authorNames": "Ali Ghanbari (Auburn University, USA), Sasan Tavakkol (Google Research, USA)",
							"abstract": "Deep neural network (DNN) mutation analysis is a promising approach to evaluating test set adequacy. Due to the large number of generated mutants that must be tested on large datasets, mutation analysis is costly. In this paper, we present a technique, named DM#, for accelerating DNN mutation testing using Fourier analysis. The key insight is that DNN outputs are real-valued functions suitable for Fourier analysis that can be leveraged to quantify mutant behavior using only a few data points. DM# uses the quantified mutant behavior to cluster the mutants so that the ones with similar behavior fall into the same group. A representative from each group is then selected for testing, and the result of the test, e.g., whether the mutant is killed or survived, is reused for all other mutants represented by the selected mutant, obviating the need for testing other mutants. 14 DNN models of sizes ranging from thousands to millions of parameters, trained on different datasets, are used to evaluate DM# and compare it to several baseline techniques. Our results provide empirical evidence on the effectiveness of DM# in accelerating mutation testing by 28.38%, on average, at the average cost of only 0.72% error in mutation score. Moreover, on average, DM# incurs 11.78, 15.16, and 114.36 times less mutation score error compared to random mutant selection, boundary sample selection, and random sample selection techniques, respectively, while generally offering comparable speed-up.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Using Fourier Analysis and Mutant Clustering to Accelerate DNN Mutation Testing 1759458328614 10.1109/ASE63991.2025.00175 Ali Ghanbari Auburn University, USA ghanbari@auburn.edu Sasan Tavakkol Google Research, USA tavakkol@google.com dnn fft mutation testing acceleration Deep neural network (DNN) mutation analysis is a promising approach to evaluating test set adequacy. Due to the large number of generated mutants that must be tested on large datasets, mutation analysis is costly. In this paper, we present a technique, named DM#, for accelerating DNN mutation testing using Fourier analysis. The key insight is that DNN outputs are real-valued functions suitable for Fourier analysis that can be leveraged to quantify mutant behavior using only a few data points. DM# uses the quantified mutant behavior to cluster the mutants so that the ones with similar behavior fall into the same group. A representative from each group is then selected for testing, and the result of the test, e.g., whether the mutant is killed or survived, is reused for all other mutants represented by the selected mutant, obviating the need for testing other mutants. 14 DNN models of sizes ranging from thousands to millions of parameters, trained on different datasets, are used to evaluate DM# and compare it to several baseline techniques. Our results provide empirical evidence on the effectiveness of DM# in accelerating mutation testing by 28.38%, on average, at the average cost of only 0.72% error in mutation score. Moreover, on average, DM# incurs 11.78, 15.16, and 114.36 times less mutation score error compared to random mutant selection, boundary sample selection, and random sample selection techniques, respectively, while generally offering comparable speed-up.",
							"pageNumber": 2108,
							"isPageNumberRoman": false
						},
						{
							"eid": "5ewtzidbhJwKZGJZipR3Vk",
							"type": "authorPaper",
							"text": "PAT-Agent: Autoformalization for Model Checking",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c121/573300c121.pdf",
							"extraLocations": [],
							"authorNames": "Xinyue Zuo (National University of Singapore, Singapore), Yifan Zhang (National University of Singapore, Singapore), Hongshu Wang (National University of Singapore, Singapore), Yufan Cai (National University of Singapore, Singapore), Zhe Hou (Griffith University, Australia), Jing Sun (University of Auckland, New Zealand), Jin Song Dong (National University of Singapore, Singapore)",
							"abstract": "Recent advances in large language models (LLMs) offer promising potential for automating formal methods. However, applying them to formal verification remains challenging due to the complexity of specification languages, the risk of hallucinated output, and the semantic gap between natural language and formal logic. We introduce PAT-Agent, an end-to-end framework for natural language autoformalization and formal model repair that combines the generative capabilities of LLMs with the rigor of formal verification to automate the construction of verifiable formal models. In PAT-Agent, a Planning LLM first extracts key modeling elements and generates a detailed plan using semantic prompts, which then guides a Code Generation LLM to synthesize syntactically correct and semantically faithful formal models. The resulting code is verified using the Process Analysis Toolkit (PAT) model checker against user-specified properties, and when discrepancies occur, a Repair Loop is triggered to iteratively correct the model using counterexamples. To improve flexibility, we built a web-based interface that enables users, particularly non-FM-experts, to describe, customize, and verify system behaviors through user-LLM interactions. Experimental results on 40 systems show that PAT-Agent consistently outperforms baselines, achieving high verification success with superior efficiency. The ablation studies confirm the importance of both planning and repair components, and the user study demonstrates that our interface is accessible and supports effective formal modeling, even for users with limited formal methods experience.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 PAT-Agent: Autoformalization for Model Checking 1759221009633 10.1109/ASE63991.2025.00176 Xinyue Zuo National University of Singapore, Singapore zuoxy@nus.edu.sg Yifan Zhang National University of Singapore, Singapore yifan.zhang_@u.nus.edu Hongshu Wang National University of Singapore, Singapore hongshu.wang@u.nus.edu Yufan Cai National University of Singapore, Singapore caiyf@nus.edu.sg Zhe Hou Griffith University, Australia z.hou@griffith.edu.au Jing Sun University of Auckland, New Zealand jing.sun@auckland.ac.nz Jin Song Dong National University of Singapore, Singapore dcsdjs@nus.edu.sg model checking large language models autoformalization llm agent Recent advances in large language models (LLMs) offer promising potential for automating formal methods. However, applying them to formal verification remains challenging due to the complexity of specification languages, the risk of hallucinated output, and the semantic gap between natural language and formal logic. We introduce PAT-Agent, an end-to-end framework for natural language autoformalization and formal model repair that combines the generative capabilities of LLMs with the rigor of formal verification to automate the construction of verifiable formal models. In PAT-Agent, a Planning LLM first extracts key modeling elements and generates a detailed plan using semantic prompts, which then guides a Code Generation LLM to synthesize syntactically correct and semantically faithful formal models. The resulting code is verified using the Process Analysis Toolkit (PAT) model checker against user-specified properties, and when discrepancies occur, a Repair Loop is triggered to iteratively correct the model using counterexamples. To improve flexibility, we built a web-based interface that enables users, particularly non-FM-experts, to describe, customize, and verify system behaviors through user-LLM interactions. Experimental results on 40 systems show that PAT-Agent consistently outperforms baselines, achieving high verification success with superior efficiency. The ablation studies confirm the importance of both planning and repair components, and the user study demonstrates that our interface is accessible and supports effective formal modeling, even for users with limited formal methods experience.",
							"pageNumber": 2121,
							"isPageNumberRoman": false
						},
						{
							"eid": "3aQ1XtnArgHyrAy05gQfzA",
							"type": "authorPaper",
							"text": "Towards Generalizable Instruction Vulnerability Prediction via LLM-Enhanced Code Representation",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c133/573300c133.pdf",
							"extraLocations": [],
							"authorNames": "Bao Wen (Nanjing University of Aeronautics and Astronautics, China), Jingjing Gu (Nanjing University of Aeronautics and Astronautics, China), Jingxuan Zhang (Nanjing University of Aeronautics and Astronautics, China), Yang Liu (Nanjing University of Aeronautics and Astronautics, China), Pengfei Yu (Nanjing University of Aeronautics and Astronautics, China), Yanchao Zhao (Nanjing University of Aeronautics and Astronautics, China)",
							"abstract": "Discovering potential vulnerabilities has long been a fundamental goal in software security. Among them, bit flips, caused by hardware or environmental disturbances, are increasingly recognized as a new type of vulnerabilities that threaten program reliability at the instruction level. However, existing work is often restricted to individual programs and requires retraining when applied to unseen code, severely limiting their practicality and responsiveness. In this paper, we propose CIVP, a novel framework for context-aware instruction vulnerability prediction, generalizing to unseen programs without retraining. Specifically, to capture the rich contextual semantics of instructions, CIVP first leverages Large Language Models (LLMs) to accurately extract semantic embeddings of instructions. Then, CIVP further constructs an instruction execution graph containing complex relations of program execution, which implicates the potential path of error propagation. To improve instruction representation for vulnerability prediction, CIVP enhances GraphSAGE with multi-hop diffusion to capture inter-program structural patterns and contextual dependencies, and adopts pseudo-labeling to improve the model's generalization for vulnerable instructions. Extensive experiments on a dataset of 26 real-world programs demonstrate that CIVP significantly outperforms the state-of-the-art approaches, achieving up to 20.5%\u2191 Recall and 18.5%\u2191 F1-score improvements. Notably, CIVP generalizes well to unseen programs, offering an efficient and scalable solution for proactive instruction-level hardening before software deployment.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Towards Generalizable Instruction Vulnerability Prediction via LLM-Enhanced Code Representation 1755754261931 10.1109/ASE63991.2025.00177 Bao Wen Nanjing University of Aeronautics and Astronautics, China wenbao@nuaa.edu.cn Jingjing Gu Nanjing University of Aeronautics and Astronautics, China gujingjing@nuaa.edu.cn Jingxuan Zhang Nanjing University of Aeronautics and Astronautics, China jxzhang@nuaa.edu.cn Yang Liu Nanjing University of Aeronautics and Astronautics, China liuyaaa@nuaa.edu.cn Pengfei Yu Nanjing University of Aeronautics and Astronautics, China nuaaypf@nuaa.edu.cn Yanchao Zhao Nanjing University of Aeronautics and Astronautics, China yczhao@nuaa.edu.cn Instruction Vulnerability Prediction Cross Program Bit Flip Discovering potential vulnerabilities has long been a fundamental goal in software security. Among them, bit flips, caused by hardware or environmental disturbances, are increasingly recognized as a new type of vulnerabilities that threaten program reliability at the instruction level. However, existing work is often restricted to individual programs and requires retraining when applied to unseen code, severely limiting their practicality and responsiveness. In this paper, we propose CIVP, a novel framework for context-aware instruction vulnerability prediction, generalizing to unseen programs without retraining. Specifically, to capture the rich contextual semantics of instructions, CIVP first leverages Large Language Models (LLMs) to accurately extract semantic embeddings of instructions. Then, CIVP further constructs an instruction execution graph containing complex relations of program execution, which implicates the potential path of error propagation. To improve instruction representation for vulnerability prediction, CIVP enhances GraphSAGE with multi-hop diffusion to capture inter-program structural patterns and contextual dependencies, and adopts pseudo-labeling to improve the model's generalization for vulnerable instructions. Extensive experiments on a dataset of 26 real-world programs demonstrate that CIVP significantly outperforms the state-of-the-art approaches, achieving up to 20.5%\u2191 Recall and 18.5%\u2191 F1-score improvements. Notably, CIVP generalizes well to unseen programs, offering an efficient and scalable solution for proactive instruction-level hardening before software deployment.",
							"pageNumber": 2133,
							"isPageNumberRoman": false
						},
						{
							"eid": "3AjS7bON25NK7aI029IgQ7",
							"type": "authorPaper",
							"text": "Don't Mess with Bro's Cheese! An Empirical Study of Resource Conflict in Android Multi-Window",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c145/573300c145.pdf",
							"extraLocations": [],
							"authorNames": "Chenkai Guo (Nankai University, China; Haihe Lab of ITAI, China), Huimin Zhao (Nankai University, China), Tianhong Wang (Nankai University, China), Naipeng  Dong (The University of Queensland, Australia), Qingqing Dong (Nankai University, China), Jiarui Che (Nankai University, China), Yaqiong Qiao (Nankai University, China), Xiangyang Luo (State Key Laboratory of Mathematical Engineering and Advanced Computing, China), Zheli Liu (Nankai University, China)",
							"abstract": "The multi-window mode in Android has greatly improved productivity and usability by allowing multiple apps to run concurrently. However, alongside the advantages, such mode also introduces unforeseen risks in both functionality and security. In this work, we present the first systematic study to identify a previously unexplored class of issues, termed Multi-window Resource Conflicts (MRCs). Such conflicts occur when multiple app windows access the same system resource concurrently, potentially leading to crashes, functionality failures or unintended behaviors. To enhance the robustness and security of Android multi-window execution, we conduct a systematic and in-depth empirical study on the MRCs. We begin with a comprehensive root cause analysis, categorizing MRCs into three fundamental types based on their triggering patterns and affected resource states. To enable large-scale detection, we develop MRC-Detector, a static analysis framework that automatically identifies MRC issues in Android apps. Our manual verification confirms its high accuracy and effectiveness. We apply the MRC-Detector to the detection of over 150k real-world apps from F-droid and Google Play, uncovering the prevalence of MRC risks. Additionally, the distribution of MRC issues is analyzed in depth across multiple dimensions, including MRC type, APK size, app source and security classification. We further investigated the recognition and confirmation from developers and received 14 positive responses from vendors and project maintainers. Finally, comprehensive mitigation strategies are discussed. The materials of the study are available at: https://github.com/Huimilia/MRC.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Don't Mess with Bro's Cheese! An Empirical Study of Resource Conflict in Android Multi-Window 1759325506590 10.1109/ASE63991.2025.00178 Chenkai Guo Nankai University, China; Haihe Lab of ITAI, China guochenkai@nankai.edu.cn Huimin Zhao Nankai University, China huimilia@mail.nankai.edu.cn Tianhong Wang Nankai University, China tianhongwang@mail.nankai.edu.cn Naipeng Dong The University of Queensland, Australia n.dong@uq.edu.au Qingqing Dong Nankai University, China qingqingdong0717@gmail.com Jiarui Che Nankai University, China 2120240716@mail.nankai.edu.cn Yaqiong Qiao Nankai University, China kitesmile@126.com Xiangyang Luo State Key Laboratory of Mathematical Engineering and Advanced Computing, China luoxy_ieu@sina.com Zheli Liu Nankai University, China liuzheli@nankai.edu.cn resource conflict Android applications multiwindow static detection The multi-window mode in Android has greatly improved productivity and usability by allowing multiple apps to run concurrently. However, alongside the advantages, such mode also introduces unforeseen risks in both functionality and security. In this work, we present the first systematic study to identify a previously unexplored class of issues, termed Multi-window Resource Conflicts (MRCs). Such conflicts occur when multiple app windows access the same system resource concurrently, potentially leading to crashes, functionality failures or unintended behaviors. To enhance the robustness and security of Android multi-window execution, we conduct a systematic and in-depth empirical study on the MRCs. We begin with a comprehensive root cause analysis, categorizing MRCs into three fundamental types based on their triggering patterns and affected resource states. To enable large-scale detection, we develop MRC-Detector, a static analysis framework that automatically identifies MRC issues in Android apps. Our manual verification confirms its high accuracy and effectiveness. We apply the MRC-Detector to the detection of over 150k real-world apps from F-droid and Google Play, uncovering the prevalence of MRC risks. Additionally, the distribution of MRC issues is analyzed in depth across multiple dimensions, including MRC type, APK size, app source and security classification. We further investigated the recognition and confirmation from developers and received 14 positive responses from vendors and project maintainers. Finally, comprehensive mitigation strategies are discussed. The materials of the study are available at: https://github.com/Huimilia/MRC.",
							"pageNumber": 2145,
							"isPageNumberRoman": false
						},
						{
							"eid": "3m6HZlcZ1VGwQgr1fP7UbL",
							"type": "authorPaper",
							"text": "FlakyGuard: Automatically Fixing Flaky Tests at Industry Scale",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c157/573300c157.pdf",
							"extraLocations": [],
							"authorNames": "Chengpeng Li (the University of Texas at Austin, USA), Farnaz Behrang (Uber Technologies, USA), August  Shi (the University of Texas at Austin, USA), Peng Liu (Uber Technologies, USA)",
							"abstract": "Flaky tests that non-deterministically pass or fail waste developer time and slow release cycles. While large language models (LLMs) show promise for automatically repairing flaky tests, existing approaches like FlakyDoctor fail in industrial settings due to the context problem: providing either too little context (missing critical production code) or too much context (overwhelming the LLM with irrelevant information). We present FLAKYGUARD, which addresses this problem by treating code as a graph structure and using selective graph exploration to find only the most relevant context. Evaluation on real-world flaky tests from industrial repositories shows that FLAKYGUARD repairs 47.6% of reproducible flaky tests with 51.8% of the fixes accepted by developers. Besides it outperforms state-of-the-art approaches by at least 22% in repair success rate. Developer surveys confirm that 100% find FLAKYGUARD's root cause explanations useful.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 FlakyGuard: Automatically Fixing Flaky Tests at Industry Scale 1759413030334 10.1109/ASE63991.2025.00179 Chengpeng Li the University of Texas at Austin, USA chengpengli@utexas.edu Farnaz Behrang Uber Technologies, USA behrang@uber.com August Shi the University of Texas at Austin, USA august@utexas.edu Peng Liu Uber Technologies, USA peng3141@uber.com Flaky tests that non-deterministically pass or fail waste developer time and slow release cycles. While large language models (LLMs) show promise for automatically repairing flaky tests, existing approaches like FlakyDoctor fail in industrial settings due to the context problem: providing either too little context (missing critical production code) or too much context (overwhelming the LLM with irrelevant information). We present FLAKYGUARD, which addresses this problem by treating code as a graph structure and using selective graph exploration to find only the most relevant context. Evaluation on real-world flaky tests from industrial repositories shows that FLAKYGUARD repairs 47.6% of reproducible flaky tests with 51.8% of the fixes accepted by developers. Besides it outperforms state-of-the-art approaches by at least 22% in repair success rate. Developer surveys confirm that 100% find FLAKYGUARD's root cause explanations useful.",
							"pageNumber": 2157,
							"isPageNumberRoman": false
						},
						{
							"eid": "1D3NOoLEndQpahS4nvoQ0Z",
							"type": "authorPaper",
							"text": "Spinner: Detecting Locking Violations in the eBPF Runtime",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c170/573300c170.pdf",
							"extraLocations": [],
							"authorNames": "Priya Govindasamy (University of California, Irvine), Joseph Bursey (University of California, Irvine), Hsin-Wei Hung (Meta, US), Ardalan Amiri Sani (University of California, Irvine)",
							"abstract": "The eBPF technology is widely used for many applications, including tracing, packet filtering, network usage monitoring, and so on. The versatility of eBPF allows the kernel's capabilities to be extended without needing to modify source code or load kernel modules. However, the eBPF subsystem may introduce new bugs that could lead to crashes, data loss, and other issues that can negatively impact system stability, reliability, availability, security, and overall performance. Specifically, locking violations, which occur when locks are not used correctly, can lead to problems like deadlocks and system hangs. Since eBPF operates at the kernel level, errors here have far-reaching consequences. To tackle this issue, we present Spinner, a tool for detecting locking violations in the eBPF runtime. Spinner uses static analysis to (1) detect cases of context confusion where incorrect locking primitives are used in eBPF helper functions given their execution context, and (2) identify locks in helper functions that can be called recursively using nested eBPF programs. Both of these situations could result in deadlocks. So far, Spinner has identified 34 locking violation bugs in the eBPF subsystem in Linux, only 5 of which were previously found by Syzbot.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Spinner: Detecting Locking Violations in the eBPF Runtime 1759264001616 10.1109/ASE63991.2025.00180 Priya Govindasamy University of California, Irvine priya.g@uci.edu Joseph Bursey University of California, Irvine jbursey@uci.edu Hsin-Wei Hung Meta, US ameryhung@gmail.com Ardalan Amiri Sani University of California, Irvine ardalan@uci.edu ebpf locking violations static analysis bug detection The eBPF technology is widely used for many applications, including tracing, packet filtering, network usage monitoring, and so on. The versatility of eBPF allows the kernel's capabilities to be extended without needing to modify source code or load kernel modules. However, the eBPF subsystem may introduce new bugs that could lead to crashes, data loss, and other issues that can negatively impact system stability, reliability, availability, security, and overall performance. Specifically, locking violations, which occur when locks are not used correctly, can lead to problems like deadlocks and system hangs. Since eBPF operates at the kernel level, errors here have far-reaching consequences. To tackle this issue, we present Spinner, a tool for detecting locking violations in the eBPF runtime. Spinner uses static analysis to (1) detect cases of context confusion where incorrect locking primitives are used in eBPF helper functions given their execution context, and (2) identify locks in helper functions that can be called recursively using nested eBPF programs. Both of these situations could result in deadlocks. So far, Spinner has identified 34 locking violation bugs in the eBPF subsystem in Linux, only 5 of which were previously found by Syzbot.",
							"pageNumber": 2170,
							"isPageNumberRoman": false
						},
						{
							"eid": "7CzrW5yxxAJ3bJnJj9StMh",
							"type": "authorPaper",
							"text": "Altered Histories in Version Control System Repositories: Evidence from the Trenches",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c183/573300c183.pdf",
							"extraLocations": [],
							"authorNames": "Solal Rapaport (Institut Polytechnique de Paris, France), Laurent Pautet (Institut Polytechnique de Paris, France), Samuel Tardieu (Institut Polytechnique de Paris, France), Stefano Zacchiroli (Institut Polytechnique de Paris, France)",
							"abstract": "Version Control Systems (VCS) like Git allow developers to locally rewrite recorded history, e.g., to reorder and suppress commits or specific data in them. These alterations have legitimate use cases, but become problematic when performed on public branches that have downstream users: they break push/pull workflows, challenge the integrity and reproducibility of repositories, and create opportunities for supply chain attackers to sneak into them nefarious changes. We conduct the first large-scale investigation of Git history alterations in public code repositories. We analyze 111 M (millions) repositories archived by Software Heritage, which preserves VCS histories even across alterations. We find history alterations in 1.22 M repositories, for a total of 8.7 M rewritten histories. We categorize changes by where they happen (which repositories, which branches) and what is changed in them (files or commit metadata). Conducting two targeted case studies we show that altered histories recurrently change licenses retroactively, or are used to remove \"secrets\" (e.g., private keys) committed by mistake. As these behaviors correspond to bad practices - in terms of project governance or security management, respectively - that software recipients might want to avoid, we introduce GitHistorian, an automated tool, that developers can use to spot and describe history alterations in public Git repositories.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Altered Histories in Version Control System Repositories: Evidence from the Trenches 1759393455833 10.1109/ASE63991.2025.00181 Solal Rapaport Institut Polytechnique de Paris, France solal.rapaport@telecom-paris.fr Laurent Pautet Institut Polytechnique de Paris, France laurent.pautet@telecom-paris.fr Samuel Tardieu Institut Polytechnique de Paris, France samuel.tardieu@telecom-paris.fr Stefano Zacchiroli Institut Polytechnique de Paris, France stefano.zacchiroli@telecom-paris.fr software heritage software integrity git version control systems Version Control Systems (VCS) like Git allow developers to locally rewrite recorded history, e.g., to reorder and suppress commits or specific data in them. These alterations have legitimate use cases, but become problematic when performed on public branches that have downstream users: they break push/pull workflows, challenge the integrity and reproducibility of repositories, and create opportunities for supply chain attackers to sneak into them nefarious changes. We conduct the first large-scale investigation of Git history alterations in public code repositories. We analyze 111 M (millions) repositories archived by Software Heritage, which preserves VCS histories even across alterations. We find history alterations in 1.22 M repositories, for a total of 8.7 M rewritten histories. We categorize changes by where they happen (which repositories, which branches) and what is changed in them (files or commit metadata). Conducting two targeted case studies we show that altered histories recurrently change licenses retroactively, or are used to remove \"secrets\" (e.g., private keys) committed by mistake. As these behaviors correspond to bad practices - in terms of project governance or security management, respectively - that software recipients might want to avoid, we introduce GitHistorian, an automated tool, that developers can use to spot and describe history alterations in public Git repositories.",
							"pageNumber": 2183,
							"isPageNumberRoman": false
						},
						{
							"eid": "5rDJY2alFTZqpOLQzN0uuz",
							"type": "authorPaper",
							"text": "Generating Failure-Based Oracles to Support Testing of Reported Bugs in Android Apps",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c195/573300c195.pdf",
							"extraLocations": [],
							"authorNames": "Jack Johnson (University of Minnesota, USA), Junayed Mahmud (University of Central Florida, USA), Oscar Chaparro (William & Mary, USA), Kevin Moran (University of Central Florida, USA), Mattia Fazzini (University of Minnesota, USA)",
							"abstract": "In the context of mobile apps, bug report management tasks have been shown to be among the most time-consuming and intellectually intensive software maintenance activities. As such, researchers have developed tools to automate the reproduction, validation, and localization of reported bugs. However, one complex, time-consuming, and important task that lacks automated support is the creation of test oracles for reported functional failures that manifest through the GUI. This is challenging task\u2014requiring nuanced, multi-modal reasoning about bug descriptions, affected GUI components, and the characteristics of the related erroneous program state(s). To explore the feasibility of automating this task, we conduct an empirical investigation into how the multi-modal (i.e., text and GUI-related code) reasoning capabilities of Large Language Models (LLMs) can be used to automatically generate assertion-based test oracles for non-crashing, functional failures described in Android app bug reports. Building upon the findings of this study, we construct and evaluate AndroB2O, an automated, LLM-based approach that, given a bug report and the GUI screen associated with the reported failure as inputs, generates failure-based oracles (FBOs) in the form of test assertions. The approach first identifies the GUI elements related to the failure and then defines assertions that aim to confirm the absence of the failure based on the elements' properties. To evaluate AndroB2O, we create the first dataset of Android bug reports containing test cases with GUI interactions and test oracles that reveal reported failures. The results of our evaluation on 152 failures show that AndroB2O is able to generate FBOs that successfully identify the failure (and hence can confirm its absence) in 61.2% of the cases. We integrated AndroB2O with ReBL, a failure reproduction tool, to evaluate its effectiveness in automated generation of test cases complete with oracles for reported failures, and obtained promising results.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Generating Failure-Based Oracles to Support Testing of Reported Bugs in Android Apps 1759527101647 10.1109/ASE63991.2025.00182 Jack Johnson University of Minnesota, USA joh19267@umn.edu Junayed Mahmud University of Central Florida, USA Junayed.Mahmud@ucf.edu Oscar Chaparro William & Mary, USA oscarch@wm.edu Kevin Moran University of Central Florida, USA kpmoran@ucf.edu Mattia Fazzini University of Minnesota, USA mfazzini@umn.edu bug reports failure reproduction mobile apps In the context of mobile apps, bug report management tasks have been shown to be among the most time-consuming and intellectually intensive software maintenance activities. As such, researchers have developed tools to automate the reproduction, validation, and localization of reported bugs. However, one complex, time-consuming, and important task that lacks automated support is the creation of test oracles for reported functional failures that manifest through the GUI. This is challenging task\u2014requiring nuanced, multi-modal reasoning about bug descriptions, affected GUI components, and the characteristics of the related erroneous program state(s). To explore the feasibility of automating this task, we conduct an empirical investigation into how the multi-modal (i.e., text and GUI-related code) reasoning capabilities of Large Language Models (LLMs) can be used to automatically generate assertion-based test oracles for non-crashing, functional failures described in Android app bug reports. Building upon the findings of this study, we construct and evaluate AndroB2O, an automated, LLM-based approach that, given a bug report and the GUI screen associated with the reported failure as inputs, generates failure-based oracles (FBOs) in the form of test assertions. The approach first identifies the GUI elements related to the failure and then defines assertions that aim to confirm the absence of the failure based on the elements' properties. To evaluate AndroB2O, we create the first dataset of Android bug reports containing test cases with GUI interactions and test oracles that reveal reported failures. The results of our evaluation on 152 failures show that AndroB2O is able to generate FBOs that successfully identify the failure (and hence can confirm its absence) in 61.2% of the cases. We integrated AndroB2O with ReBL, a failure reproduction tool, to evaluate its effectiveness in automated generation of test cases complete with oracles for reported failures, and obtained promising results.",
							"pageNumber": 2195,
							"isPageNumberRoman": false
						},
						{
							"eid": "4qUYMHWrvIANYeSfTHBCop",
							"type": "authorPaper",
							"text": "LSPFuzz: Hunting Bugs in Language Servers",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c208/573300c208.pdf",
							"extraLocations": [],
							"authorNames": "Hengcheng Zhu (The Hong Kong University of Science and Technology, Hong Kong SAR), Songqiang Chen (The Hong Kong University of Science and Technology, Hong Kong SAR), Valerio Terragni (University of Auckland, New Zealand), Lili Wei (McGill University, Canada), Yepang Liu (Southern University of Science and Technology, China), Jiarong Wu (The Hong Kong University of Science and Technology, Hong Kong SAR), Shing-Chi Cheung (The Hong Kong University of Science and Technology, Hong Kong SAR)",
							"abstract": "The Language Server Protocol (LSP) has revolutionized the integration of code intelligence in modern software development. There are approximately 300 LSP server implementations for various languages and 50 editors offering LSP integration. However, the reliability of LSP servers is a growing concern, as crashes can disable all code intelligence features and significantly impact productivity, while vulnerabilities can put developers at risk even when editing untrusted source code. Despite the widespread adoption of LSP, no existing techniques specifically target LSP server testing. To bridge this gap, we present LSPFuzz, a grey-box hybrid fuzzer for systematic LSP server testing. Our key insight is that effective LSP server testing requires holistic mutation of source code and editor operations, as bugs often manifest from their combinations. To satisfy the sophisticated constraints of LSP and effectively explore the input space, we employ a two-stage mutation pipeline: syntax-aware mutations to source code, followed by context-aware dispatching of editor operations. We evaluated LSPFuzz on four widely used LSP servers. LSPFuzz demonstrated superior performance compared to baseline fuzzers, and uncovered previously unknown bugs in real-world LSP servers. Of the 51 bugs we reported, 42 have been confirmed, 26 have been fixed by developers, and two have been assigned CVE numbers. Our work advances the quality assurance of LSP servers, providing both a practical tool and foundational insights for future research in this domain.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 LSPFuzz: Hunting Bugs in Language Servers 1758861534200 10.1109/ASE63991.2025.00183 Hengcheng Zhu The Hong Kong University of Science and Technology, Hong Kong SAR hzhuaq@connect.ust.hk Songqiang Chen The Hong Kong University of Science and Technology, Hong Kong SAR i9s.chen@connect.ust.hk Valerio Terragni University of Auckland, New Zealand v.terragni@auckland.ac.nz Lili Wei McGill University, Canada liil.wei@mcgill.ca Yepang Liu Southern University of Science and Technology, China liuyp1@sustech.edu.cn Jiarong Wu The Hong Kong University of Science and Technology, Hong Kong SAR jwubf@cse.ust.hk Shing-Chi Cheung The Hong Kong University of Science and Technology, Hong Kong SAR scc@cse.ust.hk language server protocol fuzzing software testing developer tools The Language Server Protocol (LSP) has revolutionized the integration of code intelligence in modern software development. There are approximately 300 LSP server implementations for various languages and 50 editors offering LSP integration. However, the reliability of LSP servers is a growing concern, as crashes can disable all code intelligence features and significantly impact productivity, while vulnerabilities can put developers at risk even when editing untrusted source code. Despite the widespread adoption of LSP, no existing techniques specifically target LSP server testing. To bridge this gap, we present LSPFuzz, a grey-box hybrid fuzzer for systematic LSP server testing. Our key insight is that effective LSP server testing requires holistic mutation of source code and editor operations, as bugs often manifest from their combinations. To satisfy the sophisticated constraints of LSP and effectively explore the input space, we employ a two-stage mutation pipeline: syntax-aware mutations to source code, followed by context-aware dispatching of editor operations. We evaluated LSPFuzz on four widely used LSP servers. LSPFuzz demonstrated superior performance compared to baseline fuzzers, and uncovered previously unknown bugs in real-world LSP servers. Of the 51 bugs we reported, 42 have been confirmed, 26 have been fixed by developers, and two have been assigned CVE numbers. Our work advances the quality assurance of LSP servers, providing both a practical tool and foundational insights for future research in this domain.",
							"pageNumber": 2208,
							"isPageNumberRoman": false
						},
						{
							"eid": "23co7iJASPv8ZJfymkH4ra",
							"type": "authorPaper",
							"text": "LLM-Powered Multi-Agent Collaboration for Intelligent Industrial On-Call Automation",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c221/573300c221.pdf",
							"extraLocations": [],
							"authorNames": "Ruowei Fu (Nankai University, China), Yang Zhang (ByteDance Inc., China), Zeyu Che (Nankai University, China), Xin Wu (ByteDance Inc., China), Zhenyu Zhong (Nankai University, China), Zhiqiang Ren (ByteDance Inc., China), Shenglin Zhang (Nankai University, China), Feng Wang (ByteDance Inc., China), Yongqian Sun (Nankai University, China; Tianjin Key Laboratory of Software Experience and Human Computer Interaction), Xiaozhou Liu (ByteDance Inc., China), Kexin Liu (Nankai University, China), Yu Zhang (ByteDance Inc., China)",
							"abstract": "In large-scale enterprises, on-call engineers (OCEs) are critical for ensuring service availability and reliability. However, as incidents grow in volume and complexity, traditional manual on-call processes are becoming increasingly inadequate. Recent advances in large language models (LLMs) have demonstrated remarkable capabilities in reasoning and multi-agent collaboration, presenting new opportunities for automation. We propose OncallX, an end-to-end automated on-call system designed for real-world industrial scenarios that integrates LLMs with multi-agent cooperation to enable intelligent and efficient incident management. OncallX first enhances user queries by leveraging external knowledge bases and multi-turn dialogue interactions. Subsequently, multiple expert agents collaborate through tree-search-based mechanisms to generate effective responses and solutions. When incidents cannot be resolved automatically, OncallX accurately assigns them to the most appropriate teams. Comprehensive experiments conducted in the real-world production environment of a top-tier global online video service provider demonstrate that OncallX efficiently responds to incidents and accurately triages tickets, significantly outperforming existing methods in both automated metrics and human evaluations. Furthermore, OncallX has been successfully deployed in production for two months, during which it has substantially enhanced on-call efficiency, reducing average incident response time to just 21 seconds and average triage time to 4 seconds\u2014representing a transformative improvement in operational excellence.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 LLM-Powered Multi-Agent Collaboration for Intelligent Industrial On-Call Automation 1759234920965 10.1109/ASE63991.2025.00184 Ruowei Fu Nankai University, China furuowei@mail.nankai.edu.cn Yang Zhang ByteDance Inc., China zhangyang.329@bytedance.com Zeyu Che Nankai University, China chezeyu@mail.nankai.edu.cn Xin Wu ByteDance Inc., China wuxin.29@bytedance.com Zhenyu Zhong Nankai University, China zyzhong@mail.nankai.edu.cn Zhiqiang Ren ByteDance Inc., China renzhiqiang.marvin@bytedance.com Shenglin Zhang Nankai University, China zhangsl@nankai.edu.cn Feng Wang ByteDance Inc., China wangfeng.ai@bytedance.com Yongqian Sun Nankai University, China; Tianjin Key Laboratory of Software Experience and Human Computer Interaction sunyongqian@nankai.edu.cn Xiaozhou Liu ByteDance Inc., China wangding.01@bytedance.com Kexin Liu Nankai University, China liukx@mail.nankai.edu.cn Yu Zhang ByteDance Inc., China felix.zhang@bytedance.com on-call large language model multi-agent In large-scale enterprises, on-call engineers (OCEs) are critical for ensuring service availability and reliability. However, as incidents grow in volume and complexity, traditional manual on-call processes are becoming increasingly inadequate. Recent advances in large language models (LLMs) have demonstrated remarkable capabilities in reasoning and multi-agent collaboration, presenting new opportunities for automation. We propose OncallX, an end-to-end automated on-call system designed for real-world industrial scenarios that integrates LLMs with multi-agent cooperation to enable intelligent and efficient incident management. OncallX first enhances user queries by leveraging external knowledge bases and multi-turn dialogue interactions. Subsequently, multiple expert agents collaborate through tree-search-based mechanisms to generate effective responses and solutions. When incidents cannot be resolved automatically, OncallX accurately assigns them to the most appropriate teams. Comprehensive experiments conducted in the real-world production environment of a top-tier global online video service provider demonstrate that OncallX efficiently responds to incidents and accurately triages tickets, significantly outperforming existing methods in both automated metrics and human evaluations. Furthermore, OncallX has been successfully deployed in production for two months, during which it has substantially enhanced on-call efficiency, reducing average incident response time to just 21 seconds and average triage time to 4 seconds\u2014representing a transformative improvement in operational excellence.",
							"pageNumber": 2221,
							"isPageNumberRoman": false
						},
						{
							"eid": "5I85yGEI0NpgTZRGfPptRj",
							"type": "authorPaper",
							"text": "Enhancing LLM to Decompile Optimized PTX to Readable CUDA for Tensor Programs",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c234/573300c234.pdf",
							"extraLocations": [],
							"authorNames": "Xinyu Sun (University of Science and Technology of China, China), Fugen  Tang  (University of Science and Technology of China, China), Yu Zhang (University of Science and Technology of China, China), Han Shen (Kuaishou Technology, China), Chengru Song  (Kuaishou Technology, China), Di Zhang  (Kuaishou Technology, China)",
							"abstract": "The growing demand for high-performance tensor programs on GPUs, especially for large language models (LLMs), necessitates advanced compilation and optimization techniques. However, the critical task of analyzing optimized, low-level PTX code for performance tuning or understanding poses significant challenges. While LLMs hold promise for PTX-to-CUDA decompilation to improve code intelligibility, their effectiveness is severely limited by the scarcity of aligned training data and the inherent complexity of highly optimized, unrolled PTX code. In this work, we explore methodologies to significantly enhance LLM capabilities for accurate and readable PTX-to-CUDA decompilation and present PtxDec, a decompilation prototype implementing our approach. To overcome the critical barrier of data scarcity, we develop a compiler-based data augmentation framework coupled with rigorous post-processing, enabling the creation of a large-scale, high-quality dataset of 400K aligned CUDA-PTX kernel pairs for effective LLM training. Furthermore, to empower LLMs to handle the complexity of optimized PTX, we introduce Rolled-PTX\u2014an intermediate representation generated through heuristic loop rerolling during preprocessing. Rolled-PTX condenses unrolled patterns, drastically simplifying the input structure presented to the LLM and aligning it better with higher-level loop constructs. Comprehensive evaluation demonstrates that PtxDec achieves substantial performance gains: our approach yields a 2.3\u00D7\u20133.1\u00D7 improvement in functional accuracy over baseline methods, alongside significant enhancements in generated code readability and scheduling consistency with the original optimized kernels. Ablation studies further validate the contribution of each proposed component to the overall performance. To the best of our knowledge, this is the first work tackling PTX-to-CUDA decompilation, specifically focusing on and demonstrating effective strategies for augmenting LLMs to overcome the key challenges in this domain.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Enhancing LLM to Decompile Optimized PTX to Readable CUDA for Tensor Programs 1759579704570 10.1109/ASE63991.2025.00185 Xinyu Sun University of Science and Technology of China, China sunnewrain@mail.ustc.edu.cn Fugen Tang University of Science and Technology of China, China fgtang@mail.ustc.edu.cn Yu Zhang University of Science and Technology of China, China yuzhang@ustc.edu.cn Han Shen Kuaishou Technology, China shenhan03@kuaishou.com Chengru Song Kuaishou Technology, China songchengru@kuaishou.com Di Zhang Kuaishou Technology, China zhangdi08@kuaishou.com llm decompilation deep learning compiler gpu programming The growing demand for high-performance tensor programs on GPUs, especially for large language models (LLMs), necessitates advanced compilation and optimization techniques. However, the critical task of analyzing optimized, low-level PTX code for performance tuning or understanding poses significant challenges. While LLMs hold promise for PTX-to-CUDA decompilation to improve code intelligibility, their effectiveness is severely limited by the scarcity of aligned training data and the inherent complexity of highly optimized, unrolled PTX code. In this work, we explore methodologies to significantly enhance LLM capabilities for accurate and readable PTX-to-CUDA decompilation and present PtxDec, a decompilation prototype implementing our approach. To overcome the critical barrier of data scarcity, we develop a compiler-based data augmentation framework coupled with rigorous post-processing, enabling the creation of a large-scale, high-quality dataset of 400K aligned CUDA-PTX kernel pairs for effective LLM training. Furthermore, to empower LLMs to handle the complexity of optimized PTX, we introduce Rolled-PTX\u2014an intermediate representation generated through heuristic loop rerolling during preprocessing. Rolled-PTX condenses unrolled patterns, drastically simplifying the input structure presented to the LLM and aligning it better with higher-level loop constructs. Comprehensive evaluation demonstrates that PtxDec achieves substantial performance gains: our approach yields a 2.3\u00D7\u20133.1\u00D7 improvement in functional accuracy over baseline methods, alongside significant enhancements in generated code readability and scheduling consistency with the original optimized kernels. Ablation studies further validate the contribution of each proposed component to the overall performance. To the best of our knowledge, this is the first work tackling PTX-to-CUDA decompilation, specifically focusing on and demonstrating effective strategies for augmenting LLMs to overcome the key challenges in this domain.",
							"pageNumber": 2234,
							"isPageNumberRoman": false
						},
						{
							"eid": "4ucBTBSQ55Ja5D6Vojm264",
							"type": "authorPaper",
							"text": "Mixture-of-Experts Low-Rank Adaptation for Multilingual Code Summarization",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c247/573300c247.pdf",
							"extraLocations": [],
							"authorNames": "Tianchen Yu (South China University of Technology, China; MOE of China), Li Yuan (South China University of Technology, China; MOE of China), Hailing Huang (South China University of Technology, China; MOE of China), Jiexin Wang (South China University of Technology, China; MOE of China), Yi Cai (South China University of Technology, China; MOE of China)",
							"abstract": "As Code Language Models (CLMs) are increasingly used to automate multilingual code intelligence tasks, Full-Parameter Fine-Tuning (FPFT) of CLMs has become a widely adopted approach, which is both time-consuming and resource-intensive. Parameter-Efficient Fine-Tuning (PEFT) provides a more efficient alternative to FPFT. However, it struggles to capture common features shared across languages, leading to performance degradation. Recent studies have explored mixed-language training with PEFT to avoid the loss of common features. However, these methods can result in gradient conflicts due to the diverse language-specific features, causing suboptimal performance particularly for low-resource languages. In this paper, we propose Mixture-of-Experts Multilingual Low-Rank Adaptation (MMLoRA). MMLoRA addresses gradient conflicts while preserving common features shared across languages by combining a universal expert with a set of specialized linguistic experts. Additionally, we introduce an expert loss function that maintains the diversity of specialized linguistic experts while balancing the learning progress. Experimental results indicate that MMLoRA achieves state-of-the-art performance in multilingual code summarization while maintaining efficient fine-tuning. The performance improvement is particularly significant in low-resource languages such as Ruby.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Mixture-of-Experts Low-Rank Adaptation for Multilingual Code Summarization 1759372783460 10.1109/ASE63991.2025.00186 Tianchen Yu South China University of Technology, China; MOE of China seyutianchen@mail.scut.edu.cn Li Yuan South China University of Technology, China; MOE of China seyuanli@mail.scut.edu.cn Hailing Huang South China University of Technology, China; MOE of China hhl1132714358@gmail.com Jiexin Wang South China University of Technology, China; MOE of China jiexinwang@scut.edu.cn Yi Cai South China University of Technology, China; MOE of China ycai@scut.edu.cn code summarization low-rank adaptation mixture-of-experts As Code Language Models (CLMs) are increasingly used to automate multilingual code intelligence tasks, Full-Parameter Fine-Tuning (FPFT) of CLMs has become a widely adopted approach, which is both time-consuming and resource-intensive. Parameter-Efficient Fine-Tuning (PEFT) provides a more efficient alternative to FPFT. However, it struggles to capture common features shared across languages, leading to performance degradation. Recent studies have explored mixed-language training with PEFT to avoid the loss of common features. However, these methods can result in gradient conflicts due to the diverse language-specific features, causing suboptimal performance particularly for low-resource languages. In this paper, we propose Mixture-of-Experts Multilingual Low-Rank Adaptation (MMLoRA). MMLoRA addresses gradient conflicts while preserving common features shared across languages by combining a universal expert with a set of specialized linguistic experts. Additionally, we introduce an expert loss function that maintains the diversity of specialized linguistic experts while balancing the learning progress. Experimental results indicate that MMLoRA achieves state-of-the-art performance in multilingual code summarization while maintaining efficient fine-tuning. The performance improvement is particularly significant in low-resource languages such as Ruby.",
							"pageNumber": 2247,
							"isPageNumberRoman": false
						},
						{
							"eid": "6jjNHMYfRVguDhoXUF8uRq",
							"type": "authorPaper",
							"text": "Automated Repair of OpenID Connect Programs",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c260/573300c260.pdf",
							"extraLocations": [],
							"authorNames": "Tamjid Al Rahat (University of California, Los Angeles), Yanju Chen (University of California, San Diego), Yu Feng (University of California, Santa Barbara), Yuan Tian (University of California, Los Angeles)",
							"abstract": "OpenID Connect has revolutionized online authentication based on single sign-on (SSO) by providing a secure and convenient method for accessing multiple services with a single set of credentials. Despite its widespread adoption, critical security bugs in OpenID Connect have resulted in significant financial losses and security breaches, highlighting the need for robust mitigation strategies. Automated program repair presents a promising solution for generating candidate patches for OpenID implementations. However, challenges such as domain-specific complexities and the necessity for precise fault localization and patch verification must be addressed. We propose AuthFix, a counterexample-guided repair engine leveraging LLMs for automated OpenID bug fixing. AuthFix integrates three key components: fault localization, patch synthesis, and patch verification. By employing a novel Petri-net-based model checker, AuthFix ensures the correctness of patches by effectively modeling interactions. Our evaluation on a dataset of OpenID bugs demonstrates that AuthFix successfully generated correct patches for 17 out of 23 bugs (74%), with a high proportion of patches semantically equivalent to developer-written fixes. ",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Automated Repair of OpenID Connect Programs 1759424569548 10.1109/ASE63991.2025.00187 Tamjid Al Rahat University of California, Los Angeles tamjid@ucla.edu Yanju Chen University of California, San Diego yanju@ucsd.edu Yu Feng University of California, Santa Barbara yufeng@cs.ucsb.edu Yuan Tian University of California, Los Angeles yuant@ucla.edu openid program repair OpenID Connect has revolutionized online authentication based on single sign-on (SSO) by providing a secure and convenient method for accessing multiple services with a single set of credentials. Despite its widespread adoption, critical security bugs in OpenID Connect have resulted in significant financial losses and security breaches, highlighting the need for robust mitigation strategies. Automated program repair presents a promising solution for generating candidate patches for OpenID implementations. However, challenges such as domain-specific complexities and the necessity for precise fault localization and patch verification must be addressed. We propose AuthFix, a counterexample-guided repair engine leveraging LLMs for automated OpenID bug fixing. AuthFix integrates three key components: fault localization, patch synthesis, and patch verification. By employing a novel Petri-net-based model checker, AuthFix ensures the correctness of patches by effectively modeling interactions. Our evaluation on a dataset of OpenID bugs demonstrates that AuthFix successfully generated correct patches for 17 out of 23 bugs (74%), with a high proportion of patches semantically equivalent to developer-written fixes.",
							"pageNumber": 2260,
							"isPageNumberRoman": false
						},
						{
							"eid": "7w2VgpSP0i7HIcXAV4XLDM",
							"type": "authorPaper",
							"text": "Latra: A Template-Based Language-Agnostic Transformation Framework for Effective Program Reduction",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c273/573300c273.pdf",
							"extraLocations": [],
							"authorNames": "Zhenyang Xu (University of Waterloo, Canada), Yiran Wang (University of Waterloo, Canada), Yongqiang Tian (Monash University, Australia), Mengxiao Zhang (University of Waterloo, Canada), Chengnian Sun (University of Waterloo, Canada)",
							"abstract": "Essential for debugging compilers and interpreters, existing reduction tools face a fundamental trade-off. Language-specific reducers, such as C-Reduce and ddSMT, offer highly effective reductions but require substantial engineering effort for each target language. Conversely, language-agnostic reducers, like Vulcan, sacrifice effectiveness for broad applicability. To bridge this gap, we present Latra, a novel template-based framework that balances both aspects, enabling general, effective, targeted program reduction. Latra combines language-agnostic reduction with user-defined, language-specific transformations. It facilitates user-defined transformations through a user-friendly domain-specific language based on simple matching and rewriting templates. This minimizes the need for deep formal grammar knowledge. Latra empowers users to tailor reductions to specific languages with reduced implementation overhead. Our evaluation shows that Latra significantly outperforms Vulcan. On average, it reduces 33.77% more tokens in C and 9.17% more tokens in SMT-LIB, with 32.27% faster execution in SMT-LIB. Notably, Latra closely matches the effectiveness of language-specific reducers, i.e., C-Reduce and ddSMT (89 vs. 85, 103 vs. 109 tokens on average), while significantly reducing engineering effort (167 vs. 5,685, 62 vs. 118 lines of code). We strongly believe that Latra provides a practical and cost-efficient approach to program reduction, effectively balancing language-specific effectiveness with language-agnostic generality.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Latra: A Template-Based Language-Agnostic Transformation Framework for Effective Program Reduction 1759380585287 10.1109/ASE63991.2025.00188 Zhenyang Xu University of Waterloo, Canada zhenyang.xu@uwaterloo.ca Yiran Wang University of Waterloo, Canada y443wang@uwaterloo.ca Yongqiang Tian Monash University, Australia yongqiang.tian@monash.edu Mengxiao Zhang University of Waterloo, Canada m492zhan@uwaterloo.ca Chengnian Sun University of Waterloo, Canada cnsun@uwaterloo.ca Program Reduction Test Case Minimization Essential for debugging compilers and interpreters, existing reduction tools face a fundamental trade-off. Language-specific reducers, such as C-Reduce and ddSMT, offer highly effective reductions but require substantial engineering effort for each target language. Conversely, language-agnostic reducers, like Vulcan, sacrifice effectiveness for broad applicability. To bridge this gap, we present Latra, a novel template-based framework that balances both aspects, enabling general, effective, targeted program reduction. Latra combines language-agnostic reduction with user-defined, language-specific transformations. It facilitates user-defined transformations through a user-friendly domain-specific language based on simple matching and rewriting templates. This minimizes the need for deep formal grammar knowledge. Latra empowers users to tailor reductions to specific languages with reduced implementation overhead. Our evaluation shows that Latra significantly outperforms Vulcan. On average, it reduces 33.77% more tokens in C and 9.17% more tokens in SMT-LIB, with 32.27% faster execution in SMT-LIB. Notably, Latra closely matches the effectiveness of language-specific reducers, i.e., C-Reduce and ddSMT (89 vs. 85, 103 vs. 109 tokens on average), while significantly reducing engineering effort (167 vs. 5,685, 62 vs. 118 lines of code). We strongly believe that Latra provides a practical and cost-efficient approach to program reduction, effectively balancing language-specific effectiveness with language-agnostic generality.",
							"pageNumber": 2273,
							"isPageNumberRoman": false
						},
						{
							"eid": "3JHwazSIAA3ZCdIEy0DPYc",
							"type": "authorPaper",
							"text": "Faster Runtime Verification During Testing via Feedback-Guided Selective Monitoring",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c285/573300c285.pdf",
							"extraLocations": [],
							"authorNames": "Shinhae Kim (Cornell University, USA), Saikat Dutta (Cornell University, USA), Owolabi Legunsen (Cornell University, USA)",
							"abstract": "Runtime verification (RV) uses monitors, which are dynamically synthesized from formal specifications (specs), to check running programs against specs. RV of passing tests in many open-source projects found hundreds of new bugs. But, high overheads make it hard to use RV for testing in practice. We propose Valg, the first on-the-fly selective RV technique for testing, and the first to use reinforcement learning (RL) to speed up RV. Valg leverages a recent finding: 99.87% of monitors are redundant for testing; they wastefully re-check unique traces\u2014sequences of events, e.g., method calls\u2014that the other necessary 0.13% already checked. Valg uses feedback about redundancy of prior monitors and events to selectively monitor only necessary ones subsequently. A key idea in Valg is our novel formulation of selective monitor creation as a two-armed bandit RL problem that rewards necessary monitors and penalizes redundant ones. We implement Valg for Java and compare it with state-of-the-art RV tools on one revision each of 64 open-source projects. With default RL hyperparameters, Valg is up to 20.2x and 551.5x faster than JavaMOP and TraceMOP, respectively. For example, Valg takes only 11.6 minutes in total to monitor three projects where TraceMOP takes 3.02 days in total. With default RL hyperparameters, Valg finds 99.6% of spec violations found by JavaMOP and TraceMOP, but it only checks 76.7% of their unique traces on average. After tuning RL hyperparameters, Valg checks 95.1% of unique traces on average with minor loss in speed. Using tuned hyperparameters from one revision \"into the future\" as code evolves preserves Valg's high speedups and rate of checked unique traces, without needing frequent re-tuning.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Faster Runtime Verification During Testing via Feedback-Guided Selective Monitoring 1759521102922 10.1109/ASE63991.2025.00189 Shinhae Kim Cornell University, USA sk3364@cornell.edu Saikat Dutta Cornell University, USA saikatd@cornell.edu Owolabi Legunsen Cornell University, USA legunsen@cornell.edu runtime verification software testing reinforcement learning Runtime verification (RV) uses monitors, which are dynamically synthesized from formal specifications (specs), to check running programs against specs. RV of passing tests in many open-source projects found hundreds of new bugs. But, high overheads make it hard to use RV for testing in practice. We propose Valg, the first on-the-fly selective RV technique for testing, and the first to use reinforcement learning (RL) to speed up RV. Valg leverages a recent finding: 99.87% of monitors are redundant for testing; they wastefully re-check unique traces\u2014sequences of events, e.g., method calls\u2014that the other necessary 0.13% already checked. Valg uses feedback about redundancy of prior monitors and events to selectively monitor only necessary ones subsequently. A key idea in Valg is our novel formulation of selective monitor creation as a two-armed bandit RL problem that rewards necessary monitors and penalizes redundant ones. We implement Valg for Java and compare it with state-of-the-art RV tools on one revision each of 64 open-source projects. With default RL hyperparameters, Valg is up to 20.2x and 551.5x faster than JavaMOP and TraceMOP, respectively. For example, Valg takes only 11.6 minutes in total to monitor three projects where TraceMOP takes 3.02 days in total. With default RL hyperparameters, Valg finds 99.6% of spec violations found by JavaMOP and TraceMOP, but it only checks 76.7% of their unique traces on average. After tuning RL hyperparameters, Valg checks 95.1% of unique traces on average with minor loss in speed. Using tuned hyperparameters from one revision \"into the future\" as code evolves preserves Valg's high speedups and rate of checked unique traces, without needing frequent re-tuning.",
							"pageNumber": 2285,
							"isPageNumberRoman": false
						},
						{
							"eid": "6P2eilsFWpM9qCqT97rfiI",
							"type": "authorPaper",
							"text": "FastCoder: Accelerating Repository-Level Code Generation via Efficient Retrieval and Verification",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c298/573300c298.pdf",
							"extraLocations": [],
							"authorNames": "Qianhui Zhao (Beihang University, China), Li Zhang (Beihang University, China), Fang Liu (Beihang University, China), Xiaoli Lian (Beihang University, China), Qiaoyuanhe Meng (Beihang University, China), Ziqian Jiao (Beihang University, China), Zetong Zhou (Beihang University, China), Jia Li (Peking University, China), Lin Shi (Beihang University, China)",
							"abstract": "Code generation is a latency-sensitive task that demands high timeliness. However, with the growing interest and inherent difficulty in repository-level code generation, most existing code generation studies focus on improving the correctness of generated code while overlooking the inference efficiency, which is substantially affected by the overhead during LLM generation. Although there has been work on accelerating LLM inference, these approaches are not tailored to the specific characteristics of code generation; instead, they treat code the same as natural language sequences and ignore its unique syntax and semantic characteristics, which are also crucial for improving efficiency. Consequently, these approaches exhibit limited effectiveness in code generation tasks, particularly for repository-level scenarios with considerable complexity and difficulty. To alleviate this issue, following draft-verification paradigm, we propose FastCoder, a simple yet highly efficient inference acceleration approach specifically designed for code generation, without compromising the quality of the output. FastCoder constructs a multi-source datastore, providing access to both general and project-specific knowledge, facilitating the retrieval of high-quality draft sequences. Moreover, FastCoder reduces the retrieval cost by controlling retrieval timing, and enhances efficiency through parallel retrieval and a context- and LLM preference-aware cache. Experimental results show that FastCoder can reach up to 2.53x and 2.54x speedup compared to autoregressive decoding in repository-level and standalone code generation tasks, respectively, outperforming state-of-the-art inference acceleration approaches by up to 88%. FastCoder can also be integrated with existing correctness-focused code generation approaches to accelerate the LLM generation process, and reach a speedup exceeding 2.6x.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 FastCoder: Accelerating Repository-Level Code Generation via Efficient Retrieval and Verification 1759050710617 10.1109/ASE63991.2025.00190 Qianhui Zhao Beihang University, China zhaoqianhui@buaa.edu.cn Li Zhang Beihang University, China lily@buaa.edu.cn Fang Liu Beihang University, China fangliu@buaa.edu.cn Xiaoli Lian Beihang University, China lianxiaoli@buaa.edu.cn Qiaoyuanhe Meng Beihang University, China mengqiaoyuanhe@buaa.edu.cn Ziqian Jiao Beihang University, China jiaoziqian@buaa.edu.cn Zetong Zhou Beihang University, China 3306921258@buaa.edu.cn Jia Li Peking University, China lijiaa@pku.edu.cn Lin Shi Beihang University, China shilin@buaa.edu.cn Code generation is a latency-sensitive task that demands high timeliness. However, with the growing interest and inherent difficulty in repository-level code generation, most existing code generation studies focus on improving the correctness of generated code while overlooking the inference efficiency, which is substantially affected by the overhead during LLM generation. Although there has been work on accelerating LLM inference, these approaches are not tailored to the specific characteristics of code generation; instead, they treat code the same as natural language sequences and ignore its unique syntax and semantic characteristics, which are also crucial for improving efficiency. Consequently, these approaches exhibit limited effectiveness in code generation tasks, particularly for repository-level scenarios with considerable complexity and difficulty. To alleviate this issue, following draft-verification paradigm, we propose FastCoder, a simple yet highly efficient inference acceleration approach specifically designed for code generation, without compromising the quality of the output. FastCoder constructs a multi-source datastore, providing access to both general and project-specific knowledge, facilitating the retrieval of high-quality draft sequences. Moreover, FastCoder reduces the retrieval cost by controlling retrieval timing, and enhances efficiency through parallel retrieval and a context- and LLM preference-aware cache. Experimental results show that FastCoder can reach up to 2.53x and 2.54x speedup compared to autoregressive decoding in repository-level and standalone code generation tasks, respectively, outperforming state-of-the-art inference acceleration approaches by up to 88%. FastCoder can also be integrated with existing correctness-focused code generation approaches to accelerate the LLM generation process, and reach a speedup exceeding 2.6x.",
							"pageNumber": 2298,
							"isPageNumberRoman": false
						},
						{
							"eid": "2yZn1YsMksE6QgGVnClaW1",
							"type": "authorPaper",
							"text": "Effective Code Membership Inference for Code Completion Models via Adversarial Prompts",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c311/573300c311.pdf",
							"extraLocations": [],
							"authorNames": "Yuan Jiang (Harbin Institute of Technology, China), Zehao Li (Harbin Institute of Technology, China), Shan Huang (Harbin Institute of Technology, China), Christoph Treude (Singapore Management University, Singapore), Xiaohong Su (Harbin Institute of Technology, China), Tiantian Wang (Harbin Institute of Technology, China)",
							"abstract": "Membership inference attacks (MIAs) on code completion models offer an effective way to assess privacy risks by inferring whether a given code snippet was part of the training data. Existing black- and gray-box MIAs rely on expensive surrogate models or manually crafted heuristic rules, which limit their ability to capture the nuanced memorization patterns exhibited by over-parameterized code language models. To address these challenges, we propose AdvPrompt-MIA, a method specifically designed for code completion models, combining code-specific adversarial perturbations with deep learning. The core novelty of our method lies in designing a series of adversarial prompts that induce variations in the victim code model's output. By comparing these outputs with the ground-truth completion, we construct feature vectors to train a classifier that automatically distinguishes member from non-member samples. This design allows our method to capture richer memorization patterns and accurately infer training set membership. We conduct comprehensive evaluations on widely adopted models, such as Code Llama 7B, over the APPS and HumanEval benchmarks. The results show that our approach consistently outperforms state-of-the-art baselines, with AUC gains of up to 102%. In addition, our method exhibits strong transferability across different models and datasets, underscoring its practical utility and generalizability.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Effective Code Membership Inference for Code Completion Models via Adversarial Prompts 1759412248590 10.1109/ASE63991.2025.00191 Yuan Jiang Harbin Institute of Technology, China jiangyuan@hit.edu.cn Zehao Li Harbin Institute of Technology, China 2021110768@stu.hit.edu.cn Shan Huang Harbin Institute of Technology, China 2022110145@stu.hit.edu.cn Christoph Treude Singapore Management University, Singapore ctreude@smu.edu.sg Xiaohong Su Harbin Institute of Technology, China sxh@hit.edu.cn Tiantian Wang Harbin Institute of Technology, China wangtiantian@hit.edu.cn code llms membership inference attacks adversarial prompts robustness Membership inference attacks (MIAs) on code completion models offer an effective way to assess privacy risks by inferring whether a given code snippet was part of the training data. Existing black- and gray-box MIAs rely on expensive surrogate models or manually crafted heuristic rules, which limit their ability to capture the nuanced memorization patterns exhibited by over-parameterized code language models. To address these challenges, we propose AdvPrompt-MIA, a method specifically designed for code completion models, combining code-specific adversarial perturbations with deep learning. The core novelty of our method lies in designing a series of adversarial prompts that induce variations in the victim code model's output. By comparing these outputs with the ground-truth completion, we construct feature vectors to train a classifier that automatically distinguishes member from non-member samples. This design allows our method to capture richer memorization patterns and accurately infer training set membership. We conduct comprehensive evaluations on widely adopted models, such as Code Llama 7B, over the APPS and HumanEval benchmarks. The results show that our approach consistently outperforms state-of-the-art baselines, with AUC gains of up to 102%. In addition, our method exhibits strong transferability across different models and datasets, underscoring its practical utility and generalizability.",
							"pageNumber": 2311,
							"isPageNumberRoman": false
						},
						{
							"eid": "3AsJGo4aObgGXxswKwFRKg",
							"type": "authorPaper",
							"text": "SPICE\uD83C\uDF36\uFE0F: An Automated SWE-Bench Labeling Pipeline for Issue Clarity, Test Coverage, and Effort Estimation",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c324/573300c324.pdf",
							"extraLocations": [],
							"authorNames": "Gustavo A. Oliva (Queen\u2019s University, Canada), Gopi Krishnan Rajbahadur (Queen\u2019s University, Canada), Aaditya Bhatia (Queen's University, Canada), Haoxiang Zhang (Center for Software Excellence, Huawei Canada), Yihao Chen (Center for Software Excellence, Huawei Canada), Zhilong Chen (Center for Software Excellence, Huawei Canada), Arthur Leung (Center for Software Excellence, Huawei Canada), Dayi Lin (Center for Software Excellence, Huawei Canada), Boyuan  Chen (Center for Software Excellence, Huawei Canada), Ahmed E. Hassan (Queen\u2019s University, Canada)",
							"abstract": "High-quality labeled datasets are crucial for training and evaluating foundation models in software engineering, but creating them is often prohibitively expensive and labor-intensive. We introduce SPICE, a scalable, automated pipeline for labeling SWE-bench-style datasets with annotations for issue clarity, test coverage, and effort estimation. SPICE combines context-aware code navigation, rationale-driven prompting, and multi-pass consensus to produce labels that closely approximate expert annotations. SPICE's design was informed by our own experience and frustration in labeling more than 800 instances from SWE-Gym. SPICE achieves strong agreement with human-labeled SWE-bench Verified data while reducing the cost of labeling 1,000 instances from around $100,000 (manual annotation) to only $5.10. These results demonstrate SPICE's potential to enable cost-effective, large-scale dataset creation for SE-focused FMs. To support the community, we release both SPICE\uD83C\uDF36\uFE0F tool and SPICE\uD83C\uDF36\uFE0F Bench, a new dataset of 6,802 SPICE-labeled instances curated from 291 open-source projects in SWE-Gym (over 13x larger than SWE-bench Verified). ",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 SPICE\uD83C\uDF36\uFE0F: An Automated SWE-Bench Labeling Pipeline for Issue Clarity, Test Coverage, and Effort Estimation 1759514856996 10.1109/ASE63991.2025.00192 Gustavo A. Oliva Queen\u2019s University, Canada gustavo@cs.queensu.ca Gopi Krishnan Rajbahadur Queen\u2019s University, Canada grajbahadur@acm.org Aaditya Bhatia Queen's University, Canada aaditya.bhatia@cs.queensu.ca Haoxiang Zhang Center for Software Excellence, Huawei Canada haoxiang.zhang@huawei.com Yihao Chen Center for Software Excellence, Huawei Canada yihao.chen@huawei.com Zhilong Chen Center for Software Excellence, Huawei Canada zhilong.chen@huawei.com Arthur Leung Center for Software Excellence, Huawei Canada arthur.leung1@huawei.com Dayi Lin Center for Software Excellence, Huawei Canada dayi.lin@huawei.com Boyuan Chen Center for Software Excellence, Huawei Canada boyuan.chen1@huawei.com Ahmed E. Hassan Queen\u2019s University, Canada ahmed@cs.queensu.ca data labeling code llm pretraining finetuning swe-bench benchmark High-quality labeled datasets are crucial for training and evaluating foundation models in software engineering, but creating them is often prohibitively expensive and labor-intensive. We introduce SPICE, a scalable, automated pipeline for labeling SWE-bench-style datasets with annotations for issue clarity, test coverage, and effort estimation. SPICE combines context-aware code navigation, rationale-driven prompting, and multi-pass consensus to produce labels that closely approximate expert annotations. SPICE's design was informed by our own experience and frustration in labeling more than 800 instances from SWE-Gym. SPICE achieves strong agreement with human-labeled SWE-bench Verified data while reducing the cost of labeling 1,000 instances from around $100,000 (manual annotation) to only $5.10. These results demonstrate SPICE's potential to enable cost-effective, large-scale dataset creation for SE-focused FMs. To support the community, we release both SPICE\uD83C\uDF36\uFE0F tool and SPICE\uD83C\uDF36\uFE0F Bench, a new dataset of 6,802 SPICE-labeled instances curated from 291 open-source projects in SWE-Gym (over 13x larger than SWE-bench Verified).",
							"pageNumber": 2324,
							"isPageNumberRoman": false
						},
						{
							"eid": "1sMHNdQTXtlFrn4jkPxXUB",
							"type": "authorPaper",
							"text": "On the Correctness of Software Merge",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c337/573300c337.pdf",
							"extraLocations": [],
							"authorNames": "Akira Mori (National Institute of Advanced Industrial Science and Technology, Japan), Masatomo Hashimoto (Chiba Institute of Technology, Japan)",
							"abstract": "Three-way merge tools play crucial roles in modern software development, where a developer forks a branch to make local modifications and requests it to be merged into the main branch via a \"pull request.\" Despite its importance, the task has traditionally been defined in an intuitive manner, and the results of merge tools are often accepted without scrutiny. In this paper, we present a new structural merge tool in comparison with existing tools based on the syntactic criteria we propose for evaluating the merge results. We require the merge result to be both parsable and universal. Being parsable means that the result is syntactically valid according to the grammar of the programming language. Being universal means that the result incorporates all and only the edit operations occurring in each branch while ensuring that edits common to both branches are applied only once. This requirement can be precisely defined using the notion of pushouts in category theory. In a large-scale experiment involving 43,774 file merge scenarios from 76 open-source Java projects, we found a number of incorrect results reported by existing tools such as the Git companion merge tool, whereas our tool reports none. We further compared d3j's results with 2,582 developer-resolved merges and with 2,459 merge scenarios involving 21 refactoring types. These experiments revealed both the strengths and current limitations of structural merge, and underscore the importance of clear correctness criteria. We expect that the proposed criterion will provide a foundation for developing more reliable and principled merge tools.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 On the Correctness of Software Merge 1759572589181 10.1109/ASE63991.2025.00193 Akira Mori National Institute of Advanced Industrial Science and Technology, Japan a-mori@aist.go.jp Masatomo Hashimoto Chiba Institute of Technology, Japan m.hashimoto@stair.center three-way merge abstract syntax tree (ast) ast comparison correctness criterion pushouts category theory universal property partial inclusion map Three-way merge tools play crucial roles in modern software development, where a developer forks a branch to make local modifications and requests it to be merged into the main branch via a \"pull request.\" Despite its importance, the task has traditionally been defined in an intuitive manner, and the results of merge tools are often accepted without scrutiny. In this paper, we present a new structural merge tool in comparison with existing tools based on the syntactic criteria we propose for evaluating the merge results. We require the merge result to be both parsable and universal. Being parsable means that the result is syntactically valid according to the grammar of the programming language. Being universal means that the result incorporates all and only the edit operations occurring in each branch while ensuring that edits common to both branches are applied only once. This requirement can be precisely defined using the notion of pushouts in category theory. In a large-scale experiment involving 43,774 file merge scenarios from 76 open-source Java projects, we found a number of incorrect results reported by existing tools such as the Git companion merge tool, whereas our tool reports none. We further compared d3j's results with 2,582 developer-resolved merges and with 2,459 merge scenarios involving 21 refactoring types. These experiments revealed both the strengths and current limitations of structural merge, and underscore the importance of clear correctness criteria. We expect that the proposed criterion will provide a foundation for developing more reliable and principled merge tools.",
							"pageNumber": 2337,
							"isPageNumberRoman": false
						},
						{
							"eid": "5X1deJpJJ589RJx1VEWEJy",
							"type": "authorPaper",
							"text": "Incremental Program Analysis in the Wild: An Empirical Study on Real-World Program Changes",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c349/573300c349.pdf",
							"extraLocations": [],
							"authorNames": "Xizao Wang (Nanjing University, China), Xiangrong Bin (Nanjing University, China), Lanxin Huang (Nanjing University, China), Shangqing Liu (Nanjing University, China), Jianhua Zhao (Nanjing University, China), Lei Bu (Nanjing University, China)",
							"abstract": "Incremental program analysis (IPA) has gained increasing attention as an effective approach for maintaining up-to-date analysis results by leveraging previously computed results in response to program changes. Consequently, a variety of IPA algorithms and tools have been proposed. However, their empirical performance in practical, real-world scenarios remains insufficiently investigated. To address this gap, this study presents a comprehensive examination of the current state-of-the-art in IPA evaluation. Specifically, we identify two key limitations: (1) the lack of standardized benchmarks reflecting real-world program changes, and (2) the inadequacy and imbalanced distribution of evaluation metrics. To overcome these challenges, we propose an automated pipeline for constructing real-world program change benchmarks and develop a unified incremental evaluation framework for systematically evaluating IPA tools. Using the proposed evaluation pipeline, we constructed large-scale benchmarks of real-world program changes\u2014sourced from 4,084 commits across 20 Java projects\u2014and systematically evaluated two IPA tools for Java. The results demonstrate that, although incremental analysis substantially improves efficiency compared to exhaustive analysis, existing IPA tools exhibit inconsistencies and markedly higher peak memory consumption. Finally, we distill practical insights from our findings to inform future research and development in the field of incremental program analysis.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Incremental Program Analysis in the Wild: An Empirical Study on Real-World Program Changes 1759573920980 10.1109/ASE63991.2025.00194 Xizao Wang Nanjing University, China wangxiz@smail.nju.edu.cn Xiangrong Bin Nanjing University, China xrbin@smail.nju.edu.cn Lanxin Huang Nanjing University, China lanxinhuang@smail.nju.edu.cn Shangqing Liu Nanjing University, China shangqingliu@nju.edu.cn Jianhua Zhao Nanjing University, China zhaojh@nju.edu.cn Lei Bu Nanjing University, China bulei@nju.edu.cn incremental program analysis empirical study Incremental program analysis (IPA) has gained increasing attention as an effective approach for maintaining up-to-date analysis results by leveraging previously computed results in response to program changes. Consequently, a variety of IPA algorithms and tools have been proposed. However, their empirical performance in practical, real-world scenarios remains insufficiently investigated. To address this gap, this study presents a comprehensive examination of the current state-of-the-art in IPA evaluation. Specifically, we identify two key limitations: (1) the lack of standardized benchmarks reflecting real-world program changes, and (2) the inadequacy and imbalanced distribution of evaluation metrics. To overcome these challenges, we propose an automated pipeline for constructing real-world program change benchmarks and develop a unified incremental evaluation framework for systematically evaluating IPA tools. Using the proposed evaluation pipeline, we constructed large-scale benchmarks of real-world program changes\u2014sourced from 4,084 commits across 20 Java projects\u2014and systematically evaluated two IPA tools for Java. The results demonstrate that, although incremental analysis substantially improves efficiency compared to exhaustive analysis, existing IPA tools exhibit inconsistencies and markedly higher peak memory consumption. Finally, we distill practical insights from our findings to inform future research and development in the field of incremental program analysis.",
							"pageNumber": 2349,
							"isPageNumberRoman": false
						},
						{
							"eid": "5XEEn9hMxCwB7jcwDuvSrw",
							"type": "authorPaper",
							"text": "Polyglot: An Extensible Framework to Benchmark Code Translation with LLMs",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c362/573300c362.pdf",
							"extraLocations": [],
							"authorNames": "Marco Vieira (University of North Carolina at Charlotte, USA), Priyam Ashish Shah (University of North Carolina, USA), Bhavain Shah (University of North Carolina, USA), Rrezarta Krasniqi (University of North Carolina, USA)",
							"abstract": "Large Language Models (LLMs) show great potential for automating code-related tasks. However, sound assessments are necessary to understand their true capabilities, particularly in code translation, where reliability is crucial. This paper studies the performance of LLMs in code translation by introducing a well-defined, automated, multi-language framework, referred to as Polyglot, that is adaptable to various programming languages and translation scenarios. Leveraging the IBM CodeNet Project, an extensive collection of coding problems in multiple languages, we assess translation quality using syntactic correctness, execution reliability, semantic preservation, and static code metrics. Our evaluation focuses on translating C to Java, Python, and Rust, languages that follow distinct paradigms and represent alternatives to modernize C-based systems. We evaluate open-source LLMs using three prompting strategies to understand the impact on translation performance. Our findings highlight that while LLMs show promising results for simple code translation, their limitations regarding complex logic and distinct language paradigms require further analysis.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Polyglot: An Extensible Framework to Benchmark Code Translation with LLMs 1759365037225 10.1109/ASE63991.2025.00195 Marco Vieira University of North Carolina at Charlotte, USA marco.vieira@charlotte.edu Priyam Ashish Shah University of North Carolina, USA pshah75@charlotte.edu Bhavain Shah University of North Carolina, USA bshah17@charlotte.edu Rrezarta Krasniqi University of North Carolina, USA rrezarta.krasniqi@charlotte.edu code translation llm for code code quality Large Language Models (LLMs) show great potential for automating code-related tasks. However, sound assessments are necessary to understand their true capabilities, particularly in code translation, where reliability is crucial. This paper studies the performance of LLMs in code translation by introducing a well-defined, automated, multi-language framework, referred to as Polyglot, that is adaptable to various programming languages and translation scenarios. Leveraging the IBM CodeNet Project, an extensive collection of coding problems in multiple languages, we assess translation quality using syntactic correctness, execution reliability, semantic preservation, and static code metrics. Our evaluation focuses on translating C to Java, Python, and Rust, languages that follow distinct paradigms and represent alternatives to modernize C-based systems. We evaluate open-source LLMs using three prompting strategies to understand the impact on translation performance. Our findings highlight that while LLMs show promising results for simple code translation, their limitations regarding complex logic and distinct language paradigms require further analysis.",
							"pageNumber": 2362,
							"isPageNumberRoman": false
						},
						{
							"eid": "7B3k9h7Zb7756rKXKDKQJ",
							"type": "authorPaper",
							"text": "Interleaved Learning and Exploration: A Self-Adaptive Fuzz Testing Framework for MLIR",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c375/573300c375.pdf",
							"extraLocations": [],
							"authorNames": "Zeyu Sun (Chinese Academy of Sciences, China), Jingjing Liang (East China Normal University, China), Weiyi Wang (Chinese Academy of Sciences, China), Chenyao Suo (Tianjin University, China), Junjie Chen (Tianjin University, China), Fanjiang Xu (Chinese Academy of Sciences, China)",
							"abstract": "MLIR (Multi-Level Intermediate Representation) has rapidly become a foundational technology for modern com- piler frameworks, enabling extensibility across diverse domains. However, ensuring the correctness and robustness of MLIR itself remains challenging. Existing fuzzing approaches\u2014based on manually crafted templates or rule-based mutations\u2014struggle to generate sufficiently diverse and semantically valid test cases, making it difficult to expose subtle or deep-seated bugs within MLIR's complex and evolving code space. In this paper, we present FLEX, a novel self-adaptive fuzzing framework for MLIR. FLEX leverages neural networks for program generation, a perturbed sampling strategy to encourage diversity, and a feedback-driven augmentation loop that iteratively improves its model using both crashing and non-crashing test cases. Starting from a limited seed corpus, FLEX progressively learns valid syntax and semantics and autonomously produces high-quality test inputs. We evaluate FLEX on the upstream MLIR compiler against four state-of-the-art fuzzers. In a 30-day campaign, FLEX discovers 80 previously unknown bugs\u2014including multiple new root causes and parser bugs\u2014while in 24-hour fixed-revision comparisons, it detects 53 bugs (over 3.5\u00D7 as many as the best baseline) and achieves 28.2% code coverage, outperforming the next-best tool by 42%. Ablation studies further confirm the critical role of both perturbed generation and diversity augmentation in FLEX's effectiveness.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Interleaved Learning and Exploration: A Self-Adaptive Fuzz Testing Framework for MLIR 1759217961297 10.1109/ASE63991.2025.00196 Zeyu Sun Chinese Academy of Sciences, China zeyu.zys@gmail.com Jingjing Liang East China Normal University, China jjliang@sei.ecnu.edu.cn Weiyi Wang Chinese Academy of Sciences, China wangweiyi@iscas.ac.cn Chenyao Suo Tianjin University, China chenyaosuo@tju.edu.cn Junjie Chen Tianjin University, China junjiechen@tju.edu.cn Fanjiang Xu Chinese Academy of Sciences, China fanjiang@iscas.ac.cn fuzz testing mlir neural networks MLIR (Multi-Level Intermediate Representation) has rapidly become a foundational technology for modern com- piler frameworks, enabling extensibility across diverse domains. However, ensuring the correctness and robustness of MLIR itself remains challenging. Existing fuzzing approaches\u2014based on manually crafted templates or rule-based mutations\u2014struggle to generate sufficiently diverse and semantically valid test cases, making it difficult to expose subtle or deep-seated bugs within MLIR's complex and evolving code space. In this paper, we present FLEX, a novel self-adaptive fuzzing framework for MLIR. FLEX leverages neural networks for program generation, a perturbed sampling strategy to encourage diversity, and a feedback-driven augmentation loop that iteratively improves its model using both crashing and non-crashing test cases. Starting from a limited seed corpus, FLEX progressively learns valid syntax and semantics and autonomously produces high-quality test inputs. We evaluate FLEX on the upstream MLIR compiler against four state-of-the-art fuzzers. In a 30-day campaign, FLEX discovers 80 previously unknown bugs\u2014including multiple new root causes and parser bugs\u2014while in 24-hour fixed-revision comparisons, it detects 53 bugs (over 3.5\u00D7 as many as the best baseline) and achieves 28.2% code coverage, outperforming the next-best tool by 42%. Ablation studies further confirm the critical role of both perturbed generation and diversity augmentation in FLEX's effectiveness.",
							"pageNumber": 2375,
							"isPageNumberRoman": false
						},
						{
							"eid": "4EIvZbySIoLc2jWGkYb4zh",
							"type": "authorPaper",
							"text": "FailMapper: Automated Generation of Unit Tests Guided by Failure Scenarios",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c387/573300c387.pdf",
							"extraLocations": [],
							"authorNames": "Ruiqi Dong (Swinburne University of Technology, Australia), Zehang Deng (Swinburne University of Technology, Australia), Xiaogang Zhu (Adelaide University, Australia), Xiaoning Du (Monash University, Australia), Huai Liu (Swinburne University of Technology, Australia), Shaohua Wang (Central University of Finance and Economics, China), Sheng Wen (Swinburne University of Technology, Australia), Yang Xiang (Swinburne University of Technology, Australia)",
							"abstract": "The automation of unit test generation has become a critical task for improving the overall efficiency of software development and testing. Many existing techniques attempt to generate a sufficient number of test cases to achieve high code coverage. However, it has been shown that a high coverage does not necessarily guarantee effective bug discovery. A potential enhancement is to guide the unit test generation based on bug properties. However, this solution is challenged by the large number and diversity of bug types, making it difficult to comprehensively summarize bug properties. We observe that failures, presented as the results of bugs, manifest in a limited number of scenarios. Therefore, instead of bug properties, in this paper, we propose an innovative framework, named FAILMAPPER, which uses failure scenarios to guide the generation of unit tests. We summarize nine failure scenarios and design the corresponding failure-triggering test strategies. This significantly improves the efficacy of generating test cases towards triggering bugs. To systematically explore possible failure scenarios, FAILMAPPER employs the Monte Carlo Tree Search algorithm to search for the faults that may lead to a failure. Experiments demonstrate that, on 50 known bugs in the Defects4J benchmark, FAILMAPPER can detect many more bugs than five typical unit testing approaches, including EvoSuite, Randoop, CoverUp, HITS, and SymPrompt (40 versus at most 12, out of all 50 bugs). Meanwhile, FAILMAPPER detects 12 out of 20 bugs in the GitBug-Java and Bears-benchmark datasets. We reveal 36 potential issues from 2 Apache projects, and 14 of them have been confirmed as bugs, further demonstrating FAILMAPPER's effectiveness. The experimental results show that our new framework can significantly enhance the overall efficacy of unit testing.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 FailMapper: Automated Generation of Unit Tests Guided by Failure Scenarios 1759298477390 10.1109/ASE63991.2025.00197 Ruiqi Dong Swinburne University of Technology, Australia rdong@swin.edu.au Zehang Deng Swinburne University of Technology, Australia zehangdeng@swin.edu.au Xiaogang Zhu Adelaide University, Australia xiaogang.zhu@adelaide.edu.au Xiaoning Du Monash University, Australia Xiaoning.Du@monash.edu Huai Liu Swinburne University of Technology, Australia hliu@swin.edu.au Shaohua Wang Central University of Finance and Economics, China davidshwang@ieee.org Sheng Wen Swinburne University of Technology, Australia swen@swin.edu.au Yang Xiang Swinburne University of Technology, Australia yxiang@swin.edu.au automated unit test failure scenario guided software bug llm The automation of unit test generation has become a critical task for improving the overall efficiency of software development and testing. Many existing techniques attempt to generate a sufficient number of test cases to achieve high code coverage. However, it has been shown that a high coverage does not necessarily guarantee effective bug discovery. A potential enhancement is to guide the unit test generation based on bug properties. However, this solution is challenged by the large number and diversity of bug types, making it difficult to comprehensively summarize bug properties. We observe that failures, presented as the results of bugs, manifest in a limited number of scenarios. Therefore, instead of bug properties, in this paper, we propose an innovative framework, named FAILMAPPER, which uses failure scenarios to guide the generation of unit tests. We summarize nine failure scenarios and design the corresponding failure-triggering test strategies. This significantly improves the efficacy of generating test cases towards triggering bugs. To systematically explore possible failure scenarios, FAILMAPPER employs the Monte Carlo Tree Search algorithm to search for the faults that may lead to a failure. Experiments demonstrate that, on 50 known bugs in the Defects4J benchmark, FAILMAPPER can detect many more bugs than five typical unit testing approaches, including EvoSuite, Randoop, CoverUp, HITS, and SymPrompt (40 versus at most 12, out of all 50 bugs). Meanwhile, FAILMAPPER detects 12 out of 20 bugs in the GitBug-Java and Bears-benchmark datasets. We reveal 36 potential issues from 2 Apache projects, and 14 of them have been confirmed as bugs, further demonstrating FAILMAPPER's effectiveness. The experimental results show that our new framework can significantly enhance the overall efficacy of unit testing.",
							"pageNumber": 2387,
							"isPageNumberRoman": false
						},
						{
							"eid": "4zUyA2MX1mZAEsbZZUEA90",
							"type": "authorPaper",
							"text": "LLMs for Automated Unit Test Generation and Assessment in Java: The AgoneTest Framework",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c400/573300c400.pdf",
							"extraLocations": [],
							"authorNames": "Andrea Lops (Polytechnic University of Bari, Italy), Fedelucio Narducci (Polytechnic University of Bari, Italy), Azzurra Ragone (University of Bari, Italy), Michelantonio Trizio (Wideverse, Italy), Claudio Bartolini (Wideverse, Italy)",
							"abstract": "Unit testing is an essential but resource-intensive step in software development, ensuring individual code units function correctly. This paper introduces AgoneTest, an automated evaluation framework for Large Language Model-generated (LLM) unit tests in Java. AgoneTest does not aim to propose a novel test generation algorithm; rather, it supports researchers and developers in comparing different LLMs and prompting strategies through a standardized end-to-end evaluation pipeline under realistic conditions. We introduce the Classes2Test dataset, which maps Java classes under test to their corresponding test classes, and a framework that integrates advanced evaluation metrics, such as mutation score and test smells, for a comprehensive assessment. Experimental results show that, for the subset of tests that compile, LLM-generated tests can match or exceed human-written tests in terms of coverage and defect detection. Our findings also demonstrate that enhanced prompting strategies contribute to test quality. AgoneTest clarifies the potential of LLMs in software testing and offers insights for future improvements in model design, prompt engineering, and testing practices.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 LLMs for Automated Unit Test Generation and Assessment in Java: The AgoneTest Framework 1759522524619 10.1109/ASE63991.2025.00198 Andrea Lops Polytechnic University of Bari, Italy andrea.lops@poliba.it Fedelucio Narducci Polytechnic University of Bari, Italy fedelucio.narducci@poliba.it Azzurra Ragone University of Bari, Italy azzurra.ragone@uniba.it Michelantonio Trizio Wideverse, Italy michelantonio.trizio@wideverse.com Claudio Bartolini Wideverse, Italy claudio.bartolini.consultant@wideverse.com software testing large language model automatic assessment and evaluation assessment and evaluation in software testing Unit testing is an essential but resource-intensive step in software development, ensuring individual code units function correctly. This paper introduces AgoneTest, an automated evaluation framework for Large Language Model-generated (LLM) unit tests in Java. AgoneTest does not aim to propose a novel test generation algorithm; rather, it supports researchers and developers in comparing different LLMs and prompting strategies through a standardized end-to-end evaluation pipeline under realistic conditions. We introduce the Classes2Test dataset, which maps Java classes under test to their corresponding test classes, and a framework that integrates advanced evaluation metrics, such as mutation score and test smells, for a comprehensive assessment. Experimental results show that, for the subset of tests that compile, LLM-generated tests can match or exceed human-written tests in terms of coverage and defect detection. Our findings also demonstrate that enhanced prompting strategies contribute to test quality. AgoneTest clarifies the potential of LLMs in software testing and offers insights for future improvements in model design, prompt engineering, and testing practices.",
							"pageNumber": 2400,
							"isPageNumberRoman": false
						},
						{
							"eid": "9zBoRLriOzKd3Lpy0pngC",
							"type": "authorPaper",
							"text": "DeepExploitor: LLM-Enhanced Automated Exploitation of DeepLink Attack in Hybrid Apps",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c413/573300c413.pdf",
							"extraLocations": [],
							"authorNames": "Zhangyue Zhang (Fudan University), Lei Zhang (Fudan University), Zhibo Zhang (Fudan University), Yongheng Liu (Fudan University), Zhemin Yang (Fudan University), Yuan Zhang (Fudan University), Min Yang (Fudan University)",
							"abstract": "Modern mobile apps widely embed WebView to enable rich and dynamic content, making it an increasingly attractive target for attackers. It is well known that insufficient or improper input validation on WebView-loaded URLs can compromise the entire app or even the underlying system. Among these threats, one of the most critical attack vectors is the DeepLink Attack, which often requires only a single user click to exploit WebView vulnerabilities. Despite the deployment of defense such as URL allowlists, misconfigurations and inconsistent implementations continue to expose apps to exploitation. In this paper, we present DeepExploitor, the first automated exploit generation framework targeting vulnerabilities exploitable via DeepLink Attack. DeepExploitor addresses two key challenges: First, it statically models complex, appspecific routing encapsulation and customized input parsing logic by extracing constraint-related code and resolving them through large language models (LLMs), enabling scalable discovery of valid exploits. Second, it identifies and mutates trusted domains embedded in the app to bypass black-box defenses such as domain-based allowlists. We evaluated DeepExploitor on 433 of the most popular Android apps and uncovered 83 zero-day vulnerabilities, including 24 rated as high or critical severity. All findings were responsibly disclosed to affected vendors, with 35 acknowledged to date or assigned CVE/CNVD identifiers.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 DeepExploitor: LLM-Enhanced Automated Exploitation of DeepLink Attack in Hybrid Apps 1759049821032 10.1109/ASE63991.2025.00199 Zhangyue Zhang Fudan University zhangyuezhang23@m.fudan.edu.cn Lei Zhang Fudan University zxl@fudan.edu.cn Zhibo Zhang Fudan University zhibozhang19@fudan.edu.cn Yongheng Liu Fudan University yhliu24@m.fudan.edu.cn Zhemin Yang Fudan University yangzhemin@fudan.edu.cn Yuan Zhang Fudan University yuanxzhang@fudan.edu.cn Min Yang Fudan University m_yang@fudan.edu.cn android webview deep link automated exploit generation large language mode Modern mobile apps widely embed WebView to enable rich and dynamic content, making it an increasingly attractive target for attackers. It is well known that insufficient or improper input validation on WebView-loaded URLs can compromise the entire app or even the underlying system. Among these threats, one of the most critical attack vectors is the DeepLink Attack, which often requires only a single user click to exploit WebView vulnerabilities. Despite the deployment of defense such as URL allowlists, misconfigurations and inconsistent implementations continue to expose apps to exploitation. In this paper, we present DeepExploitor, the first automated exploit generation framework targeting vulnerabilities exploitable via DeepLink Attack. DeepExploitor addresses two key challenges: First, it statically models complex, appspecific routing encapsulation and customized input parsing logic by extracing constraint-related code and resolving them through large language models (LLMs), enabling scalable discovery of valid exploits. Second, it identifies and mutates trusted domains embedded in the app to bypass black-box defenses such as domain-based allowlists. We evaluated DeepExploitor on 433 of the most popular Android apps and uncovered 83 zero-day vulnerabilities, including 24 rated as high or critical severity. All findings were responsibly disclosed to affected vendors, with 35 acknowledged to date or assigned CVE/CNVD identifiers.",
							"pageNumber": 2413,
							"isPageNumberRoman": false
						},
						{
							"eid": "3yGrRvxVudlC0N8Ctqt3oC",
							"type": "authorPaper",
							"text": "An Agent-Based Evaluation Framework for Complex Code Generation",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c426/573300c426.pdf",
							"extraLocations": [],
							"authorNames": "Xinchen Wang (Harbin Institute of Technology, China), Ruida Hu (Harbin Institute of Technology, China), Pengfei Gao (ByteDance, China), Chao Peng (ByteDance, China), Cuiyun Gao (Harbin Institute of Technology, China)",
							"abstract": "Large language models (LLMs) have demonstrated strong capabilities in code generation, underscoring the critical need for rigorous and comprehensive evaluation. Existing evaluation approaches fall into three categories, including human-centered, metric-based, and LLM-based. Considering that human-centered approaches are labour-intensive and metric-based ones overly rely on reference answers, LLM-based approaches are gaining increasing attention due to their stronger contextual understanding capabilities. However, they generally evaluate the generated code based on static prompts, and tend to fail for complex code scenarios which typically involve multiple requirements and require more contextual information. In addition, these approaches lack fine-grained evaluation for complex code, resulting in limited explainability. To mitigate the limitations, we propose CodeVisionary, the first agent-based evaluation framework for complex code generation. CodeVisionary consists of two stages: (1) Requirement-guided multi-dimensional context distillation stage, which first formulates a detailed evaluation plan by decomposing task requirements, and then stepwise collects multi-dimensional contextual information for each requirement. (2) Fine-grained scoring and summarization stage, which defines self-directed and negotiation-based actions, allowing multiple judges to comprehend complex code from fine-grained and diverse viewpoints, and reach a consensus through discussion. A comprehensive evaluation report is also generated for enhanced explainability. For validation, we construct a new benchmark consisting of 363 samples spanning 37 coding scenarios and 23 programming languages. Extensive experiments demonstrate that CodeVs achieves the best performance among three baselines for evaluating complex code generation, outperforming the best baseline with average improvements of 0.217, 0.163, and 0.141 in Pearson, Spearman, and Kendall-Tau coefficients, respectively. The resources of CodeVisionary are available at https://anonymous.4open.science/r/CodeVisionary.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 An Agent-Based Evaluation Framework for Complex Code Generation 1758100374555 10.1109/ASE63991.2025.00200 Xinchen Wang Harbin Institute of Technology, China 200111115@stu.hit.edu.cn Ruida Hu Harbin Institute of Technology, China 200111107@stu.hit.edu.cn Pengfei Gao ByteDance, China gaopengfei.se@bytedance.com Chao Peng ByteDance, China pengchao.x@bytedance.com Cuiyun Gao Harbin Institute of Technology, China gaocuiyun@hit.edu.cn Code generation evaluation large language models AI agent Large language models (LLMs) have demonstrated strong capabilities in code generation, underscoring the critical need for rigorous and comprehensive evaluation. Existing evaluation approaches fall into three categories, including human-centered, metric-based, and LLM-based. Considering that human-centered approaches are labour-intensive and metric-based ones overly rely on reference answers, LLM-based approaches are gaining increasing attention due to their stronger contextual understanding capabilities. However, they generally evaluate the generated code based on static prompts, and tend to fail for complex code scenarios which typically involve multiple requirements and require more contextual information. In addition, these approaches lack fine-grained evaluation for complex code, resulting in limited explainability. To mitigate the limitations, we propose CodeVisionary, the first agent-based evaluation framework for complex code generation. CodeVisionary consists of two stages: (1) Requirement-guided multi-dimensional context distillation stage, which first formulates a detailed evaluation plan by decomposing task requirements, and then stepwise collects multi-dimensional contextual information for each requirement. (2) Fine-grained scoring and summarization stage, which defines self-directed and negotiation-based actions, allowing multiple judges to comprehend complex code from fine-grained and diverse viewpoints, and reach a consensus through discussion. A comprehensive evaluation report is also generated for enhanced explainability. For validation, we construct a new benchmark consisting of 363 samples spanning 37 coding scenarios and 23 programming languages. Extensive experiments demonstrate that CodeVs achieves the best performance among three baselines for evaluating complex code generation, outperforming the best baseline with average improvements of 0.217, 0.163, and 0.141 in Pearson, Spearman, and Kendall-Tau coefficients, respectively. The resources of CodeVisionary are available at https://anonymous.4open.science/r/CodeVisionary.",
							"pageNumber": 2426,
							"isPageNumberRoman": false
						},
						{
							"eid": "4M2VhRSnMDTdHnNW2m3GAK",
							"type": "authorPaper",
							"text": "Token Sugar: Making Source Code Sweeter for LLMs Through Token-Efficient Shorthand",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c439/573300c439.pdf",
							"extraLocations": [],
							"authorNames": "Zhensu Sun (Singapore Management University), Chengran Yang (Singapore Management University), Xiaoning Du (Monash University), Zhou Yang (University of Alberta), Li Li (Beihang University), David Lo (Singapore Management University)",
							"abstract": "Large language models (LLMs) have shown exceptional performance in code generation and understanding tasks, yet their high computational costs hinder broader adoption. One important factor is the inherent verbosity of programming languages, such as unnecessary formatting elements and lengthy boilerplate code. This leads to inflated token counts in both input and generated outputs, which increases inference costs and slows down the generation process. Prior work improves this through simplifying programming language grammar, reducing token usage across both code understanding and generation tasks. However, it is confined to syntactic transformations, leaving significant opportunities for token reduction unrealized at the semantic level. In this work, we propose Token Sugar, a concept that replaces frequent and verbose code patterns with reversible, token-efficient shorthand in the source code. To realize this concept in practice, we designed a systematic solution that mines high-frequency, token-heavy patterns from a code corpus, maps each to a unique shorthand, and integrates them into LLM pretraining via code transformation. With this solution, we obtain 799 (code pattern, shorthand) pairs, which can reduce up to 15.1% token count in the source code and is complementary to existing syntax-focused methods. Experimental results show that these models not only achieve significant token savings (up to 11.2% reduction) during generation but also maintain near-identical Pass@1 scores compared to baselines trained on unprocessed code.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Token Sugar: Making Source Code Sweeter for LLMs Through Token-Efficient Shorthand 1759542150969 10.1109/ASE63991.2025.00201 Zhensu Sun Singapore Management University zssun@smu.edu.sg Chengran Yang Singapore Management University cryang@smu.edu.sg Xiaoning Du Monash University xiaoning.du@monash.edu Zhou Yang University of Alberta yz25@ualberta.ca Li Li Beihang University lilicoding@ieee.org David Lo Singapore Management University davidlo@smu.edu.sg large language model code simplification ai-friendly code representation Large language models (LLMs) have shown exceptional performance in code generation and understanding tasks, yet their high computational costs hinder broader adoption. One important factor is the inherent verbosity of programming languages, such as unnecessary formatting elements and lengthy boilerplate code. This leads to inflated token counts in both input and generated outputs, which increases inference costs and slows down the generation process. Prior work improves this through simplifying programming language grammar, reducing token usage across both code understanding and generation tasks. However, it is confined to syntactic transformations, leaving significant opportunities for token reduction unrealized at the semantic level. In this work, we propose Token Sugar, a concept that replaces frequent and verbose code patterns with reversible, token-efficient shorthand in the source code. To realize this concept in practice, we designed a systematic solution that mines high-frequency, token-heavy patterns from a code corpus, maps each to a unique shorthand, and integrates them into LLM pretraining via code transformation. With this solution, we obtain 799 (code pattern, shorthand) pairs, which can reduce up to 15.1% token count in the source code and is complementary to existing syntax-focused methods. Experimental results show that these models not only achieve significant token savings (up to 11.2% reduction) during generation but also maintain near-identical Pass@1 scores compared to baselines trained on unprocessed code.",
							"pageNumber": 2439,
							"isPageNumberRoman": false
						},
						{
							"eid": "2qICidAciW1nBMqnpmVRvj",
							"type": "authorPaper",
							"text": "Advancing Automated Ethical Profiling in SE: a Zero-Shot Evaluation of LLM Reasoning",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c451/573300c451.pdf",
							"extraLocations": [],
							"authorNames": "Patrizio Migliarini (University of L'Aquila, Italy), Mashal Afzal Memon (University of L'Aquila, Italy), Marco Autili (University of L'Aquila, Italy), Paola Inverardi (Gran Sasso Science Institute, Italy)",
							"abstract": "Large Language Models (LLMs) are increasingly integrated into software engineering (SE) tools for tasks that extend beyond code synthesis, including judgment under uncertainty and reasoning in ethically significant contexts. We present a fully automated framework for assessing ethical reasoning capabilities across 16 LLMs in a zero-shot setting, using 30 real-world ethically charged scenarios. Each model is prompted to identify the most applicable ethical theory to an action, assess its moral acceptability, and explain the reasoning behind their choice. Responses are compared against expert ethicists' choices using inter-model agreement metrics. Our results show that LLMs achieve an average Theory Consistency Rate (TCR) of 73.3% and Binary Agreement Rate (BAR) on moral acceptability of 86.7%, with interpretable divergences concentrated in ethically ambiguous cases. A qualitative analysis of free-text explanations reveals strong conceptual convergence across models despite surface-level lexical diversity. These findings support the potential viability of LLMs as ethical inference engines within SE pipelines, enabling scalable, auditable, and adaptive integration of user-aligned ethical reasoning. Our focus is the Ethical Interpreter component of a broader profiling pipeline: we evaluate whether current LLMs exhibit sufficient interpretive stability and theory-consistent reasoning to support automated profiling.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Advancing Automated Ethical Profiling in SE: a Zero-Shot Evaluation of LLM Reasoning 1759234095237 10.1109/ASE63991.2025.00202 Patrizio Migliarini University of L'Aquila, Italy patrizio.migliarini@univaq.it Mashal Afzal Memon University of L'Aquila, Italy mashal.memon@univaq.it Marco Autili University of L'Aquila, Italy marco.autili@univaq.it Paola Inverardi Gran Sasso Science Institute, Italy paola.inverardi@gssi.it software engineering ethics large language models moral reasoning zero-shot learning Large Language Models (LLMs) are increasingly integrated into software engineering (SE) tools for tasks that extend beyond code synthesis, including judgment under uncertainty and reasoning in ethically significant contexts. We present a fully automated framework for assessing ethical reasoning capabilities across 16 LLMs in a zero-shot setting, using 30 real-world ethically charged scenarios. Each model is prompted to identify the most applicable ethical theory to an action, assess its moral acceptability, and explain the reasoning behind their choice. Responses are compared against expert ethicists' choices using inter-model agreement metrics. Our results show that LLMs achieve an average Theory Consistency Rate (TCR) of 73.3% and Binary Agreement Rate (BAR) on moral acceptability of 86.7%, with interpretable divergences concentrated in ethically ambiguous cases. A qualitative analysis of free-text explanations reveals strong conceptual convergence across models despite surface-level lexical diversity. These findings support the potential viability of LLMs as ethical inference engines within SE pipelines, enabling scalable, auditable, and adaptive integration of user-aligned ethical reasoning. Our focus is the Ethical Interpreter component of a broader profiling pipeline: we evaluate whether current LLMs exhibit sufficient interpretive stability and theory-consistent reasoning to support automated profiling.",
							"pageNumber": 2451,
							"isPageNumberRoman": false
						},
						{
							"eid": "2y9NuQcldfBYBIQcIpBuCc",
							"type": "authorPaper",
							"text": "Exact Inference for Quantum Circuits: A Testing Oracle for Quantum Software Stacks",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c464/573300c464.pdf",
							"extraLocations": [],
							"authorNames": "Kanguk Lee (KAIST, South Korea), Jaemin Hong (KAIST, South Korea), Sukyoung Ryu (KAIST, South Korea)",
							"abstract": "Quantum software stacks (QSSs), which provide quantum circuit transformers and simulators, enable circuit transformations and the execution of circuits on classical computers. Despite their importance, they have not been effectively tested yet, leaving the correctness in question. The main obstacle to testing is the absence of a testing oracle, which checks the semantics-preservation of circuit transformations and the correctness of simulation results. While previous studies have employed differential and metamorphic testing to circumvent the necessity for an oracle, they have detected very few non-crash bugs. In this work, we address this gap by introducing QASMInfer, an exact inference system for quantum circuits, which computes the probability distribution of possible circuit outcomes. By supporting circuits written in OpenQASM, the de facto standard quantum assembly language used by most QSSs, QASMInfer acts as a unified testing oracle for multiple QSSs. Our design of QASMInfer achieves three key goals: (1) support for dynamic circuits, an important class of quantum circuits, (2) efficiency, and (3) reliability. For efficiency, we introduce two optimizations and an efficient matrix representation. For reliability, we prove physical consistency, ensuring that QASMInfer's inference results adhere to the physical principles of quantum computing. To simplify the proof, we introduce OpenQASMCore, a core language for OpenQASM, and perform exact inference for OpenQASM by desugaring it to OpenQASMCore. Our implementation and proof are fully mechanized in the Coq proof assistant. Testing six real-world QSSs using QASMInfer revealed 31 bugs, including 20 non-crash bugs, demonstrating QASMInfer's effectiveness as a testing oracle.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Exact Inference for Quantum Circuits: A Testing Oracle for Quantum Software Stacks 1759305195279 10.1109/ASE63991.2025.00203 Kanguk Lee KAIST, South Korea p51lee@kaist.ac.kr Jaemin Hong KAIST, South Korea jaemin.hong@kaist.ac.kr Sukyoung Ryu KAIST, South Korea sryu.cs@kaist.ac.kr quantum software stack quantum circuit testing oracle exact inference Quantum software stacks (QSSs), which provide quantum circuit transformers and simulators, enable circuit transformations and the execution of circuits on classical computers. Despite their importance, they have not been effectively tested yet, leaving the correctness in question. The main obstacle to testing is the absence of a testing oracle, which checks the semantics-preservation of circuit transformations and the correctness of simulation results. While previous studies have employed differential and metamorphic testing to circumvent the necessity for an oracle, they have detected very few non-crash bugs. In this work, we address this gap by introducing QASMInfer, an exact inference system for quantum circuits, which computes the probability distribution of possible circuit outcomes. By supporting circuits written in OpenQASM, the de facto standard quantum assembly language used by most QSSs, QASMInfer acts as a unified testing oracle for multiple QSSs. Our design of QASMInfer achieves three key goals: (1) support for dynamic circuits, an important class of quantum circuits, (2) efficiency, and (3) reliability. For efficiency, we introduce two optimizations and an efficient matrix representation. For reliability, we prove physical consistency, ensuring that QASMInfer's inference results adhere to the physical principles of quantum computing. To simplify the proof, we introduce OpenQASMCore, a core language for OpenQASM, and perform exact inference for OpenQASM by desugaring it to OpenQASMCore. Our implementation and proof are fully mechanized in the Coq proof assistant. Testing six real-world QSSs using QASMInfer revealed 31 bugs, including 20 non-crash bugs, demonstrating QASMInfer's effectiveness as a testing oracle.",
							"pageNumber": 2464,
							"isPageNumberRoman": false
						},
						{
							"eid": "5ThhKdLauSmY6bXTOHVojT",
							"type": "authorPaper",
							"text": "Evaluating and Improving Framework-Based Parallel Code Completion with Large Language Models",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c477/573300c477.pdf",
							"extraLocations": [],
							"authorNames": "ke Liu (National University of Defense Technology, China), Qinglin Wang (National University of Defense Technology, China), Xiang Chen (Nantong University, China), Guang Yang (Nanjing University of Aeronautics and Astronautics, China), Yigui Feng (National University of Defense Technology, China), Gencheng Liu (National University of Defense Technology, China), Jie Liu (National University of Defense Technology, China)",
							"abstract": "Modern computing architectures (e.g., multi-core CPUs, GPUs, distributed systems) rely on parallel code implemented via frameworks such as OpenMP, MPI, and CUDA. While large language models (LLMs) have shown strong performance in general code generation, they struggle with the structured reasoning required for parallel programming, such as handling concurrency, synchronization, and framework-specific semantics. In practical parallel code development, a common workflow begins with sequential code and incrementally introduces parallel directive codes. We formalize this process as the task of framework-based parallel code completion (FPCC), which involves three subtasks: identifying insertion points, selecting parallel frameworks, and completing parallel directive codes. To support this task, we construct a high-quality dataset of 16,638 framework-based parallel code pairs across six widely used frameworks, labeled with directive points, parallel frameworks, and the code of parallel directives. However, our empirical results show that six popular LLMs perform poorly on FPCC, particularly struggling with identifying insertion points and completing correct directive codes. To address these limitations, we propose HPCL, a curriculum-based fine-tuning framework that progressively improves model capabilities in insertion point identification, parallel framework selection, and parallel directive code completion. Our approach achieves substantial improvements, yielding an 17.82% increase in EM and a 5.43% improvement in DIR scores over LLM-based baselines. Finally, expert-guided error analysis reveals common failure patterns and suggests future directions, such as in retrieval-augmented completion and consistency-aware training.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Evaluating and Improving Framework-Based Parallel Code Completion with Large Language Models 1759324618613 10.1109/ASE63991.2025.00204 ke Liu National University of Defense Technology, China liuke23@nudt.edu.cn Qinglin Wang National University of Defense Technology, China wangqinglin@nudt.edu.cn Xiang Chen Nantong University, China xchencs@ntu.edu.cn Guang Yang Nanjing University of Aeronautics and Astronautics, China novelyg@outlook.com Yigui Feng National University of Defense Technology, China fengyigui@nudt.edu.cn Gencheng Liu National University of Defense Technology, China liugencheng@nudt.edu.cn Jie Liu National University of Defense Technology, China liujie@nudt.edu.cn Parallel Programming Language Large Language Model Curriculum Learning Code Completion Modern computing architectures (e.g., multi-core CPUs, GPUs, distributed systems) rely on parallel code implemented via frameworks such as OpenMP, MPI, and CUDA. While large language models (LLMs) have shown strong performance in general code generation, they struggle with the structured reasoning required for parallel programming, such as handling concurrency, synchronization, and framework-specific semantics. In practical parallel code development, a common workflow begins with sequential code and incrementally introduces parallel directive codes. We formalize this process as the task of framework-based parallel code completion (FPCC), which involves three subtasks: identifying insertion points, selecting parallel frameworks, and completing parallel directive codes. To support this task, we construct a high-quality dataset of 16,638 framework-based parallel code pairs across six widely used frameworks, labeled with directive points, parallel frameworks, and the code of parallel directives. However, our empirical results show that six popular LLMs perform poorly on FPCC, particularly struggling with identifying insertion points and completing correct directive codes. To address these limitations, we propose HPCL, a curriculum-based fine-tuning framework that progressively improves model capabilities in insertion point identification, parallel framework selection, and parallel directive code completion. Our approach achieves substantial improvements, yielding an 17.82% increase in EM and a 5.43% improvement in DIR scores over LLM-based baselines. Finally, expert-guided error analysis reveals common failure patterns and suggests future directions, such as in retrieval-augmented completion and consistency-aware training.",
							"pageNumber": 2477,
							"isPageNumberRoman": false
						},
						{
							"eid": "3iwbZnoNriA9Dhf15XyKoA",
							"type": "authorPaper",
							"text": "The Fault in our Stats",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c490/573300c490.pdf",
							"extraLocations": [],
							"authorNames": "Alexi Turcotte (CISPA Helmholtz Center for Information Security, Germany), Neev Nirav Mehta (Saarland University, Germany)",
							"abstract": "Data analysts need to be careful when they apply statistical inference techniques to data, as misuse of statistical inference methods can lead an analyst to draw the wrong conclusions. They need to be careful because, in the general case, misuse of statistics does not result in obvious problems; the numbers returned often look reasonable, and programs with misuses of statistics do not crash. In this work, we propose a technique to quickly and statically check data science programs for compliance with statistics best practice rules, including checking all assumptions made by statistical methods, as well as correcting for the multiple comparison problem, or \"data dredging\". This technique is predicated on a novel statistics intermediate representation, called SIR, that encodes the details most salient to statistics. We implement this technique in a tool called STAT-LINT, the first statistics linter, and evaluate STAT-LINT on 90 Python data science notebooks, finding that only 14 fully check all obligations, only two apply any correction for multiple comparisons, none validate model residuals, and over two thirds of obligations go unchecked.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 The Fault in our Stats 1759490040170 10.1109/ASE63991.2025.00205 Alexi Turcotte CISPA Helmholtz Center for Information Security, Germany alexi.turcotte@cispa.de Neev Nirav Mehta Saarland University, Germany neme00002@stud.uni-saarland.de statistics python static analysis data science Data analysts need to be careful when they apply statistical inference techniques to data, as misuse of statistical inference methods can lead an analyst to draw the wrong conclusions. They need to be careful because, in the general case, misuse of statistics does not result in obvious problems; the numbers returned often look reasonable, and programs with misuses of statistics do not crash. In this work, we propose a technique to quickly and statically check data science programs for compliance with statistics best practice rules, including checking all assumptions made by statistical methods, as well as correcting for the multiple comparison problem, or \"data dredging\". This technique is predicated on a novel statistics intermediate representation, called SIR, that encodes the details most salient to statistics. We implement this technique in a tool called STAT-LINT, the first statistics linter, and evaluate STAT-LINT on 90 Python data science notebooks, finding that only 14 fully check all obligations, only two apply any correction for multiple comparisons, none validate model residuals, and over two thirds of obligations go unchecked.",
							"pageNumber": 2490,
							"isPageNumberRoman": false
						},
						{
							"eid": "6cjbDyY3STKzYQQuk5dmVB",
							"type": "authorPaper",
							"text": "Unit Test Update Through LLM-Driven Context Collection and Error-Type-Aware Refinement",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c503/573300c503.pdf",
							"extraLocations": [],
							"authorNames": "Yuanhe Zhang (Zhejiang University, China), Zhiquan Yang (Zhejiang University, China), Shengyi Pan (Zhejiang University, China), Zhongxin Liu (Zhejiang University, China)",
							"abstract": "Unit testing is critical for ensuring software quality and software system stability. The current practice of manually maintaining unit tests suffers from low efficiency and the risk of delayed or overlooked fixes. Therefore, an automated approach is required to instantly update unit tests, with the capability to both repair and enhance unit tests. However, existing automated test maintenance methods primarily focus on repairing broken tests, neglecting the scenario of enhancing existing tests to verify new functionality. Meanwhile, due to their reliance on rule-based context collection and the lack of verification mechanisms, existing approaches struggle to handle complex code changes and often produce test cases with low correctness. To address these challenges, we propose TESTUPDATER, a novel Large Language Model (LLM) based approach that enables automated just-in-time test updates in response to production code changes. By emulating the reasoning process of developers, TESTUPDATER first leverages the LLM to analyze code changes and identify relevant context, which it then extracts and filters. This LLM-driven context collector can flexibly gather accurate and sufficient context, enabling better handling of complex code changes. Then, through carefully designed prompts, TESTUPDATER guides the LLM step by step to handle various types of code changes and introduce new dependencies, enabling both the repair of broken tests and the enhancement of tests. Finally, emulating the debugging process, we introduce an error-type-aware iterative refinement mechanism that executes the LLM-updated tests and repairs failures, which significantly improves the overall correctness of test updates. Since existing test repair datasets lack scenarios of test enhancement, we further construct a new benchmark, UPDATES4J, with 195 real-world samples from 7 projects, enabling execution-based evaluation of test updates. Experimental results show that TESTUPDATER achieves a compilation pass rate of 94.4% and a test pass rate of 86.7%, outperforming the state-of-the-art method SYNTER by 15.9% and 20.0%, respectively. Furthermore, TESTUPDATER exhibits 12.9% higher branch coverage and 15.2% greater line coverage than SYNTER.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Unit Test Update Through LLM-Driven Context Collection and Error-Type-Aware Refinement 1759074137820 10.1109/ASE63991.2025.00206 Yuanhe Zhang Zhejiang University, China yuanhezhang@zju.edu.cn Zhiquan Yang Zhejiang University, China zhiquanyang@zju.edu.cn Shengyi Pan Zhejiang University, China shengyi.pan@zju.edu.cn Zhongxin Liu Zhejiang University, China liu_zx@zju.edu.cn Unit testing is critical for ensuring software quality and software system stability. The current practice of manually maintaining unit tests suffers from low efficiency and the risk of delayed or overlooked fixes. Therefore, an automated approach is required to instantly update unit tests, with the capability to both repair and enhance unit tests. However, existing automated test maintenance methods primarily focus on repairing broken tests, neglecting the scenario of enhancing existing tests to verify new functionality. Meanwhile, due to their reliance on rule-based context collection and the lack of verification mechanisms, existing approaches struggle to handle complex code changes and often produce test cases with low correctness. To address these challenges, we propose TESTUPDATER, a novel Large Language Model (LLM) based approach that enables automated just-in-time test updates in response to production code changes. By emulating the reasoning process of developers, TESTUPDATER first leverages the LLM to analyze code changes and identify relevant context, which it then extracts and filters. This LLM-driven context collector can flexibly gather accurate and sufficient context, enabling better handling of complex code changes. Then, through carefully designed prompts, TESTUPDATER guides the LLM step by step to handle various types of code changes and introduce new dependencies, enabling both the repair of broken tests and the enhancement of tests. Finally, emulating the debugging process, we introduce an error-type-aware iterative refinement mechanism that executes the LLM-updated tests and repairs failures, which significantly improves the overall correctness of test updates. Since existing test repair datasets lack scenarios of test enhancement, we further construct a new benchmark, UPDATES4J, with 195 real-world samples from 7 projects, enabling execution-based evaluation of test updates. Experimental results show that TESTUPDATER achieves a compilation pass rate of 94.4% and a test pass rate of 86.7%, outperforming the state-of-the-art method SYNTER by 15.9% and 20.0%, respectively. Furthermore, TESTUPDATER exhibits 12.9% higher branch coverage and 15.2% greater line coverage than SYNTER.",
							"pageNumber": 2503,
							"isPageNumberRoman": false
						},
						{
							"eid": "2b1ZABmEtvnIDqrbR68D1A",
							"type": "authorPaper",
							"text": "On Automating Configuration Dependency Validation via Retrieval-Augmented Generation",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c515/573300c515.pdf",
							"extraLocations": [],
							"authorNames": "Sebastian Simon (Leipzig University, Germany), Alina Mailach (Leipzig University, Germany; ScaDS.AI Dresden/Leipzig, Germany), Johannes Dorn (Leipzig University, Germany), Norbert Siegmund (Leipzig University, Germany; ScaDS.AI Dresden/Leipzig, Germany)",
							"abstract": "Configuration dependencies arise when multiple technologies in a software system require coordinated settings for correct interplay. Existing approaches for detecting such dependencies often yield high false-positive rates, require additional validation mechanisms, and are typically limited to specific projects or technologies. Recent work that incorporates large language models (LLMs) for dependency validation still suffers from inaccuracies due to project- and technology-specific variations, as well as from missing contextual information. In this work, we propose to use retrieval-augmented generation (RAG) systems for configuration dependency validation, which allows to incorporate additional project- and technology-specific context information. Specifically, we evaluate whether RAG can improve LLM-based validation of configuration dependencies and what contextual information are needed to overcome the static knowledge base of LLMs. To this end, we conducted a large empirical study on validating configuration dependencies using RAG. Our evaluation shows that vanilla LLMs already demonstrate solid validation abilities, while RAG has only marginal or even negative effects on the validation performance of the models. By incorporating tailored contextual information into the RAG system\u2013derived from a qualitative analysis of validation failures\u2013we achieve significantly more accurate validation results across all models, with an average precision of 0.84 and recall of 0.70, representing improvements of 35 % and 133 % over vanilla LLMs, respectively. In addition, these results offer two important insights: Simplistic RAG systems may not benefit from additional information if it is not tailored to the task at hand, and it is often unclear upfront what kind of information yields improved performance.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 On Automating Configuration Dependency Validation via Retrieval-Augmented Generation 1758884922198 10.1109/ASE63991.2025.00207 Sebastian Simon Leipzig University, Germany sebastian.simon@cs.uni-leipzig.de Alina Mailach Leipzig University, Germany; ScaDS.AI Dresden/Leipzig, Germany alina.mailach@cs.uni-leipzig.de Johannes Dorn Leipzig University, Germany johannes.dorn@cs.uni-leipzig.de Norbert Siegmund Leipzig University, Germany; ScaDS.AI Dresden/Leipzig, Germany norbert.siegmund@cs.uni-leipzig.de RAG LLMs Configuration Dependencies De pendency Validation Configuration dependencies arise when multiple technologies in a software system require coordinated settings for correct interplay. Existing approaches for detecting such dependencies often yield high false-positive rates, require additional validation mechanisms, and are typically limited to specific projects or technologies. Recent work that incorporates large language models (LLMs) for dependency validation still suffers from inaccuracies due to project- and technology-specific variations, as well as from missing contextual information. In this work, we propose to use retrieval-augmented generation (RAG) systems for configuration dependency validation, which allows to incorporate additional project- and technology-specific context information. Specifically, we evaluate whether RAG can improve LLM-based validation of configuration dependencies and what contextual information are needed to overcome the static knowledge base of LLMs. To this end, we conducted a large empirical study on validating configuration dependencies using RAG. Our evaluation shows that vanilla LLMs already demonstrate solid validation abilities, while RAG has only marginal or even negative effects on the validation performance of the models. By incorporating tailored contextual information into the RAG system\u2013derived from a qualitative analysis of validation failures\u2013we achieve significantly more accurate validation results across all models, with an average precision of 0.84 and recall of 0.70, representing improvements of 35 % and 133 % over vanilla LLMs, respectively. In addition, these results offer two important insights: Simplistic RAG systems may not benefit from additional information if it is not tailored to the task at hand, and it is often unclear upfront what kind of information yields improved performance.",
							"pageNumber": 2515,
							"isPageNumberRoman": false
						},
						{
							"eid": "3Slj7fS00un3Vm82ZNdhPV",
							"type": "authorPaper",
							"text": "Automated Insertion of Flushes and Fences for Persistency",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c528/573300c528.pdf",
							"extraLocations": [],
							"authorNames": "Yutong Guo (University of California, Irvine), Weiyu Luo (University of California, Irvine), Brian Demsky (University of California, Irvine)",
							"abstract": "CXL shared memory and persistent memory allow the contents of memory to persist beyond crashes. Stores to persistent or CXL memory are typically not immediately made persistent; developers must manually flush the corresponding cache lines to force the data to be written to the underlying storage. Correctly using flush and fence operations is known to be challenging. While state-of-the-art tools can find missing flush instructions, they often require bug-revealing test cases. No existing tools can ensure the absence of missing flush bugs. In this paper, we present PMRobust, a compiler that automatically inserts flush and fence operations to ensure that code using persistent memory is free from missing flush and fence bugs. PMRobust employs a novel static analysis with optimizations that target newly allocated objects. We have evaluated PMRobust on persistent memory libraries and several persistent memory data structures and measured a geometric mean overhead of 0.26% relative to the original benchmarks with hand-placed flush and fence operations.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Automated Insertion of Flushes and Fences for Persistency 1758764866302 10.1109/ASE63991.2025.00208 Yutong Guo University of California, Irvine yutong4@uci.edu Weiyu Luo University of California, Irvine weiyu7@uci.edu Brian Demsky University of California, Irvine bdemsky@uci.edu persistent memory compiler robustness CXL shared memory and persistent memory allow the contents of memory to persist beyond crashes. Stores to persistent or CXL memory are typically not immediately made persistent; developers must manually flush the corresponding cache lines to force the data to be written to the underlying storage. Correctly using flush and fence operations is known to be challenging. While state-of-the-art tools can find missing flush instructions, they often require bug-revealing test cases. No existing tools can ensure the absence of missing flush bugs. In this paper, we present PMRobust, a compiler that automatically inserts flush and fence operations to ensure that code using persistent memory is free from missing flush and fence bugs. PMRobust employs a novel static analysis with optimizations that target newly allocated objects. We have evaluated PMRobust on persistent memory libraries and several persistent memory data structures and measured a geometric mean overhead of 0.26% relative to the original benchmarks with hand-placed flush and fence operations.",
							"pageNumber": 2528,
							"isPageNumberRoman": false
						},
						{
							"eid": "3dYI94iGecb3qXOOvlsy8w",
							"type": "authorPaper",
							"text": "Soleker: Uncovering Vulnerabilities in Solana Smart Contracts",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c541/573300c541.pdf",
							"extraLocations": [],
							"authorNames": "Kunsong Zhao (The Hong Kong Polytechnic University, China), Yunpeng Tian (The Hong Kong Polytechnic University, China), Zuchao Ma (The Hong Kong Polytechnic University, China), Xiapu Luo (The Hong Kong Polytechnic University, China)",
							"abstract": "Solana has rapidly evolved into a leading next generation platform for supporting decentralized applications due to its high performance and low transaction costs. Its new contract execution model, which decouples code logic from states, gives rise to new vulnerability threats that can result in significant financial losses for users within the ecosystem. However, existing studies towards detecting vulnerabilities are predominantly tailored for Ethereum smart contracts, which are unsuitable for Solana platform because of the variations in implementation languages and runtime semantics. In this paper, we propose Soleker, a novel approach that leverages learning-based techniques to automatically identifying potential vulnerabilities in Solana smart contract bytecode. More specifically, Soleker captures runtime semantic information from instructions that are associated with blockchain interactions and extracts vulnerability-specific localized features. Then, a prefix-guided graph learning model is introduced to learn and integrate extracted features, enabling effective vulnerability detection. We conduct experiments on a newly constructed contract dataset and the results demonstrate that Soleker significantly outperforms the baseline methods, achieving an average effectiveness improvement of 126.4% and a 335x boost in efficiency.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Soleker: Uncovering Vulnerabilities in Solana Smart Contracts 1759128474789 10.1109/ASE63991.2025.00209 Kunsong Zhao The Hong Kong Polytechnic University, China kunsong.zhao@connect.polyu.hk Yunpeng Tian The Hong Kong Polytechnic University, China yun-peng.tian@connect.polyu.hk Zuchao Ma The Hong Kong Polytechnic University, China zuchao.ma@connect.polyu.hk Xiapu Luo The Hong Kong Polytechnic University, China csxluo@comp.polyu.edu.hk blockchain solana smart contract vulnerability detection Solana has rapidly evolved into a leading next generation platform for supporting decentralized applications due to its high performance and low transaction costs. Its new contract execution model, which decouples code logic from states, gives rise to new vulnerability threats that can result in significant financial losses for users within the ecosystem. However, existing studies towards detecting vulnerabilities are predominantly tailored for Ethereum smart contracts, which are unsuitable for Solana platform because of the variations in implementation languages and runtime semantics. In this paper, we propose Soleker, a novel approach that leverages learning-based techniques to automatically identifying potential vulnerabilities in Solana smart contract bytecode. More specifically, Soleker captures runtime semantic information from instructions that are associated with blockchain interactions and extracts vulnerability-specific localized features. Then, a prefix-guided graph learning model is introduced to learn and integrate extracted features, enabling effective vulnerability detection. We conduct experiments on a newly constructed contract dataset and the results demonstrate that Soleker significantly outperforms the baseline methods, achieving an average effectiveness improvement of 126.4% and a 335x boost in efficiency.",
							"pageNumber": 2541,
							"isPageNumberRoman": false
						},
						{
							"eid": "p6IzcHpcez8exhXxOlVj4",
							"type": "authorPaper",
							"text": "ACTaint: Agent-Based Taint Analysis for Access Control Vulnerabilities in Smart Contracts",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c554/573300c554.pdf",
							"extraLocations": [],
							"authorNames": "Huarui Lin (Zhejiang University, China), Zhipeng Gao (Zhejiang University, China), Jiachi Chen (Zhejiang University, China), Xiang Chen (Nantong University, China), Xiaohu Yang (Zhejiang University, China), Lingfeng Bao (Zhejiang University, China)",
							"abstract": "Smart contracts have become a foundational component of blockchain systems, enabling decentralized, transparent, and autonomous execution of application logic across various domains, including decentralized finance (DeFi), gaming, and digital identity. Due to their immutable and trustless nature, smart contracts often manage and transfer substantial amounts of assets without human intervention. However, vulnerabilities in smart contracts can lead to substantial financial losses. Among these, access control vulnerabilities are particularly critical, typically originating from inadequately designed or incorrectly implemented permission mechanisms. Most existing methods for detecting access control vulnerabilities are based on static analysis, which heavily relies on manually defined rules and pattern matching. While these methods are efficient at identifying certain classes of known vulnerabilities, they are inherently limited in scope and generalization. In particular, they often fail to capture the underlying business logic of smart contracts. In this paper, we propose an LLM-based multi-agent system, named ACTAINT, for detecting access control vulnerabilities in Solidity smart contracts. ACTAINT first performs static analysis to guide the sink agent in identifying potential sinks. Then, based on the identified sinks, the taint agent conducts taint analysis to determine whether a data flow exists from untrusted sources to these sinks. We evaluate our approach on three datasets: known CVE cases, a set of 624 real-world smart contracts, and another set of 93 real-world smart contracts. The results demonstrate that our method outperforms existing tools in both datasets. On the first dataset, our approach outperforms state-of-the-art tools, including AChecker and GPTLens, achieving higher recall and F1-score. On the second dataset, our method surpasses the leading static analysis tool AChecker, with a 8.3% improvement in precision and an 9.7% improvement in F1-score.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 ACTaint: Agent-Based Taint Analysis for Access Control Vulnerabilities in Smart Contracts 1759418830362 10.1109/ASE63991.2025.00210 Huarui Lin Zhejiang University, China 12321077@zju.edu.cn Zhipeng Gao Zhejiang University, China zhipeng.gao@zju.edu.cn Jiachi Chen Zhejiang University, China chenjiachi317@gmail.com Xiang Chen Nantong University, China xchencs@ntu.edu.cn Xiaohu Yang Zhejiang University, China yangxh@zju.edu.cn Lingfeng Bao Zhejiang University, China lingfengbao@zju.edu.cn smart contract access control Smart contracts have become a foundational component of blockchain systems, enabling decentralized, transparent, and autonomous execution of application logic across various domains, including decentralized finance (DeFi), gaming, and digital identity. Due to their immutable and trustless nature, smart contracts often manage and transfer substantial amounts of assets without human intervention. However, vulnerabilities in smart contracts can lead to substantial financial losses. Among these, access control vulnerabilities are particularly critical, typically originating from inadequately designed or incorrectly implemented permission mechanisms. Most existing methods for detecting access control vulnerabilities are based on static analysis, which heavily relies on manually defined rules and pattern matching. While these methods are efficient at identifying certain classes of known vulnerabilities, they are inherently limited in scope and generalization. In particular, they often fail to capture the underlying business logic of smart contracts. In this paper, we propose an LLM-based multi-agent system, named ACTAINT, for detecting access control vulnerabilities in Solidity smart contracts. ACTAINT first performs static analysis to guide the sink agent in identifying potential sinks. Then, based on the identified sinks, the taint agent conducts taint analysis to determine whether a data flow exists from untrusted sources to these sinks. We evaluate our approach on three datasets: known CVE cases, a set of 624 real-world smart contracts, and another set of 93 real-world smart contracts. The results demonstrate that our method outperforms existing tools in both datasets. On the first dataset, our approach outperforms state-of-the-art tools, including AChecker and GPTLens, achieving higher recall and F1-score. On the second dataset, our method surpasses the leading static analysis tool AChecker, with a 8.3% improvement in precision and an 9.7% improvement in F1-score.",
							"pageNumber": 2554,
							"isPageNumberRoman": false
						},
						{
							"eid": "24wXemCV8mWDzLWz2KfvZJ",
							"type": "authorPaper",
							"text": "DRIFT: Debug-Based Trace Inference for Firmware Testing",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c567/573300c567.pdf",
							"extraLocations": [],
							"authorNames": "Changming Liu (Northeastern University, USA), Alejandro Mera (Northeastern University, USA), Meng Xu (Northeastern University, USA), Engin Kirda (Northeastern University, USA)",
							"abstract": "Binary firmware fuzzing has garnered attention in recent years. Compared to source-code-based approaches, binary approaches require less semantic information and are therefore more applicable. This is particularly relevant in firmware analysis, as most firmware vendors distribute only binaries, withholding source code due to proprietary concerns. Pivoting away from the traditional hardware-in-the-loop (HiL) methodology, researchers are exploring more efficient ways to engage real hardware for fuzzing. However, existing approaches have inherent drawbacks, such as reliance on high-end hardware features, inability to recover complete coverage, and slow execution speeds. We propose DRIFT, a novel approach for on-device binary firmware testing that follows the semihosting methodology. DRIFT addresses all the aforementioned drawbacks. The core insight of DRIFT is to use the Debug Monitor (DM) for firmware fuzzing. DM is a ARM Cortex-M CPU feature that allows triggering interrupt when a breakpoint is hit. Through chaining the DM interrupts, DRIFT is able let firmware to trace itself. This self-tracing approach minimizes interference from the workstation, significantly boosting fuzzing performance. We designed DRIFT to be highly flexible, accommodating a number of hardware resource limitations. When applied to new firmware, DRIFT discovered three previously unknown bugs that were not identified by existing binary fuzzing techniques. Furthermore, DRIFT outperforms all state-of-the-art binary firmware fuzzers in terms of speed and fidelity, trailing only SHiFT, an approach that requires source code.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 DRIFT: Debug-Based Trace Inference for Firmware Testing 1759382655877 10.1109/ASE63991.2025.00211 Changming Liu Northeastern University, USA liu.changm@northeastern.edu Alejandro Mera Northeastern University, USA mera.a@northeastern.edu Meng Xu Northeastern University, USA meng.xu.cs@uwaterloo.ca Engin Kirda Northeastern University, USA e.kirda@northeastern.edu embedded systems fuzzing debug monitor arm cortex-m Binary firmware fuzzing has garnered attention in recent years. Compared to source-code-based approaches, binary approaches require less semantic information and are therefore more applicable. This is particularly relevant in firmware analysis, as most firmware vendors distribute only binaries, withholding source code due to proprietary concerns. Pivoting away from the traditional hardware-in-the-loop (HiL) methodology, researchers are exploring more efficient ways to engage real hardware for fuzzing. However, existing approaches have inherent drawbacks, such as reliance on high-end hardware features, inability to recover complete coverage, and slow execution speeds. We propose DRIFT, a novel approach for on-device binary firmware testing that follows the semihosting methodology. DRIFT addresses all the aforementioned drawbacks. The core insight of DRIFT is to use the Debug Monitor (DM) for firmware fuzzing. DM is a ARM Cortex-M CPU feature that allows triggering interrupt when a breakpoint is hit. Through chaining the DM interrupts, DRIFT is able let firmware to trace itself. This self-tracing approach minimizes interference from the workstation, significantly boosting fuzzing performance. We designed DRIFT to be highly flexible, accommodating a number of hardware resource limitations. When applied to new firmware, DRIFT discovered three previously unknown bugs that were not identified by existing binary fuzzing techniques. Furthermore, DRIFT outperforms all state-of-the-art binary firmware fuzzers in terms of speed and fidelity, trailing only SHiFT, an approach that requires source code.",
							"pageNumber": 2567,
							"isPageNumberRoman": false
						},
						{
							"eid": "5PEwkxkPneNti5tYsRfWmC",
							"type": "authorPaper",
							"text": "WINGMUZZ: Blackbox Testing of IoT Protocols via Two-Dimensional Fuzzing Schedule",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c579/573300c579.pdf",
							"extraLocations": [],
							"authorNames": "Xiaogang Zhu (Adelaide University, Australia), Enze Dai (Swinburne University of Technology, Australia), Xiaotao Feng (Swinburne University of Technology, Australia), Shaohua Wang (Central University of Finance and Economics, China), Xin Xia (Zhejiang University, China), Sheng Wen (Swinburne University of Technology, Australia), Kwok-Yan Lam (Nanyang Technological University, Singapore), Yang Xiang (Swinburne University of Technology, Australia)",
							"abstract": "The Internet of Things (IoT) is widely used in various sectors but is often prone to vulnerabilities. With the proprietary nature of IoT devices, their source code and firmware are frequently unavailable for open review, rendering blackbox fuzzing a viable approach. However, the effectiveness of blackbox fuzzing is often challenging due to the lack of feedback, especially the information of code coverage. In this paper, we propose WINGMUZZ to provide blackbox fuzzing of IoT protocols with effective feedback. The key is to guide blackbox fuzzing by utilizing runtime information from greybox fuzzing on counterpart open-source code. This is based on our observation that IoT protocols and open-source code conform to the same specifications, indicating that inputs exploring different code regions on open-source code may also discover new coverage on IoT protocols. WINGMUZZ uses a two-dimensional fuzzing schedule to optimize the process of fuzzing IoT protocols. The first dimension involves scheduling open-source implementations, referred to as wingmates, so that similar ones are preferred to guide blackbox fuzzing. The second dimension utilizes coverage-guided greybox fuzzing to test open-source code. This solution can bridge the performance gap between blackbox fuzzing and greybox fuzzing on IoT protocols. We evaluate the performance of WINGMUZZ across eight IoT protocols and compare it with six widely-used blackbox fuzzers. On average, WINGMUZZ can discover 42.1%, 26.92%, 25.01%, 34.95%, 23.56% and 11.63% more edges than Boofuzz, Spike, Peach, SNIPUZZ, Pulsar and ChatAFL, respectively. Additionally, WINGMUZZ exposes 10 bugs in IoT protocols while other fuzzers expose no more than 3 bugs. It also exposes 2 new protocol vulnerabilities in IoT devices while other fuzzers cannot identify any.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 WINGMUZZ: Blackbox Testing of IoT Protocols via Two-Dimensional Fuzzing Schedule 1758864303792 10.1109/ASE63991.2025.00212 Xiaogang Zhu Adelaide University, Australia xiaogang.zhu@adelaide.edu.au Enze Dai Swinburne University of Technology, Australia edai@swin.edu.au Xiaotao Feng Swinburne University of Technology, Australia xfeng@swin.edu.au Shaohua Wang Central University of Finance and Economics, China davidshwang@ieee.org Xin Xia Zhejiang University, China xin.xia@acm.org Sheng Wen Swinburne University of Technology, Australia swen@swin.edu.au Kwok-Yan Lam Nanyang Technological University, Singapore kwokyan.lam@ntu.edu.sg Yang Xiang Swinburne University of Technology, Australia yxiang@swin.edu.au fuzzing blackbox testing iot protocols The Internet of Things (IoT) is widely used in various sectors but is often prone to vulnerabilities. With the proprietary nature of IoT devices, their source code and firmware are frequently unavailable for open review, rendering blackbox fuzzing a viable approach. However, the effectiveness of blackbox fuzzing is often challenging due to the lack of feedback, especially the information of code coverage. In this paper, we propose WINGMUZZ to provide blackbox fuzzing of IoT protocols with effective feedback. The key is to guide blackbox fuzzing by utilizing runtime information from greybox fuzzing on counterpart open-source code. This is based on our observation that IoT protocols and open-source code conform to the same specifications, indicating that inputs exploring different code regions on open-source code may also discover new coverage on IoT protocols. WINGMUZZ uses a two-dimensional fuzzing schedule to optimize the process of fuzzing IoT protocols. The first dimension involves scheduling open-source implementations, referred to as wingmates, so that similar ones are preferred to guide blackbox fuzzing. The second dimension utilizes coverage-guided greybox fuzzing to test open-source code. This solution can bridge the performance gap between blackbox fuzzing and greybox fuzzing on IoT protocols. We evaluate the performance of WINGMUZZ across eight IoT protocols and compare it with six widely-used blackbox fuzzers. On average, WINGMUZZ can discover 42.1%, 26.92%, 25.01%, 34.95%, 23.56% and 11.63% more edges than Boofuzz, Spike, Peach, SNIPUZZ, Pulsar and ChatAFL, respectively. Additionally, WINGMUZZ exposes 10 bugs in IoT protocols while other fuzzers expose no more than 3 bugs. It also exposes 2 new protocol vulnerabilities in IoT devices while other fuzzers cannot identify any.",
							"pageNumber": 2579,
							"isPageNumberRoman": false
						},
						{
							"eid": "3WQRIQ6yR2HWlQjUuPSXN7",
							"type": "authorPaper",
							"text": "On the Robustness Evaluation of 3D Obstacle Detection Against Specifications in Autonomous Driving",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c592/573300c592.pdf",
							"extraLocations": [],
							"authorNames": "Tri Minh-Triet Pham (Concordia University, Canada), Bo Yang (Concordia University, Canada), Jinqiu Yang (Concordia University, Canada)",
							"abstract": "Autonomous driving systems (ADSs) rely on real-time sensor data, such as cameras and LiDARs, for time-critical decisions using deep neural networks. The accuracy of these decisions is crucial for the widespread adoption of ADSs, as errors can have serious consequences. 3D obstacle detection, in particular, is sensitive to point cloud data (PCD) noise from various sources. However, the robustness of current 3D obstacle detection models against specification-based perturbations remains unevaluated. These perturbations are derived from the specification of LiDAR sensors and previous research on LiDAR's ability to capture objects of different colors and materials. They can manifest as very subtle sensor-based noises or obstacle-specific perturbations. Hence, we propose SORBET, a framework that tests the robustness of 3D obstacle detection models in ADS against such perturbations to the PCD to evaluate their robustness. We applied SORBET to evaluate the robustness of five classic 3D obstacle detection models, including one from an industry-grade Level 4 ADS (Baidu's Apollo). Furthermore, we studied how the deviated obstacle detection results would propagate and negatively impact trajectory prediction. Our evaluation emphasizes the importance of testing 3D obstacle detection against specification-based perturbations. We find that even very subtle changes in the PCD (i.e., removing two points) may introduce a non-trivial decrease in the detection performance. Furthermore, such a negative impact will further propagate to other modules and endanger the safety of the ADS. ",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 On the Robustness Evaluation of 3D Obstacle Detection Against Specifications in Autonomous Driving 1759292317612 10.1109/ASE63991.2025.00213 Tri Minh-Triet Pham Concordia University, Canada p_triet@encs.concordia.ca Bo Yang Concordia University, Canada b_yang96@encs.concordia.ca Jinqiu Yang Concordia University, Canada jinqiu.yang@concordia.ca autonomous vehicles lidar software testing system testing robustness simulation Autonomous driving systems (ADSs) rely on real-time sensor data, such as cameras and LiDARs, for time-critical decisions using deep neural networks. The accuracy of these decisions is crucial for the widespread adoption of ADSs, as errors can have serious consequences. 3D obstacle detection, in particular, is sensitive to point cloud data (PCD) noise from various sources. However, the robustness of current 3D obstacle detection models against specification-based perturbations remains unevaluated. These perturbations are derived from the specification of LiDAR sensors and previous research on LiDAR's ability to capture objects of different colors and materials. They can manifest as very subtle sensor-based noises or obstacle-specific perturbations. Hence, we propose SORBET, a framework that tests the robustness of 3D obstacle detection models in ADS against such perturbations to the PCD to evaluate their robustness. We applied SORBET to evaluate the robustness of five classic 3D obstacle detection models, including one from an industry-grade Level 4 ADS (Baidu's Apollo). Furthermore, we studied how the deviated obstacle detection results would propagate and negatively impact trajectory prediction. Our evaluation emphasizes the importance of testing 3D obstacle detection against specification-based perturbations. We find that even very subtle changes in the PCD (i.e., removing two points) may introduce a non-trivial decrease in the detection performance. Furthermore, such a negative impact will further propagate to other modules and endanger the safety of the ADS.",
							"pageNumber": 2592,
							"isPageNumberRoman": false
						},
						{
							"eid": "izbLinBx4aarC5HRih88Y",
							"type": "authorPaper",
							"text": "SE-Jury: An LLM-as-Ensemble-Judge Metric for Narrowing the Gap with Human Evaluation in SE",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c605/573300c605.pdf",
							"extraLocations": [],
							"authorNames": "Xin Zhou (Singapore Management University, Singapore), Kisub Kim (DGIST, Republic of Korea), Ting Zhang (Monash University, Australia), Martin Weyssow (Singapore Management University, Singapore), Lu\u00EDs F. Gomes (Singapore Management University, Singapore), Guang Yang (Nanjing University of Aeronautics and Astronautics, China), Kui Liu (Huawei Software Engineering Application Technology Lab, China), Xin Xia (Zhejiang University, China), David  Lo (Singapore Management University, Singapore)",
							"abstract": "Large Language Models (LLMs) and other automated techniques have been increasingly used to support software developers by generating software artifacts such as code snippets, patches, and comments. However, accurately assessing the correctness of these generated artifacts remains a significant challenge. On one hand, human evaluation provides high accuracy but is labor-intensive and lacks scalability. On the other hand, many automatic evaluation metrics are scalable and require minimal human effort, but they often fail to accurately reflect the actual correctness of generated software artifacts. In this paper, we present SE-Jury, the first evaluation metric for LLM-as-Ensemble-Judge specifically designed to accurately assess the correctness of generated software artifacts. SE-Jury first defines five distinct evaluation strategies, each implemented as an independent judge. A dynamic team selection mechanism then identifies the most appropriate subset of judges as a team to produce a final correctness score through ensembling. We evaluate SE-Jury across a diverse set of software engineering (SE) benchmarks that span three popular SE tasks: code generation, automated program repair, and code summarization. Results demonstrate that SE-Jury consistently achieves a higher correlation with human judgments, with improvements ranging from 29.6%\u2013140.8% over existing automatic metrics. SE-Jury reaches agreement levels with human annotators that are close to inter-annotator agreement in code generation and program repair. These findings underscore SE-Jury's potential as a scalable and reliable alternative to human evaluation in these SE tasks.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 SE-Jury: An LLM-as-Ensemble-Judge Metric for Narrowing the Gap with Human Evaluation in SE 1759514512839 10.1109/ASE63991.2025.00214 Xin Zhou Singapore Management University, Singapore xinzhou.2020@phdcs.smu.edu.sg Kisub Kim DGIST, Republic of Korea kisub.kim@dgist.ac.kr Ting Zhang Monash University, Australia ting.zhang@monash.edu Martin Weyssow Singapore Management University, Singapore mweyssow@smu.edu.sg Lu\u00EDs F. Gomes Singapore Management University, Singapore lfgomes@smu.edu.sg Guang Yang Nanjing University of Aeronautics and Astronautics, China novelyg@outlook.com Kui Liu Huawei Software Engineering Application Technology Lab, China brucekuiliu@gmail.com Xin Xia Zhejiang University, China xin.xia@acm.org David Lo Singapore Management University, Singapore davidlo@smu.edu.sg llm software evaluation Large Language Models (LLMs) and other automated techniques have been increasingly used to support software developers by generating software artifacts such as code snippets, patches, and comments. However, accurately assessing the correctness of these generated artifacts remains a significant challenge. On one hand, human evaluation provides high accuracy but is labor-intensive and lacks scalability. On the other hand, many automatic evaluation metrics are scalable and require minimal human effort, but they often fail to accurately reflect the actual correctness of generated software artifacts. In this paper, we present SE-Jury, the first evaluation metric for LLM-as-Ensemble-Judge specifically designed to accurately assess the correctness of generated software artifacts. SE-Jury first defines five distinct evaluation strategies, each implemented as an independent judge. A dynamic team selection mechanism then identifies the most appropriate subset of judges as a team to produce a final correctness score through ensembling. We evaluate SE-Jury across a diverse set of software engineering (SE) benchmarks that span three popular SE tasks: code generation, automated program repair, and code summarization. Results demonstrate that SE-Jury consistently achieves a higher correlation with human judgments, with improvements ranging from 29.6%\u2013140.8% over existing automatic metrics. SE-Jury reaches agreement levels with human annotators that are close to inter-annotator agreement in code generation and program repair. These findings underscore SE-Jury's potential as a scalable and reliable alternative to human evaluation in these SE tasks.",
							"pageNumber": 2605,
							"isPageNumberRoman": false
						},
						{
							"eid": "41mdTfqfSz28Kwa5LBgICR",
							"type": "authorPaper",
							"text": "EfficientEdit: Accelerating Code Editing via Edit-Oriented Speculative Decoding",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c618/573300c618.pdf",
							"extraLocations": [],
							"authorNames": "Peiding Wang (Beihang University, China), Li Zhang (Beihang University, China), Fang Liu (Beihang University, China), Yinghao Zhu (Beihang University, China), Wang Xu (Tsinghua University, China), Lin Shi (Beihang University, China), Xiaoli Lian (Beihang University, China), Minxiao Li (Beihang University, China), Bo Shen (Huawei Cloud Computing Technologies Co., Ltd., China), An Fu (Huawei Cloud Computing Technologies Co., Ltd., China)",
							"abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities in code editing, substantially enhancing software development productivity. However, the inherent complexity of code editing tasks forces existing approaches to rely on LLMs' autoregressive end-to-end generation, where decoding speed plays a critical role in efficiency. While inference acceleration techniques like speculative decoding are applied to improve the decoding efficiency, these methods fail to account for the unique characteristics of code editing tasks, where changes are typically localized and existing code segments are reused. To address this limitation, we propose EfficientEdit, a novel method that improves LLM-based code editing efficiency through two key mechanisms based on speculative decoding: (1) effective reuse of original code segments while identifying potential edit locations, and (2) efficient generation of edit content via high-quality drafts from edit-oriented draft models and a dynamic verification mechanism that balances quality and acceleration. Experimental results show that EfficientEdit can achieve up to 10.38\u00D7 and 13.09\u00D7 speedup compared to standard autoregressive decoding in CanItEdit and CodeIF-Bench, respectively, outperforming state-of-the-art inference acceleration approaches by up to 90.6%. The code and data are available at https://github.com/zhu-zhu-ding/EfficientEdit.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 EfficientEdit: Accelerating Code Editing via Edit-Oriented Speculative Decoding 1758886403634 10.1109/ASE63991.2025.00215 Peiding Wang Beihang University, China wangpeiding@buaa.edu.cn Li Zhang Beihang University, China lily@buaa.edu.cn Fang Liu Beihang University, China fangliu@buaa.edu.cn Yinghao Zhu Beihang University, China zhuyinghao@buaa.edu.cn Wang Xu Tsinghua University, China xwjim812@gmail.com Lin Shi Beihang University, China shilin@buaa.edu.cn Xiaoli Lian Beihang University, China lianxiaoli@buaa.edu.cn Minxiao Li Beihang University, China 15838781820@163.com Bo Shen Huawei Cloud Computing Technologies Co., Ltd., China shenbo21@huawei.com An Fu Huawei Cloud Computing Technologies Co., Ltd., China fuan1@huawei.com Code Editing Large Language Models Efficient Inference Speculative Decoding Large Language Models (LLMs) have demonstrated remarkable capabilities in code editing, substantially enhancing software development productivity. However, the inherent complexity of code editing tasks forces existing approaches to rely on LLMs' autoregressive end-to-end generation, where decoding speed plays a critical role in efficiency. While inference acceleration techniques like speculative decoding are applied to improve the decoding efficiency, these methods fail to account for the unique characteristics of code editing tasks, where changes are typically localized and existing code segments are reused. To address this limitation, we propose EfficientEdit, a novel method that improves LLM-based code editing efficiency through two key mechanisms based on speculative decoding: (1) effective reuse of original code segments while identifying potential edit locations, and (2) efficient generation of edit content via high-quality drafts from edit-oriented draft models and a dynamic verification mechanism that balances quality and acceleration. Experimental results show that EfficientEdit can achieve up to 10.38\u00D7 and 13.09\u00D7 speedup compared to standard autoregressive decoding in CanItEdit and CodeIF-Bench, respectively, outperforming state-of-the-art inference acceleration approaches by up to 90.6%. The code and data are available at https://github.com/zhu-zhu-ding/EfficientEdit.",
							"pageNumber": 2618,
							"isPageNumberRoman": false
						},
						{
							"eid": "2s5EG7gQeUYpaLg1mIcHXg",
							"type": "authorPaper",
							"text": "AutoFid: Adaptive and Noise-Aware Fidelity Measurement for Quantum Programs via Circuit Graph Analysis",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c630/573300c630.pdf",
							"extraLocations": [],
							"authorNames": "Tingting Li (Zhejiang University, China; Shanghai Qi Zhi Institute, China), Ziming Zhao (Zhejiang University, China), Jianwei Yin (Zhejiang University, China)",
							"abstract": "Quantum computers in the Noisy Intermediate-Scale Quantum (NISQ) era face significant challenges due to inherent noise and limited qubit coherence. Accurate fidelity evaluation of quantum states necessitates multiple repeated measurements to obtain statistical results. But determining the optimal number of measurements remains an open problem due to the dynamic, device-dependent nature of quantum noise. Existing methods either assume prior knowledge of the noise model or inherently employ a fixed measurement strategy, which limits their applicability in practical deployment scenarios. This paper presents AutoFid, an adaptive and noise-aware fidelity measurement framework that automatically determines the number of required tests based on circuit structure and hardware feedback. AutoFid models quantum circuits as Directed Acyclic Graphs and estimates structural complexity via random walks, enabling estimation of measurement effort. It further incorporates transpilation-aware features such as gate fidelity, depth inflation, and crosstalk to refine iteration budgets. During runtime, AutoFid dynamically samples fidelity results and employs an early stopping strategy based on confidence intervals to reduce redundant measurements while preserving accuracy guarantees. We evaluate AutoFid on 18 quantum benchmarks executed on real IBMQ hardware platforms. Experimental results show that AutoFid reduces measurement costs by more than 50% compared to both fixed-shot and learning-based baselines, while consistently maintaining fidelity bias below 0.01. Additional analysis using classical software testing metrics and ablation studies demonstrate its effectiveness, robustness, and adaptability across a wide range of quantum workloads.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 AutoFid: Adaptive and Noise-Aware Fidelity Measurement for Quantum Programs via Circuit Graph Analysis 1759579033572 10.1109/ASE63991.2025.00216 Tingting Li Zhejiang University, China; Shanghai Qi Zhi Institute, China litt2020@zju.edu.cn Ziming Zhao Zhejiang University, China zhaoziming@zju.edu.cn Jianwei Yin Zhejiang University, China zjuyjw@cs.zju.edu.cn adaptive fidelity estimation confidence intervals mixing time quantum software testing Quantum computers in the Noisy Intermediate-Scale Quantum (NISQ) era face significant challenges due to inherent noise and limited qubit coherence. Accurate fidelity evaluation of quantum states necessitates multiple repeated measurements to obtain statistical results. But determining the optimal number of measurements remains an open problem due to the dynamic, device-dependent nature of quantum noise. Existing methods either assume prior knowledge of the noise model or inherently employ a fixed measurement strategy, which limits their applicability in practical deployment scenarios. This paper presents AutoFid, an adaptive and noise-aware fidelity measurement framework that automatically determines the number of required tests based on circuit structure and hardware feedback. AutoFid models quantum circuits as Directed Acyclic Graphs and estimates structural complexity via random walks, enabling estimation of measurement effort. It further incorporates transpilation-aware features such as gate fidelity, depth inflation, and crosstalk to refine iteration budgets. During runtime, AutoFid dynamically samples fidelity results and employs an early stopping strategy based on confidence intervals to reduce redundant measurements while preserving accuracy guarantees. We evaluate AutoFid on 18 quantum benchmarks executed on real IBMQ hardware platforms. Experimental results show that AutoFid reduces measurement costs by more than 50% compared to both fixed-shot and learning-based baselines, while consistently maintaining fidelity bias below 0.01. Additional analysis using classical software testing metrics and ablation studies demonstrate its effectiveness, robustness, and adaptability across a wide range of quantum workloads.",
							"pageNumber": 2630,
							"isPageNumberRoman": false
						},
						{
							"eid": "3BTi4WS8NA2ZUSsESMjmde",
							"type": "authorPaper",
							"text": "Using Active Learning to Train Predictive Mutation Testing with Minimal Data",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c643/573300c643.pdf",
							"extraLocations": [],
							"authorNames": "Mikl\u00F3s Borsi (Karlsruhe Institute of Technology, Germany)",
							"abstract": "Mutation testing is a powerful method of evaluating test suite adequacy. Despite growing industry attention, wide-scale application is frequently limited by the high runtime cost of mutation testing. A set of predictive models have been proposed to mitigate this cost issue, intending to replace the actual execution of a mutated program's test suite with a predicted result of the tests' outcome. These predictive models ingest static code features, dynamic execution features, or code and documentation text to produce the predictions. Feature-based models can require a large amount of training data and mutants executed by test cases to become operational. We propose active learning-based predictive mutation testing (AL-PMT) as a way to dramatically reduce the amount of training data needed for a performant model. We conduct experiments to compare AL-PMT's performance with a non-active learning model and find that AL-PMT quickly converges to improved or on-par performance compared to the baseline of the foundational PMT. AL-PMT achieves 98% of its best possible performance in over 80% of examined projects, while observing only 10% of each project's mutant set kill status. In addition to training in a fraction of the data required for previous models, AL-PMT is organized in a way that is more amenable to a potential industry application scenario. Besides not requiring the building, running and full mutation testing of several other projects or versions for training data, AL-PMT is able to identify challenging mutants and select them for execution. As such, we expand on the coverage metric provided by basic predictive mutation testing with the ability to guide the targeted execution of important mutants and guiding attention of developers to remaining survived ones. This addresses the rarely mentioned cost of human developer time on fixing the findings of mutation testing, rather than just the computational time spent producing the mutants.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Using Active Learning to Train Predictive Mutation Testing with Minimal Data 1759516649433 10.1109/ASE63991.2025.00217 Mikl\u00F3s Borsi Karlsruhe Institute of Technology, Germany miklos.borsi@kit.edu active learning mutation testing Mutation testing is a powerful method of evaluating test suite adequacy. Despite growing industry attention, wide-scale application is frequently limited by the high runtime cost of mutation testing. A set of predictive models have been proposed to mitigate this cost issue, intending to replace the actual execution of a mutated program's test suite with a predicted result of the tests' outcome. These predictive models ingest static code features, dynamic execution features, or code and documentation text to produce the predictions. Feature-based models can require a large amount of training data and mutants executed by test cases to become operational. We propose active learning-based predictive mutation testing (AL-PMT) as a way to dramatically reduce the amount of training data needed for a performant model. We conduct experiments to compare AL-PMT's performance with a non-active learning model and find that AL-PMT quickly converges to improved or on-par performance compared to the baseline of the foundational PMT. AL-PMT achieves 98% of its best possible performance in over 80% of examined projects, while observing only 10% of each project's mutant set kill status. In addition to training in a fraction of the data required for previous models, AL-PMT is organized in a way that is more amenable to a potential industry application scenario. Besides not requiring the building, running and full mutation testing of several other projects or versions for training data, AL-PMT is able to identify challenging mutants and select them for execution. As such, we expand on the coverage metric provided by basic predictive mutation testing with the ability to guide the targeted execution of important mutants and guiding attention of developers to remaining survived ones. This addresses the rarely mentioned cost of human developer time on fixing the findings of mutation testing, rather than just the computational time spent producing the mutants.",
							"pageNumber": 2643,
							"isPageNumberRoman": false
						},
						{
							"eid": "4p3PjHVvbUp7VaqNJF1kGO",
							"type": "authorPaper",
							"text": "QuanBench: Benchmarking Quantum Code Generation with Large Language Models",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c656/573300c656.pdf",
							"extraLocations": [],
							"authorNames": "Xiaoyu Guo (Kyushu University), Minggu Wang (Kyushu University), Jianjun Zhao (Kyushu University)",
							"abstract": "Large language models (LLMs) have shown good performance in general code generation, but their capability in quantum code generation remains insufficiently studied. This paper presents QuanBench, a benchmark for evaluating LLMs on quantum code generation. QuanBench includes 44 programming tasks covering quantum algorithms, state preparation, gate decomposition, and quantum machine learning. Each task has an executable canonical solution and is evaluated by functional correctness (Pass@K) and quantum semantic equivalence (Process Fidelity). We evaluate several recent LLMs, including general-purpose and code-specialized models. The results show that current LLMs have limited capability in generating correct quantum code, with overall accuracy below 40% and frequent semantic errors. We also analyze common failure cases, such as outdated API usage, circuit construction errors, and incorrect algorithm logic. QuanBench provides a basis for future work on improving quantum code generation with LLMs.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 QuanBench: Benchmarking Quantum Code Generation with Large Language Models 1759461607075 10.1109/ASE63991.2025.00218 Xiaoyu Guo Kyushu University guo.xiaoyu.961@s.kyushu-u.ac.jp Minggu Wang Kyushu University wang.minggu.065@s.kyushu-u.ac.jp Jianjun Zhao Kyushu University zhao@ait.kyushu-u.ac.jp quantum code generation large language models benchmarking quantum programming code evaluation quantum algorithm Large language models (LLMs) have shown good performance in general code generation, but their capability in quantum code generation remains insufficiently studied. This paper presents QuanBench, a benchmark for evaluating LLMs on quantum code generation. QuanBench includes 44 programming tasks covering quantum algorithms, state preparation, gate decomposition, and quantum machine learning. Each task has an executable canonical solution and is evaluated by functional correctness (Pass@K) and quantum semantic equivalence (Process Fidelity). We evaluate several recent LLMs, including general-purpose and code-specialized models. The results show that current LLMs have limited capability in generating correct quantum code, with overall accuracy below 40% and frequent semantic errors. We also analyze common failure cases, such as outdated API usage, circuit construction errors, and incorrect algorithm logic. QuanBench provides a basis for future work on improving quantum code generation with LLMs.",
							"pageNumber": 2656,
							"isPageNumberRoman": false
						},
						{
							"eid": "3k9P0ZxnNT4N4FzkncaQwb",
							"type": "authorPaper",
							"text": "How Big is the Automaton? Certified Lower Bounds on the Size of Presburger DFAs",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c669/573300c669.pdf",
							"extraLocations": [],
							"authorNames": "Nicolas Amat (Universit\u00E9 de Toulouse, France), Pierre Ganty (IMDEA Software Institute, Spain), Alessio Mansutti (IMDEA Software Institute, Spain)",
							"abstract": "Lower bounds provide essential insights into the minimal computational resources required for algorithm execution. This paper focuses on logical theories, a domain where estimating resources is particularly difficult, and provides a novel, fully-automated method for computing lower bounds on memory usage, serving as a proxy for the computational resources required to perform logical reasoning. Specifically, the paper focuses on computing lower bounds on the size of the minimal deterministic finite automaton that encodes the solution set of a given Presburger arithmetic (also known as linear integer arithmetic) formula. The lower bounds are accompanied by independently verifiable certificates which also support a union-like operation that can be used to increase the computed bounds. We conducted an extensive empirical evaluation of our method using over 5 000 formulae from the quantifier-free fragment of Presburger arithmetic, sourced from the SMT-LIB repository. The results show that our method often produces lower bounds that are close to the actual size of the minimal deterministic finite automaton. Moreover, it succeeds in computing non-trivial bounds even for instances that are out of reach (by several orders of magnitude) for the existing state-of-the-art automata-based tools for solving Presburger arithmetic.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 How Big is the Automaton? Certified Lower Bounds on the Size of Presburger DFAs 1759507339561 10.1109/ASE63991.2025.00219 Nicolas Amat Universit\u00E9 de Toulouse, France nicolas.amat@onera.fr Pierre Ganty IMDEA Software Institute, Spain pierre.ganty@imdea.org Alessio Mansutti IMDEA Software Institute, Spain alessio.mansutti@imdea.org presburger arithmetic finite automata smt Lower bounds provide essential insights into the minimal computational resources required for algorithm execution. This paper focuses on logical theories, a domain where estimating resources is particularly difficult, and provides a novel, fully-automated method for computing lower bounds on memory usage, serving as a proxy for the computational resources required to perform logical reasoning. Specifically, the paper focuses on computing lower bounds on the size of the minimal deterministic finite automaton that encodes the solution set of a given Presburger arithmetic (also known as linear integer arithmetic) formula. The lower bounds are accompanied by independently verifiable certificates which also support a union-like operation that can be used to increase the computed bounds. We conducted an extensive empirical evaluation of our method using over 5 000 formulae from the quantifier-free fragment of Presburger arithmetic, sourced from the SMT-LIB repository. The results show that our method often produces lower bounds that are close to the actual size of the minimal deterministic finite automaton. Moreover, it succeeds in computing non-trivial bounds even for instances that are out of reach (by several orders of magnitude) for the existing state-of-the-art automata-based tools for solving Presburger arithmetic.",
							"pageNumber": 2669,
							"isPageNumberRoman": false
						},
						{
							"eid": "TGQwifRhNY7Gd3NuFhZjV",
							"type": "authorPaper",
							"text": "Understanding Resource Injection Vulnerabilities in Kubernetes Ecosystems",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c681/573300c681.pdf",
							"extraLocations": [],
							"authorNames": "Defang Bo (Institute of Information Engineering, Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China), Jie Lu (SKLP, Institute of Computing Technology, CAS, China), Feng Li (Institute of Information Engineering, Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China), Jingting Chen (Institute of Information Engineering, Chinese Academy of Sciences, China), Jinchen Wang (Institute of Information Engineering, Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China), Chendong Yu (Institute of Information Engineering, Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China), Yeting Li (Institute of Information Engineering, Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China), Wei Huo (Institute of Information Engineering, Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China)",
							"abstract": "Cloud-native technologies have revolutionized application development, with Kubernetes emerging as the de facto standard platform for containerization and orchestration. Kubernetes manages applications through API objects called resources, where users declare desired states via resource definitions that are processed by controllers to reconcile system discrepancies. However, this resource-based architecture introduces resource injection vulnerabilities, where controllers perform privileged operations using user-controllable fields without adequate validation. Attackers can exploit these weaknesses by injecting malicious content into resource fields to achieve unauthorized access and privilege escalation. In this paper, we conduct the first comprehensive study on 125 resource injection vulnerabilities from 8,306 Kubernetes-related vulnerabilities across common databases. For all studied vulnerabilities, we investigate their vulnerable fields, root causes, privileged operations, exploitation conditions, and fixing strategies. Our study reveals many interesting findings that can guide the detection and mitigation of resource injection vulnerabilities, as well as the development of more secure cloud-native applications.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Understanding Resource Injection Vulnerabilities in Kubernetes Ecosystems 1759496952279 10.1109/ASE63991.2025.00220 Defang Bo Institute of Information Engineering, Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China bodefang@iie.ac.cn Jie Lu SKLP, Institute of Computing Technology, CAS, China lujie@ict.ac.cn Feng Li Institute of Information Engineering, Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China lifeng@iie.ac.cn Jingting Chen Institute of Information Engineering, Chinese Academy of Sciences, China chenjingting@iie.ac.cn Jinchen Wang Institute of Information Engineering, Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China wangjinchen@iie.ac.cn Chendong Yu Institute of Information Engineering, Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China yuchendong@iie.ac.cn Yeting Li Institute of Information Engineering, Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China liyeting@iie.ac.cn Wei Huo Institute of Information Engineering, Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China huowei@iie.ac.cn resource injection vulnerabilities kubernetes Cloud-native technologies have revolutionized application development, with Kubernetes emerging as the de facto standard platform for containerization and orchestration. Kubernetes manages applications through API objects called resources, where users declare desired states via resource definitions that are processed by controllers to reconcile system discrepancies. However, this resource-based architecture introduces resource injection vulnerabilities, where controllers perform privileged operations using user-controllable fields without adequate validation. Attackers can exploit these weaknesses by injecting malicious content into resource fields to achieve unauthorized access and privilege escalation. In this paper, we conduct the first comprehensive study on 125 resource injection vulnerabilities from 8,306 Kubernetes-related vulnerabilities across common databases. For all studied vulnerabilities, we investigate their vulnerable fields, root causes, privileged operations, exploitation conditions, and fixing strategies. Our study reveals many interesting findings that can guide the detection and mitigation of resource injection vulnerabilities, as well as the development of more secure cloud-native applications.",
							"pageNumber": 2681,
							"isPageNumberRoman": false
						},
						{
							"eid": "1d0IziHUXK8aYkDS9qpGQ0",
							"type": "authorPaper",
							"text": "From Characters to Structure: Rethinking Real-Time Collaborative Programming Models",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c694/573300c694.pdf",
							"extraLocations": [],
							"authorNames": "Leon Freudenthaler (Hochschule Campus Wien/TU Wien, Austria), Bernhard  Taufner (Hochschule Campus Wien, Austria), Karl Michael G\u00F6schka (TU Wien/UAS Technikum Wien, Austria)",
							"abstract": "Multiple programming tasks require synchronous collaboration between developers, giving rise to real-time collaborative programming tools that enable simultaneous editing of shared source code. However, most existing tools operate at the text level, propagating every keystroke\u2013including syntactically invalid ones\u2013without considering program structure. This results in excessive communication overhead, frequent propagation of build-breaking states, and poor synchronization. A major consequence is noticeable lag, especially under unstable network conditions, as collaborators are overwhelmed with unnecessary updates that disrupt their workflow and degrade the shared coding experience. In this paper, we introduce a novel structure-aware propagation model that transmits only syntactically valid code changes. For evaluation we implemented our tool as an IntelliJ plugin and evaluate it against three industry-standard tools\u2013VS Code Live Share, Code With Me, and Replit\u2013across eight representative programming scenarios. Our results show that it significantly lowers the number and size of propagated messages while maintaining consistent, buildable program states. Our findings demonstrate the potential of structure-aware propagation as a foundation for the next generation of real-time collaborative programming environments. ",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 From Characters to Structure: Rethinking Real-Time Collaborative Programming Models 1758360354173 10.1109/ASE63991.2025.00221 Leon Freudenthaler Hochschule Campus Wien/TU Wien, Austria leon.freudenthaler@hcw.ac.at Bernhard Taufner Hochschule Campus Wien, Austria bernhard.taufner@hcw.ac.at Karl Michael G\u00F6schka TU Wien/UAS Technikum Wien, Austria karl.goeschka@tuwien.ac.at real-time collaborative programming ast-based operations structure-aware propagation synchronous collabora tion systems Multiple programming tasks require synchronous collaboration between developers, giving rise to real-time collaborative programming tools that enable simultaneous editing of shared source code. However, most existing tools operate at the text level, propagating every keystroke\u2013including syntactically invalid ones\u2013without considering program structure. This results in excessive communication overhead, frequent propagation of build-breaking states, and poor synchronization. A major consequence is noticeable lag, especially under unstable network conditions, as collaborators are overwhelmed with unnecessary updates that disrupt their workflow and degrade the shared coding experience. In this paper, we introduce a novel structure-aware propagation model that transmits only syntactically valid code changes. For evaluation we implemented our tool as an IntelliJ plugin and evaluate it against three industry-standard tools\u2013VS Code Live Share, Code With Me, and Replit\u2013across eight representative programming scenarios. Our results show that it significantly lowers the number and size of propagated messages while maintaining consistent, buildable program states. Our findings demonstrate the potential of structure-aware propagation as a foundation for the next generation of real-time collaborative programming environments.",
							"pageNumber": 2694,
							"isPageNumberRoman": false
						},
						{
							"eid": "32Efg2ShPSUGTJxSnHtxRT",
							"type": "authorPaper",
							"text": "State Field Coverage: A Metric for Oracle Quality",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c706/573300c706.pdf",
							"extraLocations": [],
							"authorNames": "Facundo Molina (IMDEA Software Institute, Spain), Nazareno Aguirre (University of Rio Cuarto and CONICET, Argentina; Guangdong Technion-Israel Institute of Technology, China), Alessandra Gorla (IMDEA Software Institute, Spain)",
							"abstract": "The effectiveness of testing in uncovering software defects depends not only on the characteristics of the test inputs and how thoroughly they exercise the software, but also on the quality of the oracles used to determine whether the software behaves as expected. Therefore, assessing the quality of oracles is crucial to improve the overall effectiveness of the testing process. Existing metrics have been used for this purpose, but they either fail to provide a comprehensive basis for guiding oracle improvement, or they are tailored to specific types of oracles, thus limiting their generality. In this paper, we introduce state field coverage, a novel metric for assessing oracle quality. This metric measures the proportion of an object's state, as statically defined by its class fields, that an oracle may access during test execution. The main intuition of our metric is that oracles with a higher state field coverage are more likely to detect faults in the software under analysis, as they inspect a larger portion of the object states to determine whether tests pass or not. We implement a mechanism to statically compute the state field coverage metric. Being statically computed, the metric is efficient and provides direct guidance for improving test oracles by identifying state fields that remain unexamined. We evaluate state field coverage through experiments involving 273 representation invariants and 249,027 test assertions. The results show that state field coverage is a well-suited metric for assessing oracle quality, as it strongly correlates with the oracles' fault-detection ability, measured by mutation score.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 State Field Coverage: A Metric for Oracle Quality 1759567239777 10.1109/ASE63991.2025.00222 Facundo Molina IMDEA Software Institute, Spain facundo.molina@imdea.org Nazareno Aguirre University of Rio Cuarto and CONICET, Argentina; Guangdong Technion-Israel Institute of Technology, China naguirre@dc.exa.unrc.edu.ar Alessandra Gorla IMDEA Software Institute, Spain alessandra.gorla@imdea.org software testing oracle assessment The effectiveness of testing in uncovering software defects depends not only on the characteristics of the test inputs and how thoroughly they exercise the software, but also on the quality of the oracles used to determine whether the software behaves as expected. Therefore, assessing the quality of oracles is crucial to improve the overall effectiveness of the testing process. Existing metrics have been used for this purpose, but they either fail to provide a comprehensive basis for guiding oracle improvement, or they are tailored to specific types of oracles, thus limiting their generality. In this paper, we introduce state field coverage, a novel metric for assessing oracle quality. This metric measures the proportion of an object's state, as statically defined by its class fields, that an oracle may access during test execution. The main intuition of our metric is that oracles with a higher state field coverage are more likely to detect faults in the software under analysis, as they inspect a larger portion of the object states to determine whether tests pass or not. We implement a mechanism to statically compute the state field coverage metric. Being statically computed, the metric is efficient and provides direct guidance for improving test oracles by identifying state fields that remain unexamined. We evaluate state field coverage through experiments involving 273 representation invariants and 249,027 test assertions. The results show that state field coverage is a well-suited metric for assessing oracle quality, as it strongly correlates with the oracles' fault-detection ability, measured by mutation score.",
							"pageNumber": 2706,
							"isPageNumberRoman": false
						},
						{
							"eid": "5ueix3GairLYbW9VK4k7eX",
							"type": "authorPaper",
							"text": "PALM: Synergizing Program Analysis and LLMs to Enhance Rust Unit Test Coverage",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c719/573300c719.pdf",
							"extraLocations": [],
							"authorNames": "Bei Chu (Nanjing University, China), Yang Feng (Nanjing University, China), Kui Liu (Software Engineering Application Technology Lab, China), Hange Shi (Nanjing University, China), Zifan Nan (Software Engineering Application Technology Lab, China), Zhaoqiang Guo (Software Engineering Application Technology Lab, China), Baowen Xu (Nanjing University, China)",
							"abstract": "Unit testing is essential for ensuring software reliability and correctness. Classic Search-Based Software Testing (SBST) methods and concolic execution-based approaches for generating unit tests often fail to achieve high coverage due to difficulties in handling complex program units, such as branching conditions and external dependencies. Recent work has increasingly utilized large language models (LLMs) to generate test cases, improving the quality of test generation by providing better context and correcting errors in the model's output. However, these methods rely on fixed prompts, resulting in relatively low compilation success rates and coverage. This paper presents PALM, an approach that leverages large language models (LLMs) to enhance the generation of high-coverage unit tests. PALM performs program analysis to identify branching conditions within functions, which are then combined into path constraints. These constraints and relevant contextual information are used to construct prompts that guide the LLMs in generating unit tests. We implement the approach and evaluate it in 15 open-source Rust crates. Experimental results show that within just two or three hours, PALM can significantly improve test coverage compared to classic methods, with increases in overall project coverage exceeding 50% in some instances and its generated tests achieving an average coverage of 72.30%, comparable to human effort (70.94%), highlighting the potential of LLMs in automated test generation. We submitted 91 PALM-generated unit tests targeting new code. Of these submissions, 80 were accepted, 5 were rejected, and 6 remain pending review. The results demonstrate the effectiveness of integrating program analysis with AI and open new avenues for future research in automated software testing.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 PALM: Synergizing Program Analysis and LLMs to Enhance Rust Unit Test Coverage 1759371085791 10.1109/ASE63991.2025.00223 Bei Chu Nanjing University, China beichu@smail.nju.edu.cn Yang Feng Nanjing University, China fengyang@nju.edu.cn Kui Liu Software Engineering Application Technology Lab, China kui.liu@huawei.com Hange Shi Nanjing University, China hangeshi@smail.nju.edu.cn Zifan Nan Software Engineering Application Technology Lab, China nanzifan@huawei.com Zhaoqiang Guo Software Engineering Application Technology Lab, China gzq@smail.nju.edu.cn Baowen Xu Nanjing University, China bwxu@nju.edu.cn unit testing automated test generation large language models rust program analysis coverage Unit testing is essential for ensuring software reliability and correctness. Classic Search-Based Software Testing (SBST) methods and concolic execution-based approaches for generating unit tests often fail to achieve high coverage due to difficulties in handling complex program units, such as branching conditions and external dependencies. Recent work has increasingly utilized large language models (LLMs) to generate test cases, improving the quality of test generation by providing better context and correcting errors in the model's output. However, these methods rely on fixed prompts, resulting in relatively low compilation success rates and coverage. This paper presents PALM, an approach that leverages large language models (LLMs) to enhance the generation of high-coverage unit tests. PALM performs program analysis to identify branching conditions within functions, which are then combined into path constraints. These constraints and relevant contextual information are used to construct prompts that guide the LLMs in generating unit tests. We implement the approach and evaluate it in 15 open-source Rust crates. Experimental results show that within just two or three hours, PALM can significantly improve test coverage compared to classic methods, with increases in overall project coverage exceeding 50% in some instances and its generated tests achieving an average coverage of 72.30%, comparable to human effort (70.94%), highlighting the potential of LLMs in automated test generation. We submitted 91 PALM-generated unit tests targeting new code. Of these submissions, 80 were accepted, 5 were rejected, and 6 remain pending review. The results demonstrate the effectiveness of integrating program analysis with AI and open new avenues for future research in automated software testing.",
							"pageNumber": 2719,
							"isPageNumberRoman": false
						},
						{
							"eid": "3SKKQZkN752IZRgoYIr9U",
							"type": "authorPaper",
							"text": "TEPHRA: Principled Discovery of Fuzzer Limitations",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c732/573300c732.pdf",
							"extraLocations": [],
							"authorNames": "Vasil Sarafov (Universit\u00E4t der Bundeswehr M\u00FCnchen, Germany), David Markvica (Universit\u00E4t der Bundeswehr M\u00FCnchen, Germany), Stefan Brunthaler (Universit\u00E4t der Bundeswehr M\u00FCnchen, Germany)",
							"abstract": "Fuzz testing has proven effective in discovering non-trivial bugs in complex, real-world systems, with coverage-guided greybox fuzzing being a key contributor to this success. Existing research has largely focused on developing new heuristics to increase code coverage, and current benchmarks measure coverage increase or the number of bugs found. However, there is a notable lack of investigation into programming constructs that systematically hinder or prevent fuzzing heuristics from achieving coverage, commonly referred to as \"obstacles\" or \"roadblocks\". This work makes two key contributions. First, we introduce TEPHRA, a principled methodology that uses semantics-guided synthesis to generate bug-free programs with diverse obstacles and statistically evaluate a fuzzer's ability to overcome them. Second, we implement TEPHRA-C/C++, a concrete instantiation, and generate 26 different C and C++ obstacles. We use these to empirically evaluate the bypassing abilities of 31 contemporary fuzzers, consuming 37.4 CPU years. Our analysis reveals limitations in current fuzzing heuristics and uncovers bugs in the fuzzers themselves, including AFL++. All evaluated fuzzers struggle with certain obstacles, such as floating-point conditionals and character strings. We also find that signed integers are more challenging than unsigned, and some heuristics are overtuned for 32- and 64-bit types, neglecting 8- and 16-bit integers. Overall, we observe a single difficult semantic construct can significantly degrade a fuzzer's overall performance. Our findings demonstrate TEPHRA's effectiveness and highlight avenues for future research in fuzzing techniques.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 TEPHRA: Principled Discovery of Fuzzer Limitations 1759520110690 10.1109/ASE63991.2025.00224 Vasil Sarafov Universit\u00E4t der Bundeswehr M\u00FCnchen, Germany vasil.sarafov@unibw.de David Markvica Universit\u00E4t der Bundeswehr M\u00FCnchen, Germany david.markvica@unibw.de Stefan Brunthaler Universit\u00E4t der Bundeswehr M\u00FCnchen, Germany brunthaler@unibw.de fuzz testing coverage-guided roadblocks obstacles benchmarking program synthesis benchmark suite empirical study Fuzz testing has proven effective in discovering non-trivial bugs in complex, real-world systems, with coverage-guided greybox fuzzing being a key contributor to this success. Existing research has largely focused on developing new heuristics to increase code coverage, and current benchmarks measure coverage increase or the number of bugs found. However, there is a notable lack of investigation into programming constructs that systematically hinder or prevent fuzzing heuristics from achieving coverage, commonly referred to as \"obstacles\" or \"roadblocks\". This work makes two key contributions. First, we introduce TEPHRA, a principled methodology that uses semantics-guided synthesis to generate bug-free programs with diverse obstacles and statistically evaluate a fuzzer's ability to overcome them. Second, we implement TEPHRA-C/C++, a concrete instantiation, and generate 26 different C and C++ obstacles. We use these to empirically evaluate the bypassing abilities of 31 contemporary fuzzers, consuming 37.4 CPU years. Our analysis reveals limitations in current fuzzing heuristics and uncovers bugs in the fuzzers themselves, including AFL++. All evaluated fuzzers struggle with certain obstacles, such as floating-point conditionals and character strings. We also find that signed integers are more challenging than unsigned, and some heuristics are overtuned for 32- and 64-bit types, neglecting 8- and 16-bit integers. Overall, we observe a single difficult semantic construct can significantly degrade a fuzzer's overall performance. Our findings demonstrate TEPHRA's effectiveness and highlight avenues for future research in fuzzing techniques.",
							"pageNumber": 2732,
							"isPageNumberRoman": false
						},
						{
							"eid": "6Vxlp3qCQDmAvHwCevRQSX",
							"type": "authorPaper",
							"text": "HFuzzer: Testing Large Language Models for Package Hallucinations via Phrase-Based Fuzzing",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c745/573300c745.pdf",
							"extraLocations": [],
							"authorNames": "Yukai Zhao (Zhejiang University, China), Menghan Wu (Zhejiang University, China), Xing Hu (Zhejiang University, China), Xin Xia (Zhejiang University, China)",
							"abstract": "Large Language Models (LLMs) are widely used for code generation, but they face critical security risks when applied to practical production due to package hallucinations, in which LLMs recommend non-existent packages. These hallucinations can be exploited in software supply chain attacks, where malicious attackers exploit them to register harmful packages. It is critical to test LLMs for package hallucinations to mitigate package hallucinations and defend against potential attacks. Although researchers have proposed testing frameworks for fact-conflicting hallucinations in natural language generation, there is a lack of research on package hallucinations. To fill this gap, we propose HFUZZER, a novel phrase-based fuzzing framework to test LLMs for package hallucinations. HFUZZER adopts fuzzing technology and guides the model to infer a wider range of reasonable information based on phrases, thereby generating enough and diverse coding tasks. Furthermore, HFUZZER extracts phrases from package information or coding tasks to ensure the relevance of phrases and code, thereby improving the relevance of generated tasks and code. We evaluate HFUZZER on multiple LLMs and find that it triggers package hallucinations across all selected models. Compared to the mutational fuzzing framework, HFUZZER identifies 2.60X more unique hallucinated packages and generates more diverse tasks. Additionally, when testing the model GPT-4o, HFUZZER finds 46 unique hallucinated packages. Further analysis reveals that for GPT-4o, LLMs exhibit package hallucinations not only during code generation but also when assisting with environment configuration.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 HFuzzer: Testing Large Language Models for Package Hallucinations via Phrase-Based Fuzzing 1759058905120 10.1109/ASE63991.2025.00225 Yukai Zhao Zhejiang University, China yukaizhao2000@zju.edu.cn Menghan Wu Zhejiang University, China menghanwu@zju.edu.cn Xing Hu Zhejiang University, China xinghu@zju.edu.cn Xin Xia Zhejiang University, China xin.xia@acm.org large language models package hallucination fuzzing Large Language Models (LLMs) are widely used for code generation, but they face critical security risks when applied to practical production due to package hallucinations, in which LLMs recommend non-existent packages. These hallucinations can be exploited in software supply chain attacks, where malicious attackers exploit them to register harmful packages. It is critical to test LLMs for package hallucinations to mitigate package hallucinations and defend against potential attacks. Although researchers have proposed testing frameworks for fact-conflicting hallucinations in natural language generation, there is a lack of research on package hallucinations. To fill this gap, we propose HFUZZER, a novel phrase-based fuzzing framework to test LLMs for package hallucinations. HFUZZER adopts fuzzing technology and guides the model to infer a wider range of reasonable information based on phrases, thereby generating enough and diverse coding tasks. Furthermore, HFUZZER extracts phrases from package information or coding tasks to ensure the relevance of phrases and code, thereby improving the relevance of generated tasks and code. We evaluate HFUZZER on multiple LLMs and find that it triggers package hallucinations across all selected models. Compared to the mutational fuzzing framework, HFUZZER identifies 2.60X more unique hallucinated packages and generates more diverse tasks. Additionally, when testing the model GPT-4o, HFUZZER finds 46 unique hallucinated packages. Further analysis reveals that for GPT-4o, LLMs exhibit package hallucinations not only during code generation but also when assisting with environment configuration.",
							"pageNumber": 2745,
							"isPageNumberRoman": false
						},
						{
							"eid": "YgoKqvu33yjMTmRkWEVSQ",
							"type": "authorPaper",
							"text": "LLM-Based Identification of Null Pointer Exception Patches",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c758/573300c758.pdf",
							"extraLocations": [],
							"authorNames": "Tahir Ullah (Beijing Institute of Technology, China), Waseem Akram (Beijing Institute of Technology, China; COMSATS University Islamabad, Pakistan), Fiza Khaliq (Beijing Institute of Technology, China), Hui Liu (Beijing Institute of Technology, China; COMSATS University Islamabad, Pakistan)",
							"abstract": "Null Pointer Exceptions (NPEs) are one of the leading causes of software crashes and runtime errors. Although existing methods attempt to detect and classify NPE fixes, they often fall short due to irrelevant or noisy data, a lack of contextual understanding, and inefficiency in processing large and imbalanced datasets. To overcome these challenges, we propose an approach, called Augmented Agentic Commit Classification (AACC for short), to accurately categorize commit patches as NPE fixes or non-NPE. AACC leverages the code structure and contextual insights from commit messages to capture the semantic intent behind code modifications. It features four key advancements: (1) Best example selection that filters high-quality, contextually relevant commits to ensure the model learns from contextual rich and accurate data; (2) an augmented knowledge base that enriches classification by combining contextual metadata, program semantics, and bug fix patterns; (3) a prioritise agent that ranks commits based on relevance and impact, optimizing resource allocation and boosting efficiency; and (4) an iterative refinement process that enables the model to learn from feedback to correct misclassifications, reducing false negative rates. Our evaluation results on ChatGPT-4o suggest that it outperforms the state-of-the-art approaches by improving the F1 score from 72.07% to 98.03%.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 LLM-Based Identification of Null Pointer Exception Patches 1759379906514 10.1109/ASE63991.2025.00226 Tahir Ullah Beijing Institute of Technology, China tahirullah7710@bit.edu.cn Waseem Akram Beijing Institute of Technology, China; COMSATS University Islamabad, Pakistan waseemakramcui@gmail.com Fiza Khaliq Beijing Institute of Technology, China fixakhaliq@gmail.com Hui Liu Beijing Institute of Technology, China; COMSATS University Islamabad, Pakistan liuhui08@bit.edu.cn null pointer exception patch classification Null Pointer Exceptions (NPEs) are one of the leading causes of software crashes and runtime errors. Although existing methods attempt to detect and classify NPE fixes, they often fall short due to irrelevant or noisy data, a lack of contextual understanding, and inefficiency in processing large and imbalanced datasets. To overcome these challenges, we propose an approach, called Augmented Agentic Commit Classification (AACC for short), to accurately categorize commit patches as NPE fixes or non-NPE. AACC leverages the code structure and contextual insights from commit messages to capture the semantic intent behind code modifications. It features four key advancements: (1) Best example selection that filters high-quality, contextually relevant commits to ensure the model learns from contextual rich and accurate data; (2) an augmented knowledge base that enriches classification by combining contextual metadata, program semantics, and bug fix patterns; (3) a prioritise agent that ranks commits based on relevance and impact, optimizing resource allocation and boosting efficiency; and (4) an iterative refinement process that enables the model to learn from feedback to correct misclassifications, reducing false negative rates. Our evaluation results on ChatGPT-4o suggest that it outperforms the state-of-the-art approaches by improving the F1 score from 72.07% to 98.03%.",
							"pageNumber": 2758,
							"isPageNumberRoman": false
						},
						{
							"eid": "50gPCzTgu18HuoJdi6Eo3a",
							"type": "authorPaper",
							"text": "Root Cause Analysis of RISC-V Build Failures via LLM and MCTS Reasoning",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c771/573300c771.pdf",
							"extraLocations": [],
							"authorNames": "Weipeng Shuai  (Institute of Software, Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China), Jie Liu (Institute of Software, Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China; Laboratory of System Software (Chinese Academy of Sciences), China), Zhirou Ma (Institute of Software, Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China), Liangyi Kang (Institute of Software, Chinese Academy of Sciences, China), Zehua Wang  (Institute of Software, Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China), Shuai Wang  (Institute of Software, Chinese Academy of Sciences, ChinaUniversity of Chinese Academy of Sciences, China), Dan Ye (Institute of Software at Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China), Hui Li (Institute of Software at Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China), Wei Wang (Institute of Software Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China; Laboratory of System Software (Chinese Academy of Sciences), China), Jiaxin Zhu (Institute of Software, Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China; Laboratory of System Software (Chinese Academy of Sciences), China)",
							"abstract": "Build failures are a major obstacle in RISC-V software migration, often involving complex interactions across logs, configurations, and environments. Traditional diagnostic tools struggle with the unstructured, multi-phase nature of build logs and lack semantic reasoning. We propose a two-stage framework for automated root cause analysis. RV-LAD compresses logs using template-based filtering and applies phase-aware anomaly detection via few-shot LLM prompting. MCTS-RCA integrates a domain-specific knowledge base with Monte Carlo Tree Search to perform LLM-guided multi-source reasoning under classification constraints. To support evaluation, we construct a curated dataset of 117 real-world RISC-V build failures, each annotated with logs, spec files, and repair records. Experiments show our approach achieves 75.2% diagnosis accuracy, surpassing previous LLM-based and rule-based methods. It also offers interpretable reasoning traces, enabling practical and transparent diagnosis. This work provides an effective and extensible solution for RCA in emerging software ecosystems like RISC-V, bridging large language models with domain-aware inference.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Root Cause Analysis of RISC-V Build Failures via LLM and MCTS Reasoning 1759111259749 10.1109/ASE63991.2025.00227 Weipeng Shuai Institute of Software, Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China shuaiweipeng22@otcaix.iscas.ac.cn Jie Liu Institute of Software, Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China; Laboratory of System Software (Chinese Academy of Sciences), China ljie@otcaix.iscas.ac.cn Zhirou Ma Institute of Software, Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China mazhirou@otcaix.iscas.ac.cn Liangyi Kang Institute of Software, Chinese Academy of Sciences, China kangliangyi15@otcaix.iscas.ac.cn Zehua Wang Institute of Software, Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China wangzehua23@otcaix.iscas.ac.cn Shuai Wang Institute of Software, Chinese Academy of Sciences, ChinaUniversity of Chinese Academy of Sciences, China wangshuai@otcaix.iscas.ac.cn Dan Ye Institute of Software at Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China yedan@otcaix.iscas.ac.cn Hui Li Institute of Software at Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China lihui2012@otcaix.iscas.ac.cn Wei Wang Institute of Software Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China; Laboratory of System Software (Chinese Academy of Sciences), China wangwei@otcaix.iscas.ac.cn Jiaxin Zhu Institute of Software, Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China; Laboratory of System Software (Chinese Academy of Sciences), China zhujiaxin@otcaix.iscas.ac.cn root cause analysis large language model log anomaly detection risc-v software migration Build failures are a major obstacle in RISC-V software migration, often involving complex interactions across logs, configurations, and environments. Traditional diagnostic tools struggle with the unstructured, multi-phase nature of build logs and lack semantic reasoning. We propose a two-stage framework for automated root cause analysis. RV-LAD compresses logs using template-based filtering and applies phase-aware anomaly detection via few-shot LLM prompting. MCTS-RCA integrates a domain-specific knowledge base with Monte Carlo Tree Search to perform LLM-guided multi-source reasoning under classification constraints. To support evaluation, we construct a curated dataset of 117 real-world RISC-V build failures, each annotated with logs, spec files, and repair records. Experiments show our approach achieves 75.2% diagnosis accuracy, surpassing previous LLM-based and rule-based methods. It also offers interpretable reasoning traces, enabling practical and transparent diagnosis. This work provides an effective and extensible solution for RCA in emerging software ecosystems like RISC-V, bridging large language models with domain-aware inference.",
							"pageNumber": 2771,
							"isPageNumberRoman": false
						},
						{
							"eid": "P6cLe2ATmAS1jBq8RsMXH",
							"type": "authorPaper",
							"text": "Understanding Feature Request Practice on GitHub via a Large-Scale Empirical Study",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c782/573300c782.pdf",
							"extraLocations": [],
							"authorNames": "Jiajun Li (Nanjing University of Aeronautics and Astronautics, China), Wenhua Yang (Nanjing University of Aeronautics and Astronautics, China; Nanjing University, China), Minxue Pan (Nanjing University, China), Yu Zhou (Nanjing University of Aeronautics and Astronautics, China)",
							"abstract": "Feature requests are a key communication mechanism on GitHub, enabling users and developers to collaboratively shape the direction of open-source projects. Feature requests are prevalent and important, but have been underexplored in existing studies. There is limited understanding of how they are labeled, how they evolve, and how they are resolved. A deeper understanding of feature requests is critical, not only for improving issue triage and project management but also for fostering more effective collaboration within open-source communities. In this work, we present the first systematic and large-scale empirical study of feature requests. Drawing on 1.4 million issues from 825 GitHub repositories, we examine how feature requests are labeled, how their submission and backlog patterns change over a project's lifecycle, how they differ from other types of issues in terms of resolution and engagement, and what factors contribute to their successful handling. Our findings reveal that labeling practices are often inconsistent across projects, that feature requests follow distinct temporal trends, and that those which are lengthy and contain large code snippets tend to be more difficult to resolve. By contrast, concise and clearly defined requests, particularly those submitted by experienced contributors and accompanied by active discussions, are more likely to be addressed. This study underscores the challenges of managing feature requests at scale and provides practical insights for maintainers, contributors, and researchers. To support future work in this area, we publicly release our dataset and analysis results.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Understanding Feature Request Practice on GitHub via a Large-Scale Empirical Study 1758867435710 10.1109/ASE63991.2025.00228 Jiajun Li Nanjing University of Aeronautics and Astronautics, China lijiajun@nuaa.edu.cn Wenhua Yang Nanjing University of Aeronautics and Astronautics, China; Nanjing University, China ywh@nuaa.edu.cn Minxue Pan Nanjing University, China mxp@nju.edu.cn Yu Zhou Nanjing University of Aeronautics and Astronautics, China zhouyu@nuaa.edu.cn github feature requests issue tracking Feature requests are a key communication mechanism on GitHub, enabling users and developers to collaboratively shape the direction of open-source projects. Feature requests are prevalent and important, but have been underexplored in existing studies. There is limited understanding of how they are labeled, how they evolve, and how they are resolved. A deeper understanding of feature requests is critical, not only for improving issue triage and project management but also for fostering more effective collaboration within open-source communities. In this work, we present the first systematic and large-scale empirical study of feature requests. Drawing on 1.4 million issues from 825 GitHub repositories, we examine how feature requests are labeled, how their submission and backlog patterns change over a project's lifecycle, how they differ from other types of issues in terms of resolution and engagement, and what factors contribute to their successful handling. Our findings reveal that labeling practices are often inconsistent across projects, that feature requests follow distinct temporal trends, and that those which are lengthy and contain large code snippets tend to be more difficult to resolve. By contrast, concise and clearly defined requests, particularly those submitted by experienced contributors and accompanied by active discussions, are more likely to be addressed. This study underscores the challenges of managing feature requests at scale and provides practical insights for maintainers, contributors, and researchers. To support future work in this area, we publicly release our dataset and analysis results.",
							"pageNumber": 2782,
							"isPageNumberRoman": false
						},
						{
							"eid": "1V05BiBirKAgeKleRX3Y4z",
							"type": "authorPaper",
							"text": "Which Is Better For Reducing Outdated and Vulnerable Dependencies: Pinning or Floating?",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c794/573300c794.pdf",
							"extraLocations": [],
							"authorNames": "Imranur Rahman (North Carolina State University), Jill Marley (North Carolina State University), William Enck (North Carolina State University), Laurie Williams (North Carolina State University)",
							"abstract": "Developers consistently use version constraints to specify acceptable versions of the dependencies for their project. Pinning dependencies can reduce the likelihood of breaking changes, but comes with a cost of manually managing the replacement of outdated and vulnerable dependencies. On the other hand, floating can be used to automatically get bug fixes and security fixes, but comes with the risk of breaking changes. Security practitioners advocate pinning dependencies to prevent against software supply chain attacks, e.g., malicious package updates. However, since pinning is the tightest version constraint, pinning is the most likely to result in outdated dependencies. Nevertheless, how the likelihood of becoming outdated or vulnerable dependencies changes across version constraint types is unknown. The goal of this study is to aid developers in making an informed dependency version constraint choice by empirically evaluating the likelihood of becoming outdated or vulnerable dependencies across version constraint types at scale. In this study, we first identify the trends in dependency version constraint usage and the patterns of version constraint type changes made by developers in the npm, PyPI, and Cargo ecosystems. We then modeled the dependency state transitions in survival analysis and estimated how the likelihood of becoming outdated or vulnerable changes when using pinning as opposed to the rest of the version constraint types. We observe that among outdated and vulnerable dependencies, the most commonly used version constraint type is floating-minor, with pinning being the next most common. We also find that floating-major is the least likely to result in outdated and floating-minor is the least likely to result in vulnerable dependencies. Based on our findings, we recommend that developers use any kind of floating constraint with lockfiles to balance the tradeoffs of pinning and floating.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Which Is Better For Reducing Outdated and Vulnerable Dependencies: Pinning or Floating? 1759503001311 10.1109/ASE63991.2025.00229 Imranur Rahman North Carolina State University irahman3@ncsu.com Jill Marley North Carolina State University jahmad5@ncsu.com William Enck North Carolina State University whenck@ncsu.com Laurie Williams North Carolina State University lawilli3@ncsu.com dependency management version constraint software supply chain security empirical software engineering Developers consistently use version constraints to specify acceptable versions of the dependencies for their project. Pinning dependencies can reduce the likelihood of breaking changes, but comes with a cost of manually managing the replacement of outdated and vulnerable dependencies. On the other hand, floating can be used to automatically get bug fixes and security fixes, but comes with the risk of breaking changes. Security practitioners advocate pinning dependencies to prevent against software supply chain attacks, e.g., malicious package updates. However, since pinning is the tightest version constraint, pinning is the most likely to result in outdated dependencies. Nevertheless, how the likelihood of becoming outdated or vulnerable dependencies changes across version constraint types is unknown. The goal of this study is to aid developers in making an informed dependency version constraint choice by empirically evaluating the likelihood of becoming outdated or vulnerable dependencies across version constraint types at scale. In this study, we first identify the trends in dependency version constraint usage and the patterns of version constraint type changes made by developers in the npm, PyPI, and Cargo ecosystems. We then modeled the dependency state transitions in survival analysis and estimated how the likelihood of becoming outdated or vulnerable changes when using pinning as opposed to the rest of the version constraint types. We observe that among outdated and vulnerable dependencies, the most commonly used version constraint type is floating-minor, with pinning being the next most common. We also find that floating-major is the least likely to result in outdated and floating-minor is the least likely to result in vulnerable dependencies. Based on our findings, we recommend that developers use any kind of floating constraint with lockfiles to balance the tradeoffs of pinning and floating.",
							"pageNumber": 2794,
							"isPageNumberRoman": false
						},
						{
							"eid": "1sAWS01LF2yFqOTqccwq1e",
							"type": "authorPaper",
							"text": "A Multi-Modality Evaluation of the Reality Gap in Autonomous Driving Systems",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c807/573300c807.pdf",
							"extraLocations": [],
							"authorNames": "Stefano Carlo Lambertenghi (Technical University of Munich, Germany), Mirena Flores Valdez (Technical University of Munich, Germany), Andrea Stocco (Technical University of Munich, Germany)",
							"abstract": "Simulation-based testing is a cornerstone of Autonomous Driving System (ADS) development, offering safe and scalable evaluation across diverse driving scenarios. However, discrepancies between simulated and real-world behavior, known as the reality gap, challenge the transferability of test results to deployed systems. In this paper, we present a comprehensive empirical study comparing four representative testing modalities: Software-in-the-Loop (SiL), Vehicle-in-the-Loop (ViL), Mixed-Reality (MR), and full real-world testing. Using a small-scale physical vehicle equipped with real sensors (camera and LiDAR) and its digital twin, we implement each setup and evaluate two ADS architectures (modular and end-to-end) across diverse indoor driving scenarios involving real obstacles, road topologies, and indoor environments. We systematically assess the impact of each testing modality along three dimensions of the reality gap: actuation, perception, and behavioral fidelity. Our results show that while SiL and ViL setups simplify critical aspects of real-world dynamics and sensing, MR testing improves perceptual realism without compromising safety or control. Importantly, we identify the conditions under which failures do not transfer across testing modalities and isolate the underlying dimensions of the gap responsible for these discrepancies. Our findings offer actionable insights into the respective strengths and limitations of each modality and outline a path toward more robust and transferable validation of autonomous driving systems.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 A Multi-Modality Evaluation of the Reality Gap in Autonomous Driving Systems 1759423273964 10.1109/ASE63991.2025.00230 Stefano Carlo Lambertenghi Technical University of Munich, Germany stefanocarlo.lambertenghi@tum.de Mirena Flores Valdez Technical University of Munich, Germany mirena.flores@tum.de Andrea Stocco Technical University of Munich, Germany andrea.stocco@tum.de autonomous driving reality gap virtual testing real-world testing vehicle-in-the-loop mixed-reality Simulation-based testing is a cornerstone of Autonomous Driving System (ADS) development, offering safe and scalable evaluation across diverse driving scenarios. However, discrepancies between simulated and real-world behavior, known as the reality gap, challenge the transferability of test results to deployed systems. In this paper, we present a comprehensive empirical study comparing four representative testing modalities: Software-in-the-Loop (SiL), Vehicle-in-the-Loop (ViL), Mixed-Reality (MR), and full real-world testing. Using a small-scale physical vehicle equipped with real sensors (camera and LiDAR) and its digital twin, we implement each setup and evaluate two ADS architectures (modular and end-to-end) across diverse indoor driving scenarios involving real obstacles, road topologies, and indoor environments. We systematically assess the impact of each testing modality along three dimensions of the reality gap: actuation, perception, and behavioral fidelity. Our results show that while SiL and ViL setups simplify critical aspects of real-world dynamics and sensing, MR testing improves perceptual realism without compromising safety or control. Importantly, we identify the conditions under which failures do not transfer across testing modalities and isolate the underlying dimensions of the gap responsible for these discrepancies. Our findings offer actionable insights into the respective strengths and limitations of each modality and outline a path toward more robust and transferable validation of autonomous driving systems.",
							"pageNumber": 2807,
							"isPageNumberRoman": false
						},
						{
							"eid": "1KQt7fa6fxMOAmw3OZsmV8",
							"type": "authorPaper",
							"text": "PoliCond: Condition-Aware Ontology-Driven LLMs for Privacy Policy Contradiction Analysis",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c820/573300c820.pdf",
							"extraLocations": [],
							"authorNames": "Yalin Feng (Nanjing University, China), Yifei Lu (Nanjing University, China), Minxue Pan (Nanjing University, China)",
							"abstract": "Although privacy policies serve as the primary mechanism for disclosing data practices under regulations like the General Data Protection Regulation, they frequently contain internal conflicts that undermine transparency and user trust. Existing research has advanced automated privacy policy contradiction analysis by leveraging language models, tuple-based knowledge representations and ontologies (or knowledge graphs) to resolve natural language ambiguities. However, traditional 3-tuple (entity, action, data type) lack contextual information and fail to distinguish data collection practices under varying scenarios, leading to incomplete or misleading contradiction detection. To address these challenges, we present POLICOND, a framework that combines condition-aware tuple representations, domain ontologies and large language models. On established benchmarks, POLICOND achieves an F1 score of 88.6%, outperforming prior methods (58.2%), with an average processing time of 8.4 seconds per policy. In a real-world analysis of 175 privacy policies, POLICOND uncovers previously undetected internal contradictions, including 46 inconsistent policies and 48 contradictory pairs of policy segments missed by existing approaches. These findings underscore the prevalence of inconsistencies in privacy policies and demonstrate the practical utility of POLICOND.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 PoliCond: Condition-Aware Ontology-Driven LLMs for Privacy Policy Contradiction Analysis 1759422657209 10.1109/ASE63991.2025.00232 Yalin Feng Nanjing University, China yalinfeng@smail.nju.edu.cn Yifei Lu Nanjing University, China lyf@nju.edu.cn Minxue Pan Nanjing University, China mxp@nju.edu.cn privacy policy llm contradiction detection Although privacy policies serve as the primary mechanism for disclosing data practices under regulations like the General Data Protection Regulation, they frequently contain internal conflicts that undermine transparency and user trust. Existing research has advanced automated privacy policy contradiction analysis by leveraging language models, tuple-based knowledge representations and ontologies (or knowledge graphs) to resolve natural language ambiguities. However, traditional 3-tuple (entity, action, data type) lack contextual information and fail to distinguish data collection practices under varying scenarios, leading to incomplete or misleading contradiction detection. To address these challenges, we present POLICOND, a framework that combines condition-aware tuple representations, domain ontologies and large language models. On established benchmarks, POLICOND achieves an F1 score of 88.6%, outperforming prior methods (58.2%), with an average processing time of 8.4 seconds per policy. In a real-world analysis of 175 privacy policies, POLICOND uncovers previously undetected internal contradictions, including 46 inconsistent policies and 48 contradictory pairs of policy segments missed by existing approaches. These findings underscore the prevalence of inconsistencies in privacy policies and demonstrate the practical utility of POLICOND.",
							"pageNumber": 2820,
							"isPageNumberRoman": false
						},
						{
							"eid": "1hJKMHR2eRCqpQSDCF4WTL",
							"type": "authorPaper",
							"text": "Reflective Unit Test Generation for Precise Type Error Detection with Large Language Models",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c833/573300c833.pdf",
							"extraLocations": [],
							"authorNames": "Chen Yang (Tianjin University, China), Ziqi Wang (Tianjin University, China), Yanjie Jiang (Tianjin University, China), Lin Yang (Tianjin University, China), Yuteng Zheng (Tianjin University, China), Jianyi Zhou (Huawei Cloud Computing Technologies Co., Ltd., China), Junjie Chen (Tianjin University, China)",
							"abstract": "Type errors in Python often lead to runtime failures, posing significant challenges to software reliability and developer productivity. Existing static analysis tools aim to detect such errors without execution but frequently suffer from high false positive rates. Recently, unit test generation techniques offer great promise in achieving high test coverage, but they often struggle to produce bug-revealing tests without tailored guidance. To address these limitations, we present RTED, a novel type-aware test generation technique for automatically detecting Python type errors. Specifically, RTED combines step-by-step type constraint analysis with reflective validation to guide the test generation process and effectively suppress false positives. We evaluated RTED on two widely-used benchmarks, BugsInPy and TypeBugs. Experimental results show that RTED can detect 22~29 more benchmarked type errors than four state-of-the-art techniques. RTED is also capable of producing fewer false positives, achieving an improvement of 173.9%~245.9% in precision. Furthermore, we applied RTED to six real-world open-source Python projects, and successfully discovered 12 previously unknown type errors, demonstrating RTED's practical value.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Reflective Unit Test Generation for Precise Type Error Detection with Large Language Models 1759407774309 10.1109/ASE63991.2025.00233 Chen Yang Tianjin University, China yangchenyc@tju.edu.cn Ziqi Wang Tianjin University, China wangziqi123@tju.edu.cn Yanjie Jiang Tianjin University, China yanjiejiang@tju.edu.cn Lin Yang Tianjin University, China linyang@tju.edu.cn Yuteng Zheng Tianjin University, China zyt_767904@tju.edu.cn Jianyi Zhou Huawei Cloud Computing Technologies Co., Ltd., China zhoujianyi2@huawei.com Junjie Chen Tianjin University, China junjiechen@tju.edu.cn test generation type error bug detection Type errors in Python often lead to runtime failures, posing significant challenges to software reliability and developer productivity. Existing static analysis tools aim to detect such errors without execution but frequently suffer from high false positive rates. Recently, unit test generation techniques offer great promise in achieving high test coverage, but they often struggle to produce bug-revealing tests without tailored guidance. To address these limitations, we present RTED, a novel type-aware test generation technique for automatically detecting Python type errors. Specifically, RTED combines step-by-step type constraint analysis with reflective validation to guide the test generation process and effectively suppress false positives. We evaluated RTED on two widely-used benchmarks, BugsInPy and TypeBugs. Experimental results show that RTED can detect 22~29 more benchmarked type errors than four state-of-the-art techniques. RTED is also capable of producing fewer false positives, achieving an improvement of 173.9%~245.9% in precision. Furthermore, we applied RTED to six real-world open-source Python projects, and successfully discovered 12 previously unknown type errors, demonstrating RTED's practical value.",
							"pageNumber": 2833,
							"isPageNumberRoman": false
						},
						{
							"eid": "2Vn1DEsJxzM2uaYOM4dd7t",
							"type": "authorPaper",
							"text": "Understanding Software Engineering Agents: A Study of Thought-Action-Result Trajectories",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c845/573300c845.pdf",
							"extraLocations": [],
							"authorNames": "Islem Bouzenia (CISPA Helmholtz Center for Information Security, Germany), Michael Pradel (CISPA Helmholtz Center for Information Security, Germany)",
							"abstract": "Large Language Model (LLM)-based agents are increasingly employed to automate complex software engineering tasks, such as program repair and issue resolution. These agents operate by autonomously generating natural language thoughts, invoking external tools, and iteratively refining their solutions. Despite their widespread adoption, the internal decision-making processes of these agents remain largely unexplored, limiting our understanding of their operational dynamics and failure modes. In this paper, we present a large-scale empirical study of the thought-action-result trajectories of three state-of-the-art LLM-based agents: RepairAgent, AutocodeRover, and OpenHands. We unify their interaction logs into a common format, capturing 120 trajectories and 2,822 LLM interactions focused on program repair and issue resolution. Our study combines quantitative analyses of structural properties, action patterns, and token usage with qualitative assessments of reasoning coherence and feedback integration. We identify key trajectory characteristics, such as iteration counts and token consumption, recurring action sequences, and the semantic coherence of thoughts, actions, and their results. Our findings reveal behavioral motifs and anti-patterns that distinguish successful from failed executions, providing actionable insights for improving agent design, including prompting strategies, failure diagnosis, and anti-pattern detection. We release our dataset and annotation framework to support further research on transparent and robust autonomous software engineering agents.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Understanding Software Engineering Agents: A Study of Thought-Action-Result Trajectories 1759403766204 10.1109/ASE63991.2025.00234 Islem Bouzenia CISPA Helmholtz Center for Information Security, Germany bouzenia.islem@pm.me Michael Pradel CISPA Helmholtz Center for Information Security, Germany michael@binaervarianz.de software engineering llm-agents llm Large Language Model (LLM)-based agents are increasingly employed to automate complex software engineering tasks, such as program repair and issue resolution. These agents operate by autonomously generating natural language thoughts, invoking external tools, and iteratively refining their solutions. Despite their widespread adoption, the internal decision-making processes of these agents remain largely unexplored, limiting our understanding of their operational dynamics and failure modes. In this paper, we present a large-scale empirical study of the thought-action-result trajectories of three state-of-the-art LLM-based agents: RepairAgent, AutocodeRover, and OpenHands. We unify their interaction logs into a common format, capturing 120 trajectories and 2,822 LLM interactions focused on program repair and issue resolution. Our study combines quantitative analyses of structural properties, action patterns, and token usage with qualitative assessments of reasoning coherence and feedback integration. We identify key trajectory characteristics, such as iteration counts and token consumption, recurring action sequences, and the semantic coherence of thoughts, actions, and their results. Our findings reveal behavioral motifs and anti-patterns that distinguish successful from failed executions, providing actionable insights for improving agent design, including prompting strategies, failure diagnosis, and anti-pattern detection. We release our dataset and annotation framework to support further research on transparent and robust autonomous software engineering agents.",
							"pageNumber": 2845,
							"isPageNumberRoman": false
						},
						{
							"eid": "6PHHJNprv6uTqdUMD7baQJ",
							"type": "authorPaper",
							"text": "SolContractEval: A Benchmark for Evaluating Contract-Level Solidity Code Generation",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c857/573300c857.pdf",
							"extraLocations": [],
							"authorNames": "Zhifan Ye (Zhejiang University, China; Hangzhou High-Tech Zone (Binjiang) Institute of Blockchain and Data Security, China), Jiachi Chen (Zhejiang University, China), Zhenzhe Shao (Sun Yat-sen University, China), Lingfeng Bao (Zhejiang University, China; Hangzhou High-Tech Zone (Binjiang) Institute of Blockchain and Data Security, China), Xiaohu Yang (Zhejiang University, China; Hangzhou High-Tech Zone (Binjiang) Institute of Blockchain and Data Security, China), Zhongxin Liu (Zhejiang University, China; Hangzhou High-Tech Zone (Binjiang) Institute of Blockchain and Data Security, China)",
							"abstract": "The rise of blockchain has brought smart contracts into mainstream use, creating a demand for smart contract generation tools. While large language models (LLMs) excel at generating code in general-purpose languages, their effectiveness on Solidity, the primary language for smart contracts, remains underexplored. Solidity constitutes only a small portion of typical LLM training data and differs from general-purpose languages in its version-sensitive syntax and limited flexibility. These factors raise concerns about the reliability of existing LLMs for Solidity code generation. Critically, existing evaluations, focused on isolated functions and synthetic inputs, fall short of assessing models' capabilities in real-world contract development. To bridge this gap, we introduce SolContractEval, the first contract-level benchmark for Solidity code generation. It comprises 124 tasks drawn from real on-chain contracts across nine major domains. Each task input, consisting of complete context dependencies, a structured contract framework, and a concise task prompt, is independently annotated and cross-validated by experienced developers. To enable precise and automated evaluation of functional correctness, we also develop a dynamic evaluation framework based on historical transaction replay. Building on SolContractEval, we perform a systematic evaluation of six mainstream LLMs. We find that Claude-3.7-Sonnet achieves the highest overall performance, though evaluated models underperform relative to their capabilities on class-level generation tasks in general-purpose programming languages. Second, current models perform better on tasks that follow standard patterns but struggle with complex logic and inter-contract dependencies. Finally, they exhibit limited understanding of Solidity-specific features and contextual dependencies. ",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 SolContractEval: A Benchmark for Evaluating Contract-Level Solidity Code Generation 1758539585895 10.1109/ASE63991.2025.00235 Zhifan Ye Zhejiang University, China; Hangzhou High-Tech Zone (Binjiang) Institute of Blockchain and Data Security, China yezhifan@zju.edu.cn Jiachi Chen Zhejiang University, China chenjch86@mail.sysu.edu.cn Zhenzhe Shao Sun Yat-sen University, China shaozhzh3@mail2.sysu.edu.cn Lingfeng Bao Zhejiang University, China; Hangzhou High-Tech Zone (Binjiang) Institute of Blockchain and Data Security, China lingfengbao@zju.edu.cn Xiaohu Yang Zhejiang University, China; Hangzhou High-Tech Zone (Binjiang) Institute of Blockchain and Data Security, China yangxh@zju.edu.cn Zhongxin Liu Zhejiang University, China; Hangzhou High-Tech Zone (Binjiang) Institute of Blockchain and Data Security, China liu_zx@zju.edu.cn large language model contract-level code generation smart contract benchmark The rise of blockchain has brought smart contracts into mainstream use, creating a demand for smart contract generation tools. While large language models (LLMs) excel at generating code in general-purpose languages, their effectiveness on Solidity, the primary language for smart contracts, remains underexplored. Solidity constitutes only a small portion of typical LLM training data and differs from general-purpose languages in its version-sensitive syntax and limited flexibility. These factors raise concerns about the reliability of existing LLMs for Solidity code generation. Critically, existing evaluations, focused on isolated functions and synthetic inputs, fall short of assessing models' capabilities in real-world contract development. To bridge this gap, we introduce SolContractEval, the first contract-level benchmark for Solidity code generation. It comprises 124 tasks drawn from real on-chain contracts across nine major domains. Each task input, consisting of complete context dependencies, a structured contract framework, and a concise task prompt, is independently annotated and cross-validated by experienced developers. To enable precise and automated evaluation of functional correctness, we also develop a dynamic evaluation framework based on historical transaction replay. Building on SolContractEval, we perform a systematic evaluation of six mainstream LLMs. We find that Claude-3.7-Sonnet achieves the highest overall performance, though evaluated models underperform relative to their capabilities on class-level generation tasks in general-purpose programming languages. Second, current models perform better on tasks that follow standard patterns but struggle with complex logic and inter-contract dependencies. Finally, they exhibit limited understanding of Solidity-specific features and contextual dependencies.",
							"pageNumber": 2857,
							"isPageNumberRoman": false
						},
						{
							"eid": "qST6ZbUsZytDTaAdGweMj",
							"type": "authorPaper",
							"text": "LLMPort: Cross-File Patch Porting via Task Decomposition and Self-Correction",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c869/573300c869.pdf",
							"extraLocations": [],
							"authorNames": "Bofei Chen (Fudan University), Lei Zhang (Fudan University), Peng Deng (Fudan University), Nan Wang (Fudan University), Haoyu Xu (Fudan University), Mingda Guo (Fudan University), Yuan Zhang (Fudan University), Min Yang (Fudan University)",
							"abstract": "Security patch porting aims to adapt patches developed for one software version so they can be used in another version. This approach is crucial for maintaining the security of software systems over time. However, existing works often rely on predefined rules to understand patches, limiting their generalizability and portability. Additionally, they are ineffective when porting complex patches that involve numerous modified code lines across multiple files, which is common in real-world software, especially Java applications. To overcome these obstacles, we propose a novel patch porting framework, called LLMPort. First, LLMPort breaks down the complex patch porting task into distinct subtasks, each containing an atomic code unit from the original patch. This enhances the LLMs' focus. Second, for each subtask, LLMPort extracts the minimal patch-related code context and constructs a prompt with task-specific domain knowledge to guide the LLM in porting the patch code to the target version. Third, LLMPort implements a progressive self-correction system to automatically assess the correctness of the generated patch, and identify and correct error subtasks based on LLMs' self-correction capabilities. We evaluate LLMPort for porting Java language patches on a large-scale dataset, including 1,992 unique patch file pairs, and it successfully ports 91.92% of them. To assess the portability of LLMPort, we also evaluate its capability to port C language patches. The results show that it outperforms state-of-the-art approaches, including TSBPORT and FixMorph. LLMPort also discovers five 0-day vulnerabilities due to incomplete patches and the developers received and merged the new patches generated by LLMPort into the official code branches.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 LLMPort: Cross-File Patch Porting via Task Decomposition and Self-Correction 1759522121998 10.1109/ASE63991.2025.00236 Bofei Chen Fudan University bfchen22@m.fudan.edu.cn Lei Zhang Fudan University zxl@fudan.edu.cn Peng Deng Fudan University pdeng21@m.fudan.edu.cn Nan Wang Fudan University wangnan24@m.fudan.edu.cn Haoyu Xu Fudan University haoyuxu21@m.fudan.edu.cn Mingda Guo Fudan University mdguo22@m.fudan.edu.cn Yuan Zhang Fudan University yuanxzhang@fudan.edu.cn Min Yang Fudan University m_yang@fudan.edu.cn patch porting patch migration Security patch porting aims to adapt patches developed for one software version so they can be used in another version. This approach is crucial for maintaining the security of software systems over time. However, existing works often rely on predefined rules to understand patches, limiting their generalizability and portability. Additionally, they are ineffective when porting complex patches that involve numerous modified code lines across multiple files, which is common in real-world software, especially Java applications. To overcome these obstacles, we propose a novel patch porting framework, called LLMPort. First, LLMPort breaks down the complex patch porting task into distinct subtasks, each containing an atomic code unit from the original patch. This enhances the LLMs' focus. Second, for each subtask, LLMPort extracts the minimal patch-related code context and constructs a prompt with task-specific domain knowledge to guide the LLM in porting the patch code to the target version. Third, LLMPort implements a progressive self-correction system to automatically assess the correctness of the generated patch, and identify and correct error subtasks based on LLMs' self-correction capabilities. We evaluate LLMPort for porting Java language patches on a large-scale dataset, including 1,992 unique patch file pairs, and it successfully ports 91.92% of them. To assess the portability of LLMPort, we also evaluate its capability to port C language patches. The results show that it outperforms state-of-the-art approaches, including TSBPORT and FixMorph. LLMPort also discovers five 0-day vulnerabilities due to incomplete patches and the developers received and merged the new patches generated by LLMPort into the official code branches.",
							"pageNumber": 2869,
							"isPageNumberRoman": false
						},
						{
							"eid": "4QmUmn0ok5kD2oIkSj9qBR",
							"type": "authorPaper",
							"text": "DIFFFIX: Incrementally Fixing AST Diffs via Context and Type Information",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c881/573300c881.pdf",
							"extraLocations": [],
							"authorNames": "Guofeng  Zeng (University of Science and Technology Beijing, China), Chang-ai Sun (University of Science and Technology Beijing, China), Kai  Gao (University of Science and Technology Beijing, China), Huai Liu (Swinburne University of Technology, Australia)",
							"abstract": "The abstract syntax tree differencing (ASTDiff) technique aims to capture syntactic code changes through comparing the differences between a pair of ASTs of a program, which has been widely used in various program analysis or testing tasks, such as code review, clone detection, and regression testing. A key issue for ASTDiff lies in the accurate mappings between nodes of two ASTs. However, most existing approaches often fail to generate such perfect diffs due to the gap between diverse code changes and unsound node matching heuristics. Our in-depth investigation reveals that most inaccurate mappings are caused by the ignorance of context- and/or type-specific constraints. Accordingly, we propose an AST diff fixing approach DIFFFIX that leverages both the node's context and type constraints to iteratively and incrementally fix imperfect diffs. Comprehensive experiments have been conducted to evaluate the effectiveness of DIFFFIX through its application to fix diffs generated by five state-of-the-art ASTDiff techniques. The experimental results demonstrate that DIFFFIX can improve the perfect diff rate of these baseline techniques by 5.25% to 51.12% with negligible time overhead.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 DIFFFIX: Incrementally Fixing AST Diffs via Context and Type Information 1759044461205 10.1109/ASE63991.2025.00237 Guofeng Zeng University of Science and Technology Beijing, China d202110394@xs.ustb.edu.cn Chang-ai Sun University of Science and Technology Beijing, China casun@ustb.edu.cn Kai Gao University of Science and Technology Beijing, China kai.gao@ustb.edu.cn Huai Liu Swinburne University of Technology, Australia hliu@swin.edu.au source code differencing abstract syntax tree quality assurance software evolution The abstract syntax tree differencing (ASTDiff) technique aims to capture syntactic code changes through comparing the differences between a pair of ASTs of a program, which has been widely used in various program analysis or testing tasks, such as code review, clone detection, and regression testing. A key issue for ASTDiff lies in the accurate mappings between nodes of two ASTs. However, most existing approaches often fail to generate such perfect diffs due to the gap between diverse code changes and unsound node matching heuristics. Our in-depth investigation reveals that most inaccurate mappings are caused by the ignorance of context- and/or type-specific constraints. Accordingly, we propose an AST diff fixing approach DIFFFIX that leverages both the node's context and type constraints to iteratively and incrementally fix imperfect diffs. Comprehensive experiments have been conducted to evaluate the effectiveness of DIFFFIX through its application to fix diffs generated by five state-of-the-art ASTDiff techniques. The experimental results demonstrate that DIFFFIX can improve the perfect diff rate of these baseline techniques by 5.25% to 51.12% with negligible time overhead.",
							"pageNumber": 2881,
							"isPageNumberRoman": false
						},
						{
							"eid": "1MP6mOUv2vTi59uenUjLjR",
							"type": "authorPaper",
							"text": "Better Safe than Sorry: Preventing Policy Violations Through Predictive Root-Cause-Analysis for IoT Systems",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c893/573300c893.pdf",
							"extraLocations": [],
							"authorNames": "Michael  Norris (Pennsylvania State University), Syed Rafiul Hussain (Pennsylvania State University), Gang Tan (Pennsylvania State University)",
							"abstract": "In an Internet of Things (IoT) environment, there are several way things can go wrong based on device activity. Poorly defined rules, conflicts between applications, physical interactions between devices, or unintentional interference by user behavior. Since these devices can have access to sensitive information or the capability to disrupt or harm physical elements in an environment, there is a strong motivation to protect confidentiality and integrity in IoT systems. In this paper we design IoTArmor, a novel Root-Cause-Analysis tool that uses machine learning models to select remediating actions that can prevent violations that would otherwise occur in the future. We assume violations have been predicted to occur and analyze the current system state to produce optimal fixes to prevent the violating behavior. Through this analysis, we can give accurate proposed fixes to prevent the violations, as well as detailed explanations to users as to why the fixes are effective. This methodology provides easily usable information to users about flaws in their environment, both in the current moment and in their overall application setup.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Better Safe than Sorry: Preventing Policy Violations Through Predictive Root-Cause-Analysis for IoT Systems 1759521054841 10.1109/ASE63991.2025.00238 Michael Norris Pennsylvania State University man5336@psu.edu Syed Rafiul Hussain Pennsylvania State University hussain1@psu.edu Gang Tan Pennsylvania State University gtan@psu.edu internet of things safety and security root cause analysis In an Internet of Things (IoT) environment, there are several way things can go wrong based on device activity. Poorly defined rules, conflicts between applications, physical interactions between devices, or unintentional interference by user behavior. Since these devices can have access to sensitive information or the capability to disrupt or harm physical elements in an environment, there is a strong motivation to protect confidentiality and integrity in IoT systems. In this paper we design IoTArmor, a novel Root-Cause-Analysis tool that uses machine learning models to select remediating actions that can prevent violations that would otherwise occur in the future. We assume violations have been predicted to occur and analyze the current system state to produce optimal fixes to prevent the violating behavior. Through this analysis, we can give accurate proposed fixes to prevent the violations, as well as detailed explanations to users as to why the fixes are effective. This methodology provides easily usable information to users about flaws in their environment, both in the current moment and in their overall application setup.",
							"pageNumber": 2893,
							"isPageNumberRoman": false
						},
						{
							"eid": "6fuJwouWd06pygzO5e6edI",
							"type": "authorPaper",
							"text": "Metamorphic Testing for Audio Content Moderation Software",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c905/573300c905.pdf",
							"extraLocations": [],
							"authorNames": "Wenxuan Wang (Renmin University of China, China), Yongjiang Wu (The Chinese University of Hong Kong, China), Junyuan Zhang (The Chinese University of Hong Kong, China), Shuqing Li (The Chinese University of Hong Kong, China), Yun Peng (The Chinese University of Hong Kong, China), Wenting Chen (City University of Hong Kong, China), Shuai Wang (Hong Kong University of Science and Technology, China), Michael R. Lyu (The Chinese University of Hong Kong, China)",
							"abstract": "The rapid growth of audio-centric platforms and applications such as WhatsApp and Twitter has transformed the way people communicate and share audio content in modern society. However, these platforms are increasingly misused to disseminate harmful audio content, such as hate speech, deceptive advertisements, and explicit material, which can have significant negative consequences (e.g., detrimental effects on mental health). In response, researchers and practitioners have been actively developing and deploying audio content moderation tools to tackle this issue. Despite these efforts, malicious actors can bypass moderation systems by making subtle alterations to audio content, such as modifying pitch or inserting noise. Moreover, the effectiveness of modern audio moderation tools against such adversarial inputs remains insufficiently studied. To address these challenges, we propose MTAM, a Metamorphic Testing framework for Audio content Moderation software. Specifically, we conduct a pilot study on 2000 audio clips and define 14 metamorphic relations across two perturbation categories: Audio Features-Based and Heuristic perturbations. MTAM applies these metamorphic relations to toxic audio content to generate test cases that remain harmful while being more likely to evade detection. In our evaluation, we employ MTAM to test five commercial textual content moderation software and an academic model against three kinds of toxic content. The results show that MTAM achieves up to 38.6%, 18.3%, 35.1%, 16.7%, and 51.1% error finding rates (EFR) when testing commercial moderation software provided by Gladia, Assembly AI, Baidu, Nextdata, and Tencent, respectively, and it obtains up to 45.7% EFR when testing the state-of-the-art algorithms from the academy. In addition, we leverage the test cases generated by MTAM to retrain the model we explored, which largely improves model robustness (nearly 0% EFR) while maintaining the accuracy on the original test set. We release the code and experiment data to facilitate future research.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Metamorphic Testing for Audio Content Moderation Software 1759113004683 10.1109/ASE63991.2025.00239 Wenxuan Wang Renmin University of China, China wangwenxuan@ruc.edu.cn Yongjiang Wu The Chinese University of Hong Kong, China yojwu@link.cuhk.edu.hk Junyuan Zhang The Chinese University of Hong Kong, China 1155191545@link.cuhk.edu.hk Shuqing Li The Chinese University of Hong Kong, China sqli21@cse.cuhk.edu.hk Yun Peng The Chinese University of Hong Kong, China ypeng@cse.cuhk.edu.hk Wenting Chen City University of Hong Kong, China wentchen@stanford.edu Shuai Wang Hong Kong University of Science and Technology, China shuaiw@cse.ust.hk Michael R. Lyu The Chinese University of Hong Kong, China lyu@cse.cuhk.edu.hk software testing metamorphic relations nlp software audio content moderation The rapid growth of audio-centric platforms and applications such as WhatsApp and Twitter has transformed the way people communicate and share audio content in modern society. However, these platforms are increasingly misused to disseminate harmful audio content, such as hate speech, deceptive advertisements, and explicit material, which can have significant negative consequences (e.g., detrimental effects on mental health). In response, researchers and practitioners have been actively developing and deploying audio content moderation tools to tackle this issue. Despite these efforts, malicious actors can bypass moderation systems by making subtle alterations to audio content, such as modifying pitch or inserting noise. Moreover, the effectiveness of modern audio moderation tools against such adversarial inputs remains insufficiently studied. To address these challenges, we propose MTAM, a Metamorphic Testing framework for Audio content Moderation software. Specifically, we conduct a pilot study on 2000 audio clips and define 14 metamorphic relations across two perturbation categories: Audio Features-Based and Heuristic perturbations. MTAM applies these metamorphic relations to toxic audio content to generate test cases that remain harmful while being more likely to evade detection. In our evaluation, we employ MTAM to test five commercial textual content moderation software and an academic model against three kinds of toxic content. The results show that MTAM achieves up to 38.6%, 18.3%, 35.1%, 16.7%, and 51.1% error finding rates (EFR) when testing commercial moderation software provided by Gladia, Assembly AI, Baidu, Nextdata, and Tencent, respectively, and it obtains up to 45.7% EFR when testing the state-of-the-art algorithms from the academy. In addition, we leverage the test cases generated by MTAM to retrain the model we explored, which largely improves model robustness (nearly 0% EFR) while maintaining the accuracy on the original test set. We release the code and experiment data to facilitate future research.",
							"pageNumber": 2905,
							"isPageNumberRoman": false
						},
						{
							"eid": "22KbGencgxMUTi0frCIL48",
							"type": "authorPaper",
							"text": "Automated Combinatorial Test Generation for Alloy",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c918/573300c918.pdf",
							"extraLocations": [],
							"authorNames": "Agust\u00EDn Borda (University of Rio Cuarto and CONICET, Argentina; Guangdong Technion-Israel Institute of Technology, China), Germ\u00E1n Regis (University of Rio Cuarto and CONICET, Argentina), Nazareno Aguirre (University of Rio Cuarto and CONICET, Argentina; Guangdong Technion-Israel Institute of Technology, China), Marcelo Frias (University of Texas at El Paso, USA), Pablo Ponzio (University of Rio Cuarto and CONICET, Argentina)",
							"abstract": "Specifications are an essential component of software development, and getting specifications right, especially formal specifications, can be very challenging. While the use of tools such as model finders and model checkers can be very effective for specification analysis through property checking, researchers have also realized that by the explicit provision of wanted and unwanted specification scenarios, in the style of testing in programs, specification assessment can be significantly enhanced. Thus, various testing and test generation techniques have been recently proposed for assessing formal specifications. In this paper, we present such a specification testing approach, in the form of a novel combinatorial testing technique for Alloy specifications, called COMBA. COMBA implements an automated partitioning of the state space of Alloy specifications solely based on elements of the specification (thus not requiring user intervention), and defines a family of test criteria, that indicate how such partitions are to be covered. The coverage of the partitions is defined by a family of combinatorial criteria that, given a positive integer t, require to cover through test cases all feasible t-uples of elements from different partitions. Finally, COMBA introduces an efficient algorithm to generate test cases that satisfy the combinatorial criteria. By leveraging on incremental SAT solving techniques, COMBA achieves significantly better performance in test generation. We experimentally assess COMBA against existing test generation approaches for Alloy, using a large number of specifications with known errors. The results show that COMBA (with t=2) runs faster, produces smaller test suites, and finds a significantly larger number of real bugs than related approaches.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Automated Combinatorial Test Generation for Alloy 1759576074487 10.1109/ASE63991.2025.00240 Agust\u00EDn Borda University of Rio Cuarto and CONICET, Argentina; Guangdong Technion-Israel Institute of Technology, China aborda@dc.exa.unrc.edu.ar Germ\u00E1n Regis University of Rio Cuarto and CONICET, Argentina gregis@dc.exa.unrc.edu.ar Nazareno Aguirre University of Rio Cuarto and CONICET, Argentina; Guangdong Technion-Israel Institute of Technology, China naguirre@dc.exa.unrc.edu.ar Marcelo Frias University of Texas at El Paso, USA mfrias4@utep.edu Pablo Ponzio University of Rio Cuarto and CONICET, Argentina pponzio@dc.exa.unrc.edu.ar alloy specification testing combinatorial testing incremental sat solving Specifications are an essential component of software development, and getting specifications right, especially formal specifications, can be very challenging. While the use of tools such as model finders and model checkers can be very effective for specification analysis through property checking, researchers have also realized that by the explicit provision of wanted and unwanted specification scenarios, in the style of testing in programs, specification assessment can be significantly enhanced. Thus, various testing and test generation techniques have been recently proposed for assessing formal specifications. In this paper, we present such a specification testing approach, in the form of a novel combinatorial testing technique for Alloy specifications, called COMBA. COMBA implements an automated partitioning of the state space of Alloy specifications solely based on elements of the specification (thus not requiring user intervention), and defines a family of test criteria, that indicate how such partitions are to be covered. The coverage of the partitions is defined by a family of combinatorial criteria that, given a positive integer t, require to cover through test cases all feasible t-uples of elements from different partitions. Finally, COMBA introduces an efficient algorithm to generate test cases that satisfy the combinatorial criteria. By leveraging on incremental SAT solving techniques, COMBA achieves significantly better performance in test generation. We experimentally assess COMBA against existing test generation approaches for Alloy, using a large number of specifications with known errors. The results show that COMBA (with t=2) runs faster, produces smaller test suites, and finds a significantly larger number of real bugs than related approaches.",
							"pageNumber": 2918,
							"isPageNumberRoman": false
						},
						{
							"eid": "6Dwjy1vCfspI1vD4DdDx2E",
							"type": "authorPaper",
							"text": "The Cost of Downgrading Build Systems A Case Study of Kubernetes",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c931/573300c931.pdf",
							"extraLocations": [],
							"authorNames": "Gareema Ranjan (University of Waterloo, Canada), Mahmoud  Alfadel (University of Calgary, Canada), Gengyi Sun (University of Waterloo, Canada), Shane McIntosh (University of Waterloo, Canada)",
							"abstract": "Since developers invoke the build system frequently, its performance can impact productivity. Modern artifact-based build tools accelerate builds, yet prior work shows that teams may abandon them for alternatives that are easier to maintain. While prior work shows why downgrades are performed, the implications of downgrades remain largely unexplored. In this paper, we describe a case study of the Kubernetes project, focusing on its downgrade from an artifact-based build tool (Bazel) to a language-specific solution (Go Build). We reproduce and analyze the full and incremental builds of change sets during the downgrade period. On the one hand, we find that Bazel builds are faster than Go Build, completing full builds in 23.06 - 38.66 % less time and incremental builds in up to 75.19 % less time. On the other hand, Bazel builds impose a larger memory footprint than Go Build of 81.42 - 351.07 % and 118.71 - 218.22 % for full and incremental builds, respectively. Bazel builds also impose a greater CPU load at parallelism settings above eight for full builds and above one for incremental builds. We estimate that downgrading from Bazel can increase CI resource costs by up to 76 %. We explore whether our observations generalize by replicating our Kubernetes study on four other projects that also downgraded from Bazel to older build tools. We observe that while build time penalties decrease, Bazel consistently consumes more memory. We conclude that abandoning artifact-based build tools, despite perceived maintainability benefits, tends to incur considerable performance costs for large projects. Our observations may help stakeholders to balance trade-offs in build tool adoption.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 The Cost of Downgrading Build Systems A Case Study of Kubernetes 1759260992151 10.1109/ASE63991.2025.00241 Gareema Ranjan University of Waterloo, Canada granjan@uwaterloo.ca Mahmoud Alfadel University of Calgary, Canada mahmoud.alfadel@ucalgary.ca Gengyi Sun University of Waterloo, Canada gengyi.sun@uwaterloo.ca Shane McIntosh University of Waterloo, Canada shane.mcintosh@uwaterloo.ca build system bazel continuous integration incremental build Since developers invoke the build system frequently, its performance can impact productivity. Modern artifact-based build tools accelerate builds, yet prior work shows that teams may abandon them for alternatives that are easier to maintain. While prior work shows why downgrades are performed, the implications of downgrades remain largely unexplored. In this paper, we describe a case study of the Kubernetes project, focusing on its downgrade from an artifact-based build tool (Bazel) to a language-specific solution (Go Build). We reproduce and analyze the full and incremental builds of change sets during the downgrade period. On the one hand, we find that Bazel builds are faster than Go Build, completing full builds in 23.06 - 38.66 % less time and incremental builds in up to 75.19 % less time. On the other hand, Bazel builds impose a larger memory footprint than Go Build of 81.42 - 351.07 % and 118.71 - 218.22 % for full and incremental builds, respectively. Bazel builds also impose a greater CPU load at parallelism settings above eight for full builds and above one for incremental builds. We estimate that downgrading from Bazel can increase CI resource costs by up to 76 %. We explore whether our observations generalize by replicating our Kubernetes study on four other projects that also downgraded from Bazel to older build tools. We observe that while build time penalties decrease, Bazel consistently consumes more memory. We conclude that abandoning artifact-based build tools, despite perceived maintainability benefits, tends to incur considerable performance costs for large projects. Our observations may help stakeholders to balance trade-offs in build tool adoption.",
							"pageNumber": 2931,
							"isPageNumberRoman": false
						},
						{
							"eid": "2cUEnXVaX6qZumSmjw1pEA",
							"type": "authorPaper",
							"text": "EPSO: A Caching-Based Efficient Superoptimizer for BPF Bytecode",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c944/573300c944.pdf",
							"extraLocations": [],
							"authorNames": "Qian Zhu (Nanjing University, China), Yuxuan Liu (Nanjing University, China), Ziyuan Zhu (Nanjing University, China), Shangqing Liu (Nanjing University, China), Lei Bu (Nanjing University, China)",
							"abstract": "Extended Berkeley Packet Filter (eBPF) allows developers to extend Linux kernel functionality without modifying its source code. To ensure system safety, an in-kernel safety checker, the verifier, enforces strict safety constraints (e.g., a limited program size) on eBPF programs loaded into the kernel. These constraints, combined with eBPF's performance-critical use cases, make effective optimization essential. However, existing compilers (e.g., Clang) offer limited optimization support, and many semantics-preserving transformations are rejected by the verifier, which makes handcrafted optimization rule design both challenging and limited in effectiveness. Superoptimization overcomes the limitations of rule-based methods by automatically discovering optimal transformations, but its high computational cost limits scalability. To address this, we propose EPSO, a caching-based superoptimizer that discovers rewrite rules via offline superoptimization, and reuses them to achieve high-quality optimizations with minimal runtime overhead. We evaluate EPSO on benchmarks from the Linux kernel and several eBPF-based projects, including Cilium, Katran, hXDP, Sysdig, Tetragon, and Tracee. EPSO discovers 795 rewrite rules and achieves up to 68.87% (avg. 24.37%) reduction in program size compared to Clang's output, outperforming the state-of-the-art BPF optimizer K2 on all benchmarks and Merlin on 92.68% of them. Additionally, EPSO reduces program runtime by an average of 6.60%, improving throughput and lowering latency in network applications.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 EPSO: A Caching-Based Efficient Superoptimizer for BPF Bytecode 1759411641566 10.1109/ASE63991.2025.00242 Qian Zhu Nanjing University, China zhuqian@smail.nju.edu.cn Yuxuan Liu Nanjing University, China yuxuanliu@smail.nju.edu.cn Ziyuan Zhu Nanjing University, China mg21330081@smail.nju.edu.cn Shangqing Liu Nanjing University, China shangqingliu@nju.edu.cn Lei Bu Nanjing University, China bulei@nju.edu.cn ebpf synthesis superoptimization Extended Berkeley Packet Filter (eBPF) allows developers to extend Linux kernel functionality without modifying its source code. To ensure system safety, an in-kernel safety checker, the verifier, enforces strict safety constraints (e.g., a limited program size) on eBPF programs loaded into the kernel. These constraints, combined with eBPF's performance-critical use cases, make effective optimization essential. However, existing compilers (e.g., Clang) offer limited optimization support, and many semantics-preserving transformations are rejected by the verifier, which makes handcrafted optimization rule design both challenging and limited in effectiveness. Superoptimization overcomes the limitations of rule-based methods by automatically discovering optimal transformations, but its high computational cost limits scalability. To address this, we propose EPSO, a caching-based superoptimizer that discovers rewrite rules via offline superoptimization, and reuses them to achieve high-quality optimizations with minimal runtime overhead. We evaluate EPSO on benchmarks from the Linux kernel and several eBPF-based projects, including Cilium, Katran, hXDP, Sysdig, Tetragon, and Tracee. EPSO discovers 795 rewrite rules and achieves up to 68.87% (avg. 24.37%) reduction in program size compared to Clang's output, outperforming the state-of-the-art BPF optimizer K2 on all benchmarks and Merlin on 92.68% of them. Additionally, EPSO reduces program runtime by an average of 6.60%, improving throughput and lowering latency in network applications.",
							"pageNumber": 2944,
							"isPageNumberRoman": false
						},
						{
							"eid": "692SNNgARAEoRCwV7JAk97",
							"type": "authorPaper",
							"text": "When Does Wasm Malware Detection Fail? A Systematic Analysis of Their Robustness to Evasion",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c956/573300c956.pdf",
							"extraLocations": [],
							"authorNames": "Taeyoung Kim (Sungkyunkwan University, Republic of Korea), Sanghak Oh (Sungkyunkwan University, Republic of Korea), Kiho Lee (Electronics and Telecommunications Research Institute, Republic of Korea), Weihang Wang (University of Southern California, USA), Yonghwi Kwon (University of Maryland, USA), Sanghyun Hong (Oregon State University, USA), Hyoungshick Kim (Sungkyunkwan University, Republic of Korea)",
							"abstract": "WebAssembly (Wasm) provides a language-agnostic compilation target that delivers near-native performance for web applications, yet it also attracts adversaries who exploit Wasm to effectively steal someone else's computer resources such as cryptojackers. While several detection tools have been proposed, their robustness against perturbations remains largely unknown. In this paper, we introduce SWAMPED (Systematic WebAssembly Module Perturbation Evaluation of Detectors), a framework that incorporates 22 semantics-preserving perturbation methods. SWAMPED generates a total of 48,840 perturbed variants from 43 cryptojacker samples and 31 additional Wasm malware binaries from real-world. We assess detection performance of six detectors: three Wasm-specific ones and three deep neural network (DNN) detectors. We find that DNN-based detectors are vulnerable to perturbations that shift the instruction distribution; profiling-based methods are disrupted by changes in instruction frequency; and semantic-aware approaches are highly sensitive to function-level dependency modifications. DNN-based detectors, which lack Wasm-specific modeling, are particularly susceptible to changes in the spatial layout of Wasm binaries. These findings highlight fundamental limitations in current Wasm malware detection approaches, relying on overly specific detection heuristics and inadequately trained or designed models. We offer suggestions to improve the robustness against perturbations.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 When Does Wasm Malware Detection Fail? A Systematic Analysis of Their Robustness to Evasion 1759128961880 10.1109/ASE63991.2025.00243 Taeyoung Kim Sungkyunkwan University, Republic of Korea tykim0402@skku.edu Sanghak Oh Sungkyunkwan University, Republic of Korea sanghak@skku.edu Kiho Lee Electronics and Telecommunications Research Institute, Republic of Korea kiho@etri.re.kr Weihang Wang University of Southern California, USA weihangw@usc.edu Yonghwi Kwon University of Maryland, USA yongkwon@umd.edu Sanghyun Hong Oregon State University, USA sanghyung.hong@oregonstate.edu Hyoungshick Kim Sungkyunkwan University, Republic of Korea hyoung@skku.edu WebAssembly (Wasm) provides a language-agnostic compilation target that delivers near-native performance for web applications, yet it also attracts adversaries who exploit Wasm to effectively steal someone else's computer resources such as cryptojackers. While several detection tools have been proposed, their robustness against perturbations remains largely unknown. In this paper, we introduce SWAMPED (Systematic WebAssembly Module Perturbation Evaluation of Detectors), a framework that incorporates 22 semantics-preserving perturbation methods. SWAMPED generates a total of 48,840 perturbed variants from 43 cryptojacker samples and 31 additional Wasm malware binaries from real-world. We assess detection performance of six detectors: three Wasm-specific ones and three deep neural network (DNN) detectors. We find that DNN-based detectors are vulnerable to perturbations that shift the instruction distribution; profiling-based methods are disrupted by changes in instruction frequency; and semantic-aware approaches are highly sensitive to function-level dependency modifications. DNN-based detectors, which lack Wasm-specific modeling, are particularly susceptible to changes in the spatial layout of Wasm binaries. These findings highlight fundamental limitations in current Wasm malware detection approaches, relying on overly specific detection heuristics and inadequately trained or designed models. We offer suggestions to improve the robustness against perturbations.",
							"pageNumber": 2956,
							"isPageNumberRoman": false
						},
						{
							"eid": "1dsRTuTdwxYaEFf1mctMB3",
							"type": "authorPaper",
							"text": "Vulnerability-Affected Versions Identification: How Far Are We?",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c969/573300c969.pdf",
							"extraLocations": [],
							"authorNames": "Xingchu Chen (Chinese Academy of Sciences, China; UCAS, China), Chengwei Liu (Nanyang Technological University, Singapore), Jialun Cao (The Hong Kong University of Science and Technology, China), Yang Xiao (Chinese Academy of Sciences, China; UCAS, China), Xinyue Cai (Chinese Academy of Sciences, China; UCAS, China), Yeting Li (Chinese Academy of Sciences, China; UCAS, China), Jingyi Shi (Chinese Academy of Sciences, China; UCAS, China), Tianqi Sun (Chinese Academy of Sciences, China; UCAS, China), Haiming Chen (UCAS, China), Wei Huo (Chinese Academy of Sciences, China; UCAS, China)",
							"abstract": "Identifying which software versions are affected by a vulnerability is critical for patching, risk mitigation. Despite a growing body of tools, their real-world effectiveness remains unclear due to narrow evaluation scopes\u2014often limited to early SZZ variants, outdated techniques, and small or coarse-grained datasets. In this paper, we present the first comprehensive empirical study of vulnerability-affected versions identification. We curate a high-quality benchmark of 1,128 real-world C/C++ vulnerabilities and systematically evaluate 12 representative tools from both tracing and matching paradigms across four dimensions: effectiveness at both vulnerability and version levels, root causes of false positives and negatives, sensitivity to patch characteristics, and ensemble potential. Our findings reveal fundamental limitations: no tool exceeds 45.0% accuracy, with key challenges stemming from heuristic dependence, limited semantic reasoning, and rigid matching logic. Patch structures such as add-only and cross-file changes further hinder performance. Although ensemble strategies can improve results by up to 10.1%, overall accuracy remains below 60.0%, highlighting the need for fundamentally new approaches. Moreover, our study offers actionable insights to guide tool development, combination strategies, and future research in this critical area. Finally, we release the replicated code and benchmark on our website to encourage future contributions.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Vulnerability-Affected Versions Identification: How Far Are We? 1759151625343 10.1109/ASE63991.2025.00244 Xingchu Chen Chinese Academy of Sciences, China; UCAS, China chenxingchu@iie.ac.cn Chengwei Liu Nanyang Technological University, Singapore chengwei.liu@ntu.edu.sg Jialun Cao The Hong Kong University of Science and Technology, China jcaoap@cse.ust.hk Yang Xiao Chinese Academy of Sciences, China; UCAS, China xiaoyang@iie.ac.cn Xinyue Cai Chinese Academy of Sciences, China; UCAS, China caixinyue@iie.ac.cn Yeting Li Chinese Academy of Sciences, China; UCAS, China liyeting@iie.ac.cn Jingyi Shi Chinese Academy of Sciences, China; UCAS, China shijingyi@iie.ac.cn Tianqi Sun Chinese Academy of Sciences, China; UCAS, China suntianqi@iie.ac.cn Haiming Chen UCAS, China chm@ios.ac.cn Wei Huo Chinese Academy of Sciences, China; UCAS, China huowei@iie.ac.cn Identifying which software versions are affected by a vulnerability is critical for patching, risk mitigation. Despite a growing body of tools, their real-world effectiveness remains unclear due to narrow evaluation scopes\u2014often limited to early SZZ variants, outdated techniques, and small or coarse-grained datasets. In this paper, we present the first comprehensive empirical study of vulnerability-affected versions identification. We curate a high-quality benchmark of 1,128 real-world C/C++ vulnerabilities and systematically evaluate 12 representative tools from both tracing and matching paradigms across four dimensions: effectiveness at both vulnerability and version levels, root causes of false positives and negatives, sensitivity to patch characteristics, and ensemble potential. Our findings reveal fundamental limitations: no tool exceeds 45.0% accuracy, with key challenges stemming from heuristic dependence, limited semantic reasoning, and rigid matching logic. Patch structures such as add-only and cross-file changes further hinder performance. Although ensemble strategies can improve results by up to 10.1%, overall accuracy remains below 60.0%, highlighting the need for fundamentally new approaches. Moreover, our study offers actionable insights to guide tool development, combination strategies, and future research in this critical area. Finally, we release the replicated code and benchmark on our website to encourage future contributions.",
							"pageNumber": 2969,
							"isPageNumberRoman": false
						},
						{
							"eid": "5XYoAw25IJvOCnpkbtMvGe",
							"type": "authorPaper",
							"text": "LAURA: Enhancing Code Review Generation with Context-Enriched Retrieval-Augmented LLM",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c982/573300c982.pdf",
							"extraLocations": [],
							"authorNames": "Yuxin Zhang (Beijing Institute of Technology, China), Yuxia Zhang (Beijing Institute of Technology, China), Zeyu Sun (Chinese Academy of Sciences, China), Yanjie Jiang (Tianjin University, China), Hui Liu (Beijing Institute of Technology, China)",
							"abstract": "Code review is critical for ensuring software quality and maintainability. With the rapid growth in software scale and complexity, code review has become a bottleneck in the development process because of its time-consuming and knowledge-intensive nature and the shortage of experienced developers willing to review code. Several approaches have been proposed for automatically generating code reviews based on retrieval, neural machine translation, pre-trained models, or large language models (LLMs). These approaches mainly leverage historical code changes and review comments. However, a large amount of crucial information for code review, such as the context of code changes and prior review knowledge, has been overlooked. This paper proposes an LLM-based review knowledge-augmented, context-aware framework for code review generation, named LAURA. The framework integrates review exemplar retrieval, context augmentation, and systematic guidance to enhance the performance of ChatGPT-4o and DeepSeek v3 in generating code review comments. Besides, given the extensive low-quality reviews in existing datasets, we also constructed a high-quality dataset. Experimental results show that for both models, LAURA generates review comments that are either completely correct or at least helpful to developers in 42.2% and 40.4% of cases, respectively, significantly outperforming SOTA baselines. Furthermore, our ablation studies demonstrate that all components of LAURA contribute positively to improving comment quality.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 LAURA: Enhancing Code Review Generation with Context-Enriched Retrieval-Augmented LLM 1759461550951 10.1109/ASE63991.2025.00245 Yuxin Zhang Beijing Institute of Technology, China yuxinzhang@bit.edu.cn Yuxia Zhang Beijing Institute of Technology, China yuxiazh@bit.edu.cn Zeyu Sun Chinese Academy of Sciences, China zeyu.zys@gmail.com Yanjie Jiang Tianjin University, China 2990094974@qq.com Hui Liu Beijing Institute of Technology, China liuhui08@bit.edu.cn code review generation llms review exemplar retrieval context-aware Code review is critical for ensuring software quality and maintainability. With the rapid growth in software scale and complexity, code review has become a bottleneck in the development process because of its time-consuming and knowledge-intensive nature and the shortage of experienced developers willing to review code. Several approaches have been proposed for automatically generating code reviews based on retrieval, neural machine translation, pre-trained models, or large language models (LLMs). These approaches mainly leverage historical code changes and review comments. However, a large amount of crucial information for code review, such as the context of code changes and prior review knowledge, has been overlooked. This paper proposes an LLM-based review knowledge-augmented, context-aware framework for code review generation, named LAURA. The framework integrates review exemplar retrieval, context augmentation, and systematic guidance to enhance the performance of ChatGPT-4o and DeepSeek v3 in generating code review comments. Besides, given the extensive low-quality reviews in existing datasets, we also constructed a high-quality dataset. Experimental results show that for both models, LAURA generates review comments that are either completely correct or at least helpful to developers in 42.2% and 40.4% of cases, respectively, significantly outperforming SOTA baselines. Furthermore, our ablation studies demonstrate that all components of LAURA contribute positively to improving comment quality.",
							"pageNumber": 2982,
							"isPageNumberRoman": false
						},
						{
							"eid": "49WDLOAJ8XnJnPjObAJQic",
							"type": "authorPaper",
							"text": "Your Build Scripts Stink: The State of Code Smells in Build Scripts",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c995/573300c995.pdf",
							"extraLocations": [],
							"authorNames": "Mahzabin Tamanna (North Carolina State University, USA), Yash Chandrani (North Carolina State University, USA), Matthew Burrows (North Carolina State University, USA), Brandon Wroblewski (North Carolina State University, USA), Laurie  Williams (North Carolina State University, USA), Dominik  Wermke (North Carolina State University, USA)",
							"abstract": "Build scripts automate the process of compiling source code, managing dependencies, running tests, and packaging software into deployable artifacts. These scripts are ubiquitous in modern software development pipelines for streamlining testing and delivery. While developing build scripts, practitioners may inadvertently introduce code smells, which are recurring patterns of poor coding practices that may lead to build failures or increase risk and technical debt. The goal of this study is to aid practitioners in avoiding code smells in build scripts through an empirical study of build scripts and issues on GitHub. We employed a mixed-methods approach, combining qualitative and quantitative analysis. First, we conducted a qualitative analysis of 2000 build-script-related GitHub issues to understand recurring smells. Next, we developed a static analysis tool, Sniffer, to automatically detect code smells in 5882 build scripts of Maven, Gradle, CMake, and Make files, collected from 4877 open-source GitHub repositories. To assess Sniffer's performance, we conducted a user study, where Sniffer achieved higher precision, recall, and F-score. We identified 13 code smell categories, with a total of 10,895 smell occurrences, where 3184 were in Maven, 1214 in Gradle, 337 in CMake, and 6160 in Makefiles. Our analysis revealed that Insecure URLs were the most prevalent code smell in Maven build scripts, while Hardcoded Paths/URLs were commonly observed in both Gradle and CMake scripts. Wildcard Usage emerged as the most frequent smell in Makefiles. The co-occurrence analysis revealed strong associations between specific smell pairs of Hardcoded Paths/URLs with Duplicates, and Inconsistent Dependency Management with Empty or Incomplete Tags, which indicate potential underlying issues in the build script structure and maintenance practices. Based on our findings, we also recommended strategies to remove code smells in build scripts to improve the efficiency, reliability, and maintainability of software projects",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Your Build Scripts Stink: The State of Code Smells in Build Scripts 1759458436043 10.1109/ASE63991.2025.00246 Mahzabin Tamanna North Carolina State University, USA mtamann@ncsu.edu Yash Chandrani North Carolina State University, USA ychandr@ncsu.edu Matthew Burrows North Carolina State University, USA myburrow@ncsu.edu Brandon Wroblewski North Carolina State University, USA bnwroble@ncsu.edu Laurie Williams North Carolina State University, USA lawilli3@ncsu.edu Dominik Wermke North Carolina State University, USA dwermke@ncsu.edu code smells build scripts ci/cd devops software supply chain security empirical study static analysis Build scripts automate the process of compiling source code, managing dependencies, running tests, and packaging software into deployable artifacts. These scripts are ubiquitous in modern software development pipelines for streamlining testing and delivery. While developing build scripts, practitioners may inadvertently introduce code smells, which are recurring patterns of poor coding practices that may lead to build failures or increase risk and technical debt. The goal of this study is to aid practitioners in avoiding code smells in build scripts through an empirical study of build scripts and issues on GitHub. We employed a mixed-methods approach, combining qualitative and quantitative analysis. First, we conducted a qualitative analysis of 2000 build-script-related GitHub issues to understand recurring smells. Next, we developed a static analysis tool, Sniffer, to automatically detect code smells in 5882 build scripts of Maven, Gradle, CMake, and Make files, collected from 4877 open-source GitHub repositories. To assess Sniffer's performance, we conducted a user study, where Sniffer achieved higher precision, recall, and F-score. We identified 13 code smell categories, with a total of 10,895 smell occurrences, where 3184 were in Maven, 1214 in Gradle, 337 in CMake, and 6160 in Makefiles. Our analysis revealed that Insecure URLs were the most prevalent code smell in Maven build scripts, while Hardcoded Paths/URLs were commonly observed in both Gradle and CMake scripts. Wildcard Usage emerged as the most frequent smell in Makefiles. The co-occurrence analysis revealed strong associations between specific smell pairs of Hardcoded Paths/URLs with Duplicates, and Inconsistent Dependency Management with Empty or Incomplete Tags, which indicate potential underlying issues in the build script structure and maintenance practices. Based on our findings, we also recommended strategies to remove code smells in build scripts to improve the efficiency, reliability, and maintainability of software projects",
							"pageNumber": 2995,
							"isPageNumberRoman": false
						},
						{
							"eid": "3lDnmH13cQmjUiobyPIKmz",
							"type": "authorPaper",
							"text": "Mockingbird: Efficient Excessive Data Exposures Detection via Dynamic Code Instrumentation",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d008/573300d008.pdf",
							"extraLocations": [],
							"authorNames": "Chenxiao Xia (Beijing Institute of Technology, China; Key Laboratory of Intelligent Networking Technology for Social Governance), Jiazheng Sun (Fudan University, China), Jun Zheng (Beijing Institute of Technology, China; Key Laboratory of Intelligent Networking Technology for Social Governance), Yu-an Tan (Beijing Institute of Technology, China; Key Laboratory of Intelligent Networking Technology for Social Governance), Hongyi Su (Beijing Institute of Technology, China; Key Laboratory of Intelligent Networking Technology for Social Governance)",
							"abstract": "Excessive Data Exposure (EDE), where an API returns redundant data to the client beyond what is required for its functionality, has become a pervasive and severe security threat. However, automated detection techniques for such vulnerabilities remain underdeveloped, and existing methods, particularly black-box fuzzing, face significant bottlenecks in terms of accuracy and efficiency. To address these challenges, we propose Mockingbird, an automated detection tool based on a statically-assisted dynamic analysis approach. The tool leverages the JavaScript Proxy mechanism for efficient dynamic taint tracking to precisely identify the dangling data that is transmitted from an API response to the client but never consumed by any expected functionality, such as UI rendering or state management. Furthermore, to tackle the lack of a standardized benchmark in this domain, we have constructed and open-sourced EDEBench, the first persistent benchmark for EDE evaluation, comprising 8 popular open-source web projects built on diverse modern technology stacks. Experimental evaluation on EDEBench shows that, compared to the state-of-the-art, Mockingbird achieves an average F1-score improvement of 24.1% (Precision +15.8%, Recall +32.8%), enhances detection speed by nearly 20 times, and demonstrates broad applicability across all tested frameworks. These results provide a clear illustration of our tool's accuracy, applicability, and efficiency. The source code is available at https://github.com/NeoSunJZ/Mockingbird-JS.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Mockingbird: Efficient Excessive Data Exposures Detection via Dynamic Code Instrumentation 1759245666585 10.1109/ASE63991.2025.00247 Chenxiao Xia Beijing Institute of Technology, China; Key Laboratory of Intelligent Networking Technology for Social Governance chenxiao_xia@bit.edu.cn Jiazheng Sun Fudan University, China jzsun24@m.fudan.edu.cn Jun Zheng Beijing Institute of Technology, China; Key Laboratory of Intelligent Networking Technology for Social Governance zhengjun@bit.edu.cn Yu-an Tan Beijing Institute of Technology, China; Key Laboratory of Intelligent Networking Technology for Social Governance tan2008@bit.edu.cn Hongyi Su Beijing Institute of Technology, China; Key Laboratory of Intelligent Networking Technology for Social Governance henrysu@bit.edu.cn excessive data exposure api security dynamic code instrumentation gray-box testing Excessive Data Exposure (EDE), where an API returns redundant data to the client beyond what is required for its functionality, has become a pervasive and severe security threat. However, automated detection techniques for such vulnerabilities remain underdeveloped, and existing methods, particularly black-box fuzzing, face significant bottlenecks in terms of accuracy and efficiency. To address these challenges, we propose Mockingbird, an automated detection tool based on a statically-assisted dynamic analysis approach. The tool leverages the JavaScript Proxy mechanism for efficient dynamic taint tracking to precisely identify the dangling data that is transmitted from an API response to the client but never consumed by any expected functionality, such as UI rendering or state management. Furthermore, to tackle the lack of a standardized benchmark in this domain, we have constructed and open-sourced EDEBench, the first persistent benchmark for EDE evaluation, comprising 8 popular open-source web projects built on diverse modern technology stacks. Experimental evaluation on EDEBench shows that, compared to the state-of-the-art, Mockingbird achieves an average F1-score improvement of 24.1% (Precision +15.8%, Recall +32.8%), enhances detection speed by nearly 20 times, and demonstrates broad applicability across all tested frameworks. These results provide a clear illustration of our tool's accuracy, applicability, and efficiency. The source code is available at https://github.com/NeoSunJZ/Mockingbird-JS.",
							"pageNumber": 3008,
							"isPageNumberRoman": false
						},
						{
							"eid": "4839MhvSnT1puy7Kz4VpxV",
							"type": "authorPaper",
							"text": "RealisticCodeBench: Towards More Realistic Evaluation of Large Language Models for Code Generation",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d020/573300d020.pdf",
							"extraLocations": [],
							"authorNames": "Xiao Yu (Zhejiang University, China), Haoxuan Chen (Wuhan University of Technology, China), Lei Liu (Xi'an Jiaotong University, China), Xing Hu (Zhejiang University, China), Jacky Wai Keung (City University of Hong Kong, China), Xin Xia (Zhejiang University, China)",
							"abstract": "Evaluating the code generation capabilities of Large Language Models (LLMs) remains an open question. Recently, more advanced benchmarks\u2014such as CoderEval, EvoCodeBench, and ClassEval\u2014have been introduced to evaluate LLMs on practical coding tasks from GitHub repositories, such as non-standalone function generation and class-level code generation. However, even the most sophisticated LLMs struggle with these complex tasks; for instance, GPT-4 achieves only a 37.0% pass@1 on ClassEval. Prior studies show that developers often discard LLM-generated code or abandon code generation models when outputs are incorrect or require extensive debugging, which leads them to rely on LLMs primarily for code generation tasks that high-performing models can reliably handle. In response to this gap, we introduce RealisticCodeBench, a benchmark specifically designed to reflect the types of problems developers commonly tackle with LLMs. By mining GitHub repositories for code samples tagged as generated by ChatGPT or Copilot, we collect real-world coding tasks that capture typical LLM usage scenarios. We modify these tasks, generate reference solutions and test cases, and adapt the problems into multiple programming languages. This effort results in RealisticCodeBench, comprising a total of 376 programming problems translated across multiple languages: 361 in Python, 346 in JavaScript, 343 in TypeScript, 307 in Java, and 323 in C++, each with corresponding reference solutions and test cases. We evaluate 12 general-purpose and code-specific LLMs on RealisticCodeBench. Our findings reveal that GPT-4.1 achieves the highest average pass@1 score across languages, closely followed by DeepSeek-V3-671B, suggesting that DeepSeek-V3-671B provides a viable open-source alternative to GPT-4.1 for large companies with sufficient GPU resources and privacy concerns. CodeGeeX4-9B, a cost-effective model, emerges as a suitable substitute for GPT-4o-mini for individual developers and smaller organizations with similar privacy considerations. Additionally, LLM performance discrepancies between HumanEval and RealisticCodeBench suggest that some LLMs are either overly specialized for HumanEval-style problems or insufficiently optimized for real-world coding challenges. Finally, we analyze failed cases, summarize common LLM limitations, and provide implications for researchers and practitioners.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 RealisticCodeBench: Towards More Realistic Evaluation of Large Language Models for Code Generation 1759497789094 10.1109/ASE63991.2025.00248 Xiao Yu Zhejiang University, China xiao.yu@zju.edu.cn Haoxuan Chen Wuhan University of Technology, China haoxuan.chen@whut.edu.cn Lei Liu Xi'an Jiaotong University, China lei.liu@stu.xjtu.edu.cn Xing Hu Zhejiang University, China xinghu@zju.edu.cn Jacky Wai Keung City University of Hong Kong, China jacky.keung@cityu.edu.hk Xin Xia Zhejiang University, China xin.xia@acm.org code generation large language model benchmark github Evaluating the code generation capabilities of Large Language Models (LLMs) remains an open question. Recently, more advanced benchmarks\u2014such as CoderEval, EvoCodeBench, and ClassEval\u2014have been introduced to evaluate LLMs on practical coding tasks from GitHub repositories, such as non-standalone function generation and class-level code generation. However, even the most sophisticated LLMs struggle with these complex tasks; for instance, GPT-4 achieves only a 37.0% pass@1 on ClassEval. Prior studies show that developers often discard LLM-generated code or abandon code generation models when outputs are incorrect or require extensive debugging, which leads them to rely on LLMs primarily for code generation tasks that high-performing models can reliably handle. In response to this gap, we introduce RealisticCodeBench, a benchmark specifically designed to reflect the types of problems developers commonly tackle with LLMs. By mining GitHub repositories for code samples tagged as generated by ChatGPT or Copilot, we collect real-world coding tasks that capture typical LLM usage scenarios. We modify these tasks, generate reference solutions and test cases, and adapt the problems into multiple programming languages. This effort results in RealisticCodeBench, comprising a total of 376 programming problems translated across multiple languages: 361 in Python, 346 in JavaScript, 343 in TypeScript, 307 in Java, and 323 in C++, each with corresponding reference solutions and test cases. We evaluate 12 general-purpose and code-specific LLMs on RealisticCodeBench. Our findings reveal that GPT-4.1 achieves the highest average pass@1 score across languages, closely followed by DeepSeek-V3-671B, suggesting that DeepSeek-V3-671B provides a viable open-source alternative to GPT-4.1 for large companies with sufficient GPU resources and privacy concerns. CodeGeeX4-9B, a cost-effective model, emerges as a suitable substitute for GPT-4o-mini for individual developers and smaller organizations with similar privacy considerations. Additionally, LLM performance discrepancies between HumanEval and RealisticCodeBench suggest that some LLMs are either overly specialized for HumanEval-style problems or insufficiently optimized for real-world coding challenges. Finally, we analyze failed cases, summarize common LLM limitations, and provide implications for researchers and practitioners.",
							"pageNumber": 3020,
							"isPageNumberRoman": false
						},
						{
							"eid": "1oNsyfStJ2kH1PYr3zfRU8",
							"type": "authorPaper",
							"text": "Issue Localization via LLM-Driven Iterative Code Graph Searching",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d033/573300d033.pdf",
							"extraLocations": [],
							"authorNames": "Zhonghao Jiang (Zhejiang University, China), Xiaoxue Ren (Zhejiang University, China), Meng Yan (Chongqing University, China), Wei Jiang (Ant Group, China), Yong Li (Ant Group, China), Zhongxin Liu (Zhejiang University, China)",
							"abstract": "Issue solving aims to generate patches to fix reported issues in real-world code repositories according to issue descriptions. Issue localization forms the basis for accurate issue solving. Recently, large language model (LLM) based issue localization methods have demonstrated state-of-the-art performance. However, these methods either search from files mentioned in issue descriptions or in the whole repository and struggle to balance the breadth and depth of the search space to converge on the target efficiently. Moreover, they allow LLM to explore whole repositories freely, making it challenging to control the search direction to prevent the LLM from searching for incorrect targets. Meanwhile, because LLMs may not correctly produce the required interaction formats with the environment, they suffer from search failures. This paper introduces CoSIL, an LLM-driven, powerful function-level issue localization method without training or indexing. To balance search breadth and depth, CoSIL employs a two-phase code graph search strategy. It first conducts broad exploration at the file level using dynamically constructed module call graphs, and then performs in-depth analysis at the function level by expanding the module call graph into a function call graph and executing iterative searches. To precisely control the search direction, CoSIL designs a pruner to filter unrelated directions and irrelevant contexts. To avoid incorrect interaction formats in long contexts, CoSIL introduces a reflection mechanism that uses additional independent queries in short contexts to enhance formatted abilities. Experiment results demonstrate that CoSIL achieves a Top-1 localization accuracy of 43.3% and 44.6% on SWE-bench Lite and SWE-bench Verified, respectively, with Qwen2.5-Coder-32B, average outperforming the state-of-the-art methods by 96.04%. When CoSIL is integrated into an issue-solving method, Agentless, the issue resolution rate improves by 2.98%\u201330.5%.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Issue Localization via LLM-Driven Iterative Code Graph Searching 1759209056623 10.1109/ASE63991.2025.00249 Zhonghao Jiang Zhejiang University, China zhonghao.j@zju.edu.cn Xiaoxue Ren Zhejiang University, China xxren@zju.edu.cn Meng Yan Chongqing University, China mengy@cqu.edu.cn Wei Jiang Ant Group, China jonny.jw@antgroup.com Yong Li Ant Group, China liyong.liy@antgroup.com Zhongxin Liu Zhejiang University, China liu_zx@zju.edu.cn n/a Issue solving aims to generate patches to fix reported issues in real-world code repositories according to issue descriptions. Issue localization forms the basis for accurate issue solving. Recently, large language model (LLM) based issue localization methods have demonstrated state-of-the-art performance. However, these methods either search from files mentioned in issue descriptions or in the whole repository and struggle to balance the breadth and depth of the search space to converge on the target efficiently. Moreover, they allow LLM to explore whole repositories freely, making it challenging to control the search direction to prevent the LLM from searching for incorrect targets. Meanwhile, because LLMs may not correctly produce the required interaction formats with the environment, they suffer from search failures. This paper introduces CoSIL, an LLM-driven, powerful function-level issue localization method without training or indexing. To balance search breadth and depth, CoSIL employs a two-phase code graph search strategy. It first conducts broad exploration at the file level using dynamically constructed module call graphs, and then performs in-depth analysis at the function level by expanding the module call graph into a function call graph and executing iterative searches. To precisely control the search direction, CoSIL designs a pruner to filter unrelated directions and irrelevant contexts. To avoid incorrect interaction formats in long contexts, CoSIL introduces a reflection mechanism that uses additional independent queries in short contexts to enhance formatted abilities. Experiment results demonstrate that CoSIL achieves a Top-1 localization accuracy of 43.3% and 44.6% on SWE-bench Lite and SWE-bench Verified, respectively, with Qwen2.5-Coder-32B, average outperforming the state-of-the-art methods by 96.04%. When CoSIL is integrated into an issue-solving method, Agentless, the issue resolution rate improves by 2.98%\u201330.5%.",
							"pageNumber": 3033,
							"isPageNumberRoman": false
						},
						{
							"eid": "6WxTFww0B8xWYg28yBS2rt",
							"type": "authorPaper",
							"text": "Clarifying Semantics of In-Context Examples for Unit Test Generation",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d045/573300d045.pdf",
							"extraLocations": [],
							"authorNames": "Chen Yang (Tianjin University, China), Lin Yang (Tianjin University, China), Ziqi Wang (Tianjin University, China), Dong Wang (Tianjin University, China), Jianyi Zhou (Huawei Cloud Computing Technologies Co., Ltd., China), Junjie Chen (Tianjin University, China)",
							"abstract": "Recent advances in large language models (LLMs) have enabled promising performance in unit test generation through in-context learning (ICL). However, the quality of in-context examples significantly influences the effectiveness of generated tests\u2014poorly structured or semantically unclear test examples often lead to suboptimal outputs. In this paper, we propose CLAST, a novel technique that systematically refines unit tests to improve their semantic clarity, thereby enhancing their utility as in-context examples. The approach decomposes complex tests into logically clearer ones and improves semantic clarity through a combination of program analysis and LLM-based rewriting. We evaluated CLAST on four open-source and three industrial projects. The results demonstrate that CLAST largely outperforms UTgen, the state-of-the-art refinement technique, in both preserving test effectiveness and enhancing semantic clarity. Specifically, CLAST fully retains the original effectiveness of unit tests, while UTgen reduces compilation success rate (CSR), pass rate (PR), test coverage (Cov), and mutation score (MS) by an average of 12.90%, 35.82%, 4.65%, and 5.07%, respectively. Over 85.33% of participants in our user study preferred the semantic clarity of CLAST-refined tests. Notably, incorporating CLAST-refined tests as examples effectively improves ICL-based unit test generation approaches such as RAGGen and TELPA, resulting in an average increase of 25.97% in CSR, 28.22% in PR, and 45.99% in Cov for generated tests, compared to incorporating UTgen-refined tests. The insights from the follow-up user study not only reinforce CLAST's potential impact in software testing practice but also illuminate avenues for future research. ",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Clarifying Semantics of In-Context Examples for Unit Test Generation 1759408835799 10.1109/ASE63991.2025.00250 Chen Yang Tianjin University, China yangchenyc@tju.edu.cn Lin Yang Tianjin University, China linyang@tju.edu.cn Ziqi Wang Tianjin University, China wangziqi123@tju.edu.cn Dong Wang Tianjin University, China dong_w@tju.edu.cn Jianyi Zhou Huawei Cloud Computing Technologies Co., Ltd., China zhoujianyi2@huawei.com Junjie Chen Tianjin University, China junjiechen@tju.edu.cn test refinement unit test generation in-context learning Recent advances in large language models (LLMs) have enabled promising performance in unit test generation through in-context learning (ICL). However, the quality of in-context examples significantly influences the effectiveness of generated tests\u2014poorly structured or semantically unclear test examples often lead to suboptimal outputs. In this paper, we propose CLAST, a novel technique that systematically refines unit tests to improve their semantic clarity, thereby enhancing their utility as in-context examples. The approach decomposes complex tests into logically clearer ones and improves semantic clarity through a combination of program analysis and LLM-based rewriting. We evaluated CLAST on four open-source and three industrial projects. The results demonstrate that CLAST largely outperforms UTgen, the state-of-the-art refinement technique, in both preserving test effectiveness and enhancing semantic clarity. Specifically, CLAST fully retains the original effectiveness of unit tests, while UTgen reduces compilation success rate (CSR), pass rate (PR), test coverage (Cov), and mutation score (MS) by an average of 12.90%, 35.82%, 4.65%, and 5.07%, respectively. Over 85.33% of participants in our user study preferred the semantic clarity of CLAST-refined tests. Notably, incorporating CLAST-refined tests as examples effectively improves ICL-based unit test generation approaches such as RAGGen and TELPA, resulting in an average increase of 25.97% in CSR, 28.22% in PR, and 45.99% in Cov for generated tests, compared to incorporating UTgen-refined tests. The insights from the follow-up user study not only reinforce CLAST's potential impact in software testing practice but also illuminate avenues for future research.",
							"pageNumber": 3045,
							"isPageNumberRoman": false
						},
						{
							"eid": "2Zzu71XXAwCICWJ8vMIcZy",
							"type": "authorPaper",
							"text": "Who's to Blame? Rethinking the Brittleness of Automated Web GUI Testing from a Pragmatic Perspective",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d057/573300d057.pdf",
							"extraLocations": [],
							"authorNames": "Haonan Zhang (University of Waterloo), Kundi Yao (University of Waterloo), Zishuo Ding (The Hong Kong University of Science and Technology, Guangzhou), Lizhi Liao (Memorial University of Newfoundland), Weiyi Shang (University of Waterloo)",
							"abstract": "Automated web GUI testing is important for software quality, however, its effectiveness is often undermined by test case brittleness, especially in continuously evolving real-world applications. In this experience paper, we pragmatically investigate the root causes of brittleness. We first analyze why legacy test cases, derived from the Mind2Web dataset, fail when executed on current web application versions. Our findings reveal that brittleness stems from multifaceted factors, including test script design, web application complexity, and automation framework limitations. A longitudinal study further shows that 81.7% of repaired tests break again within six months, primarily due to similar recurring issues, highlighting the persistent nature of brittleness. We further demonstrate that Large Language Models, when provided with human-like diagnostic context, can successfully repair a substantial portion of these brittle tests, though human expertise remains important for more complex scenarios. Our findings emphasize that brittleness is a multifaceted problem requiring collaboration between different parts involved in the automation testing.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Who's to Blame? Rethinking the Brittleness of Automated Web GUI Testing from a Pragmatic Perspective 1759152837912 10.1109/ASE63991.2025.00251 Haonan Zhang University of Waterloo haonan.zhang@uwaterloo.ca Kundi Yao University of Waterloo kundi.yao@uwaterloo.ca Zishuo Ding The Hong Kong University of Science and Technology, Guangzhou zishuoding@hkust-gz.edu.cn Lizhi Liao Memorial University of Newfoundland lizhi.liao@mun.ca Weiyi Shang University of Waterloo wshang@uwaterloo.ca experience report web gui testing test automation test evolution and maintenance Automated web GUI testing is important for software quality, however, its effectiveness is often undermined by test case brittleness, especially in continuously evolving real-world applications. In this experience paper, we pragmatically investigate the root causes of brittleness. We first analyze why legacy test cases, derived from the Mind2Web dataset, fail when executed on current web application versions. Our findings reveal that brittleness stems from multifaceted factors, including test script design, web application complexity, and automation framework limitations. A longitudinal study further shows that 81.7% of repaired tests break again within six months, primarily due to similar recurring issues, highlighting the persistent nature of brittleness. We further demonstrate that Large Language Models, when provided with human-like diagnostic context, can successfully repair a substantial portion of these brittle tests, though human expertise remains important for more complex scenarios. Our findings emphasize that brittleness is a multifaceted problem requiring collaboration between different parts involved in the automation testing.",
							"pageNumber": 3057,
							"isPageNumberRoman": false
						},
						{
							"eid": "CkDHUhPh2MbQSyX6LhoS8",
							"type": "authorPaper",
							"text": "Amur: Fixing Multi-Resource Leaks Guided by Resource Flow Analysis",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d070/573300d070.pdf",
							"extraLocations": [],
							"authorNames": "Jinyoung Kim (Sungkyunkwan University, Republic of Korea), Eunseok Lee (Sungkyunkwan University, Republic of Korea)",
							"abstract": "Resource leaks pose a persistent threat to software reliability, resulting in resource exhaustion, performance degradation, and system crashes. Existing automated repair approaches, primarily based on rigid templates, are limited in handling complex or multi-resource leak scenarios and often compromise program semantics. Although recent advances in Large language models show promise in program repair, existing LLM-based methods frequently generate semantically invalid patches for resource leaks. This paper presents Amur, a semantics-aware patching framework that leverages static analysis to guide LLMs in repairing both single- and multi-resource leaks. At the core of Amur is a novel Resource Flow Analysis (RFA), a flow-sensitive and inter-resource-aware static analysis that captures resource usage patterns and dependencies. RFA identifies potential leak points and enforces semantic constraints to guide LLMs in synthesizing semantics-preserving patches. We evaluate Amur on the NJR-1 dataset and the new JLeaks benchmark (ICSE 2024), which targets realistic multi-resource leak scenarios. Amur achieves substantial improvements over state-of-the-art methods, improving patch accuracy by 33% over RLFixer and 24% over LLM-only baselines in single-resource leak cases. For multi-resource leaks, Amur generates patches in 96% of cases and achieves 80% correctness, outperforming RLFixer and LLM-only baselines by 76% and 16%, respectively. These results demonstrate that integrating RFA into LLM-guided repair significantly enhances the correctness and generalizability of automated resource leak fixes.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Amur: Fixing Multi-Resource Leaks Guided by Resource Flow Analysis 1759396159197 10.1109/ASE63991.2025.00252 Jinyoung Kim Sungkyunkwan University, Republic of Korea danpoong@skku.edu Eunseok Lee Sungkyunkwan University, Republic of Korea leees@skku.edu automated repair resource leak llm Resource leaks pose a persistent threat to software reliability, resulting in resource exhaustion, performance degradation, and system crashes. Existing automated repair approaches, primarily based on rigid templates, are limited in handling complex or multi-resource leak scenarios and often compromise program semantics. Although recent advances in Large language models show promise in program repair, existing LLM-based methods frequently generate semantically invalid patches for resource leaks. This paper presents Amur, a semantics-aware patching framework that leverages static analysis to guide LLMs in repairing both single- and multi-resource leaks. At the core of Amur is a novel Resource Flow Analysis (RFA), a flow-sensitive and inter-resource-aware static analysis that captures resource usage patterns and dependencies. RFA identifies potential leak points and enforces semantic constraints to guide LLMs in synthesizing semantics-preserving patches. We evaluate Amur on the NJR-1 dataset and the new JLeaks benchmark (ICSE 2024), which targets realistic multi-resource leak scenarios. Amur achieves substantial improvements over state-of-the-art methods, improving patch accuracy by 33% over RLFixer and 24% over LLM-only baselines in single-resource leak cases. For multi-resource leaks, Amur generates patches in 96% of cases and achieves 80% correctness, outperforming RLFixer and LLM-only baselines by 76% and 16%, respectively. These results demonstrate that integrating RFA into LLM-guided repair significantly enhances the correctness and generalizability of automated resource leak fixes.",
							"pageNumber": 3070,
							"isPageNumberRoman": false
						},
						{
							"eid": "2r8Qh8iAJ0YDRTDBdqLtsS",
							"type": "authorPaper",
							"text": "Algernon: A Flag-Guided Hybrid Fuzzer for Unlocking Hidden Program Paths",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d082/573300d082.pdf",
							"extraLocations": [],
							"authorNames": "Peng Deng (Fudan University, China), Lei Zhang (Fudan University, China), Jingqi Long (Fudan University, China), Wenzheng Hong (Fudan University, China), Zhemin Yang (Fudan University, China), Yuan Zhang (Fudan University, China), Donglai Zhu (Fudan University, China), Min Yang (Fudan University, China)",
							"abstract": "Fuzz testing is a widely used method for finding security issues in software. However, certain code paths can only be explored under specific program states. Flag variables, which represent internal states, are crucial in influencing program behavior through flag-guarded branches. Unfortunately, existing fuzzing tools struggle to efficiently explore them due to the implicit data dependency between flag variables and the input. As a result, they commonly lack awareness of the dependency between program input and the assignments of critical flag variables, leading to a blind or random approach to satisfy flag-checking constraints, which greatly impacts the fuzzing efficiency. To address this issue, this paper proposes a dynamic flag-guided hybrid fuzzing approach, which automates the identification of flag variables and provides guidance for fuzz testing. Specifically, we first design a pre-fuzzing program analysis to recognize flag variables and a novel data structure to present how flag variables guard code branches. Then, we propose a new constraint-solving approach by separating complex flag-checking constraints into a set of atomic ones and sequentially solving them by traversing our FDG to locate execution paths that could assign the flag variables with the desired values. We implement a prototype tool, called Algernon, and evaluate it on 20 popular open-source programs. Across all tested programs, Algernon outperforms QSYM, Angora, AFL++, and INVSCOV in terms of both code coverage and vulnerability discovery, demonstrating the effectiveness of our approach. During our experiments, Algernon successfully found 30 zero-day vulnerabilities with 11 CVE IDs assigned.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Algernon: A Flag-Guided Hybrid Fuzzer for Unlocking Hidden Program Paths 1758853391331 10.1109/ASE63991.2025.00253 Peng Deng Fudan University, China pdeng21@m.fudan.edu.cn Lei Zhang Fudan University, China zxl@fudan.edu.cn Jingqi Long Fudan University, China jqlong20@fudan.edu.cn Wenzheng Hong Fudan University, China wzhong20@fudan.edu.cn Zhemin Yang Fudan University, China yangzhemin@fudan.edu.cn Yuan Zhang Fudan University, China yuanxzhang@fudan.edu.cn Donglai Zhu Fudan University, China zhudl@fudan.edu.cn Min Yang Fudan University, China m_yang@fudan.edu.cn hybrid fuzzing flag variable vulnerability Fuzz testing is a widely used method for finding security issues in software. However, certain code paths can only be explored under specific program states. Flag variables, which represent internal states, are crucial in influencing program behavior through flag-guarded branches. Unfortunately, existing fuzzing tools struggle to efficiently explore them due to the implicit data dependency between flag variables and the input. As a result, they commonly lack awareness of the dependency between program input and the assignments of critical flag variables, leading to a blind or random approach to satisfy flag-checking constraints, which greatly impacts the fuzzing efficiency. To address this issue, this paper proposes a dynamic flag-guided hybrid fuzzing approach, which automates the identification of flag variables and provides guidance for fuzz testing. Specifically, we first design a pre-fuzzing program analysis to recognize flag variables and a novel data structure to present how flag variables guard code branches. Then, we propose a new constraint-solving approach by separating complex flag-checking constraints into a set of atomic ones and sequentially solving them by traversing our FDG to locate execution paths that could assign the flag variables with the desired values. We implement a prototype tool, called Algernon, and evaluate it on 20 popular open-source programs. Across all tested programs, Algernon outperforms QSYM, Angora, AFL++, and INVSCOV in terms of both code coverage and vulnerability discovery, demonstrating the effectiveness of our approach. During our experiments, Algernon successfully found 30 zero-day vulnerabilities with 11 CVE IDs assigned.",
							"pageNumber": 3082,
							"isPageNumberRoman": false
						},
						{
							"eid": "3Y217jnoYxLecfM4UNOSrO",
							"type": "authorPaper",
							"text": "Agents in the Sandbox: End-to-End Crash Bug Reproduction for Minecraft",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d094/573300d094.pdf",
							"extraLocations": [],
							"authorNames": "Eray Yapa\u011Fc\u0131 (Bilkent University, Turkey), Yavuz Alp Sencer \u00D6zt\u00FCrk (Bilkent University, Turkey), Eray T\u00FCz\u00FCn (Bilkent University, Turkey)",
							"abstract": "Reproducing game bugs, particularly crash bugs in continuously evolving games like Minecraft, is a notoriously manual, time-consuming, and challenging process to automate; insights from a key decision maker from Minecraft we interviewed confirm this, highlighting that a substantial portion of crash reports necessitate manual scenario reconstruction. Despite the success of LLM-driven bug reproduction in other software domains, games, with their complex interactive environments, remain largely unaddressed. This paper introduces BugCraft, a novel end-to-end framework designed to automate the reproduction of crash bugs in Minecraft directly from user-submitted bug reports, addressing the critical gap in automated game bug reproduction. BugCraft employs a two-stage approach: first, a Step Synthesizer leverages LLMs and Minecraft Wiki knowledge to transform bug reports into high-quality, structured steps to reproduce (S2R). Second, an Action Model, powered by a vision-based LLM agent and a custom macro API, executes these S2R steps within Minecraft to trigger the reported crash. To facilitate evaluation, we introduce BugCraft-Bench, a curated dataset of Minecraft crash bug reports. On BugCraft-Bench, our framework end-to-end reproduced 34.9% of crash bugs with GPT-4.1, outperforming baseline computer-use models by 37%. BugCraft demonstrates the feasibility of automated reproduction of crash bugs in complex game environments using LLMs, opening promising avenues for game testing and development. Finally, we make our code open at https://bugcraft2025.github.io .",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Agents in the Sandbox: End-to-End Crash Bug Reproduction for Minecraft 1759496316050 10.1109/ASE63991.2025.00254 Eray Yapa\u011Fc\u0131 Bilkent University, Turkey eray.yapagci@bilkent.edu.tr Yavuz Alp Sencer \u00D6zt\u00FCrk Bilkent University, Turkey alp.ozturk@ug.bilkent.edu.tr Eray T\u00FCz\u00FCn Bilkent University, Turkey eraytuzun@cs.bilkent.edu.tr automated bug reproduction vision-based agent large language model crash bugs minecraft bug tracking Reproducing game bugs, particularly crash bugs in continuously evolving games like Minecraft, is a notoriously manual, time-consuming, and challenging process to automate; insights from a key decision maker from Minecraft we interviewed confirm this, highlighting that a substantial portion of crash reports necessitate manual scenario reconstruction. Despite the success of LLM-driven bug reproduction in other software domains, games, with their complex interactive environments, remain largely unaddressed. This paper introduces BugCraft, a novel end-to-end framework designed to automate the reproduction of crash bugs in Minecraft directly from user-submitted bug reports, addressing the critical gap in automated game bug reproduction. BugCraft employs a two-stage approach: first, a Step Synthesizer leverages LLMs and Minecraft Wiki knowledge to transform bug reports into high-quality, structured steps to reproduce (S2R). Second, an Action Model, powered by a vision-based LLM agent and a custom macro API, executes these S2R steps within Minecraft to trigger the reported crash. To facilitate evaluation, we introduce BugCraft-Bench, a curated dataset of Minecraft crash bug reports. On BugCraft-Bench, our framework end-to-end reproduced 34.9% of crash bugs with GPT-4.1, outperforming baseline computer-use models by 37%. BugCraft demonstrates the feasibility of automated reproduction of crash bugs in complex game environments using LLMs, opening promising avenues for game testing and development. Finally, we make our code open at https://bugcraft2025.github.io .",
							"pageNumber": 3094,
							"isPageNumberRoman": false
						},
						{
							"eid": "1ilao99bvtBiAc0yJCpkt4",
							"type": "authorPaper",
							"text": "LLM-Assisted Synthesis of High-Assurance C Programs",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d107/573300d107.pdf",
							"extraLocations": [],
							"authorNames": "Prasita Mukherjee (Purdue University, USA), Minghai Lu (Purdue University, USA), Benjamin Delaware (Purdue University, USA)",
							"abstract": "We present SynVer \u2014 a novel, general purpose synthesizer for C programs equipped with machine-checked proofs of correctness using the Verified Software Toolchain. To do so, SynVer employs two Large Language Models (LLMs): the first generates candidate programs from user-provided specifications, and the second helps automatically construct formal proofs of their correctness in the Rocq proof assistant. To facilitate verification, SynVer places a set of syntactic restrictions on candidate programs that make them amenable to automated reasoning. SynVer uses a hybrid verification strategy that combines symbolic reasoning with LLM-powered proof generation to discharge proof obligations that the symbolic engine cannot handle on its own. We demonstrate the applicability of SynVer using a diverse set of benchmarks drawn from the program synthesis and verification literature.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 LLM-Assisted Synthesis of High-Assurance C Programs 1759496416677 10.1109/ASE63991.2025.00255 Prasita Mukherjee Purdue University, USA mukher39@purdue.edu Minghai Lu Purdue University, USA lu1074@purdue.edu Benjamin Delaware Purdue University, USA bendy@purdue.edu formal verification automatic programming large language models We present SynVer \u2014 a novel, general purpose synthesizer for C programs equipped with machine-checked proofs of correctness using the Verified Software Toolchain. To do so, SynVer employs two Large Language Models (LLMs): the first generates candidate programs from user-provided specifications, and the second helps automatically construct formal proofs of their correctness in the Rocq proof assistant. To facilitate verification, SynVer places a set of syntactic restrictions on candidate programs that make them amenable to automated reasoning. SynVer uses a hybrid verification strategy that combines symbolic reasoning with LLM-powered proof generation to discharge proof obligations that the symbolic engine cannot handle on its own. We demonstrate the applicability of SynVer using a diverse set of benchmarks drawn from the program synthesis and verification literature.",
							"pageNumber": 3107,
							"isPageNumberRoman": false
						}
					],
					"pageNumber": "",
					"isPageNumberRoman": false,
					"chair": null
				},
				{
					"class": "SD",
					"type": "SD_SESSION",
					"title": "Industry Showcase",
					"lineItems": [
						{
							"eid": "1WWcGJx8scQw4UvANlhhP2",
							"type": "authorPaper",
							"text": "How Can Infrastructure as Code Accelerate Data Center Bring-ups? A Case Study at ByteDance",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d120/573300d120.pdf",
							"extraLocations": [],
							"authorNames": "Xianhao Jin (ByteDance Ltd.), Yifei Feng (ByteDance Ltd.), Yufei Gao (ByteDance Ltd.), Yongning Hu (ByteDance Ltd.), Jie Huang (ByteDance Ltd.), Kun Xia (ByteDance Ltd.), Luchuan Guo (ByteDance Ltd.)",
							"abstract": "Software companies are establishing new data centers to enhance software performance with lower response times as well as meet security requirements for storing local user data. ByteDance also has a strong need to deploy its services to new data centers worldwide quickly and with minimal error. Unfortunately, this process can also be time-consuming and errorprone, e.g., services often have dependencies on one another, requiring a strict deployment execution order. Moreover, the high similarity between resources in the new and the old data centers enables minimal modifications and maximizes the reuse of existing infrastructure configurations while providing the ability of global resource management. Additionally, manual migration across data centers often requires multiple confirmation checkpoints, which can significantly slow down the process. Therefore, to accelerate the new data center bring-ups, we adopt the idea of Infrastructure as code (IaC) which is a practice to automatically configure system dependencies and to provision local and remote instances [41]. In this work, we propose ByteRollout, an automatic intent-based software resource deployment system that is able to take customized infrastructure configurations as input and actuate deployments accordingly. We also assess ByteRollout in the following events of new data centers creations driven by site reliability engineering (SRE) teams. The evaluation results demonstrate that ByteRollout significantly accelerates the data center bring-up process, saving months of human effort and reducing costs by millions of USD simultaneously. The results also highlight that the Infrastructure as Code practice can be leveraged in the context of data center setups, offering benefits such as reduced process time and minimized errors throughout the deployment.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 How Can Infrastructure as Code Accelerate Data Center Bring-ups? A Case Study at ByteDance 1759166183875 10.1109/ASE63991.2025.00256 Xianhao Jin ByteDance Ltd. xianhao.jin@bytedance.com Yifei Feng ByteDance Ltd. yifei.feng@bytedance.com Yufei Gao ByteDance Ltd. yufei.gao@bytedance.com Yongning Hu ByteDance Ltd. yongning.hu@bytedance.com Jie Huang ByteDance Ltd. jie.huang@bytedance.com Kun Xia ByteDance Ltd. kun.xia@bytedance.com Luchuan Guo ByteDance Ltd. luchuanguo@bytedance.com infrastructure as code heterogeneous data centers software maintenance empirical software engineering Software companies are establishing new data centers to enhance software performance with lower response times as well as meet security requirements for storing local user data. ByteDance also has a strong need to deploy its services to new data centers worldwide quickly and with minimal error. Unfortunately, this process can also be time-consuming and errorprone, e.g., services often have dependencies on one another, requiring a strict deployment execution order. Moreover, the high similarity between resources in the new and the old data centers enables minimal modifications and maximizes the reuse of existing infrastructure configurations while providing the ability of global resource management. Additionally, manual migration across data centers often requires multiple confirmation checkpoints, which can significantly slow down the process. Therefore, to accelerate the new data center bring-ups, we adopt the idea of Infrastructure as code (IaC) which is a practice to automatically configure system dependencies and to provision local and remote instances [41]. In this work, we propose ByteRollout, an automatic intent-based software resource deployment system that is able to take customized infrastructure configurations as input and actuate deployments accordingly. We also assess ByteRollout in the following events of new data centers creations driven by site reliability engineering (SRE) teams. The evaluation results demonstrate that ByteRollout significantly accelerates the data center bring-up process, saving months of human effort and reducing costs by millions of USD simultaneously. The results also highlight that the Infrastructure as Code practice can be leveraged in the context of data center setups, offering benefits such as reduced process time and minimized errors throughout the deployment.",
							"pageNumber": 3120,
							"isPageNumberRoman": false
						},
						{
							"eid": "pVdmTnnwN350xMzxAqYUh",
							"type": "authorPaper",
							"text": "JSidentify-V2: Leveraging Dynamic Memory Fingerprinting for Mini-Game Plagiarism Detection",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d132/573300d132.pdf",
							"extraLocations": [],
							"authorNames": "Zhihao Li (Tencent Inc., China), Chaozheng  Wang (Tencent Inc., China; The Chinese University of Hong Kong, China), Zongjie Li (The Hong Kong University of Science and Technology, China), Xinyong  Peng (Tencent Inc., China), Qun  Xia (Tencent Inc., China), Haochuan  Lu (Tencent Inc., China), Ting  Xiong (Tencent Inc., China), Shuzheng  Gao (The Chinese University of Hong Kong, China), Cuiyun  Gao (The Chinese University of Hong Kong, China), Shuai  Wang (The Hong Kong University of Science and Technology, China), Yuetang  Deng (Tencent Inc., China), Huafeng  Ma (Tencent Inc., China)",
							"abstract": "The explosive growth of mini-game platforms has led to widespread code plagiarism, where malicious users access popular games' source code and republish them with modifications. While existing static analysis tools can detect simple obfuscation techniques like variable renaming and dead code injection, they fail against sophisticated deep obfuscation methods such as encrypted code with local or cloud-based decryption keys that completely destroy code structure and render traditional Abstract Syntax Tree analysis ineffective. To address these challenges, we present JSidentify-V2, a novel dynamic analysis framework that detects mini-game plagiarism by capturing memory invariants during program execution. Our key insight is that while obfuscation can severely distort static code characteristics, runtime memory behavior patterns remain relatively stable. JSidentify-V2 employs a four-stage pipeline: (1) static pre-analysis and instrumentation to identify potential memory invariants, (2) adaptive hot object slicing to maximize execution coverage of critical code segments, (3) Memory Dependency Graph construction to represent behavioral fingerprints resilient to obfuscation, and (4) graph-based similarity analysis for plagiarism detection. We evaluate JSidentify-V2 against eight obfuscation methods on a comprehensive dataset of 1,200 mini-games. Our framework achieves over 90% similarity detection across all tested obfuscation techniques, maintaining high accuracy even against advanced decryption-based methods where existing tools achieve near 0% detection rates. In real-world deployment, JSidentify-V2 achieves 100% precision and 99.8% recall while delivering an 8 times speedup compared to previous methods. Our production deployment demonstrates that plagiarism complaints have decreased by over 80%, proving JSidentify-V2's effectiveness in protecting intellectual property rights in mini-game ecosystems.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 JSidentify-V2: Leveraging Dynamic Memory Fingerprinting for Mini-Game Plagiarism Detection 1759064399418 10.1109/ASE63991.2025.00257 Zhihao Li Tencent Inc., China edgarlli@tencent.com Chaozheng Wang Tencent Inc., China; The Chinese University of Hong Kong, China adf111178@gmail.com Zongjie Li The Hong Kong University of Science and Technology, China zligo@cse.ust.hk Xinyong Peng Tencent Inc., China rayepeng@tencent.com Qun Xia Tencent Inc., China kelvinhhxia@tencent.com Haochuan Lu Tencent Inc., China hudsonhclu@tencent.com Ting Xiong Tencent Inc., China candyxiong@tencent.com Shuzheng Gao The Chinese University of Hong Kong, China szgao23@cse.cuhk.edu.hk Cuiyun Gao The Chinese University of Hong Kong, China cuiyungao@outlook.com Shuai Wang The Hong Kong University of Science and Technology, China shuaiw@cse.ust.hk Yuetang Deng Tencent Inc., China yuetangdeng@tencent.com Huafeng Ma Tencent Inc., China kenvinma@tencent.com mini-games javascript plagiarism detection The explosive growth of mini-game platforms has led to widespread code plagiarism, where malicious users access popular games' source code and republish them with modifications. While existing static analysis tools can detect simple obfuscation techniques like variable renaming and dead code injection, they fail against sophisticated deep obfuscation methods such as encrypted code with local or cloud-based decryption keys that completely destroy code structure and render traditional Abstract Syntax Tree analysis ineffective. To address these challenges, we present JSidentify-V2, a novel dynamic analysis framework that detects mini-game plagiarism by capturing memory invariants during program execution. Our key insight is that while obfuscation can severely distort static code characteristics, runtime memory behavior patterns remain relatively stable. JSidentify-V2 employs a four-stage pipeline: (1) static pre-analysis and instrumentation to identify potential memory invariants, (2) adaptive hot object slicing to maximize execution coverage of critical code segments, (3) Memory Dependency Graph construction to represent behavioral fingerprints resilient to obfuscation, and (4) graph-based similarity analysis for plagiarism detection. We evaluate JSidentify-V2 against eight obfuscation methods on a comprehensive dataset of 1,200 mini-games. Our framework achieves over 90% similarity detection across all tested obfuscation techniques, maintaining high accuracy even against advanced decryption-based methods where existing tools achieve near 0% detection rates. In real-world deployment, JSidentify-V2 achieves 100% precision and 99.8% recall while delivering an 8 times speedup compared to previous methods. Our production deployment demonstrates that plagiarism complaints have decreased by over 80%, proving JSidentify-V2's effectiveness in protecting intellectual property rights in mini-game ecosystems.",
							"pageNumber": 3132,
							"isPageNumberRoman": false
						},
						{
							"eid": "28Bw8aEkkLvexVccGlgXrd",
							"type": "authorPaper",
							"text": "Practical Escape of Exploration Tarpits for Mini-Game Testing in an Industrial Setting",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d144/573300d144.pdf",
							"extraLocations": [],
							"authorNames": "Yuan Cao (Peking University, China), Dezhi Ran (Peking University, China), Haochuan Lu (Tencent Inc., China), Chao Guo (Tencent Inc., China), Xuran Hao (Peking University, China), Zhuoru Chen (Capital Normal University, China), Ting Xiong (Tencent Inc., China), Yuetang Deng (Tencent Inc., China), Tao Xie (Peking University, China)",
							"abstract": "Attracting over one billion registered users globally, WeChat's mini-game platform has become one of the largest gaming platforms with hundreds of thousands of published mini-games. To ensure the quality of experiences across a massive number of mini-games, automated UI testing has become essential for WeChat. However, sliding-gesture-induced exploration tarpits, states where a testing tool becomes trapped in repetitive, unsuccessful gesture attempts, cause the testing tool to waste up to 98% of its testing budget due to its inability to execute proper sliding gestures. While mini-games typically contain visual hints (e.g., sliding indicators) guiding the desired sliding gestures, exploiting these hints to escape exploration tarpits faces two major challenges in industrial settings: (1) robustness challenge when exploiting hints from only several discontinuous screenshots, and (2) efficiency challenge to support thousands of concurrent testing services with minimal overhead and costs. To address the preceding challenges, we report our experiences in developing and deploying SlideScout, a three-stage approach for detecting and escaping sliding-gesture-induced exploration tarpits via efficient exploitation of visual hints. First, SlideScout concurrently monitors the testing progress and detects sliding indicators alongside screenshot collection, improving efficiency by reusing preprocessed results in subsequent stages. Second, SlideScout reconstructs potential sliding trajectories using multiple heuristics, addressing robustness challenges when precise trajectories are unavailable due to discontinuous screenshots. Third, SlideScout applies the inferred sliding gestures until it successfully escapes the tarpit, enabling easy integration with existing testing tools. Deployed at WeChat internally for six months, SlideScout has helped reveal 25,000 crashes and 120,000 JavaScript errors, detecting 50% more crashes compared to the pre-deployment baseline within the same time period. We summarize three major lessons learned from developing and deploying SlideScout.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Practical Escape of Exploration Tarpits for Mini-Game Testing in an Industrial Setting 1759371368331 10.1109/ASE63991.2025.00258 Yuan Cao Peking University, China cao_yuan21@stu.pku.edu.cn Dezhi Ran Peking University, China dezhiran@pku.edu.cn Haochuan Lu Tencent Inc., China hudsonhclu@tencent.com Chao Guo Tencent Inc., China willliamguo@tencent.com Xuran Hao Peking University, China hxr12138@stu.pku.edu.cn Zhuoru Chen Capital Normal University, China zdhwydtkr@gmail.com Ting Xiong Tencent Inc., China candyxiong@tencent.com Yuetang Deng Tencent Inc., China yuetangdeng@tencent.com Tao Xie Peking University, China taoxie@pku.edu.cn gui testing mini-apps game testing visual testing image processing object tracking exploration tarpits Attracting over one billion registered users globally, WeChat's mini-game platform has become one of the largest gaming platforms with hundreds of thousands of published mini-games. To ensure the quality of experiences across a massive number of mini-games, automated UI testing has become essential for WeChat. However, sliding-gesture-induced exploration tarpits, states where a testing tool becomes trapped in repetitive, unsuccessful gesture attempts, cause the testing tool to waste up to 98% of its testing budget due to its inability to execute proper sliding gestures. While mini-games typically contain visual hints (e.g., sliding indicators) guiding the desired sliding gestures, exploiting these hints to escape exploration tarpits faces two major challenges in industrial settings: (1) robustness challenge when exploiting hints from only several discontinuous screenshots, and (2) efficiency challenge to support thousands of concurrent testing services with minimal overhead and costs. To address the preceding challenges, we report our experiences in developing and deploying SlideScout, a three-stage approach for detecting and escaping sliding-gesture-induced exploration tarpits via efficient exploitation of visual hints. First, SlideScout concurrently monitors the testing progress and detects sliding indicators alongside screenshot collection, improving efficiency by reusing preprocessed results in subsequent stages. Second, SlideScout reconstructs potential sliding trajectories using multiple heuristics, addressing robustness challenges when precise trajectories are unavailable due to discontinuous screenshots. Third, SlideScout applies the inferred sliding gestures until it successfully escapes the tarpit, enabling easy integration with existing testing tools. Deployed at WeChat internally for six months, SlideScout has helped reveal 25,000 crashes and 120,000 JavaScript errors, detecting 50% more crashes compared to the pre-deployment baseline within the same time period. We summarize three major lessons learned from developing and deploying SlideScout.",
							"pageNumber": 3144,
							"isPageNumberRoman": false
						},
						{
							"eid": "3clMCvcskVG587AVzseSu4",
							"type": "authorPaper",
							"text": "Industry Practice of LLM-Assisted Protocol Fuzzing for Commercial Communication Modules",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d156/573300d156.pdf",
							"extraLocations": [],
							"authorNames": "Qiang Fu (Central South University, China; China Mobile IoT Co., Ltd, China), Changjian Liu (Central South University, China), Yuan Ding (China Mobile IoT Co., Ltd, China), Chao Fan (China Mobile IoT Co., Ltd, China), Yulai Fu (Central South University, China), Yuhan Chen (Central South University, China), Ying Fu (National University of Defense Technology, China), Ronghua Shi (Central South University, China), Fuchen Ma (Tsinghua University, China; Shuimu Yulin Technology Co., Ltd, China), Heyuan Shi (Central South University, China)",
							"abstract": "Fuzzing is widely used for software robustness testing. However, its application in commercial communication modules remains limited due to several key challenges, including labor-intensive template generation, lack of coverage collection support, limited testing performance, and inconsistencies between practical hardware and software CI/CD processes. In collaboration with China Mobile IoT, we present FuzzCM, a comprehensive protocol fuzzing framework tailored for commercial communication modules. FuzzCM employs a Retrieval-Augmented Generation (RAG)-enhanced large language model (LLM) to automate template generation and utilizes GPIO-based instrumentation for efficient runtime coverage data collection. Additionally, it leverages a knowledge base constructed from prior tests to guide hybrid mutation strategies and integrates CI/CD across both software and hardware layers, enabling continuous and environment-aware testing. We conducted industrial practice with FuzzCM on five LTE Cat.1 bis modules, identifying 21 previously unknown bugs, 15 of which have been fixed. The results demonstrate that FuzzCM outperforms both manual methods and the Peach* approach, achieving average coverage improvements of 51% and 29%, respectively, with overall coverage reaching 85%.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Industry Practice of LLM-Assisted Protocol Fuzzing for Commercial Communication Modules 1759320052806 10.1109/ASE63991.2025.00260 Qiang Fu Central South University, China; China Mobile IoT Co., Ltd, China fuqiang@cmiot.chinamobile.com Changjian Liu Central South University, China LiuChangJian@csu.edu.cn Yuan Ding China Mobile IoT Co., Ltd, China dingyuan@cmiot.chinamobile.com Chao Fan China Mobile IoT Co., Ltd, China fanchao@cmiot.chinamobile.com Yulai Fu Central South University, China fuyulai@csu.edu.cn Yuhan Chen Central South University, China Chenyuhan@csu.edu.cn Ying Fu National University of Defense Technology, China fuying1995@foxmail.com Ronghua Shi Central South University, China shirh@csu.edu.cn Fuchen Ma Tsinghua University, China; Shuimu Yulin Technology Co., Ltd, China fuchenma525@gmail.com Heyuan Shi Central South University, China shiheyuan@csu.edu.cn protocol fuzzing communication module large language model Fuzzing is widely used for software robustness testing. However, its application in commercial communication modules remains limited due to several key challenges, including labor-intensive template generation, lack of coverage collection support, limited testing performance, and inconsistencies between practical hardware and software CI/CD processes. In collaboration with China Mobile IoT, we present FuzzCM, a comprehensive protocol fuzzing framework tailored for commercial communication modules. FuzzCM employs a Retrieval-Augmented Generation (RAG)-enhanced large language model (LLM) to automate template generation and utilizes GPIO-based instrumentation for efficient runtime coverage data collection. Additionally, it leverages a knowledge base constructed from prior tests to guide hybrid mutation strategies and integrates CI/CD across both software and hardware layers, enabling continuous and environment-aware testing. We conducted industrial practice with FuzzCM on five LTE Cat.1 bis modules, identifying 21 previously unknown bugs, 15 of which have been fixed. The results demonstrate that FuzzCM outperforms both manual methods and the Peach* approach, achieving average coverage improvements of 51% and 29%, respectively, with overall coverage reaching 85%.",
							"pageNumber": 3156,
							"isPageNumberRoman": false
						},
						{
							"eid": "7oYVGqVhiZO5PV4QICBeop",
							"type": "authorPaper",
							"text": "HarmoBridge: Bridging ArkTS and C/C++ for Cross-Language Static Analysis on HarmonyOS",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d167/573300d167.pdf",
							"extraLocations": [],
							"authorNames": "Jiale Wu (Huazhong University of Science and Technology, China), Jiapeng Deng (Huazhong University of Science and Technology, China), Yanjie Zhao (Huazhong University of Science and Technology, China), Li Li (Beihang University, China), Haoyu Wang (Beihang University, China)",
							"abstract": "HarmonyOS is Huawei's distributed operating system designed for diverse smart devices, featuring ArkTS as its primary app development language. To enhance performance and leverage existing libraries, HarmonyOS apps can integrate native C/C++ modules through its Native Development Kit (NDK) mechanism. This creates significant challenges for static analysis, as critical data flows spanning ArkTS and native C/C++ boundaries remain invisible to existing single-language analyzers. Therefore, we present HarmoBridge, the first cross-language static analysis system for HarmonyOS that bridges this gap through novel summary based SumIR abstraction and seamless ecosystem integration. Our approach extracts dataflow summaries from native code (supporting both binary and source code analysis) and translates these summaries into intermediate representations that integrate seamlessly with the existing HarmonyOS analysis infrastructure. HarmoBridge introduces SumIR, a specialized intermediate representation that captures Node-API interaction semantics and converts them to ArkIR-compatible function bodies for downstream analysis tools. Also, we develop CrossFlowBench, a comprehensive benchmark covering representative Node-API interaction patterns, and identify potential security implications where established cross-language attack patterns widely prevalent in mobile ecosystems could adapt to HarmonyOS's architecture. Results demonstrate that HarmoBridge achieves 81.0% accuracy in recovering cross-language data flows on CrossFlowBench, significantly outperforming baseline approaches that treat native calls as opaque operations, establishing a foundation for comprehensive cross-language analysis in the emerging HarmonyOS ecosystem. ",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 HarmoBridge: Bridging ArkTS and C/C++ for Cross-Language Static Analysis on HarmonyOS 1759396585262 10.1109/ASE63991.2025.00261 Jiale Wu Huazhong University of Science and Technology, China jialewu@hust.edu.cn Jiapeng Deng Huazhong University of Science and Technology, China jiapeng@hust.edu.cn Yanjie Zhao Huazhong University of Science and Technology, China yanjie_zhao@hust.edu.cn Li Li Beihang University, China lilicoding@ieee.org Haoyu Wang Beihang University, China haoyuwang@hust.edu.cn harmonyos static analysis mobile security HarmonyOS is Huawei's distributed operating system designed for diverse smart devices, featuring ArkTS as its primary app development language. To enhance performance and leverage existing libraries, HarmonyOS apps can integrate native C/C++ modules through its Native Development Kit (NDK) mechanism. This creates significant challenges for static analysis, as critical data flows spanning ArkTS and native C/C++ boundaries remain invisible to existing single-language analyzers. Therefore, we present HarmoBridge, the first cross-language static analysis system for HarmonyOS that bridges this gap through novel summary based SumIR abstraction and seamless ecosystem integration. Our approach extracts dataflow summaries from native code (supporting both binary and source code analysis) and translates these summaries into intermediate representations that integrate seamlessly with the existing HarmonyOS analysis infrastructure. HarmoBridge introduces SumIR, a specialized intermediate representation that captures Node-API interaction semantics and converts them to ArkIR-compatible function bodies for downstream analysis tools. Also, we develop CrossFlowBench, a comprehensive benchmark covering representative Node-API interaction patterns, and identify potential security implications where established cross-language attack patterns widely prevalent in mobile ecosystems could adapt to HarmonyOS's architecture. Results demonstrate that HarmoBridge achieves 81.0% accuracy in recovering cross-language data flows on CrossFlowBench, significantly outperforming baseline approaches that treat native calls as opaque operations, establishing a foundation for comprehensive cross-language analysis in the emerging HarmonyOS ecosystem.",
							"pageNumber": 3167,
							"isPageNumberRoman": false
						},
						{
							"eid": "AYMi2HFwhc1mzJIIN7E2m",
							"type": "authorPaper",
							"text": "ApkArmor: Low-Cost Lightweight Anti-Decompilation Techniques for Android Apps",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d179/573300d179.pdf",
							"extraLocations": [],
							"authorNames": "Jiayang Liu (Huazhong University of Science and Technology, China), Yanjie Zhao (Huazhong University of Science and Technology, China), Pengcheng Xia (Huazhong University of Science and Technology, China), Haoyu Wang (Huazhong University of Science and Technology, China)",
							"abstract": "Android app security is a critical concern for the software industry, with companies investing significantly in protecting their intellectual property from reverse engineering attacks. While commercial protection tools exist to prevent decompilation and unauthorized code access, they pose substantial challenges for businesses: high licensing costs ranging from thousands to tens of thousands of dollars annually, significant performance overhead that impacts user experience and app ratings, and increased app size that affects download rates. These limitations particularly burden small to medium-sized enterprises and independent developers, creating an urgent industry need for cost-effective protection solutions. To address these challenges, we propose a novel file format-based anti-decompilation strategy that systematically exploits structural vulnerabilities in APK files. Building upon this strategy, we have developed ApkArmor, a lightweight and cost-effective anti-decompilation framework that exploits inherent vulnerabilities in popular reverse engineering tools. Through systematic analysis, we first identified critical weaknesses in common decompilation tools parsing mechanisms and structural assumptions. Based on these findings, we developed seven mutation-based protection strategies that deliberately trigger these vulnerabilities by introducing specific structural anomalies into APK files and the AndroidManifest.xml. These methods include Countermeasures against Dirty Code and Corrupted Payloads (CACoP), Pseudo-Encryption (PE), Using Unknown Compression Method (UUCM), Unavailable Magic Value (UMA), Modify the Offset Field in stringChunk (MOFS), and Dirty Bytecode Replacement of Android (DRA). We evaluated our exploitation strategies through extensive experiments on 100 randomly selected Android apps, testing against the latest versions of three widely used decompilation tools: JADX (v1.5.1), APKTool (v2.11.0), and Androguard (v4.1.2). Our results demonstrate that PE and DRA achieved complete protection by successfully exploiting vulnerabilities present in all tested tools. MOFS, UUCM, and UNV effectively exploited weaknesses in APKTool and Androguards parsing mechanisms.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 ApkArmor: Low-Cost Lightweight Anti-Decompilation Techniques for Android Apps 1759482943265 10.1109/ASE63991.2025.00262 Jiayang Liu Huazhong University of Science and Technology, China jiayangliu@hust.edu.cn Yanjie Zhao Huazhong University of Science and Technology, China yanjie_zhao@hust.edu.cn Pengcheng Xia Huazhong University of Science and Technology, China xpc357@hust.edu.cn Haoyu Wang Huazhong University of Science and Technology, China haoyuwang@hust.edu.cn Android app security is a critical concern for the software industry, with companies investing significantly in protecting their intellectual property from reverse engineering attacks. While commercial protection tools exist to prevent decompilation and unauthorized code access, they pose substantial challenges for businesses: high licensing costs ranging from thousands to tens of thousands of dollars annually, significant performance overhead that impacts user experience and app ratings, and increased app size that affects download rates. These limitations particularly burden small to medium-sized enterprises and independent developers, creating an urgent industry need for cost-effective protection solutions. To address these challenges, we propose a novel file format-based anti-decompilation strategy that systematically exploits structural vulnerabilities in APK files. Building upon this strategy, we have developed ApkArmor, a lightweight and cost-effective anti-decompilation framework that exploits inherent vulnerabilities in popular reverse engineering tools. Through systematic analysis, we first identified critical weaknesses in common decompilation tools parsing mechanisms and structural assumptions. Based on these findings, we developed seven mutation-based protection strategies that deliberately trigger these vulnerabilities by introducing specific structural anomalies into APK files and the AndroidManifest.xml. These methods include Countermeasures against Dirty Code and Corrupted Payloads (CACoP), Pseudo-Encryption (PE), Using Unknown Compression Method (UUCM), Unavailable Magic Value (UMA), Modify the Offset Field in stringChunk (MOFS), and Dirty Bytecode Replacement of Android (DRA). We evaluated our exploitation strategies through extensive experiments on 100 randomly selected Android apps, testing against the latest versions of three widely used decompilation tools: JADX (v1.5.1), APKTool (v2.11.0), and Androguard (v4.1.2). Our results demonstrate that PE and DRA achieved complete protection by successfully exploiting vulnerabilities present in all tested tools. MOFS, UUCM, and UNV effectively exploited weaknesses in APKTool and Androguards parsing mechanisms.",
							"pageNumber": 3179,
							"isPageNumberRoman": false
						},
						{
							"eid": "5aSYNpswO6ffjxXZL7dKup",
							"type": "authorPaper",
							"text": "KAIOps: A Platform Solution of End-to-End Multi-Modal AIOps for AI Training at Scale",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d191/573300d191.pdf",
							"extraLocations": [],
							"authorNames": "Zeying Wang (Beihang University), Junhong Liu (Beihang University), Penghao Zhang (Kuaishou Inc.), Xiaoyang Sun (University of Leeds; Kuaishou Inc.), Xu Wang (Beihang University), Tianyu Wo (Beihang University), Chunming Hu (Beihang University), Chengru Song (Kuaishou Inc.), Jin Ouyang (Kuaishou Inc.), Renyu Yang (Beihang University)",
							"abstract": "The resilience and reliability of large-scale AI training platforms are fundamental to enabling contemporary AI innovation and business development. However, with the rapid increase in the scale and complexity of AI model training tasks, anomalies become the norm rather than the exception at scale. Failing to handle them properly may lead to enormous resource waste and prolonged development cycles. Traditional anomaly detection methods struggle to tackle the complex temporal characteristics and extreme class imbalance inherently manifesting in training tasks, and fall short in automated solution to root cause analysis and the follow-up remediation. This paper proposes KAIOps, an end-to-end automated platform solution for anomaly handling in large-scale AI training clusters, and details its implementation for improving AIOps in daily operational maintenance at Kuaishou. KAIOps employs a Temporal Context Encoding mechanism to precisely capture and encode long-term trends and critical temporal context information within fault evolution. The detection model integrates a dynamic class-weighted loss function for enhancing the detection performance. KAIOps further advances these capabilities by integrating knowledge graph and large language model for automated root cause analysis and actionable solution generation, delivering a complete end-to-end intelligent processing pipeline. We conducted a systematic evaluation of KAIOps on the basis of data collected from Kuaishou's production-grade training clusters and the results show the competitive performance of the proposed approach. KAIOps has been deployed in Kuaishou, in both testbed and production grade environments, consisting of with over 10,000 GPUs, and accelerate the reliability assurance for industry-scale model training and serving.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 KAIOps: A Platform Solution of End-to-End Multi-Modal AIOps for AI Training at Scale 1759389482780 10.1109/ASE63991.2025.00263 Zeying Wang Beihang University wangzy0817@buaa.edu.cn Junhong Liu Beihang University junhongliu@buaa.edu.cn Penghao Zhang Kuaishou Inc. zhangpenghao03@kuaishou.com Xiaoyang Sun University of Leeds; Kuaishou Inc. X.Sun4@leeds.ac.uk Xu Wang Beihang University xuwang@buaa.edu.cn Tianyu Wo Beihang University woty@buaa.edu.cn Chunming Hu Beihang University hucm@buaa.edu.cn Chengru Song Kuaishou Inc. songchengru@kuaishou.com Jin Ouyang Kuaishou Inc. oyjmical@gmail.com Renyu Yang Beihang University renyuyang@buaa.edu.cn AI Training Task Anomaly Detection Root Cause Analysis The resilience and reliability of large-scale AI training platforms are fundamental to enabling contemporary AI innovation and business development. However, with the rapid increase in the scale and complexity of AI model training tasks, anomalies become the norm rather than the exception at scale. Failing to handle them properly may lead to enormous resource waste and prolonged development cycles. Traditional anomaly detection methods struggle to tackle the complex temporal characteristics and extreme class imbalance inherently manifesting in training tasks, and fall short in automated solution to root cause analysis and the follow-up remediation. This paper proposes KAIOps, an end-to-end automated platform solution for anomaly handling in large-scale AI training clusters, and details its implementation for improving AIOps in daily operational maintenance at Kuaishou. KAIOps employs a Temporal Context Encoding mechanism to precisely capture and encode long-term trends and critical temporal context information within fault evolution. The detection model integrates a dynamic class-weighted loss function for enhancing the detection performance. KAIOps further advances these capabilities by integrating knowledge graph and large language model for automated root cause analysis and actionable solution generation, delivering a complete end-to-end intelligent processing pipeline. We conducted a systematic evaluation of KAIOps on the basis of data collected from Kuaishou's production-grade training clusters and the results show the competitive performance of the proposed approach. KAIOps has been deployed in Kuaishou, in both testbed and production grade environments, consisting of with over 10,000 GPUs, and accelerate the reliability assurance for industry-scale model training and serving.",
							"pageNumber": 3191,
							"isPageNumberRoman": false
						},
						{
							"eid": "2XGxbHooDCdtM4kqbxskZX",
							"type": "authorPaper",
							"text": "iCodeReviewer: Improving Secure Code Review with Mixture of Prompts",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d203/573300d203.pdf",
							"extraLocations": [],
							"authorNames": "Yun Peng (Huawei Technologies, China), Kisub Kim (DGIST, Korea), Linghan Meng (Huawei Technologies, China), Kui Liu (Huawei Technologies, China)",
							"abstract": "Code review is an essential process to ensure the quality of software that identifies potential software issues at an early stage of software development. Among all software issues, security issues are the most important to identify, as they can easily lead to severe software crashes and service disruptions. Recent research efforts have been devoted to automated approaches to reduce the manual efforts required in the secure code review process. Despite the progress, current automated approaches on secure code review, including static analysis, deep learning models, and prompting approaches, still face the challenges of limited precision and coverage, and a lack of comprehensive evaluation. To mitigate these challenges, we propose iCodeReviewer, which is an automated secure code review approach based on large language models (LLMs). iCodeReviewer leverages a novel mixture-of-prompts architecture that incorporates many prompt experts to improve the coverage of security issues. Each prompt expert is a dynamic prompt pipeline to check the existence of a specific security issue. iCodeReviewer also implements an effective routing algorithm to activate only necessary prompt experts based on the code features in the input program, reducing the false positives induced by LLM hallucination. Experiment results in our internal dataset demonstrate the effectiveness of iCodeReviewer in security issue identification and localization with an F1 of 63.98%. The review comments generated by iCodeReviewer also achieve a high acceptance rate up to 84% when it is deployed in production environments. ",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 iCodeReviewer: Improving Secure Code Review with Mixture of Prompts 1759048402524 10.1109/ASE63991.2025.00264 Yun Peng Huawei Technologies, China yun.p@huawei.com Kisub Kim DGIST, Korea falconlk00@gmail.com Linghan Meng Huawei Technologies, China menglinghan2@huawei.com Kui Liu Huawei Technologies, China kui.liu@huawei.com code review mixture of prompts large language model security static analysis Code review is an essential process to ensure the quality of software that identifies potential software issues at an early stage of software development. Among all software issues, security issues are the most important to identify, as they can easily lead to severe software crashes and service disruptions. Recent research efforts have been devoted to automated approaches to reduce the manual efforts required in the secure code review process. Despite the progress, current automated approaches on secure code review, including static analysis, deep learning models, and prompting approaches, still face the challenges of limited precision and coverage, and a lack of comprehensive evaluation. To mitigate these challenges, we propose iCodeReviewer, which is an automated secure code review approach based on large language models (LLMs). iCodeReviewer leverages a novel mixture-of-prompts architecture that incorporates many prompt experts to improve the coverage of security issues. Each prompt expert is a dynamic prompt pipeline to check the existence of a specific security issue. iCodeReviewer also implements an effective routing algorithm to activate only necessary prompt experts based on the code features in the input program, reducing the false positives induced by LLM hallucination. Experiment results in our internal dataset demonstrate the effectiveness of iCodeReviewer in security issue identification and localization with an F1 of 63.98%. The review comments generated by iCodeReviewer also achieve a high acceptance rate up to 84% when it is deployed in production environments.",
							"pageNumber": 3203,
							"isPageNumberRoman": false
						},
						{
							"eid": "3skl4hySZHyYDb96k92COJ",
							"type": "authorPaper",
							"text": "Should We Evaluate LLM Based Security Analysis Approaches on Open Source Systems?",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d215/573300d215.pdf",
							"extraLocations": [],
							"authorNames": "Kohei Dozono (Technical University of Munich, Germany), Jonas Engesser (Technical University of Munich, Germany), Benjamin Hummel (CQSE GmbH, Germany), Tobias Roehm (CQSE GmbH, Germany), Alexander Pretschner (Technical University of Munich, Germany)",
							"abstract": "Existing research has demonstrated promising results when applying large language models (LLMs) to detect security vulnerabilities in source code. However, these studies have been exclusively evaluated on benchmarks from open-source systems, using publicly known vulnerabilities that are likely part of the LLMs' training data. This raises concerns that reported performance metrics may be inflated due to data contamination, providing a misleading view of the models' actual capabilities. In this paper, we quantify this effect with a case study that evaluates five frontier LLMs on two carefully curated datasets: CWE-Bench-Java (an open-source dataset) and TS-Vuls (based on a closed-source commercial codebase). To provide a second angle, we also split CWE-Bench-Java by CVE record date to explore temporal contamination based on LLM knowledge cutoff dates. Our results reveal that the average F1 score dropped by approximately 20 percentage points when comparing the open-source to the closed-source dataset. Additionally, the precision drops from 56% to 34% on average, which is statistically significant (p < 0.05) for four of five models. This declining trend is consistent across all tested LLMs and metrics. In contrast, the results for the temporal split on the open-source data are inconclusive, suggesting that using a knowledge cutoff may reduce but does not ensure the elimination of contamination effects. Although our study is based on a single closed-source system and thus not generalizable, these findings provide the first empirical evidence that evaluating LLM-based vulnerability detection on open-source benchmarks may lead to overly optimistic results. This motivates the inclusion of closed-source datasets in future LLM evaluations.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Should We Evaluate LLM Based Security Analysis Approaches on Open Source Systems? 1759312946051 10.1109/ASE63991.2025.00265 Kohei Dozono Technical University of Munich, Germany kohei.dozono@tum.de Jonas Engesser Technical University of Munich, Germany jonas.engesser@tum.de Benjamin Hummel CQSE GmbH, Germany hummel@cqse.eu Tobias Roehm CQSE GmbH, Germany roehm@cqse.eu Alexander Pretschner Technical University of Munich, Germany alexander.pretschner@tum.de security large language models data contamination static application security testing security vulnerabilities Existing research has demonstrated promising results when applying large language models (LLMs) to detect security vulnerabilities in source code. However, these studies have been exclusively evaluated on benchmarks from open-source systems, using publicly known vulnerabilities that are likely part of the LLMs' training data. This raises concerns that reported performance metrics may be inflated due to data contamination, providing a misleading view of the models' actual capabilities. In this paper, we quantify this effect with a case study that evaluates five frontier LLMs on two carefully curated datasets: CWE-Bench-Java (an open-source dataset) and TS-Vuls (based on a closed-source commercial codebase). To provide a second angle, we also split CWE-Bench-Java by CVE record date to explore temporal contamination based on LLM knowledge cutoff dates. Our results reveal that the average F1 score dropped by approximately 20 percentage points when comparing the open-source to the closed-source dataset. Additionally, the precision drops from 56% to 34% on average, which is statistically significant (p < 0.05) for four of five models. This declining trend is consistent across all tested LLMs and metrics. In contrast, the results for the temporal split on the open-source data are inconclusive, suggesting that using a knowledge cutoff may reduce but does not ensure the elimination of contamination effects. Although our study is based on a single closed-source system and thus not generalizable, these findings provide the first empirical evidence that evaluating LLM-based vulnerability detection on open-source benchmarks may lead to overly optimistic results. This motivates the inclusion of closed-source datasets in future LLM evaluations.",
							"pageNumber": 3215,
							"isPageNumberRoman": false
						},
						{
							"eid": "5uESOWmcVSjsJU1YKizcsS",
							"type": "authorPaper",
							"text": "TRON: Fuzzing Linux Network Stack via Protocol-System Call Payload Synthesis",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d226/573300d226.pdf",
							"extraLocations": [],
							"authorNames": "Qiang Zhang (Hunan University, China), Yifei Chu (Tsinghua University, China), Yuheng Shen (Tsinghua University, China), Jianzhong Liu (Shandong University, China), Heyuan Shi (Central South University, China), Yu Jiang (Tsinghua University, China), Wanli Chang (Hunan University, China)",
							"abstract": "The Linux kernel network stack is a critical component of modern operating systems, widely deployed across platforms and often exposed to untrusted inputs. Its complex and stateful nature makes it a frequent target of security vulnerabilities, particularly those triggered by subtle protocol interactions. While existing fuzzers like syzkaller have demonstrated strong capabilities in discovering kernel bugs, they face challenges in exercising deep protocol logic due to the lack of coordinated inputs and protocol awareness. In this paper, we present TRON, a tool designed for fuzzing the Linux kernel network stack. By synthesizing syscall\u2013packet input sequences based on protocol structure and incorporating runtime feedback, TRON enables the exploration of protocol-dependent state transitions and deep execution paths. Our approach addresses the fundamental challenges in dual-input fuzzing by integrating protocol knowledge with execution feedback. We evaluate TRON on four recent Linux kernel versions and compare it against syzkaller and kernelGPT. The results show that TRON improves branch coverage by 22.9% and 12.1% over syzkaller and kernelGPT, respectively, and discovers 25 previously unknown bugs, 7 of which have been fixed. These results demonstrate the effectiveness of protocol\u2013system call input synthesis in enhancing network stack fuzzing and uncovering hard-to-reach bugs in kernel protocol implementations.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 TRON: Fuzzing Linux Network Stack via Protocol-System Call Payload Synthesis 1759504858391 10.1109/ASE63991.2025.00266 Qiang Zhang Hunan University, China zhangqiang9413@126.com Yifei Chu Tsinghua University, China chuyf24@mails.tsinghua.edu.cn Yuheng Shen Tsinghua University, China syh1308@gmail.com Jianzhong Liu Shandong University, China liujianzhong@sdu.edu.cn Heyuan Shi Central South University, China hey.shi@foxmail.com Yu Jiang Tsinghua University, China jiangyu198964@126.com Wanli Chang Hunan University, China wanli.chang.rts@gmail.com Vulnerability Detection Kernel Fuzzing Network Stack The Linux kernel network stack is a critical component of modern operating systems, widely deployed across platforms and often exposed to untrusted inputs. Its complex and stateful nature makes it a frequent target of security vulnerabilities, particularly those triggered by subtle protocol interactions. While existing fuzzers like syzkaller have demonstrated strong capabilities in discovering kernel bugs, they face challenges in exercising deep protocol logic due to the lack of coordinated inputs and protocol awareness. In this paper, we present TRON, a tool designed for fuzzing the Linux kernel network stack. By synthesizing syscall\u2013packet input sequences based on protocol structure and incorporating runtime feedback, TRON enables the exploration of protocol-dependent state transitions and deep execution paths. Our approach addresses the fundamental challenges in dual-input fuzzing by integrating protocol knowledge with execution feedback. We evaluate TRON on four recent Linux kernel versions and compare it against syzkaller and kernelGPT. The results show that TRON improves branch coverage by 22.9% and 12.1% over syzkaller and kernelGPT, respectively, and discovers 25 previously unknown bugs, 7 of which have been fixed. These results demonstrate the effectiveness of protocol\u2013system call input synthesis in enhancing network stack fuzzing and uncovering hard-to-reach bugs in kernel protocol implementations.",
							"pageNumber": 3226,
							"isPageNumberRoman": false
						},
						{
							"eid": "3vocP59f7kxqUikqiaEKCR",
							"type": "authorPaper",
							"text": "TrioXpert: An Automated Incident Management Framework for Microservice System",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d238/573300d238.pdf",
							"extraLocations": [],
							"authorNames": "Yongqian Sun (Nankai University, China; Tianjin Key Laboratory of Software Experience and Human Computer Interaction), Yu Luo (Nankai University), Xidao Wen (BizSeer), Yuan Yuan (National University of Defense Technology), Xiaohui Nie (Chinese Academy of Sciences), Shenglin Zhang (Nankai University; Key Laboratory of Data and Intelligent System Security, Ministry of Education, China), Tong Liu (Lenovo (TianJin) Co., Ltd.), Xi Luo (Lenovo (TianJin) Co., Ltd.)",
							"abstract": "Automated incident management plays a pivotal role in large-scale microservice systems. However, many existing methods rely solely on single-modal data (e.g., metrics, logs, and traces) and struggle to simultaneously address multiple downstream tasks, including anomaly detection (AD), failure triage (FT), and root cause localization (RCL). Moreover, the lack of clear reasoning evidence in current techniques often leads to insufficient interpretability. To address these limitations, we propose TrioXpert, an end-to-end incident management framework capable of fully leveraging multimodal data. TrioXpert designs three independent data processing pipelines based on the inherent characteristics of different modalities, comprehensively characterizing the operational status of microservice systems from both numerical and textual dimensions. It employs a collaborative reasoning mechanism using large language models (LLMs) to simultaneously handle multiple tasks while providing clear reasoning evidence to ensure strong interpretability. We conducted extensive evaluations on two microservice system datasets, and the experimental results demonstrate that TrioXpert achieves outstanding performance in AD (improving by 4.7% to 57.7%), FT (improving by 2.1% to 40.6%), and RCL (improving by 1.6% to 163.1%) tasks. TrioXpert has also been deployed in Lenovo's production environment, demonstrating substantial gains in diagnostic efficiency and accuracy.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 TrioXpert: An Automated Incident Management Framework for Microservice System 1759042344623 10.1109/ASE63991.2025.00267 Yongqian Sun Nankai University, China; Tianjin Key Laboratory of Software Experience and Human Computer Interaction sunyongqian@nankai.edu.cn Yu Luo Nankai University luoyu@mail.nankai.edu.cn Xidao Wen BizSeer wenxidao@bizseer.com Yuan Yuan National University of Defense Technology yuanyuan@nudt.edu.cn Xiaohui Nie Chinese Academy of Sciences xhnie@cnic.cn Shenglin Zhang Nankai University; Key Laboratory of Data and Intelligent System Security, Ministry of Education, China zhangsl@nankai.edu.cn Tong Liu Lenovo (TianJin) Co., Ltd. liutong14@lenovo.com Xi Luo Lenovo (TianJin) Co., Ltd. luoxi9@lenovo.com anomaly detections failure triage root cause localization microservice system Automated incident management plays a pivotal role in large-scale microservice systems. However, many existing methods rely solely on single-modal data (e.g., metrics, logs, and traces) and struggle to simultaneously address multiple downstream tasks, including anomaly detection (AD), failure triage (FT), and root cause localization (RCL). Moreover, the lack of clear reasoning evidence in current techniques often leads to insufficient interpretability. To address these limitations, we propose TrioXpert, an end-to-end incident management framework capable of fully leveraging multimodal data. TrioXpert designs three independent data processing pipelines based on the inherent characteristics of different modalities, comprehensively characterizing the operational status of microservice systems from both numerical and textual dimensions. It employs a collaborative reasoning mechanism using large language models (LLMs) to simultaneously handle multiple tasks while providing clear reasoning evidence to ensure strong interpretability. We conducted extensive evaluations on two microservice system datasets, and the experimental results demonstrate that TrioXpert achieves outstanding performance in AD (improving by 4.7% to 57.7%), FT (improving by 2.1% to 40.6%), and RCL (improving by 1.6% to 163.1%) tasks. TrioXpert has also been deployed in Lenovo's production environment, demonstrating substantial gains in diagnostic efficiency and accuracy.",
							"pageNumber": 3238,
							"isPageNumberRoman": false
						},
						{
							"eid": "TC6oZDlJVqanhUoRRsQNI",
							"type": "authorPaper",
							"text": "Metrics Driven Reengineering and Continuous Code Improvement at Meta",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d250/573300d250.pdf",
							"extraLocations": [],
							"authorNames": "Audris Mockus ( Meta Platforms, Inc.; The University of Tennessee, Knoxville), Peter C Rigby (Meta Platforms, Inc.; Concordia University, Montreal), Rui Abreu  (Meta Platforms, Inc.), Anatoly Akkerman (Meta Platforms, Inc.), Yogesh Bhootada (Meta Platforms, Inc.), Payal Bhuptani (Meta Platforms, Inc.), Gurnit Ghardhora (Meta Platforms, Inc.), Lan Hoang  Dao (Meta Platforms, Inc.), Chris Hawley  (Meta Platforms, Inc.), Renzhi  He (Meta Platforms, Inc.), Sagar Krishnamoorthy (Meta Platforms, Inc.), Sergei Krauze (Meta Platforms, Inc.), Jianmin Li (Meta Platforms, Inc.), Anton Lunov (Meta Platforms, Inc.), Dragos Martac  (Meta Platforms, Inc.), Francois Morin (Meta Platforms, Inc.), Neil Mitchell (Meta Platforms, Inc.), Venus Montes (Meta Platforms, Inc.), Maher Saba (Meta Platforms, Inc.), Matt Steiner (Meta Platforms, Inc.), Andrea Valori (Meta Platforms, Inc.), Shanchao Wang  (Meta Platforms, Inc.), Nachiappan Nagappan (Meta Platforms, Inc.)",
							"abstract": "The focus on rapid software delivery inevitably results in the accumulation of technical debt, which, in turn, affects quality and slows future development. Our primary aim is to discover how companies keep their codebases maintainable and how code improvements might be automated. Method: we investigate Meta's practices by collaborating with engineers on code quality (via action research) and by analyzing rich source code change history using mixed-methods to reveal a range of practices used for continual improvement of the codebase. Results: Code improvements at Meta range from completely organic grass-roots done at the initiative of individual engineers, to regularly blocked time and engagement via gamification of Better Engineering (BE) work, to major explicit initiatives aimed at reengineering the complex parts of the codebase or deleting acumulations of dead code. Over 14% of changes are explicitly devoted to code improvement and the developers are given badges to acknowledge the type of work and the amount of effort. Based on the interactions with development teams we suggest metrics to help prioritization of code improvement efforts. Finally, our models of the impact of reengineering activities revealed substantial improvements in quality and speed and reductions in code complexity. Overall, code improvement activities are relatively effort intensive yet simple enough to be prime targets for automation.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Metrics Driven Reengineering and Continuous Code Improvement at Meta 1759182163246 10.1109/ASE63991.2025.00268 Audris Mockus Meta Platforms, Inc.; The University of Tennessee, Knoxville audris@utk.edu Peter C Rigby Meta Platforms, Inc.; Concordia University, Montreal pcr@meta.com Rui Abreu Meta Platforms, Inc. ruiabre@meta.com Anatoly Akkerman Meta Platforms, Inc. azakkerman@meta.com Yogesh Bhootada Meta Platforms, Inc. yogeshb@meta.com Payal Bhuptani Meta Platforms, Inc. pbhuptani@meta.com Gurnit Ghardhora Meta Platforms, Inc. gurnit@meta.com Lan Hoang Dao Meta Platforms, Inc. landao97@meta.com Chris Hawley Meta Platforms, Inc. chawley@meta.com Renzhi He Meta Platforms, Inc. hrz@meta.com Sagar Krishnamoorthy Meta Platforms, Inc. vkrishnamoorthy@meta.com Sergei Krauze Meta Platforms, Inc. skrauze@meta.com Jianmin Li Meta Platforms, Inc. jianminli@meta.com Anton Lunov Meta Platforms, Inc. antonl@meta.com Dragos Martac Meta Platforms, Inc. dragosmartac@meta.com Francois Morin Meta Platforms, Inc. francoismorin@meta.com Neil Mitchell Meta Platforms, Inc. ndmitchell@meta.com Venus Montes Meta Platforms, Inc. vmd@meta.com Maher Saba Meta Platforms, Inc. mahersaba@meta.com Matt Steiner Meta Platforms, Inc. mattsteiner@meta.com Andrea Valori Meta Platforms, Inc. avalori@meta.com Shanchao Wang Meta Platforms, Inc. scwang@meta.com Nachiappan Nagappan Meta Platforms, Inc. nnachi@meta.com Refactoring dead code better engineering gamification The focus on rapid software delivery inevitably results in the accumulation of technical debt, which, in turn, affects quality and slows future development. Our primary aim is to discover how companies keep their codebases maintainable and how code improvements might be automated. Method: we investigate Meta's practices by collaborating with engineers on code quality (via action research) and by analyzing rich source code change history using mixed-methods to reveal a range of practices used for continual improvement of the codebase. Results: Code improvements at Meta range from completely organic grass-roots done at the initiative of individual engineers, to regularly blocked time and engagement via gamification of Better Engineering (BE) work, to major explicit initiatives aimed at reengineering the complex parts of the codebase or deleting acumulations of dead code. Over 14% of changes are explicitly devoted to code improvement and the developers are given badges to acknowledge the type of work and the amount of effort. Based on the interactions with development teams we suggest metrics to help prioritization of code improvement efforts. Finally, our models of the impact of reengineering activities revealed substantial improvements in quality and speed and reductions in code complexity. Overall, code improvement activities are relatively effort intensive yet simple enough to be prime targets for automation.",
							"pageNumber": 3250,
							"isPageNumberRoman": false
						},
						{
							"eid": "6OjgrizTk0hPuqMYXnEdx",
							"type": "authorPaper",
							"text": "Context-Sensitive Pointer Analysis for ArkTS",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d261/573300d261.pdf",
							"extraLocations": [],
							"authorNames": "Yizhuo Yang (Beihang University, China), Lingyun Xu (CBG Software Engineering Department, Huawei), Mingyi Zhou (Beihang University, China), Li Li (Beihang University, China)",
							"abstract": "Current call graph generation methods for ArkTS, a new programming language for OpenHarmony, exhibit precision limitations when supporting advanced static analysis tasks such as data flow analysis and vulnerability pattern detection, while the workflow of traditional JavaScript(JS)/TypeScript(TS) analysis tools fails to interpret ArkUI component tree semantics. The core technical bottleneck originates from the closure mechanisms inherent in TypeScript's dynamic language features and the interaction patterns involving OpenHarmony's framework APIs. Existing static analysis tools for ArkTS struggle to achieve effective tracking and precise deduction of object reference relationships, leading to topological fractures in call graph reachability and diminished analysis coverage. This technical limitation fundamentally constrains the implementation of advanced program analysis techniques. Therefore, in this paper, we propose a tool named ArkAnalyzer Pointer Analysis Kit (APAK), the first context-sensitive pointer analysis framework specifically designed for ArkTS. APAK addresses these challenges through a unique ArkTS heap object model and a highly extensible plugin architecture, ensuring future adaptability to the evolving OpenHarmony ecosystem. In the evaluation, we construct a dataset from 1,663 real-world applications in the OpenHarmony ecosystem to evaluate APAK, demonstrating APAK's superior performance over CHA/RTA approaches in critical metrics including valid edge coverage (e.g., a 7.1% reduction compared to CHA and a 34.2% increase over RTA). The improvement in edge coverage systematically reduces false positive rates from 20% to 2%, enabling future exploration of establishing more complex program analysis tools based on our framework. Our proposed APAK has been merged into the official static analysis framework ArkAnalyzer for OpenHarmony.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Context-Sensitive Pointer Analysis for ArkTS 1759298129804 10.1109/ASE63991.2025.00269 Yizhuo Yang Beihang University, China yangyizhuo@buaa.edu.cn Lingyun Xu CBG Software Engineering Department, Huawei xulingyun1@huawei.com Mingyi Zhou Beihang University, China zhoumingyi@buaa.edu.cn Li Li Beihang University, China lilicoding@ieee.org Current call graph generation methods for ArkTS, a new programming language for OpenHarmony, exhibit precision limitations when supporting advanced static analysis tasks such as data flow analysis and vulnerability pattern detection, while the workflow of traditional JavaScript(JS)/TypeScript(TS) analysis tools fails to interpret ArkUI component tree semantics. The core technical bottleneck originates from the closure mechanisms inherent in TypeScript's dynamic language features and the interaction patterns involving OpenHarmony's framework APIs. Existing static analysis tools for ArkTS struggle to achieve effective tracking and precise deduction of object reference relationships, leading to topological fractures in call graph reachability and diminished analysis coverage. This technical limitation fundamentally constrains the implementation of advanced program analysis techniques. Therefore, in this paper, we propose a tool named ArkAnalyzer Pointer Analysis Kit (APAK), the first context-sensitive pointer analysis framework specifically designed for ArkTS. APAK addresses these challenges through a unique ArkTS heap object model and a highly extensible plugin architecture, ensuring future adaptability to the evolving OpenHarmony ecosystem. In the evaluation, we construct a dataset from 1,663 real-world applications in the OpenHarmony ecosystem to evaluate APAK, demonstrating APAK's superior performance over CHA/RTA approaches in critical metrics including valid edge coverage (e.g., a 7.1% reduction compared to CHA and a 34.2% increase over RTA). The improvement in edge coverage systematically reduces false positive rates from 20% to 2%, enabling future exploration of establishing more complex program analysis tools based on our framework. Our proposed APAK has been merged into the official static analysis framework ArkAnalyzer for OpenHarmony.",
							"pageNumber": 3261,
							"isPageNumberRoman": false
						},
						{
							"eid": "551GPWhNLLNofla1qyOSJB",
							"type": "authorPaper",
							"text": "Minuku: Detecting Diverse Display Issues in Mobile Apps with Small-Scale Dataset",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d273/573300d273.pdf",
							"extraLocations": [],
							"authorNames": "Yongxiang Hu (Fudan University, China), Ke Liu (Fudan University, China), Hailiang Jin (Meituan, China), Shiyu Guo (Meituan, China), Juxing Yuan (Meituan, China), Xin Wang (Fudan University, China; Shanghai Key Laboratory of Intelligent Information Processing, China), Yangfan Zhou (Fudan University, China; Shanghai Key Laboratory of Intelligent Information Processing, China)",
							"abstract": "User interface (UI) display issues, such as widgets occlusion, missing elements, and screen overflow, are emerging as a non-negligible source of user complaints in commercial mobile apps. However, existing automated testing tools typically rely on a vast amount of high-quality training data, making them cost-ineffective for industrial practice. Given that display issues are intuitively recognizable by humans, their diverse appearances can be abstracted by the violation of human commonsense expectations of UI appearance. Therefore, this paper proposes to reduce data requirements in display issue detection through commonsense simulation. Although leveraging large vision-language models (VLMs) to replicate human visual ability looks straightforward, off-the-shelf VLMs lack task-specific knowledge of UI designs and display correctness. To address this, we fine-tune a VLM to learn what constitutes an expected display and to reason potential display issues. This approach is termed as Minuku, an industrial data-efficient UI display issue detector. We evaluate the design effectiveness of Minuku via a set of ablation experiments. Moreover, real-world deployments in one of the largest E-commerce app providers further demonstrate that Minuku can effectively detect 40 previously unknown UI display issues and significantly reduce manual effort in industrial settings.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Minuku: Detecting Diverse Display Issues in Mobile Apps with Small-Scale Dataset 1759390089083 10.1109/ASE63991.2025.00270 Yongxiang Hu Fudan University, China yongxianghu23@m.fudan.edu.cn Ke Liu Fudan University, China keliu24@m.fudan.edu.cn Hailiang Jin Meituan, China jinhailiang@meituan.com Shiyu Guo Meituan, China guoshiyu03@meituan.com Juxing Yuan Meituan, China yuanjuxing@meituan.com Xin Wang Fudan University, China; Shanghai Key Laboratory of Intelligent Information Processing, China xinw@fudan.edu.cn Yangfan Zhou Fudan University, China; Shanghai Key Laboratory of Intelligent Information Processing, China zyf@fudan.edu.cn ui testing display issue mobile apps User interface (UI) display issues, such as widgets occlusion, missing elements, and screen overflow, are emerging as a non-negligible source of user complaints in commercial mobile apps. However, existing automated testing tools typically rely on a vast amount of high-quality training data, making them cost-ineffective for industrial practice. Given that display issues are intuitively recognizable by humans, their diverse appearances can be abstracted by the violation of human commonsense expectations of UI appearance. Therefore, this paper proposes to reduce data requirements in display issue detection through commonsense simulation. Although leveraging large vision-language models (VLMs) to replicate human visual ability looks straightforward, off-the-shelf VLMs lack task-specific knowledge of UI designs and display correctness. To address this, we fine-tune a VLM to learn what constitutes an expected display and to reason potential display issues. This approach is termed as Minuku, an industrial data-efficient UI display issue detector. We evaluate the design effectiveness of Minuku via a set of ablation experiments. Moreover, real-world deployments in one of the largest E-commerce app providers further demonstrate that Minuku can effectively detect 40 previously unknown UI display issues and significantly reduce manual effort in industrial settings.",
							"pageNumber": 3273,
							"isPageNumberRoman": false
						},
						{
							"eid": "4XcSMFH9HDVViTRV7nuKkU",
							"type": "authorPaper",
							"text": "Context-Aware CodeLLM Eviction for AI-Assisted Coding",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d286/573300d286.pdf",
							"extraLocations": [],
							"authorNames": "Kishanthan Thangarajah (Centre for Software Excellence, Canada), Boyuan Chen (Centre for Software Excellence, Canada), Shi Chang (Western University, Canada), Ahmed E. Hassan (Queen's University, Canada)",
							"abstract": "AI-assisted coding tools powered by Code Large Language Models (CodeLLMs) are increasingly integrated into modern software development workflows. To address concerns around privacy, latency, and model customization, many enterprises opt to self-host these models. However, the diversity and growing number of CodeLLMs, coupled with limited accelerator memory, introduce practical challenges in model management and serving efficiency. This paper presents CACE, a novel context-aware model eviction strategy designed specifically to optimize self-hosted CodeLLM serving under resource constraints. Unlike traditional eviction strategies based solely on recency (e.g., Least Recently Used), CACE leverages multiple context-aware factors, including model load time, task-specific latency sensitivity, expected output length, and recent usage and future demand tracked through a sliding window. We evaluate CACE using realistic workloads that include both latency-sensitive code completion and throughput-intensive code reasoning tasks. Our experiments show that CACE reduces Time-to-First-Token (TTFT) by 70% and end-to-end (E2E) latency by 37%, while significantly lowering the number of model evictions by 55% compared to state-of-the-art systems. Ablation studies further demonstrate the importance of multi-factor eviction in balancing responsiveness and resource efficiency. This work contributes practical strategies for deploying scalable, low-latency AI coding assistants in real-world software engineering environments.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Context-Aware CodeLLM Eviction for AI-Assisted Coding 1759420494144 10.1109/ASE63991.2025.00271 Kishanthan Thangarajah Centre for Software Excellence, Canada kishanthan.thangarajah1@huawei.com Boyuan Chen Centre for Software Excellence, Canada boyuan.chen1@huawei.com Shi Chang Western University, Canada schan543@uwo.ca Ahmed E. Hassan Queen's University, Canada ahmed@cs.queensu.ca codellm model eviction developer productivity coding assistants latency performance AI-assisted coding tools powered by Code Large Language Models (CodeLLMs) are increasingly integrated into modern software development workflows. To address concerns around privacy, latency, and model customization, many enterprises opt to self-host these models. However, the diversity and growing number of CodeLLMs, coupled with limited accelerator memory, introduce practical challenges in model management and serving efficiency. This paper presents CACE, a novel context-aware model eviction strategy designed specifically to optimize self-hosted CodeLLM serving under resource constraints. Unlike traditional eviction strategies based solely on recency (e.g., Least Recently Used), CACE leverages multiple context-aware factors, including model load time, task-specific latency sensitivity, expected output length, and recent usage and future demand tracked through a sliding window. We evaluate CACE using realistic workloads that include both latency-sensitive code completion and throughput-intensive code reasoning tasks. Our experiments show that CACE reduces Time-to-First-Token (TTFT) by 70% and end-to-end (E2E) latency by 37%, while significantly lowering the number of model evictions by 55% compared to state-of-the-art systems. Ablation studies further demonstrate the importance of multi-factor eviction in balancing responsiveness and resource efficiency. This work contributes practical strategies for deploying scalable, low-latency AI coding assistants in real-world software engineering environments.",
							"pageNumber": 3286,
							"isPageNumberRoman": false
						},
						{
							"eid": "7bGNYn7pG4RfgyMHnHsNQ1",
							"type": "authorPaper",
							"text": "LogPilot: Intent-Aware and Scalable Alert Diagnosis for Large-Scale Online Service Systems",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d298/573300d298.pdf",
							"extraLocations": [],
							"authorNames": "Zhihan Jiang (The Chinese University of Hong Kong), Jinyang Liu (ByteDance), Yichen Li (Bytedance), Haiyu Huang (The Chinese University of Hong Kong), Xiao He (ByteDance), Tieying Zhang (ByteDance), Jianjun Chen (ByteDance), Yi Li (ByteDance), Rui Shi (ByteDance), Michael R. Lyu (The Chinese University of Hong Kong)",
							"abstract": "Effective alert diagnosis is essential for ensuring the reliability of large-scale online service systems. However, on-call engineers are often burdened with manually inspecting massive volumes of logs to identify root causes. While various automated tools have been proposed, they struggle in practice due to alert-agnostic log scoping and the inability to organize complex data effectively for reasoning. To overcome these limitations, we introduce LogPilot, an intent-aware and scalable framework powered by Large Language Models (LLMs) for automated log-based alert diagnosis. LogPilot introduces an intent-aware approach, interpreting the logic in alert definitions (e.g., PromQL) to precisely identify causally related logs and requests. To achieve scalability, it reconstructs each request's execution into a spatiotemporal log chain, clusters similar chains to identify recurring execution patterns, and provides representative samples to the LLMs for diagnosis. This clustering-based approach ensures the input is both rich in diagnostic detail and compact enough to fit within the LLM's context window. Evaluated on real-world alerts from Volcano Engine Cloud, LogPilot improves the usefulness of root cause summarization by 50.34% and exact localization accuracy by 54.79% over state-of-the-art methods. With a diagnosis time under one minute and a cost of only $0.074 per alert, LogPilot has been successfully deployed in production, offering an automated and practical solution for service alert diagnosis.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 LogPilot: Intent-Aware and Scalable Alert Diagnosis for Large-Scale Online Service Systems 1759047364130 10.1109/ASE63991.2025.00272 Zhihan Jiang The Chinese University of Hong Kong zhjiang22@cse.cuhk.edu.hk Jinyang Liu ByteDance jinyang.liu@bytedance.com Yichen Li Bytedance Liyichen.325@bytedance.com Haiyu Huang The Chinese University of Hong Kong hyhuang25@cse.cuhk.edu.hk Xiao He ByteDance xiao.hx@bytedance.com Tieying Zhang ByteDance tieying.zhang@bytedance.com Jianjun Chen ByteDance jianjun.chen@bytedance.com Yi Li ByteDance liyi.ly@bytedance.com Rui Shi ByteDance shirui@bytedance.com Michael R. Lyu The Chinese University of Hong Kong lyu@cse.cuhk.edu.hk log analysis failure diagnosis aiops service reliability large language models Effective alert diagnosis is essential for ensuring the reliability of large-scale online service systems. However, on-call engineers are often burdened with manually inspecting massive volumes of logs to identify root causes. While various automated tools have been proposed, they struggle in practice due to alert-agnostic log scoping and the inability to organize complex data effectively for reasoning. To overcome these limitations, we introduce LogPilot, an intent-aware and scalable framework powered by Large Language Models (LLMs) for automated log-based alert diagnosis. LogPilot introduces an intent-aware approach, interpreting the logic in alert definitions (e.g., PromQL) to precisely identify causally related logs and requests. To achieve scalability, it reconstructs each request's execution into a spatiotemporal log chain, clusters similar chains to identify recurring execution patterns, and provides representative samples to the LLMs for diagnosis. This clustering-based approach ensures the input is both rich in diagnostic detail and compact enough to fit within the LLM's context window. Evaluated on real-world alerts from Volcano Engine Cloud, LogPilot improves the usefulness of root cause summarization by 50.34% and exact localization accuracy by 54.79% over state-of-the-art methods. With a diagnosis time under one minute and a cost of only $0.074 per alert, LogPilot has been successfully deployed in production, offering an automated and practical solution for service alert diagnosis.",
							"pageNumber": 3298,
							"isPageNumberRoman": false
						},
						{
							"eid": "01AVRIiAEnZQfL4C04ziBO",
							"type": "authorPaper",
							"text": "Streamlining Acceptance Test Generation for Mobile Applications Through Large Language Models: An Industrial Case Study",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d310/573300d310.pdf",
							"extraLocations": [],
							"authorNames": "Pedro Lu\u00EDs Fonseca (University of Porto, Portugal), Bruno Lima (University of Porto, Portugal), Jo\u00E3o Pascoal Faria (University of Porto, Portugal)",
							"abstract": "Mobile acceptance testing remains a bottleneck in modern software development, particularly for cross-platform mobile development using frameworks like Flutter. While developers increasingly rely on automated testing tools, creating and maintaining acceptance test artifacts still demands significant manual effort. To help tackle this issue, we introduce AToMIC, an automated framework leveraging specialized Large Language Models to generate Gherkin scenarios, Page Objects, and executable UI test scripts directly from requirements (JIRA tickets) and recent code changes. Applied to a large mobile app in the automotive domain, covering 13 real-world issues in a 170+ screen codebase, AToMIC produced executable test artifacts in under five minutes per feature on standard hardware. The generated artifacts were of high quality: 93.3% of Gherkin scenarios were syntactically correct upon generation, 78.8% of PageObjects ran without manual edits, and 100% of generated UI tests executed successfully. In a survey, all practitioners reported time savings (often a full developer-day per feature) and strong confidence in adopting the approach. These results confirm AToMIC as a scalable, practical solution for streamlining acceptance test creation and maintenance in industrial mobile projects.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Streamlining Acceptance Test Generation for Mobile Applications Through Large Language Models: An Industrial Case Study 1760125074756 10.1109/ASE63991.2025.00273 Pedro Lu\u00EDs Fonseca University of Porto, Portugal up202008307@up.pt Bruno Lima University of Porto, Portugal brunolima@fe.up.pt Jo\u00E3o Pascoal Faria University of Porto, Portugal jpf@fe.up.pt acceptance testing large language models mobile applications flutter test case generation cross-platform development gherkin test automation Mobile acceptance testing remains a bottleneck in modern software development, particularly for cross-platform mobile development using frameworks like Flutter. While developers increasingly rely on automated testing tools, creating and maintaining acceptance test artifacts still demands significant manual effort. To help tackle this issue, we introduce AToMIC, an automated framework leveraging specialized Large Language Models to generate Gherkin scenarios, Page Objects, and executable UI test scripts directly from requirements (JIRA tickets) and recent code changes. Applied to a large mobile app in the automotive domain, covering 13 real-world issues in a 170+ screen codebase, AToMIC produced executable test artifacts in under five minutes per feature on standard hardware. The generated artifacts were of high quality: 93.3% of Gherkin scenarios were syntactically correct upon generation, 78.8% of PageObjects ran without manual edits, and 100% of generated UI tests executed successfully. In a survey, all practitioners reported time savings (often a full developer-day per feature) and strong confidence in adopting the approach. These results confirm AToMIC as a scalable, practical solution for streamlining acceptance test creation and maintenance in industrial mobile projects.",
							"pageNumber": 3310,
							"isPageNumberRoman": false
						},
						{
							"eid": "1XR9AyDaDvf29stOxMTXAA",
							"type": "authorPaper",
							"text": "An Empirical Study on UI Overlap in OpenHarmony Applications",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d321/573300d321.pdf",
							"extraLocations": [],
							"authorNames": "Farong Liu (Beihang University, China), Mingyi Zhou (Beihang University, China), Li Li (Beihang University, China)",
							"abstract": "UI overlap is a phenomenon where one UI component visually covers another. While this overlap is necessary to construct rich visual hierarchies, it is also a root cause of usability issues and performance bottlenecks. However, a systematic, data-driven understanding of its prevalence and patterns has been lacking. To bridge this gap, we conduct the first large-scale empirical study on UI overlap in the OH ecosystem. We analyze 100 popular apps, classifying 33,262,624 overlap instances through a novel three-tiered taxonomy. Our findings reveal that high-cost occlusion is a critical and previously hard-to-detect performance defect where resource-intensive components are rendered while visually obscured. We propose tool, an innovative tool that leverages multimodal vision-language models (VLMs) to automatically detect such issues, successfully identifying 34 high-cost occlusion cases in commercial apps. Our study not only provides the first comprehensive understanding of UI overlap in OH but also offers a practical tool to automatically diagnose complex performance-related UI bugs. Our tools are publicly https://github.com/SMAT-Lab/HapOverlap available.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 An Empirical Study on UI Overlap in OpenHarmony Applications 1759573937167 10.1109/ASE63991.2025.00274 Farong Liu Beihang University, China liufarong@buaa.edu.cn Mingyi Zhou Beihang University, China zhoumingyi@buaa.edu.cn Li Li Beihang University, China lilicoding@ieee.org dynamic analysis ui overlap performance analysis openharmony usability UI overlap is a phenomenon where one UI component visually covers another. While this overlap is necessary to construct rich visual hierarchies, it is also a root cause of usability issues and performance bottlenecks. However, a systematic, data-driven understanding of its prevalence and patterns has been lacking. To bridge this gap, we conduct the first large-scale empirical study on UI overlap in the OH ecosystem. We analyze 100 popular apps, classifying 33,262,624 overlap instances through a novel three-tiered taxonomy. Our findings reveal that high-cost occlusion is a critical and previously hard-to-detect performance defect where resource-intensive components are rendered while visually obscured. We propose tool, an innovative tool that leverages multimodal vision-language models (VLMs) to automatically detect such issues, successfully identifying 34 high-cost occlusion cases in commercial apps. Our study not only provides the first comprehensive understanding of UI overlap in OH but also offers a practical tool to automatically diagnose complex performance-related UI bugs. Our tools are publicly https://github.com/SMAT-Lab/HapOverlap available.",
							"pageNumber": 3321,
							"isPageNumberRoman": false
						},
						{
							"eid": "6Ybd1JkhWD48cZ44FIKvrT",
							"type": "authorPaper",
							"text": "Multi-Modal Requirements Data-Based Acceptance Criteria Generation Using LLMs",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d333/573300d333.pdf",
							"extraLocations": [],
							"authorNames": "Fanyu Wang (Monash University, Australia), Chetan Arora (Monash University, Australia), Yonghui Liu (Monash University, Australia), Kaicheng Huang (Monash University, Australia), Chakkrit Tantithamthavorn (Monash University, Australia), Aldeida Aleti (Monash University, Australia), Dishan Sambathkumar (Monash University, Australia), David Lo (Singapore Management University, Singapore)",
							"abstract": "Acceptance criteria (ACs) play a critical role in software development by clearly defining the conditions under which a software feature satisfies stakeholder expectations. However, manually creating accurate, comprehensive, and unambiguous acceptance criteria is challenging, particularly in user interface-intensive applications, due to the reliance on domain-specific knowledge and visual context that is not always captured by textual requirements alone. To address these challenges, we propose RAGcceptance M2RE, a novel approach that leverages Retrieval-Augmented Generation (RAG) to generate acceptance criteria from multi-modal requirements data, including both textual documentation and visual UI information. We systematically evaluated our approach in an industrial case study involving an education-focused software system used by approximately 100,000 users. The results indicate that integrating multi-modal information significantly enhances the relevance, correctness, and comprehensibility of the generated ACs. Moreover, practitioner evaluations confirm that our approach effectively reduces manual effort, captures nuanced stakeholder intent, and provides valuable criteria that domain experts may overlook, demonstrating practical utility and significant potential for industry adoption. This research underscores the potential of multi-modal RAG techniques in streamlining software validation processes and improving development efficiency. We also make our implementation and a dataset available.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Multi-Modal Requirements Data-Based Acceptance Criteria Generation Using LLMs 1759381527667 10.1109/ASE63991.2025.00275 Fanyu Wang Monash University, Australia fanyu.wang@monash.edu Chetan Arora Monash University, Australia chetan.arora@monash.edu Yonghui Liu Monash University, Australia yonghui.liu@monash.edu Kaicheng Huang Monash University, Australia khua0042@monash.edu Chakkrit Tantithamthavorn Monash University, Australia chakkrit@monash.edu Aldeida Aleti Monash University, Australia aldeida.aleti@monash.edu Dishan Sambathkumar Monash University, Australia dishan.sambathkumar@monash.edu David Lo Singapore Management University, Singapore davidlo@smu.edu.sg requirements-driven testing multi-modal large language models retrieval-augmented generation requirements engineering acceptance criteria industry study Acceptance criteria (ACs) play a critical role in software development by clearly defining the conditions under which a software feature satisfies stakeholder expectations. However, manually creating accurate, comprehensive, and unambiguous acceptance criteria is challenging, particularly in user interface-intensive applications, due to the reliance on domain-specific knowledge and visual context that is not always captured by textual requirements alone. To address these challenges, we propose RAGcceptance M2RE, a novel approach that leverages Retrieval-Augmented Generation (RAG) to generate acceptance criteria from multi-modal requirements data, including both textual documentation and visual UI information. We systematically evaluated our approach in an industrial case study involving an education-focused software system used by approximately 100,000 users. The results indicate that integrating multi-modal information significantly enhances the relevance, correctness, and comprehensibility of the generated ACs. Moreover, practitioner evaluations confirm that our approach effectively reduces manual effort, captures nuanced stakeholder intent, and provides valuable criteria that domain experts may overlook, demonstrating practical utility and significant potential for industry adoption. This research underscores the potential of multi-modal RAG techniques in streamlining software validation processes and improving development efficiency. We also make our implementation and a dataset available.",
							"pageNumber": 3333,
							"isPageNumberRoman": false
						},
						{
							"eid": "4muzQUGh8pVb5qAUWM88Ok",
							"type": "authorPaper",
							"text": "Prompt-With-Me: in-IDE Structured Prompt Management for LLM-Driven Software Engineering",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d345/573300d345.pdf",
							"extraLocations": [],
							"authorNames": "Ziyou Li (Delft University of Technology; JetBrains Research, The Netherlands), Agnia Sergeyuk (JetBrains Research, Serbia), Maliheh Izadi (Delft University of Technology, The Netherlands)",
							"abstract": "Large Language Models are transforming software engineering, yet prompt management in practice remains ad hoc, hindering reliability, reuse, and integration into industrial workflows. We present Prompt-with-Me, a practical solution for structured prompt management embedded directly in the development environment. The system automatically classifies prompts using a four-dimensional taxonomy that encompasses intent, author role, software development lifecycle stage, and prompt type. To improve prompt reuse and quality, Prompt-with-Me suggests language refinements, masks sensitive information, and extracts reusable templates from a developer's prompt library. Our taxonomy study of 1,108 real-world prompts demonstrates that modern LLMs can accurately classify software engineering prompts. Furthermore, our user study with 11 participants shows strong developer acceptance, with high usability (Mean SUS=73), low cognitive load (Mean NASA-TLX=21), and reported gains in prompt quality and efficiency through reduced repetitive effort. Lastly, we offer actionable insights for building the next generation of prompt management and maintenance tools for software engineering workflows.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Prompt-With-Me: in-IDE Structured Prompt Management for LLM-Driven Software Engineering 1759409608195 10.1109/ASE63991.2025.00276 Ziyou Li Delft University of Technology; JetBrains Research, The Netherlands ziyou.li@tudelft.nl Agnia Sergeyuk JetBrains Research, Serbia agnia.sergeyuk@jetbrains.com Maliheh Izadi Delft University of Technology, The Netherlands m.izadi@tudelft.nl large language models human computer interaction prompt engineering software engineering Large Language Models are transforming software engineering, yet prompt management in practice remains ad hoc, hindering reliability, reuse, and integration into industrial workflows. We present Prompt-with-Me, a practical solution for structured prompt management embedded directly in the development environment. The system automatically classifies prompts using a four-dimensional taxonomy that encompasses intent, author role, software development lifecycle stage, and prompt type. To improve prompt reuse and quality, Prompt-with-Me suggests language refinements, masks sensitive information, and extracts reusable templates from a developer's prompt library. Our taxonomy study of 1,108 real-world prompts demonstrates that modern LLMs can accurately classify software engineering prompts. Furthermore, our user study with 11 participants shows strong developer acceptance, with high usability (Mean SUS=73), low cognitive load (Mean NASA-TLX=21), and reported gains in prompt quality and efficiency through reduced repetitive effort. Lastly, we offer actionable insights for building the next generation of prompt management and maintenance tools for software engineering workflows.",
							"pageNumber": 3345,
							"isPageNumberRoman": false
						},
						{
							"eid": "2xUiUaqnmDpCjDT4EgOD35",
							"type": "authorPaper",
							"text": "Bridging Research and Practice in Simulation-Based Testing of Industrial Robot Navigation Systems",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d356/573300d356.pdf",
							"extraLocations": [],
							"authorNames": "Sajad Khatiri (University of Bern, Switzerland; Universit\u00E0 della Svizzera italiana, Switzerland), Francisco Eli Vi\u00F1a Barrientos (ANYbotics AG, Switzerland), Maximilian Wulf (ANYbotics AG, Switzerland), Paolo Tonella (Universit\u00E0 della Svizzera italiana, Switzerland), Sebastiano Panichella (University of Bern, Switzerland)",
							"abstract": "Ensuring robust robotic navigation in dynamic environments is a key challenge, as traditional testing methods often struggle to cover the full spectrum of operational requirements. This paper presents the industrial adoption of Surrealist, a simulation-based test generation framework originally for UAVs, now applied to the ANYmal quadrupedal robot for industrial inspection. Our method uses a search-based algorithm to automatically generate challenging obstacle avoidance scenarios, uncovering failures often missed by manual testing. In a pilot phase, generated test suites revealed critical weaknesses in one experimental algorithm (40.3% success rate) and served as an effective benchmark to prove the superior robustness of another (71.2% success rate). The framework was then integrated into the ANYbotics workflow for a six-month industrial evaluation, where it was used to test five proprietary algorithms. A formal survey confirmed its value, showing it enhances the development process, uncovers critical failures, provides objective benchmarks, and strengthens the overall verification pipeline.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Bridging Research and Practice in Simulation-Based Testing of Industrial Robot Navigation Systems 1759477566091 10.1109/ASE63991.2025.00277 Sajad Khatiri University of Bern, Switzerland; Universit\u00E0 della Svizzera italiana, Switzerland sajad.mazraehkhatiri@unibe.ch Francisco Eli Vi\u00F1a Barrientos ANYbotics AG, Switzerland fvina@anybotics.com Maximilian Wulf ANYbotics AG, Switzerland mwulf@anybotics.com Paolo Tonella Universit\u00E0 della Svizzera italiana, Switzerland paolo.tonella@usi.ch Sebastiano Panichella University of Bern, Switzerland sebastiano.panichella@unibe.ch robotic navigation local planning obstacle avoidance simulation environments search-based testing environment generation quadrupedal robots Ensuring robust robotic navigation in dynamic environments is a key challenge, as traditional testing methods often struggle to cover the full spectrum of operational requirements. This paper presents the industrial adoption of Surrealist, a simulation-based test generation framework originally for UAVs, now applied to the ANYmal quadrupedal robot for industrial inspection. Our method uses a search-based algorithm to automatically generate challenging obstacle avoidance scenarios, uncovering failures often missed by manual testing. In a pilot phase, generated test suites revealed critical weaknesses in one experimental algorithm (40.3% success rate) and served as an effective benchmark to prove the superior robustness of another (71.2% success rate). The framework was then integrated into the ANYbotics workflow for a six-month industrial evaluation, where it was used to test five proprietary algorithms. A formal survey confirmed its value, showing it enhances the development process, uncovers critical failures, provides objective benchmarks, and strengthens the overall verification pipeline.",
							"pageNumber": 3356,
							"isPageNumberRoman": false
						},
						{
							"eid": "2UpdHUVf73mnn6KZ2QkTPp",
							"type": "authorPaper",
							"text": "A Characterization Study of Bugs in LLM Agent Workflow Orchestration Frameworks",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d368/573300d368.pdf",
							"extraLocations": [],
							"authorNames": "Ziluo Xue (Huazhong University of Science and Technology, China), Yanjie Zhao (Huazhong University of Science and Technology, China), Shenao Wang (Huazhong University of Science and Technology, China), Kai Chen (Huazhong University of Science and Technology, China), Haoyu Wang (Huazhong University of Science and Technology, China)",
							"abstract": "Large Language Models (LLMs) have rapidly gained popularity, transforming research and industry. To support their adoption, LLM agent workflow orchestration frameworks (hereinafter referred to as LLM agent frameworks) like LangChain have become essential for building advanced applications. However, their complexity makes bugs inevitable, and these bugs can propagate to downstream applications, causing severe failures or unintended behaviors. In this paper, we first present an abstraction of the structure of mainstream LLM agent frameworks, identifying four key architectural components: data preprocessing, core schema, agent construction, and featured modules. Building on this abstraction, we conduct the first empirical study on LLM agent framework bugs, analyzing 1,026 bug instances extracted from 1,577 real-world bug-related GitHub pull requests (PRs) from three popular LLM agent frameworks: LangChain, LlamaIndex, and Haystack. For each bug, we examine its root cause, symptom, and structural component, providing a systematic taxonomy of nine root causes and six symptom categories. Finally, leveraging the framework structure abstraction and the large-scale empirical study, we perform detailed statistical analysis in terms of the distribution of bugs in different frameworks, the distribution across different framework components, and the relationship between root cause and symptom. The analysis reveals unique challenge patterns compared to traditional software, providing actionable guidance for practitioners on quality assurance.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 A Characterization Study of Bugs in LLM Agent Workflow Orchestration Frameworks 1759108257815 10.1109/ASE63991.2025.00278 Ziluo Xue Huazhong University of Science and Technology, China xzl@hust.edu.cn Yanjie Zhao Huazhong University of Science and Technology, China yanjie_zhao@hust.edu.cn Shenao Wang Huazhong University of Science and Technology, China shenaowang@hust.edu.cn Kai Chen Huazhong University of Science and Technology, China kchen@hust.edu.cn Haoyu Wang Huazhong University of Science and Technology, China haoyuwang@hust.edu.cn llm frameworks bug characterization empirical study Large Language Models (LLMs) have rapidly gained popularity, transforming research and industry. To support their adoption, LLM agent workflow orchestration frameworks (hereinafter referred to as LLM agent frameworks) like LangChain have become essential for building advanced applications. However, their complexity makes bugs inevitable, and these bugs can propagate to downstream applications, causing severe failures or unintended behaviors. In this paper, we first present an abstraction of the structure of mainstream LLM agent frameworks, identifying four key architectural components: data preprocessing, core schema, agent construction, and featured modules. Building on this abstraction, we conduct the first empirical study on LLM agent framework bugs, analyzing 1,026 bug instances extracted from 1,577 real-world bug-related GitHub pull requests (PRs) from three popular LLM agent frameworks: LangChain, LlamaIndex, and Haystack. For each bug, we examine its root cause, symptom, and structural component, providing a systematic taxonomy of nine root causes and six symptom categories. Finally, leveraging the framework structure abstraction and the large-scale empirical study, we perform detailed statistical analysis in terms of the distribution of bugs in different frameworks, the distribution across different framework components, and the relationship between root cause and symptom. The analysis reveals unique challenge patterns compared to traditional software, providing actionable guidance for practitioners on quality assurance.",
							"pageNumber": 3368,
							"isPageNumberRoman": false
						},
						{
							"eid": "6Ib14ztbNNBLqNc9cHN5Ew",
							"type": "authorPaper",
							"text": "AdaptiveGuard: Towards Adaptive Runtime Safety for LLM-Powered Software",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d380/573300d380.pdf",
							"extraLocations": [],
							"authorNames": "Rui  Yang (Monash University, Transurban, Australia), Michael  Fu (The University of Melbourne, Australia), Chakkrit Tantithamthavorn (Monash University, Australia), Chetan Arora (Monash University, Australia), Gunel Gulmammadova (Transurban, Australia), Joey Chua (Transurban, Australia)",
							"abstract": "Guardrails are critical for the safe deployment of Large Language Models (LLMs)-powered software. Unlike traditional rule-based systems with limited, predefined input-output spaces that inherently constrain unsafe behavior, LLMs enable open-ended, intelligent interactions\u2014opening the door to jailbreak attacks through user inputs. Guardrails serve as a protective layer, filtering unsafe prompts before they reach the LLM. However, prior research shows that jailbreak attacks can still succeed over 70% of the time, even against advanced models like GPT-4o. While guardrails such as LlamaGuard report up to 95% accuracy, our preliminary analysis shows their performance can drop sharply\u2014to as low as 12%\u2014when confronted with unseen attacks. This highlights a growing software engineering challenge: how to build a post-deployment guardrail that adapts dynamically to emerging threats? To address this, we propose AdaptiveGuard, an adaptive guardrail that detects novel jailbreak attacks as out-of-distribution (OOD) inputs and learns to defend against them through a continual learning framework. Through empirical evaluation, AdaptiveGuard achieves 96% OOD detection accuracy, adapts to new attacks in just two update steps, and retains over 85% F1-score on in-distribution data post-adaptation, outperforming other baselines. These results demonstrate that AdaptiveGuard is a guardrail capable of evolving in response to emerging jailbreak strategies post deployment. We release our AdaptiveGuard and studied datasets at https://github.com/awsm-research/AdaptiveGuard to support further research.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 AdaptiveGuard: Towards Adaptive Runtime Safety for LLM-Powered Software 1759571540325 10.1109/ASE63991.2025.00279 Rui Yang Monash University, Transurban, Australia rui.yang1@monash.edu.au Michael Fu The University of Melbourne, Australia michael.fu@unimelb.edu.au Chakkrit Tantithamthavorn Monash University, Australia chakkrit@monash.edu Chetan Arora Monash University, Australia chetan.arora@monash.edu Gunel Gulmammadova Transurban, Australia ggulmammadova@transurban.com Joey Chua Transurban, Australia jchua@transurban.com safety and reliability llm safety out-of-distribution detection llm guardrails llm jailbreak attacks Guardrails are critical for the safe deployment of Large Language Models (LLMs)-powered software. Unlike traditional rule-based systems with limited, predefined input-output spaces that inherently constrain unsafe behavior, LLMs enable open-ended, intelligent interactions\u2014opening the door to jailbreak attacks through user inputs. Guardrails serve as a protective layer, filtering unsafe prompts before they reach the LLM. However, prior research shows that jailbreak attacks can still succeed over 70% of the time, even against advanced models like GPT-4o. While guardrails such as LlamaGuard report up to 95% accuracy, our preliminary analysis shows their performance can drop sharply\u2014to as low as 12%\u2014when confronted with unseen attacks. This highlights a growing software engineering challenge: how to build a post-deployment guardrail that adapts dynamically to emerging threats? To address this, we propose AdaptiveGuard, an adaptive guardrail that detects novel jailbreak attacks as out-of-distribution (OOD) inputs and learns to defend against them through a continual learning framework. Through empirical evaluation, AdaptiveGuard achieves 96% OOD detection accuracy, adapts to new attacks in just two update steps, and retains over 85% F1-score on in-distribution data post-adaptation, outperforming other baselines. These results demonstrate that AdaptiveGuard is a guardrail capable of evolving in response to emerging jailbreak strategies post deployment. We release our AdaptiveGuard and studied datasets at https://github.com/awsm-research/AdaptiveGuard to support further research.",
							"pageNumber": 3380,
							"isPageNumberRoman": false
						},
						{
							"eid": "1Uk3b7cMzTbLRVJggq1q6I",
							"type": "authorPaper",
							"text": "Unlocking Reproducibility: Automating re-Build Process for Open-Source Software",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d391/573300d391.pdf",
							"extraLocations": [],
							"authorNames": "Behnaz Hassanshahi (Oracle Labs, Australia), Trong Nhan Mai (Oracle Labs, Australia), Benjamin Selwyn Smith (Oracle Labs, Australia), Nicholas Allen (Oracle Labs, Australia)",
							"abstract": "Software ecosystems like Maven Central play a crucial role in modern software supply chains by providing repositories for libraries and build plugins. However, the separation between binaries and their corresponding source code in Maven Central presents a significant challenge, particularly when it comes to linking binaries back to their original build environment. This lack of transparency poses security risks, as approximately 84% of the top 1200 commonly used artifacts are not built using a transparent CI/CD pipeline. Consequently, users must place a significant amount of trust not only in the source code but also in the environment in which these artifacts are built. Rebuilding software artifacts from source provides a robust solution to improve supply chain security. This approach allows for a deeper review of code, verification of binary-source equivalence, and control over dependencies. However, challenges arise due to variations in build environments, such as JDK versions and build commands, which can lead to build failures. Additionally, ensuring that all dependencies are rebuilt from source across large and complex dependency graphs further complicates the process. In this paper, we introduce an extension to Macaron, an industry-grade open-source supply chain security framework, to automate the rebuilding of Maven artifacts from source. Our approach improves upon existing tools, by offering better performance in source code detection and automating the extraction of build specifications from GitHub Actions workflows. We also present a comprehensive root cause analysis of build failures in Java projects and propose a scalable solution to automate the rebuilding of artifacts, ultimately enhancing security and transparency in the open-source supply chain. While we demonstrate our approach for Java, our solution is easily extensible to other languages and ecosystems like Python and npm packages.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Unlocking Reproducibility: Automating re-Build Process for Open-Source Software 1759190143650 10.1109/ASE63991.2025.00280 Behnaz Hassanshahi Oracle Labs, Australia behnaz.hassanshahi@oracle.com Trong Nhan Mai Oracle Labs, Australia trong.nhan.mai@oracle.com Benjamin Selwyn Smith Oracle Labs, Australia benjamin.selwyn.smith@oracle.com Nicholas Allen Oracle Labs, Australia nicholas.allen@oracle.com software supply chain security program analysis reproducible builds Software ecosystems like Maven Central play a crucial role in modern software supply chains by providing repositories for libraries and build plugins. However, the separation between binaries and their corresponding source code in Maven Central presents a significant challenge, particularly when it comes to linking binaries back to their original build environment. This lack of transparency poses security risks, as approximately 84% of the top 1200 commonly used artifacts are not built using a transparent CI/CD pipeline. Consequently, users must place a significant amount of trust not only in the source code but also in the environment in which these artifacts are built. Rebuilding software artifacts from source provides a robust solution to improve supply chain security. This approach allows for a deeper review of code, verification of binary-source equivalence, and control over dependencies. However, challenges arise due to variations in build environments, such as JDK versions and build commands, which can lead to build failures. Additionally, ensuring that all dependencies are rebuilt from source across large and complex dependency graphs further complicates the process. In this paper, we introduce an extension to Macaron, an industry-grade open-source supply chain security framework, to automate the rebuilding of Maven artifacts from source. Our approach improves upon existing tools, by offering better performance in source code detection and automating the extraction of build specifications from GitHub Actions workflows. We also present a comprehensive root cause analysis of build failures in Java projects and propose a scalable solution to automate the rebuilding of artifacts, ultimately enhancing security and transparency in the open-source supply chain. While we demonstrate our approach for Java, our solution is easily extensible to other languages and ecosystems like Python and npm packages.",
							"pageNumber": 3391,
							"isPageNumberRoman": false
						},
						{
							"eid": "2nAgWT2KU9birtSyU6DPhZ",
							"type": "authorPaper",
							"text": "Out of Distribution Detection in Self-Adaptive Robots with AI-Powered Digital Twins",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d402/573300d402.pdf",
							"extraLocations": [],
							"authorNames": "Erblin Isaku (Simula Research Laboratory, Norway; University of Oslo, Norway), Hassan Sartaj (Simula Research Laboratory, Norway), Shaukat Ali (Simula Research Laboratory, Norway), Beatriz Sanguino (Norwegian University of Science and Technology, Norway), Tongtong Wang (Norwegian University of Science and Technology, Norway), Guoyuan Li (Norwegian University of Science and Technology, Norway), Houxiang Zhang (Norwegian University of Science and Technology, Norway), Thomas Peyrucain (PAL Robotics, Spain)",
							"abstract": "Self-adaptive robots (SARs) in complex, uncertain environments must proactively detect and address abnormal behaviors, including out-of-distribution (OOD) cases. To this end, digital twins offer a valuable solution for OOD detection. Thus, we present a digital twin-based approach for OOD detection (ODiSAR) in SARs. ODiSAR uses a Transformer-based digital twin to forecast SAR states and employs reconstruction error and Monte Carlo dropout for uncertainty quantification. By combining reconstruction error with predictive variance, the digital twin effectively detects OOD behaviors, even in previously unseen conditions. The digital twin also includes an explainability layer that links potential OOD to specific SAR states, offering insights for self-adaptation. We evaluated ODiSAR by creating digital twins of two industrial robots: one navigating an office environment, and another performing maritime ship navigation. In both cases, ODiSAR forecasts SAR behaviors (i.e., robot trajectories and vessel motion) and proactively detects OOD events. Our results showed that ODiSAR achieved high detection performance\u2014up to 98% AUROC, 96% TNR@TPR95, and 95% F1-score\u2014while providing interpretable insights to support self-adaptation.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Out of Distribution Detection in Self-Adaptive Robots with AI-Powered Digital Twins 1759135403984 10.1109/ASE63991.2025.00281 Erblin Isaku Simula Research Laboratory, Norway; University of Oslo, Norway erblin@simula.no Hassan Sartaj Simula Research Laboratory, Norway hassan@simula.no Shaukat Ali Simula Research Laboratory, Norway shaukat@simula.no Beatriz Sanguino Norwegian University of Science and Technology, Norway beatriz.i.s.c.d.c.sanguino@ntnu.no Tongtong Wang Norwegian University of Science and Technology, Norway tongtong.wang@ntnu.no Guoyuan Li Norwegian University of Science and Technology, Norway guoyuan.li@ntnu.no Houxiang Zhang Norwegian University of Science and Technology, Norway hozh@ntnu.no Thomas Peyrucain PAL Robotics, Spain thomas.peyrucain@pal-robotics.com self-adaptive robots digital twins out-of-distribution detection uncertainty quantification explainability Self-adaptive robots (SARs) in complex, uncertain environments must proactively detect and address abnormal behaviors, including out-of-distribution (OOD) cases. To this end, digital twins offer a valuable solution for OOD detection. Thus, we present a digital twin-based approach for OOD detection (ODiSAR) in SARs. ODiSAR uses a Transformer-based digital twin to forecast SAR states and employs reconstruction error and Monte Carlo dropout for uncertainty quantification. By combining reconstruction error with predictive variance, the digital twin effectively detects OOD behaviors, even in previously unseen conditions. The digital twin also includes an explainability layer that links potential OOD to specific SAR states, offering insights for self-adaptation. We evaluated ODiSAR by creating digital twins of two industrial robots: one navigating an office environment, and another performing maritime ship navigation. In both cases, ODiSAR forecasts SAR behaviors (i.e., robot trajectories and vessel motion) and proactively detects OOD events. Our results showed that ODiSAR achieved high detection performance\u2014up to 98% AUROC, 96% TNR@TPR95, and 95% F1-score\u2014while providing interpretable insights to support self-adaptation.",
							"pageNumber": 3402,
							"isPageNumberRoman": false
						},
						{
							"eid": "2lmcGkMpnlbPJe8gRv1H5n",
							"type": "authorPaper",
							"text": "Data Dependency-Aware Code Generation from Enhanced UML Sequence Diagrams",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d414/573300d414.pdf",
							"extraLocations": [],
							"authorNames": "Wenxin Mao (Tencent Inc, China ), Zhitao Wang (Tencent Inc, China ), Long Wang (Tencent Inc, China ), Sirong Chen (Tencent Inc, China ), Cuiyun Gao (The Chinese University of Hong Kong, China), Luyang Cao (Tencent Inc, China ), Ziming Liu (Tencent Inc, China ), Qiming Zhang (Tencent Inc, China ), Jun Zhou (Tencent Inc, China ), Zhi Jin (Wuhan University, China)",
							"abstract": "Large language models (LLMs) excel at generating code from natural language (NL) descriptions. However, the plain textual descriptions are inherently ambiguous and often fail to capture complex requirements like intricate system behaviors, conditional logic, and architectural constraints; implicit data dependencies in service-oriented architectures are difficult to infer and handle correctly. To bridge this gap, we propose a novel step-by-step code generation framework named UML2Dep by leveraging unambiguous formal specifications of complex requirements. First, we introduce an enhanced Unified Modeling Language (UML) sequence diagram tailored for service-oriented architectures. This diagram extends traditional visual syntax by integrating decision tables and API specifications, explicitly formalizing structural relationships and business logic flows in service interactions to rigorously eliminate linguistic ambiguity. Second, recognizing the critical role of data flow, we introduce a dedicated data dependency inference (DDI) task. DDI systematically constructs an explicit data dependency graph prior to actual code synthesis. To ensure reliability, we formalize DDI as a constrained mathematical reasoning task through novel prompting strategies, aligning with LLMs' excellent mathematical strengths. Additional static parsing and dependency pruning further reduce context complexity and cognitive load associated with intricate specifications, thereby enhancing reasoning accuracy and efficiency. Experimental results on our in-house industrial datasets demonstrate the effectiveness of the proposed framework. Specifically, our framework achieves strong performance, with 89.97% recall, 95.06% precision, and 92.33% F1 score on the DDI task. Furthermore, the integration of UML2Dep into the code generation pipeline also improves practical deployment, increasing compilation pass rate by 8.83% and unit test pass rate by 11.66%.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Data Dependency-Aware Code Generation from Enhanced UML Sequence Diagrams 1759400217036 10.1109/ASE63991.2025.00282 Wenxin Mao Tencent Inc, China mao23x@qq.com Zhitao Wang Tencent Inc, China zhitaowang@tencent.com Long Wang Tencent Inc, China oliverlwang@tencent.com Sirong Chen Tencent Inc, China sirongchen@tencent.com Cuiyun Gao The Chinese University of Hong Kong, China cuiyungao@outlook.com Luyang Cao Tencent Inc, China lucascao@tencent.com Ziming Liu Tencent Inc, China simonzmliu@tencent.com Qiming Zhang Tencent Inc, China archrzhang@tencent.com Jun Zhou Tencent Inc, China anderszhou@tencent.com Zhi Jin Wuhan University, China zhijin@pku.edu.cn data dependency inference uml sequence diagram code generation Large language models (LLMs) excel at generating code from natural language (NL) descriptions. However, the plain textual descriptions are inherently ambiguous and often fail to capture complex requirements like intricate system behaviors, conditional logic, and architectural constraints; implicit data dependencies in service-oriented architectures are difficult to infer and handle correctly. To bridge this gap, we propose a novel step-by-step code generation framework named UML2Dep by leveraging unambiguous formal specifications of complex requirements. First, we introduce an enhanced Unified Modeling Language (UML) sequence diagram tailored for service-oriented architectures. This diagram extends traditional visual syntax by integrating decision tables and API specifications, explicitly formalizing structural relationships and business logic flows in service interactions to rigorously eliminate linguistic ambiguity. Second, recognizing the critical role of data flow, we introduce a dedicated data dependency inference (DDI) task. DDI systematically constructs an explicit data dependency graph prior to actual code synthesis. To ensure reliability, we formalize DDI as a constrained mathematical reasoning task through novel prompting strategies, aligning with LLMs' excellent mathematical strengths. Additional static parsing and dependency pruning further reduce context complexity and cognitive load associated with intricate specifications, thereby enhancing reasoning accuracy and efficiency. Experimental results on our in-house industrial datasets demonstrate the effectiveness of the proposed framework. Specifically, our framework achieves strong performance, with 89.97% recall, 95.06% precision, and 92.33% F1 score on the DDI task. Furthermore, the integration of UML2Dep into the code generation pipeline also improves practical deployment, increasing compilation pass rate by 8.83% and unit test pass rate by 11.66%.",
							"pageNumber": 3414,
							"isPageNumberRoman": false
						},
						{
							"eid": "7Jd4EdtrkxDlZSdCdzgh6w",
							"type": "authorPaper",
							"text": "Automated Proactive Logging Quality Improvement for Large-Scale Codebases ",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d425/573300d425.pdf",
							"extraLocations": [],
							"authorNames": "Yichen Li (ByteDance), Jinyang Liu (ByteDance), Junsong  Pu (Sun Yat-sen University), Zhihan Jiang (The Chinese University of Hong Kong), Zhuangbin Chen (Sun Yat-sen University), Xiao He (ByteDance), Tieying Zhang (ByteDance), Jianjun Chen (ByteDance), Yi Li (ByteDance), Rui Shi (ByteDance), Michael R. Lyu (The Chinese University of Hong Kong)",
							"abstract": "High quality logging is critical for the reliability of cloud services, yet the industrial process for improving it is typically manual, reactive, and unscalable. Existing automated tools inherit this reactive nature, failing to answer the crucial whether-to-log question and are constrained to simple logging statement insertion, thus addressing only a fraction of the real-world logging improvement. To address these gaps and cope with logging debt in large-scale codebases, we propose LogImprover, a framework powered by Large Language Models (LLMs) that automates proactive logging quality improvement. LogImprover introduces two paradigm shifts: from reactive generation to proactive discovery, and from simple insertion to holistic logging patch generation. First, it identifies potential logging gaps based on principles distilled from industrial best practices. Then, it grounds each candidate through a cascading, structure-aware RAG module. Next, it prunes false positives by analyzing call-stack logging responsibilities and implicit logger inheritance. Finally, it generates holistic and explainable logging patches that reflect real-world development practices. Our evaluation provides dual confirmation of its effectiveness: LogImprover significantly outperforms state-of-the-art baselines in closed-world experiments and achieves 68.12% developer acceptance rate in its real-world deployment. This success demonstrates the practical value of automating the entire logging quality improvement lifecycle, from discovery to recommendation.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Automated Proactive Logging Quality Improvement for Large-Scale Codebases 1759331526928 10.1109/ASE63991.2025.00283 Yichen Li ByteDance liyichen.325@bytedance.com Jinyang Liu ByteDance jinyang.liu@bytedance.com Junsong Pu Sun Yat-sen University pujs@mail2.sysu.edu.cn Zhihan Jiang The Chinese University of Hong Kong zhjiang22@cse.cuhk.edu.hk Zhuangbin Chen Sun Yat-sen University chenzhb36@mail.sysu.edu.cn Xiao He ByteDance xiao.hx@bytedance.com Tieying Zhang ByteDance tieying.zhang@bytedance.com Jianjun Chen ByteDance jianjun.chen@bytedance.com Yi Li ByteDance liyi.ly@bytedance.com Rui Shi ByteDance shirui@bytedance.com Michael R. Lyu The Chinese University of Hong Kong lyu@cse.cuhk.edu.hk Logging Debt Observability Code Generation High quality logging is critical for the reliability of cloud services, yet the industrial process for improving it is typically manual, reactive, and unscalable. Existing automated tools inherit this reactive nature, failing to answer the crucial whether-to-log question and are constrained to simple logging statement insertion, thus addressing only a fraction of the real-world logging improvement. To address these gaps and cope with logging debt in large-scale codebases, we propose LogImprover, a framework powered by Large Language Models (LLMs) that automates proactive logging quality improvement. LogImprover introduces two paradigm shifts: from reactive generation to proactive discovery, and from simple insertion to holistic logging patch generation. First, it identifies potential logging gaps based on principles distilled from industrial best practices. Then, it grounds each candidate through a cascading, structure-aware RAG module. Next, it prunes false positives by analyzing call-stack logging responsibilities and implicit logger inheritance. Finally, it generates holistic and explainable logging patches that reflect real-world development practices. Our evaluation provides dual confirmation of its effectiveness: LogImprover significantly outperforms state-of-the-art baselines in closed-world experiments and achieves 68.12% developer acceptance rate in its real-world deployment. This success demonstrates the practical value of automating the entire logging quality improvement lifecycle, from discovery to recommendation.",
							"pageNumber": 3425,
							"isPageNumberRoman": false
						},
						{
							"eid": "Dj4u3ip0O7ZzS0GPu8zPT",
							"type": "authorPaper",
							"text": "From Redundancy to Efficiency: Exploiting Shared UI Interactions Towards Efficient LLM-Based Testing",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d437/573300d437.pdf",
							"extraLocations": [],
							"authorNames": "Xuan Wang (Fudan University, China), Yingchuan Wang (Fudan University, China), Yongxiang Hu (Fudan University, China), Yu Zhang (Meituan, China), Hailiang Jin (Meituan, China), Shiyu Guo (Meituan, China), Juxing Yuan (Meituan, China), Yangfan Zhou (Fudan University, China)",
							"abstract": "Redundant test cases, although well-studied in software engineering, are previously underexplored in UI testing of mobile apps. Our study of real-world test suites shows that, in large-scale testing suites, redundancy in UI testing often manifests as redundant UI interactions. Although negligible in traditional script-based workflows, such redundancy severely impacts the efficiency of emerging Large Language Model (LLM)-based UI agents, which incur substantial decision latency and token costs from repeated LLM queries for the same interactions. To this end, based on the idea of reusing LLMs' former decisions, we present TestWeaver, a cost-effective LLM-based testing framework. Leveraging a semantically annotated UI Transition Graph (UTG), TestWeaver is capable of detecting shared interactions across test cases. It processes each interaction with a single LLM query and reuses the result whenever the same interaction occurs. We evaluate TestWeaver on real-world test suites from Meituan. It achieves a 92% success rate with an average cost of $0.11 and 89.7 seconds per case, outperforming the state of the art. We have also deployed TestWeaver in a real-world testing workflow at Meituan for over six months. TestWeaver has executed nearly 2,000 test cases and uncovered 10 previously undetected bugs, while reducing manual testing effort by 75%.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 From Redundancy to Efficiency: Exploiting Shared UI Interactions Towards Efficient LLM-Based Testing 1759380090740 10.1109/ASE63991.2025.00284 Xuan Wang Fudan University, China xuanwang25@m.fudan.edu.cn Yingchuan Wang Fudan University, China yingchuanwang23@m.fudan.edu.cn Yongxiang Hu Fudan University, China yongxianghu23@m.fudan.edu.cn Yu Zhang Meituan, China zhangyu233@meituan.com Hailiang Jin Meituan, China jinhailiang@meituan.com Shiyu Guo Meituan, China guoshiyu03@meituan.com Juxing Yuan Meituan, China yuanjuxing@meituan.com Yangfan Zhou Fudan University, China zyf@fudan.edu.cn automatic ui testing large language models mobile apps cost optimization Redundant test cases, although well-studied in software engineering, are previously underexplored in UI testing of mobile apps. Our study of real-world test suites shows that, in large-scale testing suites, redundancy in UI testing often manifests as redundant UI interactions. Although negligible in traditional script-based workflows, such redundancy severely impacts the efficiency of emerging Large Language Model (LLM)-based UI agents, which incur substantial decision latency and token costs from repeated LLM queries for the same interactions. To this end, based on the idea of reusing LLMs' former decisions, we present TestWeaver, a cost-effective LLM-based testing framework. Leveraging a semantically annotated UI Transition Graph (UTG), TestWeaver is capable of detecting shared interactions across test cases. It processes each interaction with a single LLM query and reuses the result whenever the same interaction occurs. We evaluate TestWeaver on real-world test suites from Meituan. It achieves a 92% success rate with an average cost of $0.11 and 89.7 seconds per case, outperforming the state of the art. We have also deployed TestWeaver in a real-world testing workflow at Meituan for over six months. TestWeaver has executed nearly 2,000 test cases and uncovered 10 previously undetected bugs, while reducing manual testing effort by 75%.",
							"pageNumber": 3437,
							"isPageNumberRoman": false
						},
						{
							"eid": "5Lf88Ui9i4qEgSDTtpRAcP",
							"type": "authorPaper",
							"text": "Automated Prompt Generation for Code Intelligence: An Empirical Study and Experience in WeChat",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d449/573300d449.pdf",
							"extraLocations": [],
							"authorNames": "Kexing Ji (The Chinese University of Hong Kong, China), Shiyun Fu (The Chinese University of Hong Kong, China), Cuiyun Gao (The Chinese University of Hong Kong, China), Yujia Chen (The Chinese University of Hong Kong, China), Zezhou Yang (Tencent Inc., China), Chaozheng  Wang (Tencent Inc., China), Yuetang Deng (Tencent Inc., China)",
							"abstract": "Large Code Models (LCMs) have demonstrated potential in advancing various code intelligence tasks. However, their effectiveness can be greatly influenced by the quality of the prompts. Current prompt design strategies in code intelligence studies are mostly manually generated, which could be time-consuming and extremely rely on the base LCMs and tasks. Although automated prompt generation (APG) has been investigated in the natural language processing field, it has not attracted sufficient attention and been well explored in the code intelligence tasks. Considering the various tasks and black-box nature of LCMs faced by developers in practice, it is essential to automate the prompt generation process. To mitigate the gap, we empirically investigate the two important parts in APG, including Instruction Generation (IG) and Muti-Step Reasoning (MSR). The instruction generation part aims at providing a task-related description for instructing LCMs to effectively accomplish specific tasks; while the multi-step reasoning part aims at guiding LCMs to produce a series of logical steps before arriving at the final answer. For each part, we evaluate the widely-used APG methods on four open-source LCMs and three code intelligence tasks, i.e., code translation (PL-PL), code summarization (PL-NL) and API recommendation (NL-PL). Experimental results indicate that the two parts in APG can dramatically enhance the performance of the code intelligence tasks compared with the basic prompts. Based on the results, we further propose a novel APG approach by combining the best methods of the two studied parts of APG. Experiments show that the proposed APG approach achieves an average improvement of 28.38% with respect to CodeBLEU for the code translation, 58.11% in terms of ROUGE-L for the code summarization and 84.53% in SuccessRate@1 for the API recommendation over the basic prompts, respectively. To validate the effectiveness in industrial scenario, we further evaluate our approach on WeChat-Bench, a proprietary dataset from the WeChat Group in Tencent for API recommendation, achieving an average improvement of 148.89% in MRR.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Automated Prompt Generation for Code Intelligence: An Empirical Study and Experience in WeChat 1759382146717 10.1109/ASE63991.2025.00285 Kexing Ji The Chinese University of Hong Kong, China kexing1208@gmail.com Shiyun Fu The Chinese University of Hong Kong, China FuShiyun1@outlook.com Cuiyun Gao The Chinese University of Hong Kong, China cuiyungao@outlook.com Yujia Chen The Chinese University of Hong Kong, China yujiachenhit@gmail.com Zezhou Yang Tencent Inc., China zezhouyang@tencent.com Chaozheng Wang Tencent Inc., China adf111178@gmail.com Yuetang Deng Tencent Inc., China yuetangdeng@tencent.com automated prompting generation code intelligence large code models empirical study Large Code Models (LCMs) have demonstrated potential in advancing various code intelligence tasks. However, their effectiveness can be greatly influenced by the quality of the prompts. Current prompt design strategies in code intelligence studies are mostly manually generated, which could be time-consuming and extremely rely on the base LCMs and tasks. Although automated prompt generation (APG) has been investigated in the natural language processing field, it has not attracted sufficient attention and been well explored in the code intelligence tasks. Considering the various tasks and black-box nature of LCMs faced by developers in practice, it is essential to automate the prompt generation process. To mitigate the gap, we empirically investigate the two important parts in APG, including Instruction Generation (IG) and Muti-Step Reasoning (MSR). The instruction generation part aims at providing a task-related description for instructing LCMs to effectively accomplish specific tasks; while the multi-step reasoning part aims at guiding LCMs to produce a series of logical steps before arriving at the final answer. For each part, we evaluate the widely-used APG methods on four open-source LCMs and three code intelligence tasks, i.e., code translation (PL-PL), code summarization (PL-NL) and API recommendation (NL-PL). Experimental results indicate that the two parts in APG can dramatically enhance the performance of the code intelligence tasks compared with the basic prompts. Based on the results, we further propose a novel APG approach by combining the best methods of the two studied parts of APG. Experiments show that the proposed APG approach achieves an average improvement of 28.38% with respect to CodeBLEU for the code translation, 58.11% in terms of ROUGE-L for the code summarization and 84.53% in SuccessRate@1 for the API recommendation over the basic prompts, respectively. To validate the effectiveness in industrial scenario, we further evaluate our approach on WeChat-Bench, a proprietary dataset from the WeChat Group in Tencent for API recommendation, achieving an average improvement of 148.89% in MRR.",
							"pageNumber": 3449,
							"isPageNumberRoman": false
						},
						{
							"eid": "3ExT4BJHvp1jPb2mN0E66y",
							"type": "authorPaper",
							"text": "From Technical Excellence to Practical Adoption: Lessons Learned Building an ML-Enhanced Trace Analysis Tool",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d461/573300d461.pdf",
							"extraLocations": [],
							"authorNames": "Kaveh Shahedi (Polytechnique Montr\u00E9al, Canada), Matthew Khouzam (Ericsson AB, Canada), Heng Li (Polytechnique Montr\u00E9al, Canada), Maxime Lamothe (Polytechnique Montr\u00E9al, Canada), Foutse Khomh (Polytechnique Montr\u00E9al, Canada)",
							"abstract": "System tracing has become essential for understanding complex software behavior in modern systems, yet sophisticated trace analysis tools face significant adoption gaps in industrial settings. Through a year-long collaboration with Ericsson Montr\u00E9al, developing TMLL (Trace-Server Machine Learning Library, now in the Eclipse Foundation), we investigated barriers to trace analysis adoption. Contrary to assumptions about complexity or automation needs, practitioners struggled with translating expert knowledge into actionable insights, integrating analysis into their workflows, and trusting automated results that they could not validate. We identified what we called the Excellence Paradox: technical excellence can actively impede adoption when conflicting with usability, transparency, and practitioner trust. TMLL addresses this through an adoption-focused design that embeds expert knowledge in interfaces, provides transparent explanations, and enables incremental adoption. Validation through Ericsson's experts' feedback, Eclipse Foundation's integration, and a survey of 40 industry and academic professionals revealed consistent patterns: survey results showed that 77.5% prioritize quality and trust in results over technical sophistication, while 67.5% prefer semi-automated analysis with user control, findings supported by qualitative feedback from industrial collaboration and external peer review. Results validate three core principles: cognitive compatibility, embedded expertise, and transparency-based trust. This challenges conventional capability-focused tool development, demonstrating that sustainable adoption requires reorientation toward adoption-focused design with actionable implications for automated software engineering tools.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 From Technical Excellence to Practical Adoption: Lessons Learned Building an ML-Enhanced Trace Analysis Tool 1759345959815 10.1109/ASE63991.2025.00286 Kaveh Shahedi Polytechnique Montr\u00E9al, Canada kaveh.shahedi@polymtl.ca Matthew Khouzam Ericsson AB, Canada matthew.khouzam@ericsson.com Heng Li Polytechnique Montr\u00E9al, Canada heng.li@polymtl.ca Maxime Lamothe Polytechnique Montr\u00E9al, Canada maxime.lamothe@polymtl.ca Foutse Khomh Polytechnique Montr\u00E9al, Canada foutse.khomh@polymtl.ca software engineering performance engineering tracing instrumentation machine learning tool development System tracing has become essential for understanding complex software behavior in modern systems, yet sophisticated trace analysis tools face significant adoption gaps in industrial settings. Through a year-long collaboration with Ericsson Montr\u00E9al, developing TMLL (Trace-Server Machine Learning Library, now in the Eclipse Foundation), we investigated barriers to trace analysis adoption. Contrary to assumptions about complexity or automation needs, practitioners struggled with translating expert knowledge into actionable insights, integrating analysis into their workflows, and trusting automated results that they could not validate. We identified what we called the Excellence Paradox: technical excellence can actively impede adoption when conflicting with usability, transparency, and practitioner trust. TMLL addresses this through an adoption-focused design that embeds expert knowledge in interfaces, provides transparent explanations, and enables incremental adoption. Validation through Ericsson's experts' feedback, Eclipse Foundation's integration, and a survey of 40 industry and academic professionals revealed consistent patterns: survey results showed that 77.5% prioritize quality and trust in results over technical sophistication, while 67.5% prefer semi-automated analysis with user control, findings supported by qualitative feedback from industrial collaboration and external peer review. Results validate three core principles: cognitive compatibility, embedded expertise, and transparency-based trust. This challenges conventional capability-focused tool development, demonstrating that sustainable adoption requires reorientation toward adoption-focused design with actionable implications for automated software engineering tools.",
							"pageNumber": 3461,
							"isPageNumberRoman": false
						},
						{
							"eid": "6C0o6QfbwEyLy6tmTwTiO5",
							"type": "authorPaper",
							"text": "Evaluating Large Language Models for Functional and Maintainable Code in Industrial Settings: A Case Study at ASML",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d474/573300d474.pdf",
							"extraLocations": [],
							"authorNames": "Yash Mundhra (Delft University of Technology, The Netherlands), Max Valk (ASML, Netherlands), Maliheh Izadi (Delft University of Technology, The Netherlands)",
							"abstract": "Large language models have shown impressive performance in various domains, including code generation across diverse open-source domains. However, their applicability in proprietary industrial settings, where domain-specific constraints and code interdependencies are prevalent, remains largely unexplored. We present a case study conducted in collaboration with the leveling department at ASML to investigate the performance of LLMs in generating functional, maintainable code within a closed, highly specialized software environment. We developed an evaluation framework tailored to ASML's proprietary codebase and introduced a new benchmark. Additionally, we proposed a new evaluation metric, build@k, to assess whether LLM-generated code successfully compiles and integrates within real industrial repositories. We investigate various prompting techniques, compare the performance of generic and code-specific LLMs, and examine the impact of model size on code generation capabilities, using both match-based and execution-based metrics. The findings reveal that prompting techniques and model size have a significant impact on output quality, with few-shot and chain-of-thought prompting yielding the highest build success rates. The difference in performance between the code-specific LLMs and generic LLMs was less pronounced and varied substantially across different model families.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Evaluating Large Language Models for Functional and Maintainable Code in Industrial Settings: A Case Study at ASML 1759416981328 10.1109/ASE63991.2025.00287 Yash Mundhra Delft University of Technology, The Netherlands y.mundhra@student.tudelft.nl Max Valk ASML, Netherlands max.valk@asml.com Maliheh Izadi Delft University of Technology, The Netherlands m.izadi@tudelft.nl code generation large language models llm prompting techniques few-shot chain-of-thought evaluation Large language models have shown impressive performance in various domains, including code generation across diverse open-source domains. However, their applicability in proprietary industrial settings, where domain-specific constraints and code interdependencies are prevalent, remains largely unexplored. We present a case study conducted in collaboration with the leveling department at ASML to investigate the performance of LLMs in generating functional, maintainable code within a closed, highly specialized software environment. We developed an evaluation framework tailored to ASML's proprietary codebase and introduced a new benchmark. Additionally, we proposed a new evaluation metric, build@k, to assess whether LLM-generated code successfully compiles and integrates within real industrial repositories. We investigate various prompting techniques, compare the performance of generic and code-specific LLMs, and examine the impact of model size on code generation capabilities, using both match-based and execution-based metrics. The findings reveal that prompting techniques and model size have a significant impact on output quality, with few-shot and chain-of-thought prompting yielding the highest build success rates. The difference in performance between the code-specific LLMs and generic LLMs was less pronounced and varied substantially across different model families.",
							"pageNumber": 3474,
							"isPageNumberRoman": false
						},
						{
							"eid": "5jI1dyEJ6wBbE1XIhBwsXu",
							"type": "authorPaper",
							"text": "BitsAI-Fix: LLM-Driven Approach for Automated Lint Error Resolution in Practice",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d485/573300d485.pdf",
							"extraLocations": [],
							"authorNames": "Yuanpeng Li (Bytedance, China), Qi Long (Carnegie Mellon University, United States), Zhiyuan Yao (Zhejiang University, China), Jian Xu (ByteDance, China), Lintao Xie (ByteDance, China), Xu He (ByteDance, China), Lu Geng (ByteDance, China), Xin Han (ByteDance, China), Yueyan Chen (ByteDance, China), Wenbo Duan (ByteDance, China)",
							"abstract": "As enterprise codebases continue to grow in scale and complexity, the volume of lint errors far exceeds engineers' manual remediation capacity, leading to continuous accumulation of technical debt and hindered development efficiency. This paper presents BitsAI-Fix, an automated lint error remediation workflow based on Large Language Models (LLMs), designed to address this critical challenge in industrial-scale environments. BitsAI-Fix employs tree-sitter for context expansion and generates search-and-replace format patches through specially trained LLMs, followed by lint scan re-verification to output final remediation results. Additionally, our approach introduces an innovative progressive reinforcement learning (RL) training strategy that can automatically acquire verifiable training data during the project cold-start phase and continuously iterate the model by collecting online samples through feedback after system deployment. Furthermore, we designed a targeted rule-based reward mechanism that combines format rewards and correctness rewards while penalizing redundant modifications. We also propose a \"code diff matching\" methodology to continuously track online effectiveness. In production deployment at ByteDance, our solution has supported over 5,000 engineers, resolved more than 12,000 static analysis issues, achieved approximately 85% remediation accuracy, with around 1,000 weekly active adopters. This work demonstrates the practical feasibility of LLM-based code remediation solutions in enterprise environments and serves as a reference for automated code fix in large-scale industrial scenarios.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 BitsAI-Fix: LLM-Driven Approach for Automated Lint Error Resolution in Practice 1759066975688 10.1109/ASE63991.2025.00288 Yuanpeng Li Bytedance, China liyuanpeng.meta@bytedance.com Qi Long Carnegie Mellon University, United States qilong@andrew.cmu.edu Zhiyuan Yao Zhejiang University, China yaozhiyuan@zju.edu.cn Jian Xu ByteDance, China xujian.1502@bytedance.com Lintao Xie ByteDance, China xielintao@bytedance.com Xu He ByteDance, China hexu.324@bytedance.com Lu Geng ByteDance, China genglu.32@bytedance.com Xin Han ByteDance, China hanxin.hx@bytedance.com Yueyan Chen ByteDance, China chenyueyan@bytedance.com Wenbo Duan ByteDance, China duanwenbo@bytedance.com lint error automated program repair large language model reinforcement learning As enterprise codebases continue to grow in scale and complexity, the volume of lint errors far exceeds engineers' manual remediation capacity, leading to continuous accumulation of technical debt and hindered development efficiency. This paper presents BitsAI-Fix, an automated lint error remediation workflow based on Large Language Models (LLMs), designed to address this critical challenge in industrial-scale environments. BitsAI-Fix employs tree-sitter for context expansion and generates search-and-replace format patches through specially trained LLMs, followed by lint scan re-verification to output final remediation results. Additionally, our approach introduces an innovative progressive reinforcement learning (RL) training strategy that can automatically acquire verifiable training data during the project cold-start phase and continuously iterate the model by collecting online samples through feedback after system deployment. Furthermore, we designed a targeted rule-based reward mechanism that combines format rewards and correctness rewards while penalizing redundant modifications. We also propose a \"code diff matching\" methodology to continuously track online effectiveness. In production deployment at ByteDance, our solution has supported over 5,000 engineers, resolved more than 12,000 static analysis issues, achieved approximately 85% remediation accuracy, with around 1,000 weekly active adopters. This work demonstrates the practical feasibility of LLM-based code remediation solutions in enterprise environments and serves as a reference for automated code fix in large-scale industrial scenarios.",
							"pageNumber": 3485,
							"isPageNumberRoman": false
						},
						{
							"eid": "xstB8UkJcLRmqCGbuz808",
							"type": "authorPaper",
							"text": "Adaptive Performance Regression Detection Using A Semi-Supervised Siamese Network",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d497/573300d497.pdf",
							"extraLocations": [],
							"authorNames": "Yongqian Sun (Nankai University; Tianjin Key Laboratory of Software Experience and Human Computer Interaction), Mengyao Li (Nankai University), Xiao Xiong (Nankai University), Lei Tao (Nankai University), Yimin Zuo (Nankai University), Wenwei Gu (Nankai University), Shenglin Zhang (Nankai University; Ministry of Education, China), Junhua Kuang (Nankai University), Yu Luo (Nankai University), Huandong Zhuang (Huawei Cloud), Bowen Deng (Huawei Cloud), Dan Pei (Tsinghua University)",
							"abstract": "Timely detection of performance regression issues is critical to ensuring the stability and user experience of software systems. Traditional methods often rely on high-quality annotated data or data distribution assumptions, which cannot effectively adapt to performance changes in dynamic workload environments. To solve this problem, we propose DynamicRegress, a performance regression detection method based on Siamese network and semi-supervised learning. DynamicRegress integrates multi-dimensional key performance indicators (KPIs) with workload context to accurately characterize system states and detect performance regressions in real time. By employing a dual weight-shared LSTM network, DynamicRegress reduces training complexity while retaining strong feature extraction capabilities. Data augmentation and a weighted loss function are incorporated to enhance the learning of minority regression cases, mitigating the class imbalance issue. Additionally, a semi-supervised learning strategy generates high-quality pseudo-labels to expand the training dataset, effectively addressing the challenge of limited labeled data. Experiments on production data from a top-tier global cloud service provider demonstrate that DynamicRegress achieves a superior F1 Score of 0.958 (outperforming the best baseline method by 0.282) while maintaining a low detection latency of 0.006 seconds per KPI pair. DynamicRegress provides a robust adaptive solution for performance regression detection in dynamic and complex software systems, and we have made the code publicly available to facilitate further research.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Adaptive Performance Regression Detection Using A Semi-Supervised Siamese Network 1759276626306 10.1109/ASE63991.2025.00289 Yongqian Sun Nankai University; Tianjin Key Laboratory of Software Experience and Human Computer Interaction sunyongqian@nankai.edu.cn Mengyao Li Nankai University limengyao@mail.nankai.edu.cn Xiao Xiong Nankai University xiongxiao@mail.nankai.edu.cn Lei Tao Nankai University leitao@mail.nankai.edu.cn Yimin Zuo Nankai University 2213023@mail.nankai.edu.cn Wenwei Gu Nankai University wwgu@nankai.edu.cn Shenglin Zhang Nankai University; Ministry of Education, China zhangsl@nankai.edu.cn Junhua Kuang Nankai University 2120240797@mail.nankai.edu.cn Yu Luo Nankai University 2111934@mail.nankai.edu.cn Huandong Zhuang Huawei Cloud zhuanghuandong@huawei.com Bowen Deng Huawei Cloud dengbowen10@huawei.com Dan Pei Tsinghua University peidan@tsinghua.edu.cn performance regression detection siamese network semi-supervised learning Timely detection of performance regression issues is critical to ensuring the stability and user experience of software systems. Traditional methods often rely on high-quality annotated data or data distribution assumptions, which cannot effectively adapt to performance changes in dynamic workload environments. To solve this problem, we propose DynamicRegress, a performance regression detection method based on Siamese network and semi-supervised learning. DynamicRegress integrates multi-dimensional key performance indicators (KPIs) with workload context to accurately characterize system states and detect performance regressions in real time. By employing a dual weight-shared LSTM network, DynamicRegress reduces training complexity while retaining strong feature extraction capabilities. Data augmentation and a weighted loss function are incorporated to enhance the learning of minority regression cases, mitigating the class imbalance issue. Additionally, a semi-supervised learning strategy generates high-quality pseudo-labels to expand the training dataset, effectively addressing the challenge of limited labeled data. Experiments on production data from a top-tier global cloud service provider demonstrate that DynamicRegress achieves a superior F1 Score of 0.958 (outperforming the best baseline method by 0.282) while maintaining a low detection latency of 0.006 seconds per KPI pair. DynamicRegress provides a robust adaptive solution for performance regression detection in dynamic and complex software systems, and we have made the code publicly available to facilitate further research.",
							"pageNumber": 3497,
							"isPageNumberRoman": false
						},
						{
							"eid": "7onVT1aBto6mE8lwVS31mG",
							"type": "authorPaper",
							"text": "TreeRanker: Fast and Model-Agnostic Ranking System for Code Suggestions in IDEs",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d509/573300d509.pdf",
							"extraLocations": [],
							"authorNames": "Daniele Cipollone (JetBrains, The Netherlands; Delft University of Technology, The Netherlands), Egor Bogomolov (JetBrains Research, The Netherlands), Arie van Deursen (Delft University of Technology, The Netherlands), Maliheh Izadi (Delft University of Technology, The Netherlands)",
							"abstract": "Token-level code completion is one of the most critical features in modern Integrated Development Environments (IDEs). It assists developers by suggesting relevant identifiers and APIs during coding. While completions are typically derived from static analysis, their usefulness depends heavily on how they are ranked, as correct predictions buried deep in the list are rarely seen by users. Most current systems rely on hand-crafted heuristics or lightweight machine learning models trained on user logs, which can be further improved to capture context information and generalize across projects and coding styles. In this work, we propose a new scoring approach to ranking static completions using language models in a lightweight and model-agnostic way. Our method organizes all valid completions into a prefix tree and performs a single greedy decoding pass to collect token-level scores across the tree. This enables a precise token-aware ranking without needing beam search, prompt engineering, or model adaptations. The approach is fast, architecture-agnostic, and compatible with already deployed models for code completion. These findings highlight a practical and effective pathway for integrating language models into already existing tools within IDEs, and ultimately providing smarter and more responsive developer assistance.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 TreeRanker: Fast and Model-Agnostic Ranking System for Code Suggestions in IDEs 1759301172649 10.1109/ASE63991.2025.00290 Daniele Cipollone JetBrains, The Netherlands; Delft University of Technology, The Netherlands d.cipollone@tudelft.nl Egor Bogomolov JetBrains Research, The Netherlands egor.bogomolov@jetbrains.com Arie van Deursen Delft University of Technology, The Netherlands arie.vandeursen@tudelft.nl Maliheh Izadi Delft University of Technology, The Netherlands m.izadi@tudelft.nl ranking code suggestions language models integrated development environments ides Token-level code completion is one of the most critical features in modern Integrated Development Environments (IDEs). It assists developers by suggesting relevant identifiers and APIs during coding. While completions are typically derived from static analysis, their usefulness depends heavily on how they are ranked, as correct predictions buried deep in the list are rarely seen by users. Most current systems rely on hand-crafted heuristics or lightweight machine learning models trained on user logs, which can be further improved to capture context information and generalize across projects and coding styles. In this work, we propose a new scoring approach to ranking static completions using language models in a lightweight and model-agnostic way. Our method organizes all valid completions into a prefix tree and performs a single greedy decoding pass to collect token-level scores across the tree. This enables a precise token-aware ranking without needing beam search, prompt engineering, or model adaptations. The approach is fast, architecture-agnostic, and compatible with already deployed models for code completion. These findings highlight a practical and effective pathway for integrating language models into already existing tools within IDEs, and ultimately providing smarter and more responsive developer assistance.",
							"pageNumber": 3509,
							"isPageNumberRoman": false
						},
						{
							"eid": "3A6Ercb9ghB0zD3h9gqDoK",
							"type": "authorPaper",
							"text": "Evaluating Large Language Models for Time Series Anomaly Detection in Aerospace Software",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d521/573300d521.pdf",
							"extraLocations": [],
							"authorNames": "Yang Liu (Beijing Institute of Control Engineering, China), Yixing Luo (Beijing Institute of Control Engineering, China), Xiaofeng Li (Beijing Institute of Control Engineering, China), Xiaogang Dong (Beijing Institute of Control Engineering, China), Bin Gu (Beijing Institute of Control Engineering, China), Zhi Jin (Peking University, China)",
							"abstract": "Time series anomaly detection (TSAD) is essential for ensuring the safety and reliability of aerospace software systems. Although large language models (LLMs) provide a promising training-free alternative to unsupervised approaches, their effectiveness in aerospace settings remains under-examined because of complex telemetry, misaligned evaluation metrics, and the absence of domain knowledge. To address this gap, we introduce TSADBench, the first benchmark for aerospace TSAD. TSADBench comprises nine tasks that combine three pattern-wise anomaly types, univariate and multivariate signals, and both in-loop and out-of-loop feedback scenarios, yielding 108,000 data points. Using this benchmark, we systematically evaluate state-of-the-art open-source LLMs under two paradigms: Direct, which labels anomalies within sliding windows, and Prediction-Based, which detects anomalies from prediction errors. To reflect operational needs, we reformulate evaluation at the window level and propose three user-oriented metrics: Alarm Accuracy (AA), Alarm Latency (AL), and Alarm Contiguity (AC), which quantify alarm correctness, timeliness, and credibility. We further examine two enhancement strategies, few-shot learning and retrieval-augmented generation (RAG), to inject domain knowledge. The evaluation results show that (1) LLMs perform well on univariate tasks but struggle with multivariate telemetry, (2) their AA and AC on multivariate tasks approach random guessing, (3) few-shot learning provides modest gains whereas RAG offers no significant improvement, and (4) in practice LLMs can detect true anomaly onsets yet sometimes raise false alarms, which few-shot prompting mitigates but RAG exacerbates. These findings offer guidance for future LLM-based TSAD in aerospace software.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Evaluating Large Language Models for Time Series Anomaly Detection in Aerospace Software 1759045360498 10.1109/ASE63991.2025.00291 Yang Liu Beijing Institute of Control Engineering, China liuyang12339@163.com Yixing Luo Beijing Institute of Control Engineering, China luoyi_xing@126.com Xiaofeng Li Beijing Institute of Control Engineering, China li_x_feng@126.com Xiaogang Dong Beijing Institute of Control Engineering, China dongxiaogang@263.net Bin Gu Beijing Institute of Control Engineering, China gubinbj@sina.com Zhi Jin Peking University, China zhijin@pku.edu.cn time series anomaly detection large language model aerospace software Time series anomaly detection (TSAD) is essential for ensuring the safety and reliability of aerospace software systems. Although large language models (LLMs) provide a promising training-free alternative to unsupervised approaches, their effectiveness in aerospace settings remains under-examined because of complex telemetry, misaligned evaluation metrics, and the absence of domain knowledge. To address this gap, we introduce TSADBench, the first benchmark for aerospace TSAD. TSADBench comprises nine tasks that combine three pattern-wise anomaly types, univariate and multivariate signals, and both in-loop and out-of-loop feedback scenarios, yielding 108,000 data points. Using this benchmark, we systematically evaluate state-of-the-art open-source LLMs under two paradigms: Direct, which labels anomalies within sliding windows, and Prediction-Based, which detects anomalies from prediction errors. To reflect operational needs, we reformulate evaluation at the window level and propose three user-oriented metrics: Alarm Accuracy (AA), Alarm Latency (AL), and Alarm Contiguity (AC), which quantify alarm correctness, timeliness, and credibility. We further examine two enhancement strategies, few-shot learning and retrieval-augmented generation (RAG), to inject domain knowledge. The evaluation results show that (1) LLMs perform well on univariate tasks but struggle with multivariate telemetry, (2) their AA and AC on multivariate tasks approach random guessing, (3) few-shot learning provides modest gains whereas RAG offers no significant improvement, and (4) in practice LLMs can detect true anomaly onsets yet sometimes raise false alarms, which few-shot prompting mitigates but RAG exacerbates. These findings offer guidance for future LLM-based TSAD in aerospace software.",
							"pageNumber": 3521,
							"isPageNumberRoman": false
						},
						{
							"eid": "1JYp5NC448m0zJSfHium9u",
							"type": "authorPaper",
							"text": "ErrorPrism: Reconstructing Error Propagation Paths in Cloud Service Systems",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d533/573300d533.pdf",
							"extraLocations": [],
							"authorNames": "Junsong Pu (Sun Yat-sen University, China), Yichen Li (ByteDance), Zhuangbin Chen (Sun Yat-sen University, China), Jinyang Liu (ByteDance), Zhihan Jiang (The Chinese University of Hong Kong, China), Jianjun Chen (Bytedance), Rui Shi (Bytedance), Zibin Zheng (Sun Yat-sen University, China), Tieying Zhang (ByteDance)",
							"abstract": "Reliability management in cloud service systems is challenging due to the cascading effect of failures. Error wrapping, a practice prevalent in modern microservice development, enriches errors with context at each layer of the function call stack, constructing an error chain that describes a failure from its technical origin to its business impact. However, this also presents a significant traceability problem when recovering the complete error propagation path from the final log message back to its source. Existing approaches are ineffective at addressing this problem. To fill this gap, we present ErrorPrism in this work for automated reconstruction of error propagation paths in production microservice systems. ErrorPrism first performs static analysis on service code repositories to build a function call graph and map log strings to relevant candidate functions. This significantly reduces the path search space for subsequent analysis. Then, ErrorPrism employs an LLM agent to perform an iterative backward search to accurately reconstruct the complete, multi-hop error path. Evaluated on 67 production microservices at ByteDance, ErrorPrism achieves 97.0% accuracy in reconstructing paths for 102 real-world errors, outperforming existing static analysis and LLM-based approaches. ErrorPrism provides an effective and practical tool for root cause analysis in industrial microservice systems.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 ErrorPrism: Reconstructing Error Propagation Paths in Cloud Service Systems 1759316176776 10.1109/ASE63991.2025.00292 Junsong Pu Sun Yat-sen University, China pujs@mail2.sysu.edu.cn Yichen Li ByteDance liyichen.325@bytedance.com Zhuangbin Chen Sun Yat-sen University, China chenzhb36@mail.sysu.edu.cn Jinyang Liu ByteDance jinyang.liu@bytedance.com Zhihan Jiang The Chinese University of Hong Kong, China zhjiang22@cse.cuhk.edu.hk Jianjun Chen Bytedance jianjun.chen@bytedance.com Rui Shi Bytedance shirui@bytedance.com Zibin Zheng Sun Yat-sen University, China zhzibin@mail.sysu.edu.cn Tieying Zhang ByteDance tieying.zhang@bytedance.com cloud computing system reliability root cause analysis error tracking log analysis Reliability management in cloud service systems is challenging due to the cascading effect of failures. Error wrapping, a practice prevalent in modern microservice development, enriches errors with context at each layer of the function call stack, constructing an error chain that describes a failure from its technical origin to its business impact. However, this also presents a significant traceability problem when recovering the complete error propagation path from the final log message back to its source. Existing approaches are ineffective at addressing this problem. To fill this gap, we present ErrorPrism in this work for automated reconstruction of error propagation paths in production microservice systems. ErrorPrism first performs static analysis on service code repositories to build a function call graph and map log strings to relevant candidate functions. This significantly reduces the path search space for subsequent analysis. Then, ErrorPrism employs an LLM agent to perform an iterative backward search to accurately reconstruct the complete, multi-hop error path. Evaluated on 67 production microservices at ByteDance, ErrorPrism achieves 97.0% accuracy in reconstructing paths for 102 real-world errors, outperforming existing static analysis and LLM-based approaches. ErrorPrism provides an effective and practical tool for root cause analysis in industrial microservice systems.",
							"pageNumber": 3533,
							"isPageNumberRoman": false
						},
						{
							"eid": "4qf3wsz0PFWJKN26UhfXoN",
							"type": "authorPaper",
							"text": "LLM-Assisted Industrial-Scale Differential Testing of Package Incompatibilities in Linux Distributions",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d545/573300d545.pdf",
							"extraLocations": [],
							"authorNames": "Yuhao Yang (Central South University, China), Chijin Zhou (East China Normal University, China; Tsinghua University, China), Runzhe Wang (Alibaba Co., Ltd, China), Weibo Zhang (Central South University, China), Yuheng Shen (Tsinghua University, China), Xiaohai Shi (Alibaba Co., Ltd, China), Tao Ma (Alibaba Co., Ltd, China), Chang Gao (Alibaba Co., Ltd, China), Zhe Wang (Alibaba Co., Ltd, China), Ying Fu (Tsinghua University, China), Heyuan Shi (Central South University, China)",
							"abstract": "An open source Linux distribution often undergoes version upgrades and migrations, which is prone to incompatibility issues especially when it comes to large-scale software changes. Although differential testing has been widely used in software testing, it is still challenging to apply it for detecting such incompatibilities in the context of industrial settings. In this paper, we report our experience in leveraging LLMs to address the challenges faced by the Linux distribution community. Specifically, we develop an LLM-based differential testing method called Versify to assist maintainers of Linux distributions in locating incompatibilities during version upgrades and migrations. Its trial operation period within the Linux distribution community shows that it uncovered 8,489 instances of differing behavior, of which 644 were prioritized for attention by developers. After deduplication and filtering, 39 unique compatibility reports were identified. Feedback from Linux distributions developers indicates that our reports have provided valuable recommendations for package selection in future OS releases.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 LLM-Assisted Industrial-Scale Differential Testing of Package Incompatibilities in Linux Distributions 1759401098935 10.1109/ASE63991.2025.00293 Yuhao Yang Central South University, China young_est@163.com Chijin Zhou East China Normal University, China; Tsinghua University, China tlock.chijin@gmail.com Runzhe Wang Alibaba Co., Ltd, China runzhe.wrz@alibaba-inc.com Weibo Zhang Central South University, China zhangweibo@csu.edu.cn Yuheng Shen Tsinghua University, China shenyh20@mails.tsinghua.edu.cn Xiaohai Shi Alibaba Co., Ltd, China xiaohai.sxh@alibaba-inc.com Tao Ma Alibaba Co., Ltd, China boyu.mt@taobao.com Chang Gao Alibaba Co., Ltd, China gc-taifu@linux.alibaba.com Zhe Wang Alibaba Co., Ltd, China wanglan.wz@alibaba-inc.com Ying Fu Tsinghua University, China fuying1995@foxmail.com Heyuan Shi Central South University, China hey.shi@foxmail.com differential testing software test large language model linux distribution An open source Linux distribution often undergoes version upgrades and migrations, which is prone to incompatibility issues especially when it comes to large-scale software changes. Although differential testing has been widely used in software testing, it is still challenging to apply it for detecting such incompatibilities in the context of industrial settings. In this paper, we report our experience in leveraging LLMs to address the challenges faced by the Linux distribution community. Specifically, we develop an LLM-based differential testing method called Versify to assist maintainers of Linux distributions in locating incompatibilities during version upgrades and migrations. Its trial operation period within the Linux distribution community shows that it uncovered 8,489 instances of differing behavior, of which 644 were prioritized for attention by developers. After deduplication and filtering, 39 unique compatibility reports were identified. Feedback from Linux distributions developers indicates that our reports have provided valuable recommendations for package selection in future OS releases.",
							"pageNumber": 3545,
							"isPageNumberRoman": false
						},
						{
							"eid": "44a0D21QY9zfm5L4vOEeLI",
							"type": "authorPaper",
							"text": "Shrunk, Yet Complete: Code Shrinking-Resilient Android Third-Party Library Detection",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d556/573300d556.pdf",
							"extraLocations": [],
							"authorNames": "Jingkun Zhang (Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China), Jingzheng Wu (Chinese Academy of Sciences, China), Xiang Ling (Chinese Academy of Sciences, China), Tianyue Luo (Chinese Academy of Sciences, China), Bolin Zhou (Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China), Mutian Yang (Beijing VuLab Technology Co.Ltd, China)",
							"abstract": "Managing third-party libraries is a costly and critical task for enterprises, essential for both vulnerability assessment and license compliance. Existing android software composition analysis tools focus on mitigating code obfuscation but neglect the impact of code optimization, which is deeply integrated into build pipelines and disrupts library structure. To tackle these challenges, we developed LibSleuth, a detection tool designed to be resilient to code shrinking and obfuscation. It is based on the observation that even after shrinking, the remaining code still retains functional completeness. LibSleuth adopts two novel strategies: (1) Method level functional module matching: We break down feature matching to method level and define a functional module as related methods that represent used functionality. This allows us to detect libraries based on functional module completeness to address code shrinking. (2) Context-enhanced multi-level filtering: To improve robustness against obfuscation and reduce the cost of pairing, LibSleuth leverages contextual relationships to enhance feature stability and adopts a coarse-to-fine progressive matching process. We evaluated LibSleuth on datasets containing obfuscated and optimized Android apps. LibSleuth outperforms state-of-the-art academic and commercial tools in both scenarios. Under combined code shrinking and obfuscation, LibSleuth achieves an average 27.74% higher version level F1-score. Moreover, our analysis of 10,000 real world Android apps shows that 20.35% still depend on vulnerable library, demonstrating the practical utility of LibSleuth for downstream tasks.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Shrunk, Yet Complete: Code Shrinking-Resilient Android Third-Party Library Detection 1759331013777 10.1109/ASE63991.2025.00294 Jingkun Zhang Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China zhangjingkun23@mails.ucas.ac.cn Jingzheng Wu Chinese Academy of Sciences, China jingzheng08@iscas.ac.cn Xiang Ling Chinese Academy of Sciences, China lingxiang@iscas.ac.cn Tianyue Luo Chinese Academy of Sciences, China tianyue@iscas.ac.cn Bolin Zhou Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China zhoubolin22@mails.ucas.ac.cn Mutian Yang Beijing VuLab Technology Co.Ltd, China mutian@vulab.com.cn android third-party library software composition analysis code obfuscation code shrinking Managing third-party libraries is a costly and critical task for enterprises, essential for both vulnerability assessment and license compliance. Existing android software composition analysis tools focus on mitigating code obfuscation but neglect the impact of code optimization, which is deeply integrated into build pipelines and disrupts library structure. To tackle these challenges, we developed LibSleuth, a detection tool designed to be resilient to code shrinking and obfuscation. It is based on the observation that even after shrinking, the remaining code still retains functional completeness. LibSleuth adopts two novel strategies: (1) Method level functional module matching: We break down feature matching to method level and define a functional module as related methods that represent used functionality. This allows us to detect libraries based on functional module completeness to address code shrinking. (2) Context-enhanced multi-level filtering: To improve robustness against obfuscation and reduce the cost of pairing, LibSleuth leverages contextual relationships to enhance feature stability and adopts a coarse-to-fine progressive matching process. We evaluated LibSleuth on datasets containing obfuscated and optimized Android apps. LibSleuth outperforms state-of-the-art academic and commercial tools in both scenarios. Under combined code shrinking and obfuscation, LibSleuth achieves an average 27.74% higher version level F1-score. Moreover, our analysis of 10,000 real world Android apps shows that 20.35% still depend on vulnerable library, demonstrating the practical utility of LibSleuth for downstream tasks.",
							"pageNumber": 3556,
							"isPageNumberRoman": false
						},
						{
							"eid": "6AEuVVYMUnLXcZSVp55nSf",
							"type": "authorPaper",
							"text": "Tuning LLM-Based Code Optimization via Meta-Prompting: An Industrial Perspective",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d568/573300d568.pdf",
							"extraLocations": [],
							"authorNames": "Jingzhi Gong (University of Leeds, UK; TurinTech AI, UK), Rafail Giavrimis (University of Surrey, UK; TurinTech AI, UK), Paul Brookes (TurinTech AI, UK), Vardan Voskanyan (TurinTech AI, UK), Fan Wu (TurinTech AI, UK), Mari Ashiga (University of West London, UK; TurinTech AI, UK), Matthew Truscott (TurinTech AI, UK), Mike Basios (TurinTech AI, UK), Leslie Kanthan (TurinTech AI, UK), Jie Xu (University of Leeds, UK), Zheng Wang (University of Leeds, UK)",
							"abstract": "There is a growing interest in leveraging multiple large language models (LLMs) for automated code optimization. However, industrial platforms deploying multiple LLMs face a critical challenge: prompts optimized for one LLM often fail with others, requiring expensive model-specific prompt engineering. This cross-model prompt engineering bottleneck severely limits the practical deployment of multi-LLM systems in production environments. We introduce Meta-Prompted Code Optimization (MPCO), a framework that automatically generates high-quality, task-specific prompts across diverse LLMs while maintaining industrial efficiency requirements. MPCO leverages metaprompting to dynamically synthesize context-aware optimization prompts by integrating project metadata, task requirements, and LLM-specific contexts. It is an essential part of the ARTEMIS code optimization platform for automated validation and scaling. Our comprehensive evaluation on five real-world codebases with 366 hours of runtime benchmarking demonstrates MPCO's effectiveness: it achieves overall performance improvements up to 19.06% with the best statistical rank across all systems compared to baseline methods. Analysis shows that 96% of the top-performing optimizations stem from meaningful edits. Through systematic ablation studies and meta-prompter sensitivity analysis, we identify that comprehensive context integration is essential for effective meta-prompting and that major LLMs can serve effectively as meta-prompters, providing actionable insights for industrial practitioners.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Tuning LLM-Based Code Optimization via Meta-Prompting: An Industrial Perspective 1759253994279 10.1109/ASE63991.2025.00295 Jingzhi Gong University of Leeds, UK; TurinTech AI, UK J.Gong@leeds.ac.uk Rafail Giavrimis University of Surrey, UK; TurinTech AI, UK rafail@turintech.ai Paul Brookes TurinTech AI, UK paul@turintech.ai Vardan Voskanyan TurinTech AI, UK vardan@turintech.ai Fan Wu TurinTech AI, UK fan@turintech.ai Mari Ashiga University of West London, UK; TurinTech AI, UK mari.ashiga@uwl.ac.uk Matthew Truscott TurinTech AI, UK matthew.truscott@turintech.ai Mike Basios TurinTech AI, UK mike@turintech.ai Leslie Kanthan TurinTech AI, UK leslie@turintech.ai Jie Xu University of Leeds, UK j.xu@leeds.ac.uk Zheng Wang University of Leeds, UK z.wang5@leeds.ac.uk meta-prompting code optimization prompt engineering performance optimization llm4code ai4se There is a growing interest in leveraging multiple large language models (LLMs) for automated code optimization. However, industrial platforms deploying multiple LLMs face a critical challenge: prompts optimized for one LLM often fail with others, requiring expensive model-specific prompt engineering. This cross-model prompt engineering bottleneck severely limits the practical deployment of multi-LLM systems in production environments. We introduce Meta-Prompted Code Optimization (MPCO), a framework that automatically generates high-quality, task-specific prompts across diverse LLMs while maintaining industrial efficiency requirements. MPCO leverages metaprompting to dynamically synthesize context-aware optimization prompts by integrating project metadata, task requirements, and LLM-specific contexts. It is an essential part of the ARTEMIS code optimization platform for automated validation and scaling. Our comprehensive evaluation on five real-world codebases with 366 hours of runtime benchmarking demonstrates MPCO's effectiveness: it achieves overall performance improvements up to 19.06% with the best statistical rank across all systems compared to baseline methods. Analysis shows that 96% of the top-performing optimizations stem from meaningful edits. Through systematic ablation studies and meta-prompter sensitivity analysis, we identify that comprehensive context integration is essential for effective meta-prompting and that major LLMs can serve effectively as meta-prompters, providing actionable insights for industrial practitioners.",
							"pageNumber": 3568,
							"isPageNumberRoman": false
						},
						{
							"eid": "2Gii4YiIweMRvMXbvnLF99",
							"type": "authorPaper",
							"text": "Element-Aware Fine-Tuning of Vision-Language Models for Cost-Efficient GUI Testing in an Industrial Setting",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d580/573300d580.pdf",
							"extraLocations": [],
							"authorNames": "Mengzhou Wu (Peking University, China), Yuzhe Guo (Beijing Jiaotong University, China), Yuan Cao (Peking University, China), Haochuan Lu (Tencent Inc., China), Hengyu Zhang (Tencent Inc., China), Xia Zeng (Tencent Inc., China), Liangchao Yao (Tencent Inc., China), Yuetang Deng (Tencent Inc., China), Dezhi Ran (Peking University, China), Wei Yang (University of Texas at Dallas, USA), Tao Xie (Peking University, China)",
							"abstract": "User Interface (UI) testing is crucial for quality assurance of industrial mobile applications, and yet it remains labor-intensive and challenging to automate effectively. Recent advances in Vision-Language Models (VLMs) present a promising solution for automating GUI testing by mapping natural language instructions to pixel-level actions, significantly reducing the manual effort required for writing test scripts and even designing test cases. While numerous VLMs have been proposed and evaluated for GUI testing, they often fail to meet two critical industrial requirements: (1) effectiveness when handling complex, multi-step workflows in industrial applications, and (2) efficiency for large-scale, high-frequency testing environments typical in industrial settings. Toward addressing the preceding industrial requirements, in this paper, we report our experiences in developing and deploying RePeek, a novel approach employing a unified three-stage pipeline for both training and inference, enables a VLM to explicitly detect and reason over discrete GUI elements, thereby overcoming the limitations of pixel-based reasoning for both efficiency and effectiveness improvements. In the first stage, RePeek integrates a lightweight UI-element detector named OmniParser to decompose UI screenshots into a structured element list. In the second stage, RePeek adopts the vision encoder of the VLM to generate the embedding for each element. In the third stage, RePeek fuses these element embeddings with the textual instruction to reason and perform classification directly on the UI elements, empowering efficient small models to achieve superior performance against expensive large models. Comprehensive evaluations on public benchmarks and deployment at WeChat show that RePeek consistently achieves superior accuracy and efficiency compared to state-of-the-art VLMs. Specifically, RePeek enables a fine-tuned Qwen2.5-VL-3B model to outperform a 72B model with 75% less training data, validating the effectiveness of incorporating domain knowledge into VLM-based GUI testing. We conclude by summarizing three key lessons from developing and deploying RePeek, offering insights for both researchers and practitioners working on industrial-strength UI testing.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Element-Aware Fine-Tuning of Vision-Language Models for Cost-Efficient GUI Testing in an Industrial Setting 1760066791902 10.1109/ASE63991.2025.00296 Mengzhou Wu Peking University, China wmz@stu.pku.edu.cn Yuzhe Guo Beijing Jiaotong University, China yuzhe.guo@bjtu.edu.cn Yuan Cao Peking University, China cao_yuan21@stu.pku.edu.cn Haochuan Lu Tencent Inc., China hudsonhclu@tencent.com Hengyu Zhang Tencent Inc., China lockerzhang@tencent.com Xia Zeng Tencent Inc., China xiazeng@tencent.com Liangchao Yao Tencent Inc., China clarkyao@tencent.com Yuetang Deng Tencent Inc., China yuetangdeng@tencent.com Dezhi Ran Peking University, China dezhiran@pku.edu.cn Wei Yang University of Texas at Dallas, USA wei.yang@utdallas.edu Tao Xie Peking University, China taoxie@pku.edu.cn vision-language model gui testing test generation object detection visual testing User Interface (UI) testing is crucial for quality assurance of industrial mobile applications, and yet it remains labor-intensive and challenging to automate effectively. Recent advances in Vision-Language Models (VLMs) present a promising solution for automating GUI testing by mapping natural language instructions to pixel-level actions, significantly reducing the manual effort required for writing test scripts and even designing test cases. While numerous VLMs have been proposed and evaluated for GUI testing, they often fail to meet two critical industrial requirements: (1) effectiveness when handling complex, multi-step workflows in industrial applications, and (2) efficiency for large-scale, high-frequency testing environments typical in industrial settings. Toward addressing the preceding industrial requirements, in this paper, we report our experiences in developing and deploying RePeek, a novel approach employing a unified three-stage pipeline for both training and inference, enables a VLM to explicitly detect and reason over discrete GUI elements, thereby overcoming the limitations of pixel-based reasoning for both efficiency and effectiveness improvements. In the first stage, RePeek integrates a lightweight UI-element detector named OmniParser to decompose UI screenshots into a structured element list. In the second stage, RePeek adopts the vision encoder of the VLM to generate the embedding for each element. In the third stage, RePeek fuses these element embeddings with the textual instruction to reason and perform classification directly on the UI elements, empowering efficient small models to achieve superior performance against expensive large models. Comprehensive evaluations on public benchmarks and deployment at WeChat show that RePeek consistently achieves superior accuracy and efficiency compared to state-of-the-art VLMs. Specifically, RePeek enables a fine-tuned Qwen2.5-VL-3B model to outperform a 72B model with 75% less training data, validating the effectiveness of incorporating domain knowledge into VLM-based GUI testing. We conclude by summarizing three key lessons from developing and deploying RePeek, offering insights for both researchers and practitioners working on industrial-strength UI testing.",
							"pageNumber": 3580,
							"isPageNumberRoman": false
						},
						{
							"eid": "55TlNo7b1ItwJEMhcQt9XP",
							"type": "authorPaper",
							"text": "AutoPLC: Generating Vendor-Aware Structured Text for Programmable Logic Controllers",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d592/573300d592.pdf",
							"extraLocations": [],
							"authorNames": "Donghao Yang (Beihang University, China), Aolang Wu (Beihang University, China), Tianyi Zhang (Beihang University, China), Li Zhang  (Beihang University, China), Xiaoli  Lian  (Beihang University, China), Fang  Liu  (Beihang University, China), Yuming  Ren  (Beihang University, China), Jiaji  Tian  (Beihang University, China), Xiaoyin  Che  (Siemens AG, China)",
							"abstract": "Among the programming languages for Programmable Logic Controllers (PLCs), Structured Text (ST) is widely adopted for industrial automation due to its expressiveness and flexibility. However, major vendors implement ST with proprietary extensions and hardware-specific libraries - Siemens' SCL and CODESYS' ST each differ in syntax and functionality. This fragmentation forces engineers to relearn implementation details across platforms, creating substantial productivity barriers. To address this challenge, we developed AutoPLC, a framework capable of automatically generating vendor-aware ST code directly from natural language requirements. Our solution begins by building two essential knowledge sources tailored to each vendor's specifications: a structured API library containing platform-exclusive functions, and an annotated case database that captures real-world implementation experience. Building on these foundations, we created a four-stage generation process that combines step-wise planning (enhanced with a lightweight natural language state machine support for control logic), contextual case retrieval using LLM-based reranking, API recommendation guided by industrial data, and dynamic validation through direct interaction with vendor IDEs. Implemented for Siemens TIA Portal and the CODESYS platform, AutoPLC achieves 90%+ compilation success on our 914-task benchmark (covering general-purpose and process control functions), outperforming all selected baselines, at an average cost of only $0.13 per task. Experienced PLC engineers positively assessed the practical utility of the generated code, including cases that failed compilation.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 AutoPLC: Generating Vendor-Aware Structured Text for Programmable Logic Controllers 1759128916009 10.1109/ASE63991.2025.00297 Donghao Yang Beihang University, China yangdonghao@buaa.edu.cn Aolang Wu Beihang University, China aolangwoo@buaa.edu.cn Tianyi Zhang Beihang University, China tianyiz@buaa.edu.cn Li Zhang Beihang University, China lily@buaa.edu.cn Xiaoli Lian Beihang University, China lianxiaoli@buaa.edu.cn Fang Liu Beihang University, China fangliu@buaa.edu.cn Yuming Ren Beihang University, China yumingren@buaa.edu.cn Jiaji Tian Beihang University, China tianjiaji@buaa.edu.cn Xiaoyin Che Siemens AG, China xiaoyin.che@siemens.com code generation plcs large language models structured text iec 61131-3 Among the programming languages for Programmable Logic Controllers (PLCs), Structured Text (ST) is widely adopted for industrial automation due to its expressiveness and flexibility. However, major vendors implement ST with proprietary extensions and hardware-specific libraries - Siemens' SCL and CODESYS' ST each differ in syntax and functionality. This fragmentation forces engineers to relearn implementation details across platforms, creating substantial productivity barriers. To address this challenge, we developed AutoPLC, a framework capable of automatically generating vendor-aware ST code directly from natural language requirements. Our solution begins by building two essential knowledge sources tailored to each vendor's specifications: a structured API library containing platform-exclusive functions, and an annotated case database that captures real-world implementation experience. Building on these foundations, we created a four-stage generation process that combines step-wise planning (enhanced with a lightweight natural language state machine support for control logic), contextual case retrieval using LLM-based reranking, API recommendation guided by industrial data, and dynamic validation through direct interaction with vendor IDEs. Implemented for Siemens TIA Portal and the CODESYS platform, AutoPLC achieves 90%+ compilation success on our 914-task benchmark (covering general-purpose and process control functions), outperforming all selected baselines, at an average cost of only $0.13 per task. Experienced PLC engineers positively assessed the practical utility of the generated code, including cases that failed compilation.",
							"pageNumber": 3592,
							"isPageNumberRoman": false
						},
						{
							"eid": "4uUCihcqYSZXUebXI3FUxV",
							"type": "authorPaper",
							"text": "IntelliTopo: An IaC Generation Service for Industrial Network Topology Construction",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d604/573300d604.pdf",
							"extraLocations": [],
							"authorNames": "Mingyu Shao (Harbin Institute of Technology, China; Pengcheng Laboratory, China), Zhao Liu (Pengcheng Laboratory, China), Weihong Han (Pengcheng Laboratory, China), Cuiyun Gao (Harbin Institute of Technology, China), Jiachen Liu (Harbin Institute of Technology, China), Qing Liao (Harbin Institute of Technology, China; Pengcheng Laboratory, China)",
							"abstract": "Network topology construction in this paper refers to designing the structural layouts and configuration rules among network devices according to natural language requirements in network simulation. Relatedly, Infrastructure as Code (IaC) enables the configuration and management of network devices through machine-readable code. Although there exist IaC generation approaches powered by Large Language Models (LLMs), they only focus on generating isolated configurations without consideration for holistic topology structure, leading to failure to form a complete, functional topology. Additionally, due to the LLMs' limited knowledge of industry-specific device images, existing approaches struggle to adapt to diverse industry scenarios. In this paper, we introduce IntelliTopo, which, to the best of our knowledge, is the first IaC generation framework targeted at industrial network topology construction. Specifically, IntelliTopo enhances the capabilities of LLMs through two novel mechanisms: (1) Through semantic topology parsing, we enhance the LLMs' understanding of the holistic topology structure; (2) Through domain-aware image retrieval, the outputs of IntelliTopo are more aligned with real-world industry scenarios. Deployed on our PaaS system, the IntelliTopo service has operated continuously for 3 months, handling 50+ network simulation tasks across 10+ industries. IntelliTopo reduces average network topology deployment time from days to hours while requiring less computational power for LLM reasoning. This work bridges the gap between high-level requirements and executable infrastructure, providing a scalable solution for network topology construction.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 IntelliTopo: An IaC Generation Service for Industrial Network Topology Construction 1759108655533 10.1109/ASE63991.2025.00298 Mingyu Shao Harbin Institute of Technology, China; Pengcheng Laboratory, China 24b951080@stu.hit.edu.cn Zhao Liu Pengcheng Laboratory, China liuzh08@pcl.ac.cn Weihong Han Pengcheng Laboratory, China hanwh@pcl.ac.cn Cuiyun Gao Harbin Institute of Technology, China gaocuiyun@hit.edu.cn Jiachen Liu Harbin Institute of Technology, China 200110207@stu.hit.edu.cn Qing Liao Harbin Institute of Technology, China; Pengcheng Laboratory, China liaoqing@hit.edu.cn network topology infrastructure as code large language models Network topology construction in this paper refers to designing the structural layouts and configuration rules among network devices according to natural language requirements in network simulation. Relatedly, Infrastructure as Code (IaC) enables the configuration and management of network devices through machine-readable code. Although there exist IaC generation approaches powered by Large Language Models (LLMs), they only focus on generating isolated configurations without consideration for holistic topology structure, leading to failure to form a complete, functional topology. Additionally, due to the LLMs' limited knowledge of industry-specific device images, existing approaches struggle to adapt to diverse industry scenarios. In this paper, we introduce IntelliTopo, which, to the best of our knowledge, is the first IaC generation framework targeted at industrial network topology construction. Specifically, IntelliTopo enhances the capabilities of LLMs through two novel mechanisms: (1) Through semantic topology parsing, we enhance the LLMs' understanding of the holistic topology structure; (2) Through domain-aware image retrieval, the outputs of IntelliTopo are more aligned with real-world industry scenarios. Deployed on our PaaS system, the IntelliTopo service has operated continuously for 3 months, handling 50+ network simulation tasks across 10+ industries. IntelliTopo reduces average network topology deployment time from days to hours while requiring less computational power for LLM reasoning. This work bridges the gap between high-level requirements and executable infrastructure, providing a scalable solution for network topology construction.",
							"pageNumber": 3604,
							"isPageNumberRoman": false
						},
						{
							"eid": "4bAcgMRR87Mb1LLG8y7xj2",
							"type": "authorPaper",
							"text": "RPG: Linux Kernel Fuzzing Guided by Distribution-Specific Runtime Parameter Interfaces",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d615/573300d615.pdf",
							"extraLocations": [],
							"authorNames": "Yuhan Chen (Central South University, China), Yuheng Shen (Tsinghua University, China), Guoyu Yin (Central South University, China), Fan Ding (Central South University, China), Runzhe Wang (Alibaba Co., Ltd, China), Tao Ma (Alibaba Co., Ltd, China), Xiaohai Shi (Alibaba Co., Ltd, China), Qiang Fu (Central South University, China), Ying Fu (Tsinghua University, China), Heyuan Shi (Central South University, China)",
							"abstract": "The Linux distribution kernel differs significantly from the mainline kernel, incorporating additional features and vendor-specific extensions. Among these additions, many runtime parameter interfaces are unique to distribution kernels, which expands the attack surface and increases the risk of potential vulnerabilities. Fuzzing has been used to assess Linux distributions, but existing tools cannot systematically test these distribution-specific interfaces due to two main challenges: (1) generating test cases for these runtime parameter interfaces, and (2) concentrating test resources on the distribution-specific interface code. To address these challenges, we propose RPG, a distribution-specific runtime parameter-guided kernel fuzzer. RPG operates in three phases: First, RPG extracts distribution-specific runtime parameter interfaces. Then, RPG uses LLM and tuning software databases to model each parameter range to generate meaningful interface test cases. Third, RPG utilizes the distribution kernel's function control flow graph to guide the fuzzer to generate generic test cases that are more closely related to the distribution-specific interface code. We evaluated RPG on four Linux distribution kernels: Ubuntu 22.04, Fedora 42, OpenAnolis 8.8, and OpenAnolis 23.1. RPG detected 22 previously unknown bugs (13 distribution-specific), of which 15 were confirmed and 10 fixed by kernel maintainers. RPG also achieved 20.4% and 21.2% higher branch coverage than Syzkaller and Healer, respectively.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 RPG: Linux Kernel Fuzzing Guided by Distribution-Specific Runtime Parameter Interfaces 1759417670525 10.1109/ASE63991.2025.00299 Yuhan Chen Central South University, China Chenyuhan@csu.edu.cn Yuheng Shen Tsinghua University, China syh1308@gmail.com Guoyu Yin Central South University, China yinguoyu@csu.edu.cn Fan Ding Central South University, China 254511001@csu.edu.cn Runzhe Wang Alibaba Co., Ltd, China runzhe.wrz@alibaba-inc.com Tao Ma Alibaba Co., Ltd, China boyu.mt@taobao.com Xiaohai Shi Alibaba Co., Ltd, China xiaohai.sxh@alibaba-inc.com Qiang Fu Central South University, China fuqiang@cmiot.chinamobile.com Ying Fu Tsinghua University, China fuying1995@foxmail.com Heyuan Shi Central South University, China hey.shi@foxmail.com kernel fuzzing linux distribution kernels tuning software The Linux distribution kernel differs significantly from the mainline kernel, incorporating additional features and vendor-specific extensions. Among these additions, many runtime parameter interfaces are unique to distribution kernels, which expands the attack surface and increases the risk of potential vulnerabilities. Fuzzing has been used to assess Linux distributions, but existing tools cannot systematically test these distribution-specific interfaces due to two main challenges: (1) generating test cases for these runtime parameter interfaces, and (2) concentrating test resources on the distribution-specific interface code. To address these challenges, we propose RPG, a distribution-specific runtime parameter-guided kernel fuzzer. RPG operates in three phases: First, RPG extracts distribution-specific runtime parameter interfaces. Then, RPG uses LLM and tuning software databases to model each parameter range to generate meaningful interface test cases. Third, RPG utilizes the distribution kernel's function control flow graph to guide the fuzzer to generate generic test cases that are more closely related to the distribution-specific interface code. We evaluated RPG on four Linux distribution kernels: Ubuntu 22.04, Fedora 42, OpenAnolis 8.8, and OpenAnolis 23.1. RPG detected 22 previously unknown bugs (13 distribution-specific), of which 15 were confirmed and 10 fixed by kernel maintainers. RPG also achieved 20.4% and 21.2% higher branch coverage than Syzkaller and Healer, respectively.",
							"pageNumber": 3615,
							"isPageNumberRoman": false
						},
						{
							"eid": "66sDDOZ2WvKPgLNXvTCRNi",
							"type": "authorPaper",
							"text": "DALEQ - Explainable Equivalence for Java Bytecode",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d627/573300d627.pdf",
							"extraLocations": [],
							"authorNames": "Jens Dietrich (Victoria University of Wellington, New Zealand), Behnaz Hassanshahi (Oracle Labs Australia, Australia)",
							"abstract": "The security of software builds has attracted increased attention in recent years in response to incidents like solarwinds and xz. Now, several companies including Oracle and Google rebuild open source projects in a secure environment and publish the resulting binaries through dedicated repositories. This practice enables direct comparison between these rebuilt binaries and the original ones produced by developers and published in repositories such as Maven Central. These binaries are often not bitwise identical; however, in most cases, the differences can be attributed to variations in the build environment, and the binaries can still be considered equivalent. Establishing such equivalence, however, is a labor-intensive and error-prone process. While there are some tools that can be used for this purpose, they all fall short of providing provenance, i.e. readable explanation of why two binaries are equivalent, or not. To address this issue, we present daleq, a tool that disassembles Java byte code into a relational database, and can normalise this database by applying datalog rules. Those databases can then be used to infer equivalence between two classes. Notably, equivalence statements are accompanied with datalog proofs recording the normalisation process. We demonstrate the impact of daleq in an industrial context through a large-scale evaluation involving 2,714 pairs of jars, comprising 265,690 class pairs. In this evaluation, daleq is compared to two existing bytecode transformation tools. Our findings reveal a significant reduction in the manual effort required to assess non-bitwise equivalent artifacts, which would otherwise demand intensive human inspection. Furthermore, the results show that daleq outperforms existing tools by identifying more artifacts rebuilt from the same code as equivalent, even when no behavioral differences are present.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 DALEQ - Explainable Equivalence for Java Bytecode 1759442967813 10.1109/ASE63991.2025.00300 Jens Dietrich Victoria University of Wellington, New Zealand jens.dietrich@vuw.ac.nz Behnaz Hassanshahi Oracle Labs Australia, Australia behnaz.hassanshahi@oracle.com software supply chain security build security reproducible builds java maven The security of software builds has attracted increased attention in recent years in response to incidents like solarwinds and xz. Now, several companies including Oracle and Google rebuild open source projects in a secure environment and publish the resulting binaries through dedicated repositories. This practice enables direct comparison between these rebuilt binaries and the original ones produced by developers and published in repositories such as Maven Central. These binaries are often not bitwise identical; however, in most cases, the differences can be attributed to variations in the build environment, and the binaries can still be considered equivalent. Establishing such equivalence, however, is a labor-intensive and error-prone process. While there are some tools that can be used for this purpose, they all fall short of providing provenance, i.e. readable explanation of why two binaries are equivalent, or not. To address this issue, we present daleq, a tool that disassembles Java byte code into a relational database, and can normalise this database by applying datalog rules. Those databases can then be used to infer equivalence between two classes. Notably, equivalence statements are accompanied with datalog proofs recording the normalisation process. We demonstrate the impact of daleq in an industrial context through a large-scale evaluation involving 2,714 pairs of jars, comprising 265,690 class pairs. In this evaluation, daleq is compared to two existing bytecode transformation tools. Our findings reveal a significant reduction in the manual effort required to assess non-bitwise equivalent artifacts, which would otherwise demand intensive human inspection. Furthermore, the results show that daleq outperforms existing tools by identifying more artifacts rebuilt from the same code as equivalent, even when no behavioral differences are present.",
							"pageNumber": 3627,
							"isPageNumberRoman": false
						},
						{
							"eid": "3l010m1NDBZVcIQOtYVj3F",
							"type": "authorPaper",
							"text": "M2QCode: A Model-Driven Framework for Generating Multi-Platform Quantum Programs",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d638/573300d638.pdf",
							"extraLocations": [],
							"authorNames": "Xiaoyu Guo (Kyushu University), Shinobu Saito (NTT, Inc. Computer & Data Science Laboratories), Jianjun Zhao (Kyushu University)",
							"abstract": "With the growing interest in quantum computing, the emergence of quantum supremacy has marked a pivotal milestone in the field. As a result, numerous quantum programming languages (QPLs) have been introduced to support the development of quantum algorithms. However, the application of Model-Driven Development (MDD) in quantum system engineering remains largely underexplored. This paper presents an MDD-based approach to support the structured design and implementation of quantum systems. Our framework enables the automatic generation of quantum code for multiple QPLs, thereby enhancing development efficiency and consistency across heterogeneous quantum platforms. The effectiveness and practicality of our approach have been demonstrated through multiple case studies.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 M2QCode: A Model-Driven Framework for Generating Multi-Platform Quantum Programs 1759460795628 10.1109/ASE63991.2025.00301 Xiaoyu Guo Kyushu University guo.xiaoyu.961@s.kyushu-u.ac.jp Shinobu Saito NTT, Inc. Computer & Data Science Laboratories shinobu.saito@ntt.com Jianjun Zhao Kyushu University zhao@ait.kyushu-u.ac.jp model-driven development automatic code generation quantum software With the growing interest in quantum computing, the emergence of quantum supremacy has marked a pivotal milestone in the field. As a result, numerous quantum programming languages (QPLs) have been introduced to support the development of quantum algorithms. However, the application of Model-Driven Development (MDD) in quantum system engineering remains largely underexplored. This paper presents an MDD-based approach to support the structured design and implementation of quantum systems. Our framework enables the automatic generation of quantum code for multiple QPLs, thereby enhancing development efficiency and consistency across heterogeneous quantum platforms. The effectiveness and practicality of our approach have been demonstrated through multiple case studies.",
							"pageNumber": 3638,
							"isPageNumberRoman": false
						},
						{
							"eid": "2tu6elIC9hh8fJjttZqz7B",
							"type": "authorPaper",
							"text": "SCOPE: Evaluating and Enhancing Permission Explanation Transparency in Mobile Apps",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d649/573300d649.pdf",
							"extraLocations": [],
							"authorNames": "Liu Wang (Huazhong University of Science and Technology, China), Tianshu Zhou (Beijing University of Posts and Telecommunications, China), Haoyu Wang (Huazhong University of Science and Technology, China), Xiyuan Liu (Freshippo, Alibaba Group, China), Yi Wang (Beijing University of Posts and Telecommunications, China)",
							"abstract": "Permission explanations, explanatory text accompanying mobile app permission requests, are crucial for user privacy transparency and informed consent. Despite their importance, current practices often fall short of regulatory expectations due to the lack of systematic evaluation mechanisms. Through an empirical study of 600 mainstream mobile apps, we reveal widespread deficiencies: 15% of permission requests provide no explanation, others use vague language or technical jargon, and critically, many fail to disclose third-party SDK data access despite these components actively using granted permissions. To address these transparency gaps, we present SCOPE, an automated multi-agent framework that systematically evaluates permission explanation compliance and generates targeted optimization recommendations. SCOPE employs four specialized agents working collaboratively: multimodal LLM-based explanation extraction, few-shot learning-based linguistic analysis, dynamic API-based purpose inference, and adaptive report generation. Comprehensive evaluation demonstrates SCOPE's effectiveness, achieving 98% accuracy in explanation extraction, 93.5% consistency in compliance analysis, and 92% accuracy in purpose inference. A user study with 30 participants shows 84.6% preference for SCOPE-optimized explanations, confirming practical utility. Our work provides the first systematic analysis of permission explanation practices and establishes a scalable solution for enhancing mobile app privacy transparency.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 SCOPE: Evaluating and Enhancing Permission Explanation Transparency in Mobile Apps 1759497160603 10.1109/ASE63991.2025.00302 Liu Wang Huazhong University of Science and Technology, China wwillow324@gmail.com Tianshu Zhou Beijing University of Posts and Telecommunications, China dangysss@bupt.edu.cn Haoyu Wang Huazhong University of Science and Technology, China haoyuwang@hust.edu.cn Xiyuan Liu Freshippo, Alibaba Group, China lxy451799@alibaba-inc.com Yi Wang Beijing University of Posts and Telecommunications, China yiwang@bupt.edu.cn permission explanation usable privacy data transparency mobile apps Permission explanations, explanatory text accompanying mobile app permission requests, are crucial for user privacy transparency and informed consent. Despite their importance, current practices often fall short of regulatory expectations due to the lack of systematic evaluation mechanisms. Through an empirical study of 600 mainstream mobile apps, we reveal widespread deficiencies: 15% of permission requests provide no explanation, others use vague language or technical jargon, and critically, many fail to disclose third-party SDK data access despite these components actively using granted permissions. To address these transparency gaps, we present SCOPE, an automated multi-agent framework that systematically evaluates permission explanation compliance and generates targeted optimization recommendations. SCOPE employs four specialized agents working collaboratively: multimodal LLM-based explanation extraction, few-shot learning-based linguistic analysis, dynamic API-based purpose inference, and adaptive report generation. Comprehensive evaluation demonstrates SCOPE's effectiveness, achieving 98% accuracy in explanation extraction, 93.5% consistency in compliance analysis, and 92% accuracy in purpose inference. A user study with 30 participants shows 84.6% preference for SCOPE-optimized explanations, confirming practical utility. Our work provides the first systematic analysis of permission explanation practices and establishes a scalable solution for enhancing mobile app privacy transparency.",
							"pageNumber": 3649,
							"isPageNumberRoman": false
						},
						{
							"eid": "2AarFb5Vzvg4v96BNm3Fmk",
							"type": "authorPaper",
							"text": "The Gold Digger in the Dark Forest: Industrial-Scale MEV Analysis in Ethereum",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d660/573300d660.pdf",
							"extraLocations": [],
							"authorNames": "Ningyu He (The Hong Kong Polytechnic University, China), Tianyang Chi (Beijing University of Posts and Telecommunications, China), Xiaohui Hu (Huazhong University of Science and Technology, China), Haoyu Wang (Huazhong University of Science and Technology, China)",
							"abstract": "Maximal Extractable Value (MEV) activities pose critical operational challenges for blockchain enterprises, requiring automated detection systems to maintain platform integrity and regulatory compliance. Current industrial practices rely on heuristic rule-based methods with substantial accuracy limitations and inability to adapt to evolving MEV strategies. This paper presents an automated software engineering solution for large-scale MEV detection, introducing a novel graph-based profitability identification algorithm that replaces inflexible heuristic rules with adaptive mechanisms. Our automated system achieves 0.6% false positive rates for arbitrage detection and 2.4% false negative rates, significant improvements over existing methods with much higher error rates. We validate our approach on 21 million Ethereum blocks containing 2.5 billion transactions, covering critical infrastructure transitions including The Merge and Proposer-Builder Separation. Our automated pipeline identifies 12.1 million MEV activities, including 1.2 million previously undetectable advanced variants that pose emerging risks to platform operators. Key findings provide actionable insights for blockchain enterprises: private transaction architectures protect 71.4% of low-yield MEV opportunities rather than harming participants, contradicting previous assumptions. However, we identify concerning buildersearcher collusion involving 2,000+ transactions worth 350 ETH, highlighting compliance risks. Additionally, intensifying centralization trends show a single oligopoly controlling 43.1% of MEV activities in 2024, presenting systemic risks. Our automated detection framework provides blockchain enterprises with productionready tools for MEV monitoring, risk assessment, and compliance management while offering critical insights for infrastructure design decisions in rapidly evolving DeFi environments.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 The Gold Digger in the Dark Forest: Industrial-Scale MEV Analysis in Ethereum 1759500787030 10.1109/ASE63991.2025.00303 Ningyu He The Hong Kong Polytechnic University, China ningyu.he@polyu.edu.hk Tianyang Chi Beijing University of Posts and Telecommunications, China chitianyang@bupt.edu.cn Xiaohui Hu Huazhong University of Science and Technology, China xiaohui_hu@hust.edu.cn Haoyu Wang Huazhong University of Science and Technology, China haoyuwang@hust.edu.cn blockchain ethereum maximal extractable value mev Maximal Extractable Value (MEV) activities pose critical operational challenges for blockchain enterprises, requiring automated detection systems to maintain platform integrity and regulatory compliance. Current industrial practices rely on heuristic rule-based methods with substantial accuracy limitations and inability to adapt to evolving MEV strategies. This paper presents an automated software engineering solution for large-scale MEV detection, introducing a novel graph-based profitability identification algorithm that replaces inflexible heuristic rules with adaptive mechanisms. Our automated system achieves 0.6% false positive rates for arbitrage detection and 2.4% false negative rates, significant improvements over existing methods with much higher error rates. We validate our approach on 21 million Ethereum blocks containing 2.5 billion transactions, covering critical infrastructure transitions including The Merge and Proposer-Builder Separation. Our automated pipeline identifies 12.1 million MEV activities, including 1.2 million previously undetectable advanced variants that pose emerging risks to platform operators. Key findings provide actionable insights for blockchain enterprises: private transaction architectures protect 71.4% of low-yield MEV opportunities rather than harming participants, contradicting previous assumptions. However, we identify concerning buildersearcher collusion involving 2,000+ transactions worth 350 ETH, highlighting compliance risks. Additionally, intensifying centralization trends show a single oligopoly controlling 43.1% of MEV activities in 2024, presenting systemic risks. Our automated detection framework provides blockchain enterprises with productionready tools for MEV monitoring, risk assessment, and compliance management while offering critical insights for infrastructure design decisions in rapidly evolving DeFi environments.",
							"pageNumber": 3660,
							"isPageNumberRoman": false
						},
						{
							"eid": "1gGsbM6GQ5m3s0VLj9xb9U",
							"type": "authorPaper",
							"text": "RepoMasterEval: Evaluating Code Completion via Real-World Repositories",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d671/573300d671.pdf",
							"extraLocations": [],
							"authorNames": "Qinyun Wu (ByteDance, China), Chao Peng (ByteDance, China), Pengfei Gao (ByteDance, China), Ruida Hu (Harbin Institute of Technology, China), Haoyu Gan (ByteDance, China), Bo Jiang (ByteDance, China), Jinhe Tang (ByteDance, China), Zhiwen Deng (ByteDance, China), Zhanming Guan (ByteDance, China), Cuiyun Gao (Harbin Institute of Technology, China), Xia Liu (ByteDance, China), Ping Yang (ByteDance)",
							"abstract": "With the growing reliance on automated code completion tools in software development, the need for comprehensive evaluation benchmarks has become critical. Existing benchmarks focus more on code completion in function and class level by providing text descriptions to prompt the model. By contrast, such descriptive prompt is commonly unavailable in real development and code completion can occur in wider range of situations such as in the middle of a function or a code block. These limitations makes existing evaluation benchmarks poorly align with the practical scenarios of code completion tools. In this paper, we propose RepoMasterEval, a novel benchmark for evaluating code completion models constructed from real-world repositories. Each benchmark datum is generated by masking a code snippet (ground truth) from one source code file with existing test suites. To improve test accuracy of model generated code, we employ mutation testing to measure the effectiveness of the test cases and we manually crafted new test cases for those test suites with low mutation score. Our empirical evaluation on 10 state-of-the-art models shows that test argumentation is critical in improving the accuracy of the benchmark and RepoMasterEval is able to report variance in model performance in real-world scenarios. The deployment of RepoMasterEval also revealed that the benchmark is useful to give accurate feedback during model training and the score is in high correlation with the model's performance in practice.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 RepoMasterEval: Evaluating Code Completion via Real-World Repositories 1759063249128 10.1109/ASE63991.2025.00304 Qinyun Wu ByteDance, China wuqinyun@bytedance.com Chao Peng ByteDance, China pengchao.x@bytedance.com Pengfei Gao ByteDance, China gaopengfei.se@bytedance.com Ruida Hu Harbin Institute of Technology, China 200111107@stu.hit.edu.cn Haoyu Gan ByteDance, China ganhaoyu@bytedance.com Bo Jiang ByteDance, China jiangbo.jacob@bytedance.com Jinhe Tang ByteDance, China tangjinhe@bytedance.com Zhiwen Deng ByteDance, China dengzhiwen.11@bytedance.com Zhanming Guan ByteDance, China guanzhanming.steph@bytedance.com Cuiyun Gao Harbin Institute of Technology, China gaocuiyun@hit.edu.cn Xia Liu ByteDance, China linlandong@bytedance.com Ping Yang ByteDance yangping.cser@bytedance.com llm code completion evaluation benchmark With the growing reliance on automated code completion tools in software development, the need for comprehensive evaluation benchmarks has become critical. Existing benchmarks focus more on code completion in function and class level by providing text descriptions to prompt the model. By contrast, such descriptive prompt is commonly unavailable in real development and code completion can occur in wider range of situations such as in the middle of a function or a code block. These limitations makes existing evaluation benchmarks poorly align with the practical scenarios of code completion tools. In this paper, we propose RepoMasterEval, a novel benchmark for evaluating code completion models constructed from real-world repositories. Each benchmark datum is generated by masking a code snippet (ground truth) from one source code file with existing test suites. To improve test accuracy of model generated code, we employ mutation testing to measure the effectiveness of the test cases and we manually crafted new test cases for those test suites with low mutation score. Our empirical evaluation on 10 state-of-the-art models shows that test argumentation is critical in improving the accuracy of the benchmark and RepoMasterEval is able to report variance in model performance in real-world scenarios. The deployment of RepoMasterEval also revealed that the benchmark is useful to give accurate feedback during model training and the score is in high correlation with the model's performance in practice.",
							"pageNumber": 3671,
							"isPageNumberRoman": false
						},
						{
							"eid": "2hQuiQ7F7ZYCN7fi7nUSkz",
							"type": "authorPaper",
							"text": "Securing Millions of Decentralized Identities in Alipay Super App with End-to-End Formal Verification",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d683/573300d683.pdf",
							"extraLocations": [],
							"authorNames": "Ziyu Mao (Zhejiang University, China), Xiaolin Ma (Zhejiang University, China), Lin Huang (Ant Group, China), Huan Yang (Ant Group, China), Wu Zhang (Ant Group, China), Weichao Sun (Ant Group, China), Yongtao Wang (Ant Group, China), Jingling Xue (UNSW Sydney, Australia), Jingyi Wang (Zhejiang University, China)",
							"abstract": "Decentralized Identity (DID) enhances authentication and privacy by empowering individuals to control their own digital identities, which has gained traction globally. To our knowledge, this paper presents the first end-to-end verification effort (from design to implementation) of a real-world Decentralized Identity (DID) protocol following the IIFAA DID standard, which has been deployed within the widely used super app Alipay and issued millions of DIDs in practice. We integrate formal verification into the development lifecycle of such industrial security protocol to systematically enhance its reliability from two levels: (1) At the design level, we utilized state-of-the-art protocol design verifier Tamarin to formally model the IIFAA DID standard under a realistic threat model tailored for super apps. We then formulated and performed automated verification of desired security properties using Tamarin. We identified several design flaws that could lead to a security breach. These issues were reported to the design team and have been addressed in the updated design. (2) At the implementation level, we first extract the desired specification derived from the verified symbolic model of protocol design in the form of a set of intermediate I/O specifications. Subsequently, we translate the I/O specifications into a set of functional specifications at the implementation level, which can then be verified by the automated tool VeriFast. We identified several inconsistencies between the implementation and the verified design which are fixed by the development team and led to verified implementation faithfully obeying the verified design, together offering an end-to-end verified secure DID protocol in Alipay super app. Our work showcases how an industrial security protocol development team can design and implement a practical verified secure Decentralized Identity (DID) protocol with the help of end-to-end formal verification.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Securing Millions of Decentralized Identities in Alipay Super App with End-to-End Formal Verification 1759481567714 10.1109/ASE63991.2025.00305 Ziyu Mao Zhejiang University, China maoziyu@zju.edu.cn Xiaolin Ma Zhejiang University, China XiaolinMa@zju.edu.cn Lin Huang Ant Group, China linyu.hl@antgroup.com Huan Yang Ant Group, China qiaoyi.yh@antgroup.com Wu Zhang Ant Group, China jeff.zw@antgroup.com Weichao Sun Ant Group, China tudou.swc@antgroup.com Yongtao Wang Ant Group, China mengju@antgroup.com Jingling Xue UNSW Sydney, Australia j.xue@unsw.edu.au Jingyi Wang Zhejiang University, China wangjyee@zju.edu.cn formal method security protocol dids Decentralized Identity (DID) enhances authentication and privacy by empowering individuals to control their own digital identities, which has gained traction globally. To our knowledge, this paper presents the first end-to-end verification effort (from design to implementation) of a real-world Decentralized Identity (DID) protocol following the IIFAA DID standard, which has been deployed within the widely used super app Alipay and issued millions of DIDs in practice. We integrate formal verification into the development lifecycle of such industrial security protocol to systematically enhance its reliability from two levels: (1) At the design level, we utilized state-of-the-art protocol design verifier Tamarin to formally model the IIFAA DID standard under a realistic threat model tailored for super apps. We then formulated and performed automated verification of desired security properties using Tamarin. We identified several design flaws that could lead to a security breach. These issues were reported to the design team and have been addressed in the updated design. (2) At the implementation level, we first extract the desired specification derived from the verified symbolic model of protocol design in the form of a set of intermediate I/O specifications. Subsequently, we translate the I/O specifications into a set of functional specifications at the implementation level, which can then be verified by the automated tool VeriFast. We identified several inconsistencies between the implementation and the verified design which are fixed by the development team and led to verified implementation faithfully obeying the verified design, together offering an end-to-end verified secure DID protocol in Alipay super app. Our work showcases how an industrial security protocol development team can design and implement a practical verified secure Decentralized Identity (DID) protocol with the help of end-to-end formal verification.",
							"pageNumber": 3683,
							"isPageNumberRoman": false
						},
						{
							"eid": "6IWQIp956Kd8oQFBq0VInJ",
							"type": "authorPaper",
							"text": "Quantum Machine Learning-Based Test Oracle for Autonomous Mobile Robots",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d694/573300d694.pdf",
							"extraLocations": [],
							"authorNames": "Xinyi Wang (University of Oslo, Norway), Qinghua Xu (University of Limerick, Ireland), Paolo Arcaini (National Institute of Informatics, Japan), Shaukat Ali (Oslo Metropolitan University, Norway), Thomas Peyrucain (PAL Robotics, Spain)",
							"abstract": "Robots are increasingly becoming part of our daily lives, interacting with both the environment and humans to perform their tasks. The software of such robots often undergoes upgrades, for example, to add new functionalities, fix bugs, or delete obsolete functionalities. As a result, regression testing of robot software becomes necessary. However, determining the expected correct behavior of robots (i.e., a test oracle) is challenging due to the potentially unknown environments in which the robots must operate. To address this challenge, machine learning (ML)-based test oracles present a viable solution. This paper reports on the development of a test oracle to support regression testing of autonomous mobile robots built by PAL Robotics (Spain), using quantum machine learning (QML), which enables faster training and the construction of more precise test oracles. Specifically, we propose a hybrid framework, QuReBot, that combines both quantum reservoir computing (QRC) and a simple neural network, inspired by residual connection, to predict the expected behavior of a robot. Results show that QRC alone fails to converge in our case, yielding high prediction error. In contrast, QuReBot converges and achieves 15% reduction of prediction error compared to the classical neural network baseline. Finally, we further examine QuReBot under different configurations and offer practical guidance on optimal settings to support future robot software testing.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Quantum Machine Learning-Based Test Oracle for Autonomous Mobile Robots 1759423144490 10.1109/ASE63991.2025.00306 Xinyi Wang University of Oslo, Norway xinyi@simula.no Qinghua Xu University of Limerick, Ireland qinghua.xu@ul.ie Paolo Arcaini National Institute of Informatics, Japan arcaini@nii.ac.jp Shaukat Ali Oslo Metropolitan University, Norway shaukat@simula.no Thomas Peyrucain PAL Robotics, Spain thomas.peyrucain@pal-robotics.com autonomous mobile robots regression testing ml-based test oracle quantum machine learning Robots are increasingly becoming part of our daily lives, interacting with both the environment and humans to perform their tasks. The software of such robots often undergoes upgrades, for example, to add new functionalities, fix bugs, or delete obsolete functionalities. As a result, regression testing of robot software becomes necessary. However, determining the expected correct behavior of robots (i.e., a test oracle) is challenging due to the potentially unknown environments in which the robots must operate. To address this challenge, machine learning (ML)-based test oracles present a viable solution. This paper reports on the development of a test oracle to support regression testing of autonomous mobile robots built by PAL Robotics (Spain), using quantum machine learning (QML), which enables faster training and the construction of more precise test oracles. Specifically, we propose a hybrid framework, QuReBot, that combines both quantum reservoir computing (QRC) and a simple neural network, inspired by residual connection, to predict the expected behavior of a robot. Results show that QRC alone fails to converge in our case, yielding high prediction error. In contrast, QuReBot converges and achieves 15% reduction of prediction error compared to the classical neural network baseline. Finally, we further examine QuReBot under different configurations and offer practical guidance on optimal settings to support future robot software testing.",
							"pageNumber": 3694,
							"isPageNumberRoman": false
						},
						{
							"eid": "454UtGYXIp0azRpaxsYmLt",
							"type": "authorPaper",
							"text": "Securing Self-Managed Third-Party Libraries",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d706/573300d706.pdf",
							"extraLocations": [],
							"authorNames": "Xin Zhou (Nanjing University, China), Jinwei Xu (Nanjing University, China), He Zhang (Nanjing University, China), Yanjing Yang (Nanjing University, China), Lanxin Yang (Nanjing University, China), Bohan Liu (Nanjing University, China), Hongshan Tang (JD.com, Inc., China)",
							"abstract": "Modern software development reuses third-party libraries to cut costs but may introduce vulnerabilities. A critical practice is to verify the security of third-party libraries against public vulnerability reports. Many automated methods have been proposed to identify vulnerable libraries from vulnerability reports. Existing methods are designed for the generic identification of vulnerable libraries, considering the security of all software libraries. Generic identification is inherently challenging, resulting in limited accuracy. However, organizations only consider the security of libraries they trust and use, by self-managing a library whitelist. Therefore, we propose LibGuard, a framework to adapt existing methods to help organizations secure the libraries they use. LibGuard supplies a library whitelist for existing methods and filters the results according to a threshold, facilitating the discovery of risks overlooked by organizations while controlling false alarms. LibGuard is implemented in two ways. The first attaches the whitelist after existing methods. The second integrates the whitelist into existing methods. We evaluated LibGuard using 5,107 vulnerability reports and the library whitelist built from 79 Google projects and 29 Huawei projects. The results show that the two implementations of LibGuard increase the average F1 score by 10.25% and 11.77%, respectively. Moreover, LibGuard performs stably during the extension of whitelists. To our knowledge, this paper is the first study dedicated to securing self-managed third-party libraries, offering insights into adapting generic software security management to self-managed contexts.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Securing Self-Managed Third-Party Libraries 1759414907803 10.1109/ASE63991.2025.00307 Xin Zhou Nanjing University, China zhouxin@nju.edu.cn Jinwei Xu Nanjing University, China jinwei_xu@smail.nju.edu.cn He Zhang Nanjing University, China hezhang@nju.edu.cn Yanjing Yang Nanjing University, China yj_yang@smail.nju.edu.cn Lanxin Yang Nanjing University, China yang931001@outlook.com Bohan Liu Nanjing University, China bohanliu@nju.edu.cn Hongshan Tang JD.com, Inc., China wytanghongshan@jd.com vulnerable library detection third-party library software supply chain security Modern software development reuses third-party libraries to cut costs but may introduce vulnerabilities. A critical practice is to verify the security of third-party libraries against public vulnerability reports. Many automated methods have been proposed to identify vulnerable libraries from vulnerability reports. Existing methods are designed for the generic identification of vulnerable libraries, considering the security of all software libraries. Generic identification is inherently challenging, resulting in limited accuracy. However, organizations only consider the security of libraries they trust and use, by self-managing a library whitelist. Therefore, we propose LibGuard, a framework to adapt existing methods to help organizations secure the libraries they use. LibGuard supplies a library whitelist for existing methods and filters the results according to a threshold, facilitating the discovery of risks overlooked by organizations while controlling false alarms. LibGuard is implemented in two ways. The first attaches the whitelist after existing methods. The second integrates the whitelist into existing methods. We evaluated LibGuard using 5,107 vulnerability reports and the library whitelist built from 79 Google projects and 29 Huawei projects. The results show that the two implementations of LibGuard increase the average F1 score by 10.25% and 11.77%, respectively. Moreover, LibGuard performs stably during the extension of whitelists. To our knowledge, this paper is the first study dedicated to securing self-managed third-party libraries, offering insights into adapting generic software security management to self-managed contexts.",
							"pageNumber": 3706,
							"isPageNumberRoman": false
						},
						{
							"eid": "3hgasK7uQRmgwYp2aENIrE",
							"type": "authorPaper",
							"text": "MobileUPReg: Identifying User-Perceived Performance Regressions in Mobile OS Versions",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d718/573300d718.pdf",
							"extraLocations": [],
							"authorNames": "Wei Liu (Concordia University, Canada), Yi Wen Heng (Concordia University, Canada), Feng Lin (Concordia University, Canada), Tse-Hsun Peter Chen (Concordia University, Canada), Ahmed E. Hassan (Queen's University, Canada)",
							"abstract": "Mobile operating systems (OS) are frequently updated, but such updates can unintentionally degrade user experience by introducing performance regressions. Existing detection techniques often rely on system-level metrics (e.g., CPU or memory usage) or focus on specific OS components, which may miss regressions actually perceived by users\u2014such as slower responses or UI stutters. To address this gap, we present MobileUPReg, a black-box framework for detecting user-perceived performance regressions across OS versions. MobileUPReg runs the same apps under different OS versions and compares user-perceived performance metrics\u2014response time, finish time, launch time, and dropped frames\u2014to identify regressions that are truly perceptible to users. In a large-scale study, MobileUPReg achieves high accuracy in extracting user-perceived metrics and detects user-perceived regressions with 0.96 precision, 0.91 recall, and 0.93 F1-score\u2014significantly outperforming a statistical baseline using the Wilcoxon rank-sum test and Cliff's Delta. MobileUPReg has been deployed in an industrial CI pipeline, where it analyzes thousands of screencasts across hundreds of apps daily and has uncovered regressions missed by traditional tools. These results demonstrate that MobileUPReg enables accurate, scalable, and perceptually aligned regression detection for mobile OS validation.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 MobileUPReg: Identifying User-Perceived Performance Regressions in Mobile OS Versions 1759461985121 10.1109/ASE63991.2025.00308 Wei Liu Concordia University, Canada w_liu201@encs.concordia.ca Yi Wen Heng Concordia University, Canada he_yiwen@encs.concordia.ca Feng Lin Concordia University, Canada feng.lin@mail.concordia.ca Tse-Hsun Peter Chen Concordia University, Canada peterc@encs.concordia.ca Ahmed E. Hassan Queen's University, Canada ahmed@cs.queensu.ca mobile operating systems performance regression detection user-perceived performance screencast analysis gui performance Mobile operating systems (OS) are frequently updated, but such updates can unintentionally degrade user experience by introducing performance regressions. Existing detection techniques often rely on system-level metrics (e.g., CPU or memory usage) or focus on specific OS components, which may miss regressions actually perceived by users\u2014such as slower responses or UI stutters. To address this gap, we present MobileUPReg, a black-box framework for detecting user-perceived performance regressions across OS versions. MobileUPReg runs the same apps under different OS versions and compares user-perceived performance metrics\u2014response time, finish time, launch time, and dropped frames\u2014to identify regressions that are truly perceptible to users. In a large-scale study, MobileUPReg achieves high accuracy in extracting user-perceived metrics and detects user-perceived regressions with 0.96 precision, 0.91 recall, and 0.93 F1-score\u2014significantly outperforming a statistical baseline using the Wilcoxon rank-sum test and Cliff's Delta. MobileUPReg has been deployed in an industrial CI pipeline, where it analyzes thousands of screencasts across hundreds of apps daily and has uncovered regressions missed by traditional tools. These results demonstrate that MobileUPReg enables accurate, scalable, and perceptually aligned regression detection for mobile OS validation.",
							"pageNumber": 3718,
							"isPageNumberRoman": false
						},
						{
							"eid": "7ysODdeyU5GcNGdgIJMMlk",
							"type": "authorPaper",
							"text": "Thinking Longer, Not Larger: Enhancing Software Engineering Agents via Scaling Test-Time Compute",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d729/573300d729.pdf",
							"extraLocations": [],
							"authorNames": "Yingwei Ma (Tongyi Lab, Alibaba Group), Yongbin Li (Tongyi Lab, Alibaba Group), Yihong Dong (Tongyi Lab, Alibaba Group), Xue Jiang (Tongyi Lab, Alibaba Group), Yanhao Li (Tongyi Lab, Alibaba Group), Yue Liu (Tongyi Lab, Alibaba Group), Rongyu Cao (Tongyi Lab, Alibaba Group), Jue Chen (Tongyi Lab, Alibaba Group), Fei Huang (Tongyi Lab, Alibaba Group), Binhua Li (Tongyi Lab, Alibaba Group)",
							"abstract": "Recent advancements in software engineering agents have demonstrated promising capabilities in automating program improvements. However, their reliance on closed-source or resource-intensive models introduces significant deployment challenges in private environments, prompting a critical question: How can personally deployable open-source LLMs achieve comparable code reasoning performance? To this end, we propose a unified Test-Time Compute (TTC) scaling framework that leverages increased inference-time computation instead of larger models. Our framework incorporates two complementary strategies: internal TTC and external TTC. Internally, we introduce a development-contextualized trajectory synthesis method leveraging real-world software repositories to bootstrap multi-stage reasoning processes, such as fault localization and patch generation. We further enhance trajectory quality through rejection sampling, rigorously evaluating trajectories along accuracy and complexity. Externally, we propose a novel development-process-based search strategy guided by reward models and execution verification. This approach enables targeted computational allocation at critical development decision points, overcoming limitations of existing \"end-point only\" verification methods. Evaluations on SWE-bench Verified demonstrate our 32B model achieves a 46% issue resolution rate, surpassing significantly larger models such as DeepSeek R1 671B and OpenAI o1. Additionally, we provide the empirical validation of the test-time scaling phenomenon within SWE agents, revealing that models dynamically allocate more tokens to increasingly challenging problems, effectively enhancing reasoning capabilities. We publicly release all training data, models, and code to facilitate future research. In fact, our method has been deployed in Tongyi Lingma, an IDE-based coding assistant developed by Alibaba Cloud, where it helps developers solve real-world programming problems.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Thinking Longer, Not Larger: Enhancing Software Engineering Agents via Scaling Test-Time Compute 1759499981461 10.1109/ASE63991.2025.00309 Yingwei Ma Tongyi Lab, Alibaba Group 193769981@qq.com Yongbin Li Tongyi Lab, Alibaba Group shuide.lyb@alibaba-inc.com Yihong Dong Tongyi Lab, Alibaba Group dongyh@stu.pku.edu.cn Xue Jiang Tongyi Lab, Alibaba Group jiangxue@stu.pku.edu.cn Yanhao Li Tongyi Lab, Alibaba Group yanhaoli@alibaba-inc.com Yue Liu Tongyi Lab, Alibaba Group yueliu@alibaba-inc.com Rongyu Cao Tongyi Lab, Alibaba Group caorongyu.cry@alibaba-inc.com Jue Chen Tongyi Lab, Alibaba Group chenjue.cj@alibaba-inc.com Fei Huang Tongyi Lab, Alibaba Group f.huang@alibaba-inc.com Binhua Li Tongyi Lab, Alibaba Group binhua.lbh@alibaba-inc.com Recent advancements in software engineering agents have demonstrated promising capabilities in automating program improvements. However, their reliance on closed-source or resource-intensive models introduces significant deployment challenges in private environments, prompting a critical question: How can personally deployable open-source LLMs achieve comparable code reasoning performance? To this end, we propose a unified Test-Time Compute (TTC) scaling framework that leverages increased inference-time computation instead of larger models. Our framework incorporates two complementary strategies: internal TTC and external TTC. Internally, we introduce a development-contextualized trajectory synthesis method leveraging real-world software repositories to bootstrap multi-stage reasoning processes, such as fault localization and patch generation. We further enhance trajectory quality through rejection sampling, rigorously evaluating trajectories along accuracy and complexity. Externally, we propose a novel development-process-based search strategy guided by reward models and execution verification. This approach enables targeted computational allocation at critical development decision points, overcoming limitations of existing \"end-point only\" verification methods. Evaluations on SWE-bench Verified demonstrate our 32B model achieves a 46% issue resolution rate, surpassing significantly larger models such as DeepSeek R1 671B and OpenAI o1. Additionally, we provide the empirical validation of the test-time scaling phenomenon within SWE agents, revealing that models dynamically allocate more tokens to increasingly challenging problems, effectively enhancing reasoning capabilities. We publicly release all training data, models, and code to facilitate future research. In fact, our method has been deployed in Tongyi Lingma, an IDE-based coding assistant developed by Alibaba Cloud, where it helps developers solve real-world programming problems.",
							"pageNumber": 3729,
							"isPageNumberRoman": false
						},
						{
							"eid": "3KzvxKGCkClLSJdrgnC6Kq",
							"type": "authorPaper",
							"text": "LogSage: An LLM-Based Framework for CI/CD Failure Detection and Remediation with Industrial Validation",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d741/573300d741.pdf",
							"extraLocations": [],
							"authorNames": "Weiyuan Xu (East China Normal University, China; ByteDance, China), Juntao Luo (ByteDance, China), Tao Huang (ByteDance, China), Kaixin Sui (ByteDance, China), Jie Geng (ByteDance, China), Qijun Ma (ByteDance, China), Isami Akasaka (ByteDance, China), Xiaoxue Shi (ByteDance, China), Jing Tang (ByteDance, China), Peng Cai (East China Normal University, China)",
							"abstract": "Continuous Integration and Deployment (CI/CD) pipelines are critical to modern software engineering, yet diagnosing and resolving their failures remains complex and laborintensive. We present LogSage, the first end-to-end LLM-powered framework for root cause analysis (RCA) and automated remediation of CI/CD failures. LogSage employs a token-efficient log preprocessing pipeline to filter noise and extract critical errors, then performs structured diagnostic prompting for accurate RCA. For solution generation, it leverages retrieval-augmented generation (RAG) to reuse historical fixes and invokes automation fixes via LLM tool-calling. On a newly curated benchmark of 367 GitHub CI/CD failures, LogSage achieves over 98% precision, near-perfect recall, and an F1 improvement of more than 38% points in the RCA stage, compared with recent LLM-based baselines. In a year-long industrial deployment at ByteDance, it processed over 1.07M executions, with end-to-end precision exceeding 80%. These results demonstrate that LogSage provides a scalable and practical solution for automating CI/CD failure management in real-world DevOps workflows.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 LogSage: An LLM-Based Framework for CI/CD Failure Detection and Remediation with Industrial Validation 1759572550973 10.1109/ASE63991.2025.00310 Weiyuan Xu East China Normal University, China; ByteDance, China 72275900021@stu.ecnu.edu.cn Juntao Luo ByteDance, China luojuntao@bytedance.com Tao Huang ByteDance, China huangtao.806955@bytedance.com Kaixin Sui ByteDance, China sunyikai.s@bytedance.com Jie Geng ByteDance, China gengjie.02@bytedance.com Qijun Ma ByteDance, China maqijun@bytedance.com Isami Akasaka ByteDance, China isami.akasaka@bytedance.com Xiaoxue Shi ByteDance, China shixiaoxue.111@bytedance.com Jing Tang ByteDance, China tangjing.fisher@bytedance.com Peng Cai East China Normal University, China pcai@dase.ecnu.edu.cn continuous integration continuous deployment large language models log analysis root cause diagnosis failure remediation Continuous Integration and Deployment (CI/CD) pipelines are critical to modern software engineering, yet diagnosing and resolving their failures remains complex and laborintensive. We present LogSage, the first end-to-end LLM-powered framework for root cause analysis (RCA) and automated remediation of CI/CD failures. LogSage employs a token-efficient log preprocessing pipeline to filter noise and extract critical errors, then performs structured diagnostic prompting for accurate RCA. For solution generation, it leverages retrieval-augmented generation (RAG) to reuse historical fixes and invokes automation fixes via LLM tool-calling. On a newly curated benchmark of 367 GitHub CI/CD failures, LogSage achieves over 98% precision, near-perfect recall, and an F1 improvement of more than 38% points in the RCA stage, compared with recent LLM-based baselines. In a year-long industrial deployment at ByteDance, it processed over 1.07M executions, with end-to-end precision exceeding 80%. These results demonstrate that LogSage provides a scalable and practical solution for automating CI/CD failure management in real-world DevOps workflows.",
							"pageNumber": 3741,
							"isPageNumberRoman": false
						},
						{
							"eid": "70qINxoLmlcSSYggyim6zv",
							"type": "authorPaper",
							"text": "KAIR: A Statistical and Causal Approach to Pinpointing Stragglers in Distributed Model Training",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d753/573300d753.pdf",
							"extraLocations": [],
							"authorNames": "Yitang Yang (Beihang University, China), Junhong Liu (Beihang University, China), Jiapeng Chen (Kuaishou Inc., China), Xiaoyang Sun (University of Leeds, UK), Tianyu Wo (Beihang University, China), Chunming Hu (Beihang University, China), Chengru Song (Kuaishou Inc., China), Jin Ouyang (Kuaishou Inc., China), Renyu Yang (Beihang University, China)",
							"abstract": "The distributed deep learning training process within large-scale clusters serves as the foundation of contemporary artificial intelligence. However, its inherent characteristics make it particularly sensitive to stragglers, specifically the presence of slow workers, which can significantly decelerate the entire procedure. Observability tools are essential for identifying stragglers within systems. However, the prevailing system profiling tools are either designed for single-node analysis, lacking visibility across multiple workers, or they recognize stragglers but only deliver high-level symptoms, providing engineers with insufficient insight into the underlying causes. We design KAIR, a robust production-standard observability tool. KAIR uses an innovative hierarchical approach, transitioning from statistical anomaly detection to causal inference. It employs Kolmogorov-Smirnov statistics for the identification of statistically anomalous workers and implements a causal path tracing algorithm to accurately determine the specific operations, such as computation or communication, that are responsible for the delay. KAIR has been evaluated in a production cluster of 2,048 NVIDIA A800 GPUs and demonstrated high effectiveness in detecting latent stragglers at the framework level that are often overlooked by conventional tools. It offers precise suggestions that markedly reduce processing inefficiencies and engineering workload.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 KAIR: A Statistical and Causal Approach to Pinpointing Stragglers in Distributed Model Training 1759331153648 10.1109/ASE63991.2025.00311 Yitang Yang Beihang University, China yi1tang.yang@gmail.com Junhong Liu Beihang University, China junhongliu@buaa.edu.cn Jiapeng Chen Kuaishou Inc., China chenjiapeng@kuaishou.com Xiaoyang Sun University of Leeds, UK x.sun4@leeds.ac.uk Tianyu Wo Beihang University, China woty@buaa.edu.cn Chunming Hu Beihang University, China hucm@buaa.edu.cn Chengru Song Kuaishou Inc., China songchengru@kuaishou.com Jin Ouyang Kuaishou Inc., China oyjmical@gmail.com Renyu Yang Beihang University, China renyuyang@buaa.edu.cn Distributed Training Performance Analysis System Observability and Straggler Detection The distributed deep learning training process within large-scale clusters serves as the foundation of contemporary artificial intelligence. However, its inherent characteristics make it particularly sensitive to stragglers, specifically the presence of slow workers, which can significantly decelerate the entire procedure. Observability tools are essential for identifying stragglers within systems. However, the prevailing system profiling tools are either designed for single-node analysis, lacking visibility across multiple workers, or they recognize stragglers but only deliver high-level symptoms, providing engineers with insufficient insight into the underlying causes. We design KAIR, a robust production-standard observability tool. KAIR uses an innovative hierarchical approach, transitioning from statistical anomaly detection to causal inference. It employs Kolmogorov-Smirnov statistics for the identification of statistically anomalous workers and implements a causal path tracing algorithm to accurately determine the specific operations, such as computation or communication, that are responsible for the delay. KAIR has been evaluated in a production cluster of 2,048 NVIDIA A800 GPUs and demonstrated high effectiveness in detecting latent stragglers at the framework level that are often overlooked by conventional tools. It offers precise suggestions that markedly reduce processing inefficiencies and engineering workload.",
							"pageNumber": 3753,
							"isPageNumberRoman": false
						},
						{
							"eid": "1aFvd9TMxcRrtekiIsy8Ju",
							"type": "authorPaper",
							"text": "What Types of Code Review Comments Do Developers Most Frequently Resolve?",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d759/573300d759.pdf",
							"extraLocations": [],
							"authorNames": "Saul Goldman (The University of Melbourne, Australia), Hong Yi  Lin (The University of Melbourne, Australia), Jirat Pasuksmit (Atlassian, Australia), Patanamon Thongtanunam (The University of Melbourne, Australia), Kla Tantithamthavorn (Atlassian, Australia; Monash University, Australia), Zhe Wang (Atlassian, Australia), Ray Zhang (Atlassian, Australia), Ali Behnaz (Atlassian, Australia), Fan Jiang (Atlassian, Australia), Michael Siers (Atlassian, Australia), Ryan Jiang (Atlassian, Australia), Mike Buller (Atlassian, Australia), Minwoo Jeong (Atlassian, USA), Ming Wu (Atlassian, USA)",
							"abstract": "Large language model (LLM)-powered code re- view automation tools have been introduced to generate code review comments. However, not all generated comments will drive code changes. Understanding what types of generated review comments are likely to trigger code changes is crucial for identifying those that are actionable. In this paper, we set out to investigate (1) the types of review comments written by humans and LLMs, and (2) the types of generated comments that are most frequently resolved by developers. To do so, we developed an LLM-as-a-Judge to automatically classify review comments based on our own taxonomy of five categories. Our empirical study confirms that (1) the LLM reviewer and human reviewers exhibit distinct strengths and weaknesses depending on the project context, and (2) readability, bugs, and maintainability-related comments had higher resolution rates than those focused on code design. These results suggest that a substantial proportion of LLM-generated comments are actionable and can be resolved by developers. Our work highlights the complementarity between LLM and human reviewers and offers suggestions to improve the practical effectiveness of LLM-powered code review tools.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 What Types of Code Review Comments Do Developers Most Frequently Resolve? 1759096521592 10.1109/ASE63991.2025.00312 Saul Goldman The University of Melbourne, Australia saulg@student.unimelb.edu.au Hong Yi Lin The University of Melbourne, Australia tom.lin1@unimelb.edu.au Jirat Pasuksmit Atlassian, Australia jpasuksmit@atlassian.com Patanamon Thongtanunam The University of Melbourne, Australia patanamon.t@unimelb.edu.au Kla Tantithamthavorn Atlassian, Australia; Monash University, Australia chakkrit@monash.edu Zhe Wang Atlassian, Australia zwang4@atlassian.com Ray Zhang Atlassian, Australia rzhang6@atlassian.com Ali Behnaz Atlassian, Australia abehnaz@atlassian.com Fan Jiang Atlassian, Australia fjiang2@atlassian.com Michael Siers Atlassian, Australia msiers@atlassian.com Ryan Jiang Atlassian, Australia rjiang2@atlassian.com Mike Buller Atlassian, Australia mbuller@atlassian.com Minwoo Jeong Atlassian, USA mjeong@atlassian.com Ming Wu Atlassian, USA mwu2@atlassian.com code review actionable code review comments online experiment Large language model (LLM)-powered code re- view automation tools have been introduced to generate code review comments. However, not all generated comments will drive code changes. Understanding what types of generated review comments are likely to trigger code changes is crucial for identifying those that are actionable. In this paper, we set out to investigate (1) the types of review comments written by humans and LLMs, and (2) the types of generated comments that are most frequently resolved by developers. To do so, we developed an LLM-as-a-Judge to automatically classify review comments based on our own taxonomy of five categories. Our empirical study confirms that (1) the LLM reviewer and human reviewers exhibit distinct strengths and weaknesses depending on the project context, and (2) readability, bugs, and maintainability-related comments had higher resolution rates than those focused on code design. These results suggest that a substantial proportion of LLM-generated comments are actionable and can be resolved by developers. Our work highlights the complementarity between LLM and human reviewers and offers suggestions to improve the practical effectiveness of LLM-powered code review tools.",
							"pageNumber": 3759,
							"isPageNumberRoman": false
						},
						{
							"eid": "5DGCCF21SvHVrgrv5sskpc",
							"type": "authorPaper",
							"text": "Towards Reliable LLM-Based Exam Generation Lessons Learned and Open Challenges in an Industrial Project",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d765/573300d765.pdf",
							"extraLocations": [],
							"authorNames": "Renzo Degiovanni (Luxembourg Institute of Science and Technology (LIST)), Jordi Cabot (Luxembourg Institute of Science and Technology (LIST))",
							"abstract": "Large Language Models (LLMs) have revolutionized the way natural language tasks are handled, with big potential applications in the context of education. LLMs can save educators time and effort, for instance, in content creation and exam generation. Although promising, LLMs' integration into educational products brings some risks that companies must mitigate. In the context of an industrial project, we investigate the effectiveness of LLMs to generate educational multiple-choice questions. The experiments include 16 commercial and open-source LLMs, rely on standard metrics to assess the accuracy (F1 and BLEU) and linguistic quality (perplexity and diversity) of the generated questions, and compare with five specialized models. The results suggest that recent LLMs can outperform the fine-tuned models for question generation, open-source LLMs are very competitive with the commercial ones, with Meta Llama models being the best performing, and DeepSeek as performing as recent GPT4 models. This promising empirical evidence encourages us to focus on advanced prompting strategies, for which we report relevant open challenges we aim to address in the short term. ",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Towards Reliable LLM-Based Exam Generation Lessons Learned and Open Challenges in an Industrial Project 1759323735257 10.1109/ASE63991.2025.00313 Renzo Degiovanni Luxembourg Institute of Science and Technology (LIST) renzo.degiovanni@list.lu Jordi Cabot Luxembourg Institute of Science and Technology (LIST) jordi.cabot@list.lu large language models educational question generation empirical study Large Language Models (LLMs) have revolutionized the way natural language tasks are handled, with big potential applications in the context of education. LLMs can save educators time and effort, for instance, in content creation and exam generation. Although promising, LLMs' integration into educational products brings some risks that companies must mitigate. In the context of an industrial project, we investigate the effectiveness of LLMs to generate educational multiple-choice questions. The experiments include 16 commercial and open-source LLMs, rely on standard metrics to assess the accuracy (F1 and BLEU) and linguistic quality (perplexity and diversity) of the generated questions, and compare with five specialized models. The results suggest that recent LLMs can outperform the fine-tuned models for question generation, open-source LLMs are very competitive with the commercial ones, with Meta Llama models being the best performing, and DeepSeek as performing as recent GPT4 models. This promising empirical evidence encourages us to focus on advanced prompting strategies, for which we report relevant open challenges we aim to address in the short term.",
							"pageNumber": 3765,
							"isPageNumberRoman": false
						},
						{
							"eid": "q5ZYT1ZMLRqWcd4VATIuy",
							"type": "authorPaper",
							"text": "Acceleration of Automotive Software Development by Retrieval Augmented Integration Test Script Generation",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d771/573300d771.pdf",
							"extraLocations": [],
							"authorNames": "Masashi Mizoguchi (Hitachi, Ltd., Japan), Kentaro Yoshimura (Hitachi, Ltd., Japan), Keita Nakazawa (Astemo, Ltd., Japan), Yasuomi Sato (Astemo, Ltd., Japan), Takahiro Iida (Astemo, Ltd., Japan), Fumio Narisawa (Astemo, Ltd., Japan)",
							"abstract": "Improving the efficiency of software integration testing is a critical challenge in the automotive industry, particularly as Electronic Control Unit (ECU) architectures become increasingly complex. This paper addresses the automation of integration test script generation by leveraging Large Language Models (LLMs) with Retrieval Augmented Generation (RAG). Specifically, we target the phase in which test engineers translate natural language test case specifications into executable scripts for integration test environments containing hardware debug interfaces. To bridge the knowledge gap between LLMs and domain-specific test tool APIs, we construct a task-oriented vector store that incorporates both API manuals and supplemental, workflow-centric information. By combining these with prompts containing code prefixes, our method enables LLMs to generate robust and correct integration test scripts. We evaluated our approach on typical test scenarios reflecting industry practices for multi-core ECUs. While the test cases used were not directly taken from a specific development project, they closely mirror those routinely employed across numerous automotive ECU development initiatives. The proposed method successfully generated executable scripts for all cases and reduced total test execution man-hours by 43% compared to a realistic baseline of manual execution. These results demonstrate the practical benefit of context-enriched LLMs in accelerating specialized software engineering tasks within the automotive domain, and it also identifies remaining challenges in extending automation to broader aspects such as test coverage, maintainability, and seamless process integration.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Acceleration of Automotive Software Development by Retrieval Augmented Integration Test Script Generation 1759298668388 10.1109/ASE63991.2025.00314 Masashi Mizoguchi Hitachi, Ltd., Japan masashi.mizoguchi.re@hitachi.com Kentaro Yoshimura Hitachi, Ltd., Japan kentaro.yoshimura.jr@hitachi.com Keita Nakazawa Astemo, Ltd., Japan keita.nakazawa.yy@hitachiastemo.com Yasuomi Sato Astemo, Ltd., Japan yasuomi.sato.sb@hitachiastemo.com Takahiro Iida Astemo, Ltd., Japan takahiro.iida.pf@hitachiastemo.com Fumio Narisawa Astemo, Ltd., Japan fumio.narisawa.ks@hitachiastemo.com automotive software integration test large language model retrieval augmented generation test script Improving the efficiency of software integration testing is a critical challenge in the automotive industry, particularly as Electronic Control Unit (ECU) architectures become increasingly complex. This paper addresses the automation of integration test script generation by leveraging Large Language Models (LLMs) with Retrieval Augmented Generation (RAG). Specifically, we target the phase in which test engineers translate natural language test case specifications into executable scripts for integration test environments containing hardware debug interfaces. To bridge the knowledge gap between LLMs and domain-specific test tool APIs, we construct a task-oriented vector store that incorporates both API manuals and supplemental, workflow-centric information. By combining these with prompts containing code prefixes, our method enables LLMs to generate robust and correct integration test scripts. We evaluated our approach on typical test scenarios reflecting industry practices for multi-core ECUs. While the test cases used were not directly taken from a specific development project, they closely mirror those routinely employed across numerous automotive ECU development initiatives. The proposed method successfully generated executable scripts for all cases and reduced total test execution man-hours by 43% compared to a realistic baseline of manual execution. These results demonstrate the practical benefit of context-enriched LLMs in accelerating specialized software engineering tasks within the automotive domain, and it also identifies remaining challenges in extending automation to broader aspects such as test coverage, maintainability, and seamless process integration.",
							"pageNumber": 3771,
							"isPageNumberRoman": false
						},
						{
							"eid": "4kVkkt7GmvUFb4Q8wMjJDV",
							"type": "authorPaper",
							"text": "SGCR: A Specification-Grounded Framework for Trustworthy LLM Code Review",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d777/573300d777.pdf",
							"extraLocations": [],
							"authorNames": "Kai Wang (HiThink Research, China; Zhejiang University, China), Bingcheng Mao (HiThink Research, China), Shuai Jia (HiThink Research, China; Zhejiang University, China), Yujie Ding (HiThink Research, China; Zhejiang University, China), Dongming Han (HiThink Research, China; Zhejiang University, China), Tianyi Ma (HiThink Research, China), Bin Cao (Zhejiang University of Technology, China)",
							"abstract": "Automating code review with Large Language Models (LLMs) shows immense promise, yet practical adoption is hampered by their lack of reliability, context-awareness, and control. To address this, we propose Specification-Grounded Code Review (SGCR), a framework that grounds LLMs in human-authored specifications to produce trustworthy and relevant feedback. SGCR features a novel dual-pathway architecture: an explicit path ensures deterministic compliance with predefined rules derived from these specifications, while an implicit path heuristically discovers and verifies issues beyond those rules. Deployed in a live industrial environment at HiThink Research, SGCR's suggestions achieved a 42% developer adoption rate\u2014a 90.9% relative improvement over a baseline LLM (22%). Our work demonstrates that specification-grounding is a powerful paradigm for bridging the gap between the generative power of LLMs and the rigorous reliability demands of software engineering.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 SGCR: A Specification-Grounded Framework for Trustworthy LLM Code Review 1759212648963 10.1109/ASE63991.2025.00315 Kai Wang HiThink Research, China; Zhejiang University, China wangkai7@myhexin.com Bingcheng Mao HiThink Research, China maobingcheng@myhexin.com Shuai Jia HiThink Research, China; Zhejiang University, China jiashuai@myhexin.com Yujie Ding HiThink Research, China; Zhejiang University, China dingyujie2@myhexin.com Dongming Han HiThink Research, China; Zhejiang University, China handongming2@myhexin.com Tianyi Ma HiThink Research, China matianyi@myhexin.com Bin Cao Zhejiang University of Technology, China bincao@zjut.edu.cn code review specification-grounded large language model Automating code review with Large Language Models (LLMs) shows immense promise, yet practical adoption is hampered by their lack of reliability, context-awareness, and control. To address this, we propose Specification-Grounded Code Review (SGCR), a framework that grounds LLMs in human-authored specifications to produce trustworthy and relevant feedback. SGCR features a novel dual-pathway architecture: an explicit path ensures deterministic compliance with predefined rules derived from these specifications, while an implicit path heuristically discovers and verifies issues beyond those rules. Deployed in a live industrial environment at HiThink Research, SGCR's suggestions achieved a 42% developer adoption rate\u2014a 90.9% relative improvement over a baseline LLM (22%). Our work demonstrates that specification-grounding is a powerful paradigm for bridging the gap between the generative power of LLMs and the rigorous reliability demands of software engineering.",
							"pageNumber": 3777,
							"isPageNumberRoman": false
						}
					],
					"pageNumber": "",
					"isPageNumberRoman": false,
					"chair": null
				},
				{
					"class": "SD",
					"type": "SD_SESSION",
					"title": "New Ideas and Emerging Results (NIER)",
					"lineItems": [
						{
							"eid": "7hQYmgWuvMiovtmRNUCjEB",
							"type": "authorPaper",
							"text": "Walk the Talk: Is Your Log-Based Software Reliability Maintenance System Really Reliable?",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d783/573300d783.pdf",
							"extraLocations": [],
							"authorNames": "Minghua He (Peking University, China), Tong Jia (Peking University, China; National Key Laboratory of Data Space Technology and System, China ), Chiming Duan (Peking University, China), Pei Xiao (Peking University, China), Lingzhe Zhang (Peking University, China), Kangjin Wang (Alibaba Group, China), Yifan Wu (Peking University, China), Ying Li (Peking University, China), Gang Huang (Peking University, China; National Key Laboratory of Data Space Technology and System, China)",
							"abstract": "Log-based software reliability maintenance systems are crucial for sustaining stable customer experience. However, existing deep learning-based methods represent a black box for service providers, making it impossible for providers to understand how these methods detect anomalies, thereby hindering trust and deployment in real production environments. To address this issue, this paper defines a trustworthiness metric\u2014diagnostic faithfulness\u2014for models to gain service providers' trust, based on surveys of SREs at a major cloud provider. We design two evaluation tasks: attention-based root cause localization and event perturbation. Empirical studies demonstrate that existing methods perform poorly in diagnostic faithfulness. Consequently, we propose FaithLog, a faithful log-based anomaly detection system, which achieves faithfulness through a carefully designed causality-guided attention mechanism and adversarial consistency learning. Evaluation results on two public datasets and one industrial dataset demonstrate that the proposed method achieves state-of-the-art performance in diagnostic faithfulness.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Walk the Talk: Is Your Log-Based Software Reliability Maintenance System Really Reliable? 1756020230864 10.1109/ASE63991.2025.00316 Minghua He Peking University, China hemh2120@stu.pku.edu.cn Tong Jia Peking University, China; National Key Laboratory of Data Space Technology and System, China jia.tong@pku.edu.cn Chiming Duan Peking University, China duanchiming@stu.pku.edu.cn Pei Xiao Peking University, China xiaopei@stu.pku.edu.cn Lingzhe Zhang Peking University, China zhang.lingzhe@stu.pku.edu.cn Kangjin Wang Alibaba Group, China kangjin.wkj@alibaba-inc.com Yifan Wu Peking University, China yifanwu@pku.edu.cn Ying Li Peking University, China li.ying@pku.edu.cn Gang Huang Peking University, China; National Key Laboratory of Data Space Technology and System, China hg@pku.edu.cn software reliability log analysis anomaly detection trustworthiness Log-based software reliability maintenance systems are crucial for sustaining stable customer experience. However, existing deep learning-based methods represent a black box for service providers, making it impossible for providers to understand how these methods detect anomalies, thereby hindering trust and deployment in real production environments. To address this issue, this paper defines a trustworthiness metric\u2014diagnostic faithfulness\u2014for models to gain service providers' trust, based on surveys of SREs at a major cloud provider. We design two evaluation tasks: attention-based root cause localization and event perturbation. Empirical studies demonstrate that existing methods perform poorly in diagnostic faithfulness. Consequently, we propose FaithLog, a faithful log-based anomaly detection system, which achieves faithfulness through a carefully designed causality-guided attention mechanism and adversarial consistency learning. Evaluation results on two public datasets and one industrial dataset demonstrate that the proposed method achieves state-of-the-art performance in diagnostic faithfulness.",
							"pageNumber": 3783,
							"isPageNumberRoman": false
						},
						{
							"eid": "5kn4tz9A5e60ca9y4nX1X6",
							"type": "authorPaper",
							"text": "From Modules to Marketplaces: A Vision for Composable Capability Sharing Across Organizations",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d788/573300d788.pdf",
							"extraLocations": [],
							"authorNames": "Wei-Ji Wang (National Taiwan University, Taiwan)",
							"abstract": "Assembly-oriented software architecture is transforming how modern systems are developed\u2014shifting focus from writing code to composing business-aligned capabilities. While modular components are increasingly common, most remain confined within organizational boundaries, limiting their reuse potential. This paper envisions a capability marketplace that enables cross-organizational sharing, discovery, and composition of semantically rich, contract-governed, and deployable software modules. Unlike traditional code repositories, this marketplace promotes scalable reuse of high-level capabilities supported by trust modeling, interface verification, and lifecycle governance. We outline the conceptual architecture and key design mechanisms, and identify open challenges in trust establishment and developer workflow integration. By rethinking software engineering as ecosystem-scale composition, this vision aims to advance a more composable, collaborative, and sustainable model of modular development.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 From Modules to Marketplaces: A Vision for Composable Capability Sharing Across Organizations 1756264284822 10.1109/ASE63991.2025.00317 Wei-Ji Wang National Taiwan University, Taiwan sckhg1367@gmail.com composable capabilities capability marketplace cross-boundary reuse assembly-oriented development governance and discoverability Assembly-oriented software architecture is transforming how modern systems are developed\u2014shifting focus from writing code to composing business-aligned capabilities. While modular components are increasingly common, most remain confined within organizational boundaries, limiting their reuse potential. This paper envisions a capability marketplace that enables cross-organizational sharing, discovery, and composition of semantically rich, contract-governed, and deployable software modules. Unlike traditional code repositories, this marketplace promotes scalable reuse of high-level capabilities supported by trust modeling, interface verification, and lifecycle governance. We outline the conceptual architecture and key design mechanisms, and identify open challenges in trust establishment and developer workflow integration. By rethinking software engineering as ecosystem-scale composition, this vision aims to advance a more composable, collaborative, and sustainable model of modular development.",
							"pageNumber": 3788,
							"isPageNumberRoman": false
						},
						{
							"eid": "sxp6siRVExK68MUJk12We",
							"type": "authorPaper",
							"text": "Measuring Software Resilience Using Socially Aware Truck Factor Estimation",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d793/573300d793.pdf",
							"extraLocations": [],
							"authorNames": "Alexis Butler (Royal Holloway University of London, United Kingdom), Dan O'Keeffe (Royal Holloway University of London, United Kingdom), Santanu Kumar Dash (University of Surrey, United Kingdom)",
							"abstract": "Continued timely maintenance is a key aspect of project security, but typically requires in-depth knowledge of a project's code base. Truck Factor is a metric that aims to represent how vulnerable a project is to losing this knowledge through the attrition of key contributors. However, the accuracy of existing Truck Factor estimators scales poorly with project size since they tend to ignore influential team members in managerial roles, which are more common in large projects. This work proposes SNet, a novel socially aware Truck Factor estimator based on social network analysis. SNet uses network centrality measures and social signals such as GitHub Issue interactions to estimate Truck Factor and identify Truck Factor contributors. We evaluate SNet against an existing ground truth comprised of twenty-six open source projects. Our social network analysis approach achieves superior contributor classification performance (Median F1 score = 0.8) while reducing computation time by over 2x compared to state-of-the-art estimators.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Measuring Software Resilience Using Socially Aware Truck Factor Estimation 1755858801815 10.1109/ASE63991.2025.00318 Alexis Butler Royal Holloway University of London, United Kingdom alexis.butler.2023@live.rhul.ac.uk Dan O'Keeffe Royal Holloway University of London, United Kingdom daniel.okeeffe@rhul.ac.uk Santanu Kumar Dash University of Surrey, United Kingdom s.k.dash@surrey.ac.uk software engineering software maintenance software security truck factor open source software Continued timely maintenance is a key aspect of project security, but typically requires in-depth knowledge of a project's code base. Truck Factor is a metric that aims to represent how vulnerable a project is to losing this knowledge through the attrition of key contributors. However, the accuracy of existing Truck Factor estimators scales poorly with project size since they tend to ignore influential team members in managerial roles, which are more common in large projects. This work proposes SNet, a novel socially aware Truck Factor estimator based on social network analysis. SNet uses network centrality measures and social signals such as GitHub Issue interactions to estimate Truck Factor and identify Truck Factor contributors. We evaluate SNet against an existing ground truth comprised of twenty-six open source projects. Our social network analysis approach achieves superior contributor classification performance (Median F1 score = 0.8) while reducing computation time by over 2x compared to state-of-the-art estimators.",
							"pageNumber": 3793,
							"isPageNumberRoman": false
						},
						{
							"eid": "1zZYeRDqNNT8mbEqdTNGbg",
							"type": "authorPaper",
							"text": "Interaction-Aware Patch Assessment for Multi-Fault Automated Program Repair",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d798/573300d798.pdf",
							"extraLocations": [],
							"authorNames": "Omar I. Al-Bataineh (Gran Sasso Science Institute, Italy)",
							"abstract": "Patch overfitting remains a persistent challenge in automated program repair (APR), especially when validation depends on incomplete test suites. We argue that this problem is significantly exacerbated by the overlooked presence of multiple interacting faults, a common yet under-addressed reality in real-world software. Conventional APR tools typically treat faults in isolation, neglecting subtle interactions that can mask faults or introduce regressions. To address this, we develop a taxonomy of five fault interaction-aware patch assessment strategies, supported by a formal model that identifies when and how each should be applied. Our framework guides robust multi-fault repair and exposes how fault interactions critically influence patch outcomes. To our knowledge, this is the first formal treatment of patch assessment and overfitting in multi-fault settings, offering a foundation for more reliable and practical APR.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Interaction-Aware Patch Assessment for Multi-Fault Automated Program Repair 1755540859621 10.1109/ASE63991.2025.00319 Omar I. Al-Bataineh Gran Sasso Science Institute, Italy omar.albataineh@gssi.it Patch overfitting remains a persistent challenge in automated program repair (APR), especially when validation depends on incomplete test suites. We argue that this problem is significantly exacerbated by the overlooked presence of multiple interacting faults, a common yet under-addressed reality in real-world software. Conventional APR tools typically treat faults in isolation, neglecting subtle interactions that can mask faults or introduce regressions. To address this, we develop a taxonomy of five fault interaction-aware patch assessment strategies, supported by a formal model that identifies when and how each should be applied. Our framework guides robust multi-fault repair and exposes how fault interactions critically influence patch outcomes. To our knowledge, this is the first formal treatment of patch assessment and overfitting in multi-fault settings, offering a foundation for more reliable and practical APR.",
							"pageNumber": 3798,
							"isPageNumberRoman": false
						},
						{
							"eid": "4dfK0RXrUBewnLtdLr4JFb",
							"type": "authorPaper",
							"text": "Debugging the Undebuggable: Why Multi-Fault Programs Break Debugging and Repair Tools",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d803/573300d803.pdf",
							"extraLocations": [],
							"authorNames": "Omar I. Al-Bataineh (Gran Sasso Science Institute, Italy)",
							"abstract": "Multi-fault programs, which contain more than one bug simultaneously, are notoriously difficult to debug and repair. This is largely because faults can interact in subtle ways: one might hide the effects of another, or even cause new failures to appear when combined. In this paper, we investigate why multi-fault programs remain so challenging for today's debugging and repair tools. We introduce a formal model that captures the different ways faults can interact, including masking, synergy, and cascading. Building on this model, we propose a novel framework for reasoning about faults, not in isolation, but as part of a network of influences. This perspective opens the door for future tools that can better understand, diagnose, and repair programs with multiple faults.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Debugging the Undebuggable: Why Multi-Fault Programs Break Debugging and Repair Tools 1755257727362 10.1109/ASE63991.2025.00320 Omar I. Al-Bataineh Gran Sasso Science Institute, Italy omar.albataineh@gssi.it multi-fault programs fault interactions fault-aware debugging Multi-fault programs, which contain more than one bug simultaneously, are notoriously difficult to debug and repair. This is largely because faults can interact in subtle ways: one might hide the effects of another, or even cause new failures to appear when combined. In this paper, we investigate why multi-fault programs remain so challenging for today's debugging and repair tools. We introduce a formal model that captures the different ways faults can interact, including masking, synergy, and cascading. Building on this model, we propose a novel framework for reasoning about faults, not in isolation, but as part of a network of influences. This perspective opens the door for future tools that can better understand, diagnose, and repair programs with multiple faults.",
							"pageNumber": 3803,
							"isPageNumberRoman": false
						},
						{
							"eid": "3NDbnvWAUG0DUA2Venf0Eb",
							"type": "authorPaper",
							"text": "How Does ChatGPT Make Assumptions When Creating Erroneous Programs?",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d808/573300d808.pdf",
							"extraLocations": [],
							"authorNames": "Sadia Jahan (The University of Texas at San Antonio, USA), Xiaoyin Wang (The University of Texas at San Antonio, USA)",
							"abstract": "Large Language Models (LLMs) like ChatGPT are increasingly integrated into software development environments due to their strong performance in code generation. However, they often struggle with complex logic, security vulnerabilities, and code quality issues. These problems frequently originate from misunderstandings of problem requirements and logical inconsistencies, which can lead to faulty or vulnerable software. In this study, we conduct an initial empirical analysis to investigate the causes of erroneous code generated by the state-of-the-art LLM model GPT-4o. Using the HumanEval dataset, we prompt GPT-4o to generate Python solutions and list its 3 most important assumptions. We validate these outputs against the provided test cases in dataset and identify 17 defective programs out of 164 total solutions. By analyzing the 17 failures and 51 assumptions made on these tasks, we find that about 53% the failures are directly related to wrong or erroneously implemented assumptions raised by the GPT model itself, and totally 71% of code generation failures are related to erroneously made or implemented assumptions.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 How Does ChatGPT Make Assumptions When Creating Erroneous Programs? 1756957207114 10.1109/ASE63991.2025.00321 Sadia Jahan The University of Texas at San Antonio, USA sadia.jahan@utsa.edu Xiaoyin Wang The University of Texas at San Antonio, USA xiaoyin.wang@utsa.edu llm assumptions code generation Large Language Models (LLMs) like ChatGPT are increasingly integrated into software development environments due to their strong performance in code generation. However, they often struggle with complex logic, security vulnerabilities, and code quality issues. These problems frequently originate from misunderstandings of problem requirements and logical inconsistencies, which can lead to faulty or vulnerable software. In this study, we conduct an initial empirical analysis to investigate the causes of erroneous code generated by the state-of-the-art LLM model GPT-4o. Using the HumanEval dataset, we prompt GPT-4o to generate Python solutions and list its 3 most important assumptions. We validate these outputs against the provided test cases in dataset and identify 17 defective programs out of 164 total solutions. By analyzing the 17 failures and 51 assumptions made on these tasks, we find that about 53% the failures are directly related to wrong or erroneously implemented assumptions raised by the GPT model itself, and totally 71% of code generation failures are related to erroneously made or implemented assumptions.",
							"pageNumber": 3808,
							"isPageNumberRoman": false
						},
						{
							"eid": "77nm8cJJwAK9EHgUPnmKcZ",
							"type": "authorPaper",
							"text": "LLM-Based Dynamic Differential Testing for Database Connectors with Reinforcement Learning-Guided Prompt Selection",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d813/573300d813.pdf",
							"extraLocations": [],
							"authorNames": "Ce Lyu (East China Normal University, China), Yanhao Wang (East China Normal University, China), Jie Liang (Beihang University, China), Minghao Zhao (East China Normal University, China)",
							"abstract": "Database connectors are critical components that enable applications to interact with database management systems (DBMS) but their security vulnerabilities are often neglected. Unlike traditional software defects, connector vulnerabilities exhibit subtle behavioral patterns and are inherently challenging to detect. Moreover, non-standardized implementation of connectors leaves potential risks (i.e., unsafe implementations) but is more elusive. As a result, existing fuzzing methods are ineffective in finding such vulnerabilities. Even large language model (LLM)-based methods are still incapable of generating test cases that can invoke all the interface and internal logic of database connectors due to a lack of domain knowledge. In this paper, we propose a new LLM-based test case generation method guided by reinforcement learning (RL) for database connector testing. Specifically, to equip the LLM with sufficient and appropriate domain knowledge, a parameterized template is composed for prompt construction. The LLM then generates test cases instructed by the constructed prompts, which are dynamically evaluated through differential testing across multiple connectors. The testing process is carried out iteratively, where RL is adopted to select the optimal prompt in each round based on behavioral feedback from the previous rounds, to maximize the efficiency of discovering inconsistencies. Finally, we implement and evaluate the aforementioned methodology on two widely used JDBC connectors, namely MySQL Connector/J and OceanBase Connector/J. In the preliminary results, we have reported 16 bugs, among which 10 are officially confirmed, and the rest are acknowledged as unsafe implementations.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 LLM-Based Dynamic Differential Testing for Database Connectors with Reinforcement Learning-Guided Prompt Selection 1755785196506 10.1109/ASE63991.2025.00322 Ce Lyu East China Normal University, China 51275903097@stu.ecnu.edu.cn Yanhao Wang East China Normal University, China yhwang@dase.ecnu.edu.cn Jie Liang Beihang University, China liangjie_work@buaa.edu.cn Minghao Zhao East China Normal University, China mhzhao@dase.ecnu.edu.cn differential testing dynamic testing database connector large language models Database connectors are critical components that enable applications to interact with database management systems (DBMS) but their security vulnerabilities are often neglected. Unlike traditional software defects, connector vulnerabilities exhibit subtle behavioral patterns and are inherently challenging to detect. Moreover, non-standardized implementation of connectors leaves potential risks (i.e., unsafe implementations) but is more elusive. As a result, existing fuzzing methods are ineffective in finding such vulnerabilities. Even large language model (LLM)-based methods are still incapable of generating test cases that can invoke all the interface and internal logic of database connectors due to a lack of domain knowledge. In this paper, we propose a new LLM-based test case generation method guided by reinforcement learning (RL) for database connector testing. Specifically, to equip the LLM with sufficient and appropriate domain knowledge, a parameterized template is composed for prompt construction. The LLM then generates test cases instructed by the constructed prompts, which are dynamically evaluated through differential testing across multiple connectors. The testing process is carried out iteratively, where RL is adopted to select the optimal prompt in each round based on behavioral feedback from the previous rounds, to maximize the efficiency of discovering inconsistencies. Finally, we implement and evaluate the aforementioned methodology on two widely used JDBC connectors, namely MySQL Connector/J and OceanBase Connector/J. In the preliminary results, we have reported 16 bugs, among which 10 are officially confirmed, and the rest are acknowledged as unsafe implementations.",
							"pageNumber": 3813,
							"isPageNumberRoman": false
						},
						{
							"eid": "3fS9qyfLxfRtjUcoJYTjeT",
							"type": "authorPaper",
							"text": "Uncovering Systematic Failures of LLMs in Verifying Code Against Natural Language Specifications",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d818/573300d818.pdf",
							"extraLocations": [],
							"authorNames": "Haolin Jin (The University of Sydney, Australia), Huaming Chen (The University of Sydney, Australia)",
							"abstract": "Large language models (LLMs) have become essential tools in software development, widely used for requirements engineering, code generation and review tasks. Software engineers increasingly rely on LLMs to assess whether system code implementation satisfy task requirements, thereby enhancing code robustness and accuracy. However, it remains unclear whether LLMs can reliably determine whether the code complies fully with the given task descriptions, which is usually natural language specifications. In this paper, we uncover a systematic failure of LLMs in evaluating whether code aligns with natural language requirements. Specifically, using widely adopted benchmarks, we employ unified prompts to judge code correctness. Our results reveal that LLMs frequently misclassify correct code implementations as either \"not satisfying requirements\" or containing potential defects. Surprisingly, more complex prompting, especially when leveraging prompt engineering techniques involving explanations and proposed corrections, leads to higher misjudgment rate, which highlights the critical reliability issues in using LLMs as code review assistants. We further analyze the root causes of these misjudgments, and propose two improved prompting strategies for mitigation. For the first time, our findings reveals unrecognized limitations in LLMs to match code with requirements. We also offer novel insights and practical guidance for effective use of LLMs in automated code review and task-oriented agent scenarios.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Uncovering Systematic Failures of LLMs in Verifying Code Against Natural Language Specifications 1755508497767 10.1109/ASE63991.2025.00323 Haolin Jin The University of Sydney, Australia haolin.jin@sydney.edu.au Huaming Chen The University of Sydney, Australia huaming.chen@sydney.edu.au large language models code review prompt engineering code understanding Large language models (LLMs) have become essential tools in software development, widely used for requirements engineering, code generation and review tasks. Software engineers increasingly rely on LLMs to assess whether system code implementation satisfy task requirements, thereby enhancing code robustness and accuracy. However, it remains unclear whether LLMs can reliably determine whether the code complies fully with the given task descriptions, which is usually natural language specifications. In this paper, we uncover a systematic failure of LLMs in evaluating whether code aligns with natural language requirements. Specifically, using widely adopted benchmarks, we employ unified prompts to judge code correctness. Our results reveal that LLMs frequently misclassify correct code implementations as either \"not satisfying requirements\" or containing potential defects. Surprisingly, more complex prompting, especially when leveraging prompt engineering techniques involving explanations and proposed corrections, leads to higher misjudgment rate, which highlights the critical reliability issues in using LLMs as code review assistants. We further analyze the root causes of these misjudgments, and propose two improved prompting strategies for mitigation. For the first time, our findings reveals unrecognized limitations in LLMs to match code with requirements. We also offer novel insights and practical guidance for effective use of LLMs in automated code review and task-oriented agent scenarios.",
							"pageNumber": 3818,
							"isPageNumberRoman": false
						},
						{
							"eid": "6zjKQXQHsvdryQDxUc4wgL",
							"type": "authorPaper",
							"text": "Is Measurement Enough? Rethinking Output Validation in Quantum Program Testing",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d823/573300d823.pdf",
							"extraLocations": [],
							"authorNames": "Jiaming Ye (Southwest Jiaotong University, China), Xiongfei Wu (University of Luxembourg, Luxembourg), Shangzhou Xia (Kyushu University, Japan), Fuyuan Zhang (Zhejiang University, China), Jianjun Zhao (Kyushu University, Japan)",
							"abstract": "As quantum computing continues to emerge, ensuring the quality of quantum programs has become increasingly critical. Quantum program testing has emerged as a prominent research area within the scope of quantum software engineering. While numerous approaches have been proposed to address quantum program quality assurance, our analysis reveals that most existing methods rely on measurement-based validation in practice. However, due to the inherently probabilistic nature of quantum programs, measurement-based validation methods face significant limitations. To investigate these limitations, we conducted an empirical study of recent research on quantum program testing, analyzing measurement-based validation methods in the literature. Our analysis categorizes existing measurement-based validation methods into two groups: distribution-level validation and output-value-level validation. We then compare measurement-based validation with statevector-based validation methods to evaluate their pros and cons. Our findings demonstrate that measurement-based validation is suitable for straightforward assessments, such as verifying the existence of specific output values, while statevector-based validation proves more effective for complicated tasks such as assessing the program behaviors.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Is Measurement Enough? Rethinking Output Validation in Quantum Program Testing 1755656179030 10.1109/ASE63991.2025.00324 Jiaming Ye Southwest Jiaotong University, China yejiaming@swjtu.edu.cn Xiongfei Wu University of Luxembourg, Luxembourg xiongfei.wu.a94@gmail.com Shangzhou Xia Kyushu University, Japan xiaszore19@gmail.com Fuyuan Zhang Zhejiang University, China fuyuanzhang@163.com Jianjun Zhao Kyushu University, Japan zhao@ait.kyushu-u.ac.jp As quantum computing continues to emerge, ensuring the quality of quantum programs has become increasingly critical. Quantum program testing has emerged as a prominent research area within the scope of quantum software engineering. While numerous approaches have been proposed to address quantum program quality assurance, our analysis reveals that most existing methods rely on measurement-based validation in practice. However, due to the inherently probabilistic nature of quantum programs, measurement-based validation methods face significant limitations. To investigate these limitations, we conducted an empirical study of recent research on quantum program testing, analyzing measurement-based validation methods in the literature. Our analysis categorizes existing measurement-based validation methods into two groups: distribution-level validation and output-value-level validation. We then compare measurement-based validation with statevector-based validation methods to evaluate their pros and cons. Our findings demonstrate that measurement-based validation is suitable for straightforward assessments, such as verifying the existence of specific output values, while statevector-based validation proves more effective for complicated tasks such as assessing the program behaviors.",
							"pageNumber": 3823,
							"isPageNumberRoman": false
						},
						{
							"eid": "5tVSaFD2INvQ7sermf48dD",
							"type": "authorPaper",
							"text": "The Future of Software Transparency: Bridging Understanding, Measurement, and Practice",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d828/573300d828.pdf",
							"extraLocations": [],
							"authorNames": "Gregorio Dalia (University of Sannio, Italy), Annibale  Panichella (Delft University of Technology, The Netherlands), Andrea Di Sorbo (University of Sannio, Italy), Gerardo Canfora (University of Sannio, Italy), Corrado Aaron Visaggio (University of Foggia, Italy)",
							"abstract": "Although the study of software transparency has deep roots in software engineering, a shared definition and practical application in real-world development contexts remain elusive. Through an in-depth analysis of the academic and industrial landscape, this article provides an overview of the current state of knowledge on software transparency, outlining a path to a deeper understanding of the subject for both developers and researchers. The challenge of software transparency involves not only establishing a formal, widely accepted understanding within the community, but also measuring and quantifying it in production environments. To this end, we survey academics and developers to evaluate an innovative approach to defining transparency and present a vision of a new framework for its quantification.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 The Future of Software Transparency: Bridging Understanding, Measurement, and Practice 1756734255112 10.1109/ASE63991.2025.00325 Gregorio Dalia University of Sannio, Italy g.dalia@studenti.unisannio.it Annibale Panichella Delft University of Technology, The Netherlands a.panichella@tudelft.nl Andrea Di Sorbo University of Sannio, Italy disorbo@unisannio.it Gerardo Canfora University of Sannio, Italy canfora@unisannio.it Corrado Aaron Visaggio University of Foggia, Italy corrado.visaggio@unifg.it software transparency software reuse security and privacy software engineering supply chain security Although the study of software transparency has deep roots in software engineering, a shared definition and practical application in real-world development contexts remain elusive. Through an in-depth analysis of the academic and industrial landscape, this article provides an overview of the current state of knowledge on software transparency, outlining a path to a deeper understanding of the subject for both developers and researchers. The challenge of software transparency involves not only establishing a formal, widely accepted understanding within the community, but also measuring and quantifying it in production environments. To this end, we survey academics and developers to evaluate an innovative approach to defining transparency and present a vision of a new framework for its quantification.",
							"pageNumber": 3828,
							"isPageNumberRoman": false
						},
						{
							"eid": "Ffk4juZDqIbSHGGD3jYob",
							"type": "authorPaper",
							"text": "Fault Injection for Simulink-Based CPS Models: Insights and Future Directions",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d833/573300d833.pdf",
							"extraLocations": [],
							"authorNames": "Drishti Yadav (University of Luxembourg, Luxembourg), Claudio Mandrioli (University of Luxembourg, Luxembourg), Ezio Bartocci (TU Wien, Austria), Domenico Bianculli (University of Luxembourg, Luxembourg)",
							"abstract": "Ensuring the safety and reliability of Cyber-Physical Systems (CPS) is critical, particularly in safety-critical domains such as automotive and aerospace. Fault Injection (FI) is a well-established technique for testing system resilience, but current FI tools often face challenges when applied to Simulink-based CPS models. In this paper, we analyze the shortcomings of existing FI methods, and reflect on the key challenges of FI for Simulink-based CPS models. By offering insights into these challenges and proposing research pathways, we aim to inspire further advances in FI methodologies, enabling more robust testing of CPS in real-world applications.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Fault Injection for Simulink-Based CPS Models: Insights and Future Directions 1756283872612 10.1109/ASE63991.2025.00326 Drishti Yadav University of Luxembourg, Luxembourg drishti.yadav@uni.lu Claudio Mandrioli University of Luxembourg, Luxembourg claudio.mandrioli@uni.lu Ezio Bartocci TU Wien, Austria ezio.bartocci@tuwien.ac.at Domenico Bianculli University of Luxembourg, Luxembourg domenico.bianculli@uni.lu cyber-physical systems fault injection simulink model-based development testing mutation Ensuring the safety and reliability of Cyber-Physical Systems (CPS) is critical, particularly in safety-critical domains such as automotive and aerospace. Fault Injection (FI) is a well-established technique for testing system resilience, but current FI tools often face challenges when applied to Simulink-based CPS models. In this paper, we analyze the shortcomings of existing FI methods, and reflect on the key challenges of FI for Simulink-based CPS models. By offering insights into these challenges and proposing research pathways, we aim to inspire further advances in FI methodologies, enabling more robust testing of CPS in real-world applications.",
							"pageNumber": 3833,
							"isPageNumberRoman": false
						},
						{
							"eid": "11Nb6bM8mgX0J5PR2z95aH",
							"type": "authorPaper",
							"text": "Taming Uncertainty via Automation: Observing, Analyzing, and Optimizing Agentic AI Systems",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d839/573300d839.pdf",
							"extraLocations": [],
							"authorNames": "Dany Moshkovich (IBM Research, Israel), Sergey Zeltyn (IBM Research, Israel)",
							"abstract": "Large Language Models (LLMs) are increasingly deployed within agentic systems\u2014collections of interacting, LLM-powered agents that execute complex, adaptive workflows using memory, tools, and dynamic planning. While enabling powerful new capabilities, these systems also introduce unique forms of uncertainty stemming from probabilistic reasoning, evolving memory states, and fluid execution paths. Traditional software observability and operations practices fall short in addressing these challenges. This paper presents our vision of AgentOps: a comprehensive framework for observing, analyzing, optimizing, and automating operation of agentic AI systems. We identify distinct needs across four key roles\u2014developers, testers, site reliability engineers (SREs), and business users\u2014each of whom engages with the system at different points in its lifecycle. We present the AgentOps Automation Pipeline, a six-stage process encompassing behavior observation, metric collection, issue detection, root cause analysis, optimized recommendations, and runtime automation. Throughout, we emphasize the critical role of automation in managing uncertainty and enabling self-improving AI systems\u2014not by eliminating uncertainty, but by taming it to ensure safe, adaptive, and effective operation.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Taming Uncertainty via Automation: Observing, Analyzing, and Optimizing Agentic AI Systems 1756986411267 10.1109/ASE63991.2025.00327 Dany Moshkovich IBM Research, Israel mdany@il.ibm.com Sergey Zeltyn IBM Research, Israel sergeyz@il.ibm.com Large Language Models Multi-Agent Systems Monitoring Analytics Observability Agentic systems Perfor mance Optimization Evaluation Large Language Models (LLMs) are increasingly deployed within agentic systems\u2014collections of interacting, LLM-powered agents that execute complex, adaptive workflows using memory, tools, and dynamic planning. While enabling powerful new capabilities, these systems also introduce unique forms of uncertainty stemming from probabilistic reasoning, evolving memory states, and fluid execution paths. Traditional software observability and operations practices fall short in addressing these challenges. This paper presents our vision of AgentOps: a comprehensive framework for observing, analyzing, optimizing, and automating operation of agentic AI systems. We identify distinct needs across four key roles\u2014developers, testers, site reliability engineers (SREs), and business users\u2014each of whom engages with the system at different points in its lifecycle. We present the AgentOps Automation Pipeline, a six-stage process encompassing behavior observation, metric collection, issue detection, root cause analysis, optimized recommendations, and runtime automation. Throughout, we emphasize the critical role of automation in managing uncertainty and enabling self-improving AI systems\u2014not by eliminating uncertainty, but by taming it to ensure safe, adaptive, and effective operation.",
							"pageNumber": 3839,
							"isPageNumberRoman": false
						},
						{
							"eid": "376H1fY3sCjXN9RPSc8YSH",
							"type": "authorPaper",
							"text": "Detecting and Repairing Incomplete Software Requirements with Multi-LLM Ensembles",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d844/573300d844.pdf",
							"extraLocations": [],
							"authorNames": "Mohamad Kassab (Boston University, U.S.A.), Marwan AbdElhameed (New York University Abu Dhabi, U.A.E.)",
							"abstract": "Ensuring complete software requirements specifications (SRS) is critical to preventing costly downstream errors. We present a tool that ensembles three complementary LLMs-DeepSeek Chat, GPT-4o Mini, and Claude Sonnet 4 to detect and suggest remedies for missing requirements. The tool generates a structured domain model and applies parallel external and internal completeness checks through tailored prompts. Users can select LLMs and aggregation methods (majority, weighted, or meta-fusion). Unlike prior single-model approaches, we systematically evaluate aggregation strategies across four diverse SRS domains. In experiments with seeded omissions, single models achieved only 0\u201352% recall, whereas our ensemble consistently exceeded 75%-reaching up to 100%-with 95-100% plausibility. These results demonstrate the feasibility of multi-LLM ensembles as practical aids-complementing rather than replacing human analysts-and supporting interactive refinement workflows.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Detecting and Repairing Incomplete Software Requirements with Multi-LLM Ensembles 1756892125587 10.1109/ASE63991.2025.00328 Mohamad Kassab Boston University, U.S.A. mkassab@bu.edu Marwan AbdElhameed New York University Abu Dhabi, U.A.E. marwan@nyu.edu Requirements Completeness Requirements En gineering Quality Metrics Large Language Models (LLMs) Ensuring complete software requirements specifications (SRS) is critical to preventing costly downstream errors. We present a tool that ensembles three complementary LLMs-DeepSeek Chat, GPT-4o Mini, and Claude Sonnet 4 to detect and suggest remedies for missing requirements. The tool generates a structured domain model and applies parallel external and internal completeness checks through tailored prompts. Users can select LLMs and aggregation methods (majority, weighted, or meta-fusion). Unlike prior single-model approaches, we systematically evaluate aggregation strategies across four diverse SRS domains. In experiments with seeded omissions, single models achieved only 0\u201352% recall, whereas our ensemble consistently exceeded 75%-reaching up to 100%-with 95-100% plausibility. These results demonstrate the feasibility of multi-LLM ensembles as practical aids-complementing rather than replacing human analysts-and supporting interactive refinement workflows.",
							"pageNumber": 3844,
							"isPageNumberRoman": false
						},
						{
							"eid": "4HXw8RAnb7IjfpRWFLUczi",
							"type": "authorPaper",
							"text": "Linguistic Theories Coincide with Misformalization in Temporal Logic",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d849/573300d849.pdf",
							"extraLocations": [],
							"authorNames": "Colin S. Gordon (Drexel University, USA)",
							"abstract": "One of the key challenges in using formal methods is producing accurate formalizations of natural language requirements, as providing incorrect formalizations may miss bugs or even codify their existence. Yet despite this critical role, recent studies have revealed that even experienced experts make mistakes when formalizing relatively simple specifications in Linear Temporal Logic (LTL). We analyze the data from one recent study from the perspective of linguistic phenomena that enrich what is said with additional meaning. We find that misunderstanding whether and when to formalize these phenomena could impact nearly half of novice mistakes and most expert mistakes in the dataset. We conclude that further study of the relationship between natural language specifications and these specific phenomena has potential to reduce misformalizations.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Linguistic Theories Coincide with Misformalization in Temporal Logic 1756955588373 10.1109/ASE63991.2025.00329 Colin S. Gordon Drexel University, USA csgordon@drexel.edu linguistics pragmatics temporal logic formal specification One of the key challenges in using formal methods is producing accurate formalizations of natural language requirements, as providing incorrect formalizations may miss bugs or even codify their existence. Yet despite this critical role, recent studies have revealed that even experienced experts make mistakes when formalizing relatively simple specifications in Linear Temporal Logic (LTL). We analyze the data from one recent study from the perspective of linguistic phenomena that enrich what is said with additional meaning. We find that misunderstanding whether and when to formalize these phenomena could impact nearly half of novice mistakes and most expert mistakes in the dataset. We conclude that further study of the relationship between natural language specifications and these specific phenomena has potential to reduce misformalizations.",
							"pageNumber": 3849,
							"isPageNumberRoman": false
						},
						{
							"eid": "7w5OTDBESUlPBaE0pZWzQZ",
							"type": "authorPaper",
							"text": "Exploring Autonomous Agents: A Closer Look at Why They Fail When Completing Tasks",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d855/573300d855.pdf",
							"extraLocations": [],
							"authorNames": "Ruofan Lu (The Chinese University of Hong Kong, Hong Kong), Yichen Li (The Chinese University of Hong Kong, Hong Kong), Yintong Huo (Singapore Management University, Singapore)",
							"abstract": "Autonomous agent systems powered by Large Language Models (LLMs) have demonstrated promising capabilities in automating complex tasks. However, current evaluations largely rely on success rates without systematically analyzing the interactions, communication mechanisms, and failure causes within these systems. To bridge this gap, we present a benchmark of 34 representative programmable tasks designed to rigorously assess autonomous agents. Using this benchmark, we evaluate three popular open-source agent frameworks combined with two LLM backbones, observing a task completion rate of approximately 50%. Through in-depth failure analysis, we develop a three-tier taxonomy of failure causes aligned with task phases, highlighting planning errors, task execution issues, and incorrect response generation. Based on these insights, we propose actionable improvements to enhance agent planning and self-diagnosis capabilities. Our failure taxonomy, together with mitigation advice, provides an empirical foundation for developing more robust and effective autonomous agent systems in the future.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Exploring Autonomous Agents: A Closer Look at Why They Fail When Completing Tasks 1755505483875 10.1109/ASE63991.2025.00330 Ruofan Lu The Chinese University of Hong Kong, Hong Kong rflu@cse.cuhk.edu.hk Yichen Li The Chinese University of Hong Kong, Hong Kong ycli21@cse.cuhk.edu.hk Yintong Huo Singapore Management University, Singapore ythuo@smu.edu.sg llm agents autonomous agents failure analysis Autonomous agent systems powered by Large Language Models (LLMs) have demonstrated promising capabilities in automating complex tasks. However, current evaluations largely rely on success rates without systematically analyzing the interactions, communication mechanisms, and failure causes within these systems. To bridge this gap, we present a benchmark of 34 representative programmable tasks designed to rigorously assess autonomous agents. Using this benchmark, we evaluate three popular open-source agent frameworks combined with two LLM backbones, observing a task completion rate of approximately 50%. Through in-depth failure analysis, we develop a three-tier taxonomy of failure causes aligned with task phases, highlighting planning errors, task execution issues, and incorrect response generation. Based on these insights, we propose actionable improvements to enhance agent planning and self-diagnosis capabilities. Our failure taxonomy, together with mitigation advice, provides an empirical foundation for developing more robust and effective autonomous agent systems in the future.",
							"pageNumber": 3855,
							"isPageNumberRoman": false
						},
						{
							"eid": "6BNapr1NkeqJbmUtmeILTA",
							"type": "authorPaper",
							"text": "LLM-Powered Fully Automated Chaos Engineering: Towards Enabling Anyone to Build Resilient Software Systems at Low Cost",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d860/573300d860.pdf",
							"extraLocations": [],
							"authorNames": "Daisuke Kikuta (NTT, Inc., Japan), Hiroki Ikeuchi (NTT, Inc., Japan), Kengo Tajiri (NTT, Inc., Japan)",
							"abstract": "Chaos Engineering (CE) is an engineering technique aimed at improving the resilience of distributed systems. It involves intentionally injecting faults into a system to test its resilience, uncover weaknesses, and address them before they cause failures in production. Recent CE tools automate the execution of predefined CE experiments. However, planning such experiments and improving the system based on the experimental results still remain manual. These processes are labor-intensive and require multi-domain expertise. To address these challenges and enable anyone to build resilient systems at low cost, this paper proposes ChaosEater, a system that automates the entire CE cycle with Large Language Models (LLMs). It predefines an agentic workflow according to a systematic CE cycle and assigns subdivided processes within the workflow to LLMs. ChaosEater targets CE for software systems built on Kubernetes. Therefore, the LLMs in ChaosEater complete CE cycles through software engineering tasks, including requirement definition, code generation, testing, and debugging. We evaluate ChaosEater through case studies on small- and large-scale Kubernetes systems. The results demonstrate that it consistently completes reasonable CE cycles with significantly low time and monetary costs. Its cycles are also qualitatively validated by human engineers and LLMs.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 LLM-Powered Fully Automated Chaos Engineering: Towards Enabling Anyone to Build Resilient Software Systems at Low Cost 1757065421882 10.1109/ASE63991.2025.00331 Daisuke Kikuta NTT, Inc., Japan daisuke.kikuta@ntt.com Hiroki Ikeuchi NTT, Inc., Japan hiroki.ikeuchi@ntt.com Kengo Tajiri NTT, Inc., Japan kengo.tajiri@ntt.com Large Language Models AI Agents AIOps Chaos Engineering Failure Management Software Systems Chaos Engineering (CE) is an engineering technique aimed at improving the resilience of distributed systems. It involves intentionally injecting faults into a system to test its resilience, uncover weaknesses, and address them before they cause failures in production. Recent CE tools automate the execution of predefined CE experiments. However, planning such experiments and improving the system based on the experimental results still remain manual. These processes are labor-intensive and require multi-domain expertise. To address these challenges and enable anyone to build resilient systems at low cost, this paper proposes ChaosEater, a system that automates the entire CE cycle with Large Language Models (LLMs). It predefines an agentic workflow according to a systematic CE cycle and assigns subdivided processes within the workflow to LLMs. ChaosEater targets CE for software systems built on Kubernetes. Therefore, the LLMs in ChaosEater complete CE cycles through software engineering tasks, including requirement definition, code generation, testing, and debugging. We evaluate ChaosEater through case studies on small- and large-scale Kubernetes systems. The results demonstrate that it consistently completes reasonable CE cycles with significantly low time and monetary costs. Its cycles are also qualitatively validated by human engineers and LLMs.",
							"pageNumber": 3860,
							"isPageNumberRoman": false
						},
						{
							"eid": "wYg6MNErJRX2SXc2Qsbfx",
							"type": "authorPaper",
							"text": "Unseen Data Detection using Routing Entropy in Mixture-of-Experts for Autonomous Vehicles",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d865/573300d865.pdf",
							"extraLocations": [],
							"authorNames": "Sang In Lee (Chungnam National University, South Korea), Donghwan Shin (University of Sheffield, United Kingdom), Jihun Park (Chungnam National University, South Korea)",
							"abstract": "Unseen data that differ significantly from the training data can cause machine learning models to behave unpredictably, which is particularly problematic in safety-critical systems like autonomous vehicles. Detecting such data, commonly called out-of-distribution (OOD) data, is essential for ensuring the robustness of these models. Existing methods often rely on the model's final output, which are limited since the model can be overconfident on unseen data. In this paper, we propose Routing Entropy, a novel OOD detection method that leverages the internal routing behavior of Mixture-of-Experts (MoE) models, a design increasingly adopted in modern neural networks. We hypothesize that MoE models exhibit high confidence routing for in-distribution (ID) inputs, but greater uncertainty for OOD inputs. We quantify this uncertainty by calculating the entropy of the routing scores for a given input. Experimental results on a MoE-based semantic segmentation model used for perception in autonomous driving demonstrate that Routing Entropy is effective on its own and, more importantly, provides a complementary signal to existing output-based methods. Combining Routing Entropy with an existing method significantly improves OOD detection performance. These results suggest that leveraging internal routing behavior of MoE models is a promising direction for robust OOD detection.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Unseen Data Detection using Routing Entropy in Mixture-of-Experts for Autonomous Vehicles 1756450494114 10.1109/ASE63991.2025.00332 Sang In Lee Chungnam National University, South Korea sangin.lee.life@o.cnu.ac.kr Donghwan Shin University of Sheffield, United Kingdom d.shin@sheffield.ac.uk Jihun Park Chungnam National University, South Korea jihun.park@cnu.ac.kr Out-of-distribution detection uncertainty quantification mixture-of-experts routing entropy Unseen data that differ significantly from the training data can cause machine learning models to behave unpredictably, which is particularly problematic in safety-critical systems like autonomous vehicles. Detecting such data, commonly called out-of-distribution (OOD) data, is essential for ensuring the robustness of these models. Existing methods often rely on the model's final output, which are limited since the model can be overconfident on unseen data. In this paper, we propose Routing Entropy, a novel OOD detection method that leverages the internal routing behavior of Mixture-of-Experts (MoE) models, a design increasingly adopted in modern neural networks. We hypothesize that MoE models exhibit high confidence routing for in-distribution (ID) inputs, but greater uncertainty for OOD inputs. We quantify this uncertainty by calculating the entropy of the routing scores for a given input. Experimental results on a MoE-based semantic segmentation model used for perception in autonomous driving demonstrate that Routing Entropy is effective on its own and, more importantly, provides a complementary signal to existing output-based methods. Combining Routing Entropy with an existing method significantly improves OOD detection performance. These results suggest that leveraging internal routing behavior of MoE models is a promising direction for robust OOD detection.",
							"pageNumber": 3865,
							"isPageNumberRoman": false
						},
						{
							"eid": "DjD1BQbjUjIXS3mhg3Lmb",
							"type": "authorPaper",
							"text": "CodeACT-R: A Cognitive Simulation Framework for Human Attention in Code Reading",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d870/573300d870.pdf",
							"extraLocations": [],
							"authorNames": "Yueke Zhang (Vanderbilt University, USA), Zihan Fang (Vanderbilt University, USA), Greg Trafton (US Naval Research Laboratory, USA), Daniel Levin (Vanderbilt University, USA), Kevin Leach (Vanderbilt University, USA), Yu Huang (Vanderbilt University, USA)",
							"abstract": "Reading code is a fundamental activity in both software engineering and computer science education. Understanding the cognitive processes involved in reading code is crucial for identifying effective cognitive strategies, which can inform teaching methods and tooling support for developers. However, collecting large human subject eye tracking datasets, especially for programming tasks, is often costly and time-consuming, limiting its scalability and applicability. To address this issue, we present CodeACT-R, the first cognitive simulation framework tailored for code reading, based on the well-established Adaptive Control of ThoughtRational (ACT-R) architecture from cognitive science. CodeACT-R simulates how humans read code and requires only a small, manageable amount of human data to initiate the simulator design, offering a cost-effective and scalable alternative to traditional data collection methods like eye tracking. Specifically, we first collected real human visual attention data from 48 programmers reading code using eye tracking. These data were then used to develop CodeACT-R, enabling the simulation of human-like code reading behaviors. Our evaluation demonstrates that CodeACT-R is capable of simulating visual attention patterns (i.e., scanpaths) that closely resemble real-world human attention patterns, also accounting for up to 87% of observed pattern variations. ",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 CodeACT-R: A Cognitive Simulation Framework for Human Attention in Code Reading 1756154176683 10.1109/ASE63991.2025.00333 Yueke Zhang Vanderbilt University, USA yueke.zhang@vanderbilt.edu Zihan Fang Vanderbilt University, USA zihan.fang@vanderbilt.edu Greg Trafton US Naval Research Laboratory, USA greg.j.trafton.civ@us.navy.mil Daniel Levin Vanderbilt University, USA daniel.t.levin@vanderbilt.edu Kevin Leach Vanderbilt University, USA kevin.leach@vanderbilt.edu Yu Huang Vanderbilt University, USA yu.huang@vanderbilt.edu Cognitive Simulation Eye Tracking Code Reading Program Comprehension Reading code is a fundamental activity in both software engineering and computer science education. Understanding the cognitive processes involved in reading code is crucial for identifying effective cognitive strategies, which can inform teaching methods and tooling support for developers. However, collecting large human subject eye tracking datasets, especially for programming tasks, is often costly and time-consuming, limiting its scalability and applicability. To address this issue, we present CodeACT-R, the first cognitive simulation framework tailored for code reading, based on the well-established Adaptive Control of ThoughtRational (ACT-R) architecture from cognitive science. CodeACT-R simulates how humans read code and requires only a small, manageable amount of human data to initiate the simulator design, offering a cost-effective and scalable alternative to traditional data collection methods like eye tracking. Specifically, we first collected real human visual attention data from 48 programmers reading code using eye tracking. These data were then used to develop CodeACT-R, enabling the simulation of human-like code reading behaviors. Our evaluation demonstrates that CodeACT-R is capable of simulating visual attention patterns (i.e., scanpaths) that closely resemble real-world human attention patterns, also accounting for up to 87% of observed pattern variations.",
							"pageNumber": 3870,
							"isPageNumberRoman": false
						},
						{
							"eid": "7sx8K8H3p1oiAdIv4BVvAM",
							"type": "authorPaper",
							"text": "Envisioning Intelligent Requirements Engineering via Knowledge-Guided Multi-Agent Collaboration",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d875/573300d875.pdf",
							"extraLocations": [],
							"authorNames": "Jiangping Huang (Chongqing University of Posts and Telecommunications, China), Dongmin Jin (Peking University, China), Weisong Sun ( Nanyang Technological University, Singapore), Yang Liu (Nanyang Technological University, Singapore), Zhi Jin (Wuhan University, China)",
							"abstract": "Requirements Engineering (RE) is an initial and critical phase in software development, with the aim of producing well-defined software requirements specifications (SRSs) from rough ideas of clients. It involves multiple tasks (e.g., elicitation, analysis) and roles (e.g., interviewer, analyst). With the rise of Large Language Models (LLMs), many studies have leveraged LLMs to support specific RE tasks. However, existing LLM-based agents often lack domain knowledge integration and fall short in simulating the complex collaboration of human experts across the full RE process. To address this gap, we propose KGMAF, a knowledge-guided multi-agent framework designed to assist requirements engineers in developing high-quality SRSs. KGMAF comprises six LLM-based agents and a shared artifact pool. Each agent is equipped with predefined actions, dedicated functions, and injected knowledge tailored to specific RE tasks. The artifact pool stores both intermediate and final artifacts, serving as a communication channel for inter-agent collaboration. A human-in-the-loop (HITL) mechanism is embedded to guide and validate agent outputs. We present the design of KGMAF, along with preliminary experiments and a case study to demonstrate its practicality. This work lays the foundation for future research on knowledge-driven multi-agent collaboration in RE and highlights key challenges in building trustworthy intelligent assistants for real-world RE tasks.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Envisioning Intelligent Requirements Engineering via Knowledge-Guided Multi-Agent Collaboration 1757040912230 10.1109/ASE63991.2025.00334 Jiangping Huang Chongqing University of Posts and Telecommunications, China huangjp@cqupt.edu.cn Dongmin Jin Peking University, China dmjin@stu.pku.edu.cn Weisong Sun Nanyang Technological University, Singapore weisong.sun@ntu.edu.sg Yang Liu Nanyang Technological University, Singapore yangliu@ntu.edu.sg Zhi Jin Wuhan University, China zhijin@whu.edu.cn intelligent requirements development require ments engineering large language models multi-agent collabo ration knowledge injection human-in-the-loop Requirements Engineering (RE) is an initial and critical phase in software development, with the aim of producing well-defined software requirements specifications (SRSs) from rough ideas of clients. It involves multiple tasks (e.g., elicitation, analysis) and roles (e.g., interviewer, analyst). With the rise of Large Language Models (LLMs), many studies have leveraged LLMs to support specific RE tasks. However, existing LLM-based agents often lack domain knowledge integration and fall short in simulating the complex collaboration of human experts across the full RE process. To address this gap, we propose KGMAF, a knowledge-guided multi-agent framework designed to assist requirements engineers in developing high-quality SRSs. KGMAF comprises six LLM-based agents and a shared artifact pool. Each agent is equipped with predefined actions, dedicated functions, and injected knowledge tailored to specific RE tasks. The artifact pool stores both intermediate and final artifacts, serving as a communication channel for inter-agent collaboration. A human-in-the-loop (HITL) mechanism is embedded to guide and validate agent outputs. We present the design of KGMAF, along with preliminary experiments and a case study to demonstrate its practicality. This work lays the foundation for future research on knowledge-driven multi-agent collaboration in RE and highlights key challenges in building trustworthy intelligent assistants for real-world RE tasks.",
							"pageNumber": 3875,
							"isPageNumberRoman": false
						},
						{
							"eid": "58d6NNIRQvgPuxNLp4m4cw",
							"type": "authorPaper",
							"text": "NovaQ: Improving Quantum Program Testing through Diversity-Guided Test Case Generation",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d880/573300d880.pdf",
							"extraLocations": [],
							"authorNames": "Tiancheng Jin (Kyushu University, Japan), Shangzhou Xia (Kyushu University, Japan), Jianjun Zhao (Kyushu University, Japan)",
							"abstract": "Quantum programs are designed to run on quantum computers, leveraging quantum circuits to solve problems that are intractable for classical machines. As quantum computing advances, ensuring the reliability of quantum programs has become increasingly important. This paper introduces NovaQ, a diversity-guided testing framework for quantum programs. NovaQ combines a distribution-based test case generator with a novelty-driven evaluation module. The generator produces diverse quantum state inputs by mutating circuit parameters, while the evaluator quantifies behavioral novelty based on internal circuit state metrics, including magnitude, phase, and entanglement. By selecting inputs that map to infrequently covered regions in the metric space, NovaQ effectively explores under-tested program behaviors. We evaluate NovaQ on quantum programs of varying sizes and complexities. Experimental results show that NovaQ consistently achieves higher test input diversity and detects more bugs than existing baseline approaches.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 NovaQ: Improving Quantum Program Testing through Diversity-Guided Test Case Generation 1756881845163 10.1109/ASE63991.2025.00335 Tiancheng Jin Kyushu University, Japan jintc1@f.ait.kyushu-u.ac.jp Shangzhou Xia Kyushu University, Japan xia.shangzhou.218@s.kyushu-u.ac.jp Jianjun Zhao Kyushu University, Japan zhao@ait.kyushu-u.ac.jp quantum programs test case diversity magnitude phase entanglement Quantum programs are designed to run on quantum computers, leveraging quantum circuits to solve problems that are intractable for classical machines. As quantum computing advances, ensuring the reliability of quantum programs has become increasingly important. This paper introduces NovaQ, a diversity-guided testing framework for quantum programs. NovaQ combines a distribution-based test case generator with a novelty-driven evaluation module. The generator produces diverse quantum state inputs by mutating circuit parameters, while the evaluator quantifies behavioral novelty based on internal circuit state metrics, including magnitude, phase, and entanglement. By selecting inputs that map to infrequently covered regions in the metric space, NovaQ effectively explores under-tested program behaviors. We evaluate NovaQ on quantum programs of varying sizes and complexities. Experimental results show that NovaQ consistently achieves higher test input diversity and detects more bugs than existing baseline approaches.",
							"pageNumber": 3880,
							"isPageNumberRoman": false
						},
						{
							"eid": "13JVfGpDqYUPedYkFXTXvG",
							"type": "authorPaper",
							"text": "When Abstraction Breaks Physics: Rethinking Modular Design in Quantum Software",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d885/573300d885.pdf",
							"extraLocations": [],
							"authorNames": "Jianjun Zhao (Kyushu University, Japan)",
							"abstract": "Abstraction is a fundamental principle in classical software engineering, which enables modularity, reusability, and scalability. However, quantum programs adhere to fundamentally different semantics, such as unitarity, entanglement, the no-cloning theorem, and the destructive nature of measurement, which introduce challenges to the safe use of classical abstraction mechanisms. This paper identifies a fundamental conflict in quantum software engineering: abstraction practices that are syntactically valid may violate the physical constraints of quantum computation. We present three classes of failure cases where naive abstraction breaks quantum semantics and propose a set of design principles for physically sound abstraction mechanisms. We further propose research directions, including quantum-specific type systems, effect annotations, and contract-based module design. Our goal is to initiate a systematic rethinking of abstraction in quantum programming, based on quantum semantics and considering engineering scalability.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 When Abstraction Breaks Physics: Rethinking Modular Design in Quantum Software 1757087457054 10.1109/ASE63991.2025.00336 Jianjun Zhao Kyushu University, Japan zhao@ait.kyushu-u.ac.jp quantum software engineering abstraction modularity quantum programming quantum semantics Abstraction is a fundamental principle in classical software engineering, which enables modularity, reusability, and scalability. However, quantum programs adhere to fundamentally different semantics, such as unitarity, entanglement, the no-cloning theorem, and the destructive nature of measurement, which introduce challenges to the safe use of classical abstraction mechanisms. This paper identifies a fundamental conflict in quantum software engineering: abstraction practices that are syntactically valid may violate the physical constraints of quantum computation. We present three classes of failure cases where naive abstraction breaks quantum semantics and propose a set of design principles for physically sound abstraction mechanisms. We further propose research directions, including quantum-specific type systems, effect annotations, and contract-based module design. Our goal is to initiate a systematic rethinking of abstraction in quantum programming, based on quantum semantics and considering engineering scalability.",
							"pageNumber": 3885,
							"isPageNumberRoman": false
						},
						{
							"eid": "2b1QUGYyYwlD11QNgOwE61",
							"type": "authorPaper",
							"text": "Towards Automated Governance: A DSL for Human-Agent Collaboration in Software Projects",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d890/573300d890.pdf",
							"extraLocations": [],
							"authorNames": "Adem Ait (University of Luxembourg, Luxembourg), Gwendal Jouneaux (Luxembourg Institute of Science and Technology, Luxembourg), Javier Luis C\u00E1novas Izquierdo (Universitat Oberta de Catalunya, Spain), Jordi Cabot (University of Luxembourg, Luxembourg)",
							"abstract": "The stakeholders involved in software development are becoming increasingly diverse, with both human contributors from varied backgrounds and AI-powered agents collaborating together in the process. This situation presents unique governance challenges, particularly in Open-Source Software (OSS) projects, where explicit policies are often lacking or unclear. This paper presents the vision and foundational concepts for a novel Domain-Specific Language (DSL) designed to define and enforce rich governance policies in systems involving diverse stakeholders, including agents. This DSL offers a pathway towards more robust, adaptable, and ultimately automated governance, paving the way for more effective collaboration in software projects, especially OSS ones.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Towards Automated Governance: A DSL for Human-Agent Collaboration in Software Projects 1756883715939 10.1109/ASE63991.2025.00337 Adem Ait University of Luxembourg, Luxembourg adem.ait@uni.lu Gwendal Jouneaux Luxembourg Institute of Science and Technology, Luxembourg gwendal.jouneaux@list.lu Javier Luis C\u00E1novas Izquierdo Universitat Oberta de Catalunya, Spain jcanovasi@uoc.edu Jordi Cabot University of Luxembourg, Luxembourg jordi.cabot@list.lu The stakeholders involved in software development are becoming increasingly diverse, with both human contributors from varied backgrounds and AI-powered agents collaborating together in the process. This situation presents unique governance challenges, particularly in Open-Source Software (OSS) projects, where explicit policies are often lacking or unclear. This paper presents the vision and foundational concepts for a novel Domain-Specific Language (DSL) designed to define and enforce rich governance policies in systems involving diverse stakeholders, including agents. This DSL offers a pathway towards more robust, adaptable, and ultimately automated governance, paving the way for more effective collaboration in software projects, especially OSS ones.",
							"pageNumber": 3890,
							"isPageNumberRoman": false
						},
						{
							"eid": "zKAuMoXjICvzHa6FC3i7n",
							"type": "authorPaper",
							"text": "Simulated Interactive Debugging",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d895/573300d895.pdf",
							"extraLocations": [],
							"authorNames": "Yannic Noller (Ruhr University Bochum, Germany), Erick Chandra (Singapore University of Technology and Design, Singapore), Srinidhi Chandrashekar (Singapore University of Technology and Design, Singapore), Kenny Choo (Singapore University of Technology and Design, Singapore), Cyrille Jegourel (Singapore University of Technology and Design, Singapore), Oka Kurniawan (Singapore University of Technology and Design, Singapore), Christopher M. Poskitt (Singapore Management University, Singapore)",
							"abstract": "Debugging software, i.e., the localization of faults and their repair, is a key activity in software engineering. Therefore, effective and efficient debugging is one of the core skills a software engineer must develop. However, the teaching of debugging techniques is usually very limited or only taught in indirect ways, e.g., during software projects. As a result, most Computer Science (CS) students learn debugging only in an ad-hoc and unstructured way. In this work, we present our approach called Simulated Interactive Debugging that interactively guides students along the debugging process. The guidance aims to empower the students to repair their solutions and have a proper learning experience. We envision that such guided debugging techniques can be integrated into programming courses early in the CS education curriculum. We developed a prototypical implementation using traditional fault localization techniques and large language models. Students can use features like the automated setting of breakpoints or an interactive chatbot. We designed and executed a small-scale, controlled experiment with eight undergraduate CS students. Based on the responses, we conclude that the participants liked the systematic guidance. They rated the automated setting of breakpoints as most effective, followed by the interactive debugging and chatting, and the breakpoint explanations. In future, we will extend our concept and implementation, and perform more intensive user studies.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Simulated Interactive Debugging 1755874783152 10.1109/ASE63991.2025.00338 Yannic Noller Ruhr University Bochum, Germany yannic.noller@acm.org Erick Chandra Singapore University of Technology and Design, Singapore erick_chandra@sutd.edu.sg Srinidhi Chandrashekar Singapore University of Technology and Design, Singapore srinidhi_chandrashekar@sutd.edu.sg Kenny Choo Singapore University of Technology and Design, Singapore kenny_choo@sutd.edu.sg Cyrille Jegourel Singapore University of Technology and Design, Singapore cyrille_jegourel@sutd.edu.sg Oka Kurniawan Singapore University of Technology and Design, Singapore oka_kurniawan@sutd.edu.sg Christopher M. Poskitt Singapore Management University, Singapore cposkitt@smu.edu.sg intelligent tutoring debugging software engineering education Debugging software, i.e., the localization of faults and their repair, is a key activity in software engineering. Therefore, effective and efficient debugging is one of the core skills a software engineer must develop. However, the teaching of debugging techniques is usually very limited or only taught in indirect ways, e.g., during software projects. As a result, most Computer Science (CS) students learn debugging only in an ad-hoc and unstructured way. In this work, we present our approach called Simulated Interactive Debugging that interactively guides students along the debugging process. The guidance aims to empower the students to repair their solutions and have a proper learning experience. We envision that such guided debugging techniques can be integrated into programming courses early in the CS education curriculum. We developed a prototypical implementation using traditional fault localization techniques and large language models. Students can use features like the automated setting of breakpoints or an interactive chatbot. We designed and executed a small-scale, controlled experiment with eight undergraduate CS students. Based on the responses, we conclude that the participants liked the systematic guidance. They rated the automated setting of breakpoints as most effective, followed by the interactive debugging and chatting, and the breakpoint explanations. In future, we will extend our concept and implementation, and perform more intensive user studies.",
							"pageNumber": 3895,
							"isPageNumberRoman": false
						},
						{
							"eid": "65VYQfSZ3fTt55mN4lgfwj",
							"type": "authorPaper",
							"text": "LLM-Guided Genetic Improvement: Envisioning Semantic Aware Automated Software Evolution",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d901/573300d901.pdf",
							"extraLocations": [],
							"authorNames": "Karine Even-Mendoza (King's College London, UK), Alexander Brownlee (University of Stirling, UK), Alina Geiger (Johannes Gutenberg University Mainz, Germany), Carol Hanna (University College London, UK), Justyna Petke (University College London, UK), Federica Sarro (University College London, UK), Dominik Sobania (Johannes Gutenberg University Mainz, Germany)",
							"abstract": "Genetic Improvement (GI) of software automatically creates alternative software versions that are improved according to certain properties of interests (e.g., running-time). Search-based GI excels at navigating large program spaces, but operates primarily at the syntactic level. In contrast, Large Language Models (LLMs) offer semantic-aware edits, yet lack goal-directed feedback and control (which is instead a strength of GI). As such, we propose the investigation of a new research line on AI-powered GI aimed at incorporating semantic aware search. We take a first step at it by augmenting GI with the use of automated clustering of LLM edits. We provide initial empirical evidence that our proposal, dubbed PatchCat, allows us to automatically and effectively categorize LLM-suggested patches. PatchCat identified 18 different types of software patches and categorized newly suggested patches with high accuracy. It also enabled detecting NoOp edits in advance and, prospectively, to skip test suite execution to save resources in many cases. These results, coupled with the fact that PatchCat works with small, local LLMs, are a promising step toward interpretable, efficient, and green GI. We outline a rich agenda of future work and call for the community to join our vision of building a principled understanding of LLM-driven mutations, guiding the GI search process with semantic signals.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 LLM-Guided Genetic Improvement: Envisioning Semantic Aware Automated Software Evolution 1755851932617 10.1109/ASE63991.2025.00339 Karine Even-Mendoza King's College London, UK karine.even_mendoza@kcl.ac.uk Alexander Brownlee University of Stirling, UK alexander.brownlee@stir.ac.uk Alina Geiger Johannes Gutenberg University Mainz, Germany geiger@uni-mainz.de Carol Hanna University College London, UK carol.hanna.21@ucl.ac.uk Justyna Petke University College London, UK j.petke@ucl.ac.uk Federica Sarro University College London, UK f.sarro@ucl.ac.uk Dominik Sobania Johannes Gutenberg University Mainz, Germany dsobania@uni-mainz.de large language models genetic improvement Genetic Improvement (GI) of software automatically creates alternative software versions that are improved according to certain properties of interests (e.g., running-time). Search-based GI excels at navigating large program spaces, but operates primarily at the syntactic level. In contrast, Large Language Models (LLMs) offer semantic-aware edits, yet lack goal-directed feedback and control (which is instead a strength of GI). As such, we propose the investigation of a new research line on AI-powered GI aimed at incorporating semantic aware search. We take a first step at it by augmenting GI with the use of automated clustering of LLM edits. We provide initial empirical evidence that our proposal, dubbed PatchCat, allows us to automatically and effectively categorize LLM-suggested patches. PatchCat identified 18 different types of software patches and categorized newly suggested patches with high accuracy. It also enabled detecting NoOp edits in advance and, prospectively, to skip test suite execution to save resources in many cases. These results, coupled with the fact that PatchCat works with small, local LLMs, are a promising step toward interpretable, efficient, and green GI. We outline a rich agenda of future work and call for the community to join our vision of building a principled understanding of LLM-driven mutations, guiding the GI search process with semantic signals.",
							"pageNumber": 3901,
							"isPageNumberRoman": false
						},
						{
							"eid": "2MGH8Pk4OZCOwkoeyVno05",
							"type": "authorPaper",
							"text": "ConfuseTaint: Exploiting Vulnerabilities to Bypass Dynamic Taint Analysis",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d906/573300d906.pdf",
							"extraLocations": [],
							"authorNames": "Yufei Wu (Ume\u00E5 University), Alexandre Bartel (Ume\u00E5 University)",
							"abstract": "Dynamic taint analysis (DTA) tracks how sensitive data flows through a program at runtime, enabling the detection of security violations such as information leaks and injection attacks. However, most DTA systems assume that memory layouts are type-safe and structurally consistent\u2014an assumption that can be violated by vulnerabilities such as type confusion. While type confusion has been studied in the context of sandbox escape, its ability to silently bypass taint tracking without altering program behavior remains unexplored. In this paper, we present ConfuseTaint, a technique that leverages type confusion vulnerabilities to corrupt taint metadata without modifying program semantics or the analysis tool. ConfuseTaint uses wide memory overwrites enabled by type confusion to corrupt taint tags, breaking the assumptions of taint tracking mechanisms that rely on shadow memory. We evaluate ConfuseTaint on two widely used taint tracking frameworks: Phosphor for the JVM and TaintDroid for Android. In both cases, ConfuseTaint successfully bypasses taint tracking, allowing sensitive data to reach designated sinks without detection. These results reveal a structural weakness in current DTA designs: their reliance on type-safe memory layouts leaves them vulnerable to low-level reinterpretation. Overall, our work reveals that runtime-level memory reinterpretation is an overlooked threat, calling for taint tracking architectures that do not rely on fragile assumptions about type and memory layout.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 ConfuseTaint: Exploiting Vulnerabilities to Bypass Dynamic Taint Analysis 1755631304627 10.1109/ASE63991.2025.00340 Yufei Wu Ume\u00E5 University yufeiwu@cs.umu.se Alexandre Bartel Ume\u00E5 University alexandre.bartel@cs.umu.se Program Analysis Dynamic analysis Taint analysis Type confusion Vulnerability Dynamic taint analysis (DTA) tracks how sensitive data flows through a program at runtime, enabling the detection of security violations such as information leaks and injection attacks. However, most DTA systems assume that memory layouts are type-safe and structurally consistent\u2014an assumption that can be violated by vulnerabilities such as type confusion. While type confusion has been studied in the context of sandbox escape, its ability to silently bypass taint tracking without altering program behavior remains unexplored. In this paper, we present ConfuseTaint, a technique that leverages type confusion vulnerabilities to corrupt taint metadata without modifying program semantics or the analysis tool. ConfuseTaint uses wide memory overwrites enabled by type confusion to corrupt taint tags, breaking the assumptions of taint tracking mechanisms that rely on shadow memory. We evaluate ConfuseTaint on two widely used taint tracking frameworks: Phosphor for the JVM and TaintDroid for Android. In both cases, ConfuseTaint successfully bypasses taint tracking, allowing sensitive data to reach designated sinks without detection. These results reveal a structural weakness in current DTA designs: their reliance on type-safe memory layouts leaves them vulnerable to low-level reinterpretation. Overall, our work reveals that runtime-level memory reinterpretation is an overlooked threat, calling for taint tracking architectures that do not rely on fragile assumptions about type and memory layout.",
							"pageNumber": 3906,
							"isPageNumberRoman": false
						},
						{
							"eid": "Ya4EgeZxxyBPzQkr0BnI7",
							"type": "authorPaper",
							"text": "Human-In-The-Loop Oracle Learning for Simulation-Based Testing",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d911/573300d911.pdf",
							"extraLocations": [],
							"authorNames": "Ben-Hau Chia (Carnegie Mellon University, USA), Eunsuk Kang (Carnegie Mellon University, USA), Christopher S. Timperley (Carnegie Mellon University, USA)",
							"abstract": "Ensuring safety and providing rigorous behavioral guarantees are critical for robotic systems operating in high-stakes environments such as autonomous driving. Field testing is common, but costly and risky. Simulation-based testing offers a safer and lower-cost alternative for automatically generating traces for analysis and performance assessment. An oracle is essential for evaluating each trace, assessing whether a robot behavior fulfills key criteria such as task completion, safety, efficiency, and reliability. Supervised learning for oracle learning is accurate but costly and time-consuming due to manual labeling, whereas unsupervised learning requires no labels but often sacrifices accuracy. To overcome these limitations, we propose human-in-the-loop oracle learning as a new approach to develop and refine oracles that are capable of distinguishing good from bad behaviors with reduced manual effort. We illustrate this approach through a conceptual framework for integrating human-in-the-loop learning into robotic system evaluation.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Human-In-The-Loop Oracle Learning for Simulation-Based Testing 1757029064174 10.1109/ASE63991.2025.00341 Ben-Hau Chia Carnegie Mellon University, USA bhchia@cmu.edu Eunsuk Kang Carnegie Mellon University, USA eskang@cmu.edu Christopher S. Timperley Carnegie Mellon University, USA ctimperley@cmu.edu robotics testing simulation oracle learning Ensuring safety and providing rigorous behavioral guarantees are critical for robotic systems operating in high-stakes environments such as autonomous driving. Field testing is common, but costly and risky. Simulation-based testing offers a safer and lower-cost alternative for automatically generating traces for analysis and performance assessment. An oracle is essential for evaluating each trace, assessing whether a robot behavior fulfills key criteria such as task completion, safety, efficiency, and reliability. Supervised learning for oracle learning is accurate but costly and time-consuming due to manual labeling, whereas unsupervised learning requires no labels but often sacrifices accuracy. To overcome these limitations, we propose human-in-the-loop oracle learning as a new approach to develop and refine oracles that are capable of distinguishing good from bad behaviors with reduced manual effort. We illustrate this approach through a conceptual framework for integrating human-in-the-loop learning into robotic system evaluation.",
							"pageNumber": 3911,
							"isPageNumberRoman": false
						},
						{
							"eid": "7HMDP7dKDrUSBt4q2Nb8Lk",
							"type": "authorPaper",
							"text": "Tether: A Personalized Support Assistant for Software Engineers with ADHD",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d916/573300d916.pdf",
							"extraLocations": [],
							"authorNames": "Aarsh Shah (University of Calgary, Canada), Cleyton Magalhaes (UFRPE, Brazil), Kiev Gama (CIn-UFPE, Brazil), Ronnie de Souza Santos (University of Calgary, Canada)",
							"abstract": "Equity, diversity, and inclusion in software engineering often overlook neurodiversity, particularly the experiences of developers with Attention Deficit Hyperactivity Disorder (ADHD). Despite the growing awareness about that population in SE, few tools are designed to support their cognitive challenges (e.g., sustained attention, task initiation, self-regulation) within development workflows. We present Tether, an LLM-powered desktop application designed to support software engineers with ADHD by delivering adaptive, context-aware assistance. Drawing from engineering research methodology, Tether combines local activity monitoring, retrieval-augmented generation (RAG), and gamification to offer real-time focus support and personalized dialogue. The system integrates operating system-level system tracking to prompt engagement, and its chatbot leverages ADHD-specific resources to offer relevant responses. Preliminary validation through self-use revealed improved contextual accuracy following iterative prompt refinements and RAG enhancements. Tether differentiates itself from generic tools by being adaptable and aligned with software-specific workflows and ADHD-related challenges. While not yet evaluated by target users, this work lays the foundation for future neurodiversity-aware tools in SE and highlights the potential of LLMs as personalized support systems for underrepresented cognitive needs.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Tether: A Personalized Support Assistant for Software Engineers with ADHD 1756787224564 10.1109/ASE63991.2025.00342 Aarsh Shah University of Calgary, Canada aarsh.shah@ucalgary.ca Cleyton Magalhaes UFRPE, Brazil cleyton.vanut@ufrpe.br Kiev Gama CIn-UFPE, Brazil kiev@cin.ufpe.br Ronnie de Souza Santos University of Calgary, Canada ronnie.desouzasantos@ucalgary.ca adhd assistive tools llms Equity, diversity, and inclusion in software engineering often overlook neurodiversity, particularly the experiences of developers with Attention Deficit Hyperactivity Disorder (ADHD). Despite the growing awareness about that population in SE, few tools are designed to support their cognitive challenges (e.g., sustained attention, task initiation, self-regulation) within development workflows. We present Tether, an LLM-powered desktop application designed to support software engineers with ADHD by delivering adaptive, context-aware assistance. Drawing from engineering research methodology, Tether combines local activity monitoring, retrieval-augmented generation (RAG), and gamification to offer real-time focus support and personalized dialogue. The system integrates operating system-level system tracking to prompt engagement, and its chatbot leverages ADHD-specific resources to offer relevant responses. Preliminary validation through self-use revealed improved contextual accuracy following iterative prompt refinements and RAG enhancements. Tether differentiates itself from generic tools by being adaptable and aligned with software-specific workflows and ADHD-related challenges. While not yet evaluated by target users, this work lays the foundation for future neurodiversity-aware tools in SE and highlights the potential of LLMs as personalized support systems for underrepresented cognitive needs.",
							"pageNumber": 3916,
							"isPageNumberRoman": false
						},
						{
							"eid": "6M2NQZ9rFWs858R6IxsgqM",
							"type": "authorPaper",
							"text": "Measuring LLM Code Generation Stability via Structural Entropy",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d921/573300d921.pdf",
							"extraLocations": [],
							"authorNames": "Yewei Song (University of Luxembourg), Tiezhu Sun (University of Luxembourg), Xunzhu Tang (University of Luxembourg), Prateek Kumar Rajput (University of Luxembourg), Tegawend\u00E9 F. Bissyand\u00E9 (University of Luxembourg), Jacques Klein (University of Luxembourg)",
							"abstract": "Assessing the stability of code generation from large language models (LLMs) is essential for judging their reliability in real-world development. We extend prior \"structural-entropy\" concepts to the program domain by pairing entropy with abstract-syntax-tree (AST) analysis. For any fixed prompt, we collect the multiset of depth-bounded subtrees of AST in each generated program and treat their relative frequencies as a probability distribution. We then measure stability in two complementary ways: (i) Jensen\u2013Shannon divergence, a symmetric, bounded indicator of structural overlap, and (ii) a Structural Cross-Entropy ratio that highlights missing high-probability patterns. Both metrics admit structural-only and token-aware variants, enabling separate views on control-flow shape and identifier-level variability. Unlike pass@k, BLEU, or CodeBLEU, our metrics are reference-free, language-agnostic, and execution-independent. We benchmark several leading LLMs on standard code generation tasks, demonstrating that AST-driven structural entropy reveals nuances in model consistency and robustness. The method runs in O(n,d) time with no external tests, providing a lightweight addition to the code-generation evaluation toolkit.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Measuring LLM Code Generation Stability via Structural Entropy 1755635443124 10.1109/ASE63991.2025.00343 Yewei Song University of Luxembourg yewei.song@uni.lu Tiezhu Sun University of Luxembourg tiezhu.sun@uni.lu Xunzhu Tang University of Luxembourg xunzhu.tang@uni.lu Prateek Kumar Rajput University of Luxembourg prateek.rajput@uni.lu Tegawend\u00E9 F. Bissyand\u00E9 University of Luxembourg tegawende.bissyande@uni.lu Jacques Klein University of Luxembourg jacques.klein@uni.lu Large Language Models Code Generation Structural Entropy Evaluation Metrics Stability Test Assessing the stability of code generation from large language models (LLMs) is essential for judging their reliability in real-world development. We extend prior \"structural-entropy\" concepts to the program domain by pairing entropy with abstract-syntax-tree (AST) analysis. For any fixed prompt, we collect the multiset of depth-bounded subtrees of AST in each generated program and treat their relative frequencies as a probability distribution. We then measure stability in two complementary ways: (i) Jensen\u2013Shannon divergence, a symmetric, bounded indicator of structural overlap, and (ii) a Structural Cross-Entropy ratio that highlights missing high-probability patterns. Both metrics admit structural-only and token-aware variants, enabling separate views on control-flow shape and identifier-level variability. Unlike pass@k, BLEU, or CodeBLEU, our metrics are reference-free, language-agnostic, and execution-independent. We benchmark several leading LLMs on standard code generation tasks, demonstrating that AST-driven structural entropy reveals nuances in model consistency and robustness. The method runs in O(n,d) time with no external tests, providing a lightweight addition to the code-generation evaluation toolkit.",
							"pageNumber": 3921,
							"isPageNumberRoman": false
						},
						{
							"eid": "3Ke3RWpPQ1mNseLej6it6y",
							"type": "authorPaper",
							"text": "Multiple Schema-Conformant Declarative Code Generation",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d926/573300d926.pdf",
							"extraLocations": [],
							"authorNames": "Mehant Kammakomati (IBM Research, India), Srikanth G. Tamilselvam (IBM Research, India)",
							"abstract": "Many enterprise systems including large-scale deployment platforms like Ansible provide a declarative user interface through programming languages like JavaScript Object Notation (JSON). The integrity of such systems is maintained through validation rules, such as JSON schemas, enforced over the code. Enterprise tasks in such systems are often complex, involving multiple schemas, making it challenging for the developers to choose the correct set and subsequently write multiple schema-compliant code snippets for each task. Recently, Large Language Models (LLMs) have shown promising performance for many declarative code generation tasks when adopted with constrained generation using a pre-known schema. However, to cater to real-world enterprise tasks, each task often requiring multiple code snippets to generate while ensuring compliance with their respective schemas, we introduce a novel framework that allows LLMs to generate multiple code snippets while choosing an appropriate schema for each of the snippets for constrained generation. To the best of our knowledge, we are the first to study this crucial enterprise problem for declarative systems and preliminary results on two real-world use cases demonstrate substantial improvements in both syntactic and semantic task performance. These findings highlight the potential of the approach to enhance the reliability and scalability of LLMs in declarative enterprise systems, indicating a promising direction for future research and development.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Multiple Schema-Conformant Declarative Code Generation 1755888969491 10.1109/ASE63991.2025.00344 Mehant Kammakomati IBM Research, India mehant.kammakomati2@ibm.com Srikanth G. Tamilselvam IBM Research, India srikanth.tamilselvam@in.ibm.com code generation constrained generation llms Many enterprise systems including large-scale deployment platforms like Ansible provide a declarative user interface through programming languages like JavaScript Object Notation (JSON). The integrity of such systems is maintained through validation rules, such as JSON schemas, enforced over the code. Enterprise tasks in such systems are often complex, involving multiple schemas, making it challenging for the developers to choose the correct set and subsequently write multiple schema-compliant code snippets for each task. Recently, Large Language Models (LLMs) have shown promising performance for many declarative code generation tasks when adopted with constrained generation using a pre-known schema. However, to cater to real-world enterprise tasks, each task often requiring multiple code snippets to generate while ensuring compliance with their respective schemas, we introduce a novel framework that allows LLMs to generate multiple code snippets while choosing an appropriate schema for each of the snippets for constrained generation. To the best of our knowledge, we are the first to study this crucial enterprise problem for declarative systems and preliminary results on two real-world use cases demonstrate substantial improvements in both syntactic and semantic task performance. These findings highlight the potential of the approach to enhance the reliability and scalability of LLMs in declarative enterprise systems, indicating a promising direction for future research and development.",
							"pageNumber": 3926,
							"isPageNumberRoman": false
						},
						{
							"eid": "7FhF2LLdCHxUye7nEdlisr",
							"type": "authorPaper",
							"text": "Requirements Development and Formalization for Reliable Code Generation: A Multi-Agent Vision",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d931/573300d931.pdf",
							"extraLocations": [],
							"authorNames": "Xu Lu (Xidian University, China), Weisong Sun (Nanyang Technological University, Singapore), Yiran Zhang (Nanyang Technological University, Singapore), Ming Hu (Singapore Management University, Singapore), Cong Tian (Xidian University, China), Zhi Jin (Wuhan University, China), Yang Liu (Nanyang Technological University, Singapore)",
							"abstract": "Automated code generation has long been considered the holy grail of software engineering. The emergence of Large Language Models (LLMs) has catalyzed a revolutionary breakthrough in this area. However, existing methods that only rely on LLMs remain inadequate in the quality of generated code, offering no guarantees of satisfying practical requirements. They lack a systematic strategy for requirements development and modeling. Recently, LLM-based agents typically possess powerful abilities and play an essential role in facilitating the alignment of LLM outputs with user requirements. In this paper, we envision the first multi-agent framework for reliable code generation based on Requirements Development and Formalization, named ReDeFo. This framework incorporates three agents, highlighting their augmentation with knowledge and techniques of formal methods, into the requirements-to-code generation pipeline to strengthen quality assurance. The core of ReDeFo is the use of formal specifications to bridge the gap between potentially ambiguous natural language requirements and precise executable code. ReDeFo enables rigorous reasoning about correctness, uncovering hidden bugs, and enforcing critical properties throughout the development process.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Requirements Development and Formalization for Reliable Code Generation: A Multi-Agent Vision 1756290185247 10.1109/ASE63991.2025.00345 Xu Lu Xidian University, China xlu@xidian.edu.cn Weisong Sun Nanyang Technological University, Singapore weisong.sun@ntu.edu.sg Yiran Zhang Nanyang Technological University, Singapore yiran002@e.ntu.edu.sg Ming Hu Singapore Management University, Singapore ecnu_hm@163.com Cong Tian Xidian University, China ctian@mail.xidian.edu.cn Zhi Jin Wuhan University, China zhijin@whu.edu.cn Yang Liu Nanyang Technological University, Singapore yangliu@ntu.edu.sg automated code generation formal specification large language model multi-agent Automated code generation has long been considered the holy grail of software engineering. The emergence of Large Language Models (LLMs) has catalyzed a revolutionary breakthrough in this area. However, existing methods that only rely on LLMs remain inadequate in the quality of generated code, offering no guarantees of satisfying practical requirements. They lack a systematic strategy for requirements development and modeling. Recently, LLM-based agents typically possess powerful abilities and play an essential role in facilitating the alignment of LLM outputs with user requirements. In this paper, we envision the first multi-agent framework for reliable code generation based on Requirements Development and Formalization, named ReDeFo. This framework incorporates three agents, highlighting their augmentation with knowledge and techniques of formal methods, into the requirements-to-code generation pipeline to strengthen quality assurance. The core of ReDeFo is the use of formal specifications to bridge the gap between potentially ambiguous natural language requirements and precise executable code. ReDeFo enables rigorous reasoning about correctness, uncovering hidden bugs, and enforcing critical properties throughout the development process.",
							"pageNumber": 3931,
							"isPageNumberRoman": false
						},
						{
							"eid": "3gcH2K3rL7skBNRoP4gbuh",
							"type": "authorPaper",
							"text": "IDBFuzz: Web Storage DataBase Fuzzing with Controllable Semantics",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d937/573300d937.pdf",
							"extraLocations": [],
							"authorNames": "Jingyi Chen (Jiangsu University, China), Jinfu Chen (Jiangsu University, China), Saihua Cai (Jiangsu University, China), Shengran Wang (Jiangsu University, China)",
							"abstract": "Despite great progress in fuzzing browser APIs, systematic approaches for testing web storage techniques remain absent. IndexedDB, the most popular NoSql database in modern browsers, brings unique challenges for fuzzing its API due to its asynchronous event-driven feature and strict phase separation. Current browser fuzzing techniques frequently struggle to generate nested event flows and invocations, which significantly impacts semantic correctness. Moreover, they often rely heavily on the try-catch block to suppress exceptions, which introduces substantial performance overhead. We propose IDBFuzz, the first fuzzing approach tailored for the IndexedDB API, which effectively tackles the challenge of capturing the execution context and event semantics inherent to IndexedDB, as well as handling large persistent objects. We design a seed generator based on intermediate representation (IR) that decouples layered IR skeletons from input object generation. With the aid of a global database snapshot, IDBFuzz can generate semantically controllable seeds, enabling the efficient production of high-quality test cases that significantly improve coverage.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 IDBFuzz: Web Storage DataBase Fuzzing with Controllable Semantics 1756987069504 10.1109/ASE63991.2025.00346 Jingyi Chen Jiangsu University, China jychen@stmail.ujs.edu.cn Jinfu Chen Jiangsu University, China jinfuchen@ujs.edu.cn Saihua Cai Jiangsu University, China caisaih@ujs.edu.cn Shengran Wang Jiangsu University, China shrwang@stmail.ujs.edu.cn fuzzing web storage web api indexeddb Despite great progress in fuzzing browser APIs, systematic approaches for testing web storage techniques remain absent. IndexedDB, the most popular NoSql database in modern browsers, brings unique challenges for fuzzing its API due to its asynchronous event-driven feature and strict phase separation. Current browser fuzzing techniques frequently struggle to generate nested event flows and invocations, which significantly impacts semantic correctness. Moreover, they often rely heavily on the try-catch block to suppress exceptions, which introduces substantial performance overhead. We propose IDBFuzz, the first fuzzing approach tailored for the IndexedDB API, which effectively tackles the challenge of capturing the execution context and event semantics inherent to IndexedDB, as well as handling large persistent objects. We design a seed generator based on intermediate representation (IR) that decouples layered IR skeletons from input object generation. With the aid of a global database snapshot, IDBFuzz can generate semantically controllable seeds, enabling the efficient production of high-quality test cases that significantly improve coverage.",
							"pageNumber": 3937,
							"isPageNumberRoman": false
						},
						{
							"eid": "5jPwrHZ4XxoKvOS4Ev6uas",
							"type": "authorPaper",
							"text": "STaint: Detecting Second-Order Vulnerabilities in PHP Applications with LLM-Assisted Bi-Directional Static Taint Analysis",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d942/573300d942.pdf",
							"extraLocations": [],
							"authorNames": "Yuchen Ji (ShanghaiTech University, China), Hongchen Cao (ShanghaiTech University, China), Jingzhu He (ShanghaiTech University, China)",
							"abstract": "Second-order vulnerabilities, such as second-order Cross-Site Scripting (XSS) and Server-Side Request Forgery (SSRF), occur when user-controlled inputs are stored in databases and later retrieved in different execution contexts, complicating static detection. Existing static analysis approaches struggle primarily with two challenges. First, they struggle in accurately identifying database-accessing functions defined by third-party libraries or custom data access layers, often leading to missed taint propagation paths. Second, they may fail to contextually model database operations when queries are dynamically constructed and depend on runtime parameters. To address these limitations, we propose STaint, a novel bi-directional static analysis method that integrates taint analysis with large language models (LLMs). Using semantic reasoning, STaint accurately identifies and models custom database reads and writes, effectively reconstructing comprehensive taint data flows in the database. Preliminary evaluations on ten real-world PHP applications show that STaint successfully detects 56 second-order vulnerability paths, including 7 previously unknown cases, outperforming existing techniques.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 STaint: Detecting Second-Order Vulnerabilities in PHP Applications with LLM-Assisted Bi-Directional Static Taint Analysis 1756357222427 10.1109/ASE63991.2025.00347 Yuchen Ji ShanghaiTech University, China jiych2022@shanghaitech.edu.cn Hongchen Cao ShanghaiTech University, China caohch2023@shanghaitech.edu.cn Jingzhu He ShanghaiTech University, China hejzh1@shanghaitech.edu.cn second-order vulnerabilities taint analysis php Second-order vulnerabilities, such as second-order Cross-Site Scripting (XSS) and Server-Side Request Forgery (SSRF), occur when user-controlled inputs are stored in databases and later retrieved in different execution contexts, complicating static detection. Existing static analysis approaches struggle primarily with two challenges. First, they struggle in accurately identifying database-accessing functions defined by third-party libraries or custom data access layers, often leading to missed taint propagation paths. Second, they may fail to contextually model database operations when queries are dynamically constructed and depend on runtime parameters. To address these limitations, we propose STaint, a novel bi-directional static analysis method that integrates taint analysis with large language models (LLMs). Using semantic reasoning, STaint accurately identifies and models custom database reads and writes, effectively reconstructing comprehensive taint data flows in the database. Preliminary evaluations on ten real-world PHP applications show that STaint successfully detects 56 second-order vulnerability paths, including 7 previously unknown cases, outperforming existing techniques.",
							"pageNumber": 3942,
							"isPageNumberRoman": false
						},
						{
							"eid": "pgIoIS6wVOxz0rPcPrgT0",
							"type": "authorPaper",
							"text": "Vessel: A Taxonomy of Reproducibility Issues for Container Images",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d947/573300d947.pdf",
							"extraLocations": [],
							"authorNames": "Kevin Pitstick (Carnegie Mellon Software Engineering Institute, USA), Alex Derr (Carnegie Mellon Software Engineering Institute, USA), Lihan Zhan (Carnegie Mellon Software Engineering Institute, USA), Sebasti\u00E1n Echeverr\u00EDa (Carnegie Mellon Software Engineering Institute, USA)",
							"abstract": "Build reproducibility of container images is essential to ensure that deployed systems will work as expected and have not been tampered with. However, bit-by-bit reproducibility of container images is almost never achievable due to external factors, and it is also very slow and labor intensive to determine the causes and severity of reproducibility failures. In this paper, we present a taxonomy of reproducibility issues for container images, as well as a tool, Vessel Diff, to help automatically categorize the type and severity of reproducibility failures in container images. We analyzed a set of open source repositories where container images are built to find common patterns and configure our tool to properly categorize failures. Our analysis shows that approximately 87% of their reproducibility failures were automatically classified by the tool according to our taxonomy. However, the vast majority of these failures were caused by trivial issues and not non-trivial issues, which could cause noticeable changes in execution of container applications and are more difficult to detect. These results highlight the need for additional research and tooling to detect, classify, and fix reproducibility issues, especially those that can lead to major failures.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Vessel: A Taxonomy of Reproducibility Issues for Container Images 1755785377848 10.1109/ASE63991.2025.00348 Kevin Pitstick Carnegie Mellon Software Engineering Institute, USA kapitstick@sei.cmu.edu Alex Derr Carnegie Mellon Software Engineering Institute, USA aderr@sei.cmu.edu Lihan Zhan Carnegie Mellon Software Engineering Institute, USA lzhan@sei.cmu.edu Sebasti\u00E1n Echeverr\u00EDa Carnegie Mellon Software Engineering Institute, USA secheverria@sei.cmu.edu containers builds docker reproducibility Build reproducibility of container images is essential to ensure that deployed systems will work as expected and have not been tampered with. However, bit-by-bit reproducibility of container images is almost never achievable due to external factors, and it is also very slow and labor intensive to determine the causes and severity of reproducibility failures. In this paper, we present a taxonomy of reproducibility issues for container images, as well as a tool, Vessel Diff, to help automatically categorize the type and severity of reproducibility failures in container images. We analyzed a set of open source repositories where container images are built to find common patterns and configure our tool to properly categorize failures. Our analysis shows that approximately 87% of their reproducibility failures were automatically classified by the tool according to our taxonomy. However, the vast majority of these failures were caused by trivial issues and not non-trivial issues, which could cause noticeable changes in execution of container applications and are more difficult to detect. These results highlight the need for additional research and tooling to detect, classify, and fix reproducibility issues, especially those that can lead to major failures.",
							"pageNumber": 3947,
							"isPageNumberRoman": false
						},
						{
							"eid": "3YOMAk4VtQOjWyNvRYWF9N",
							"type": "authorPaper",
							"text": "Autonomous Agents for Accessibility: Simulating Visual Impairments in Web Interfaces",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d952/573300d952.pdf",
							"extraLocations": [],
							"authorNames": "Juan Diego Yepes-Parra (Universidad de los Andes, Colombia), Camilo Escobar-Vel\u00E1squez (Universidad de los Andes, Colombia)",
							"abstract": "Static code analysis cannot detect real-time interaction issues faced by users with disabilities. We propose a multimodal Artificial Intelligence (AI) agent framework that simulates interactions of users with visual impairments without code access. The agent would closely simulate the experience of these users by interacting with web interfaces using the same modalities available to them, primarily keyboard navigation and screen readers. The agent perceives the interface through perceptual filters that mimic conditions including glaucoma and myopia, and handles both the altered visual input and audio output from screen readers. This approach aims to replicate the real-world constraints and strategies of users with disabilities, enabling more realistic evaluation, with the objective of identifying, locating and repairing web accessibility issues. We suggest a framework to evaluate how such filters affect user behavior, task success, and User Interface (UI) usability. Our approach aims to uncover visual accessibility flaws that become apparent under impaired perception. ",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Autonomous Agents for Accessibility: Simulating Visual Impairments in Web Interfaces 1756927955232 10.1109/ASE63991.2025.00349 Juan Diego Yepes-Parra Universidad de los Andes, Colombia j.yepes@uniandes.edu.co Camilo Escobar-Vel\u00E1squez Universidad de los Andes, Colombia ca.escobar2434@uniandes.edu.co Web Accessibility Autonomous Artificial Intel ligence Agents Automated Testing Static code analysis cannot detect real-time interaction issues faced by users with disabilities. We propose a multimodal Artificial Intelligence (AI) agent framework that simulates interactions of users with visual impairments without code access. The agent would closely simulate the experience of these users by interacting with web interfaces using the same modalities available to them, primarily keyboard navigation and screen readers. The agent perceives the interface through perceptual filters that mimic conditions including glaucoma and myopia, and handles both the altered visual input and audio output from screen readers. This approach aims to replicate the real-world constraints and strategies of users with disabilities, enabling more realistic evaluation, with the objective of identifying, locating and repairing web accessibility issues. We suggest a framework to evaluate how such filters affect user behavior, task success, and User Interface (UI) usability. Our approach aims to uncover visual accessibility flaws that become apparent under impaired perception.",
							"pageNumber": 3952,
							"isPageNumberRoman": false
						},
						{
							"eid": "6ehRCL42wnosLjRzG50clH",
							"type": "authorPaper",
							"text": "Are We SOLID Yet? An Empirical Study on Prompting LLMs to Detect Design Principle Violations",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d957/573300d957.pdf",
							"extraLocations": [],
							"authorNames": "Fatih Pehlivan (Bilkent University, Turkey), Ar\u00E7in \u00DClk\u00FC Erg\u00FCzen (Bilkent University, Turkey), Sahand Moslemi Yengejeh (Bilkent University, Turkey), Mayasah Lami (Bilkent University, Turkey), Anil Koyuncu (Bilkent University, Turkey)",
							"abstract": "Traditional static analysis methods struggle to detect semantic design flaws, such as violations of the SOLID principles, which require a strong understanding of object-oriented design patterns and principles. Existing solutions typically focus on individual SOLID principles or specific programming languages, leaving a gap in the ability to detect violations across all five principles in multi-language codebases. This paper presents a new approach: a methodology that leverages tailored prompt engineering to assess LLMs on their ability to detect SOLID violations across multiple languages. We present a benchmark of four leading LLMs\u2014CodeLlama:70B, DeepSeekCoder:33B, Qwen2.5 Coder:32B, and GPT-4o Mini\u2014on their ability to detect violations of all five SOLID principles. For this evaluation, we construct a new benchmark dataset of 240 manually validated code examples. Using this dataset, we test four distinct prompt strategies inspired by established zero-shot, few-shot, and chain-of-thought techniques to systematically measure their impact on detection accuracy. Our emerging results reveal a stark hierarchy among models, with GPT-4o Mini decisively outperforming others, yet even it struggles with challenging principles like DIP. Crucially, we show that prompt strategy has a dramatic impact, but no single strategy is universally best; for instance, a deliberative ENSEMBLE prompt excels at OCP detection while a hint-based EXAMPLE prompt is superior for DIP violations. Across all experiments, detection accuracy is heavily influenced by language characteristics and degrades sharply with increasing code complexity. These initial findings demonstrate that effective, AI-driven design analysis requires not a single \"best\" model, but a tailored approach that matches the right model and prompt to the specific design context, highlighting the potential of LLMs to support maintainability through AI-assisted code analysis.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Are We SOLID Yet? An Empirical Study on Prompting LLMs to Detect Design Principle Violations 1756737533827 10.1109/ASE63991.2025.00350 Fatih Pehlivan Bilkent University, Turkey fatih.pehlivan@bilkent.edu.tr Ar\u00E7in \u00DClk\u00FC Erg\u00FCzen Bilkent University, Turkey ulku.erguzen@bilkent.edu.tr Sahand Moslemi Yengejeh Bilkent University, Turkey sahand.moslemi@bilkent.edu.tr Mayasah Lami Bilkent University, Turkey m.lami@bilkent.edu.tr Anil Koyuncu Bilkent University, Turkey anil.koyuncu@cs.bilkent.edu.tr solid principles code refactoring large language models prompt patterns Traditional static analysis methods struggle to detect semantic design flaws, such as violations of the SOLID principles, which require a strong understanding of object-oriented design patterns and principles. Existing solutions typically focus on individual SOLID principles or specific programming languages, leaving a gap in the ability to detect violations across all five principles in multi-language codebases. This paper presents a new approach: a methodology that leverages tailored prompt engineering to assess LLMs on their ability to detect SOLID violations across multiple languages. We present a benchmark of four leading LLMs\u2014CodeLlama:70B, DeepSeekCoder:33B, Qwen2.5 Coder:32B, and GPT-4o Mini\u2014on their ability to detect violations of all five SOLID principles. For this evaluation, we construct a new benchmark dataset of 240 manually validated code examples. Using this dataset, we test four distinct prompt strategies inspired by established zero-shot, few-shot, and chain-of-thought techniques to systematically measure their impact on detection accuracy. Our emerging results reveal a stark hierarchy among models, with GPT-4o Mini decisively outperforming others, yet even it struggles with challenging principles like DIP. Crucially, we show that prompt strategy has a dramatic impact, but no single strategy is universally best; for instance, a deliberative ENSEMBLE prompt excels at OCP detection while a hint-based EXAMPLE prompt is superior for DIP violations. Across all experiments, detection accuracy is heavily influenced by language characteristics and degrades sharply with increasing code complexity. These initial findings demonstrate that effective, AI-driven design analysis requires not a single \"best\" model, but a tailored approach that matches the right model and prompt to the specific design context, highlighting the potential of LLMs to support maintainability through AI-assisted code analysis.",
							"pageNumber": 3957,
							"isPageNumberRoman": false
						},
						{
							"eid": "5SDrFErxUYakDjMug9XVsr",
							"type": "authorPaper",
							"text": "RAML: Toward Retrieval-Augmented Localization of Malicious Payloads in Android Apps",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d962/573300d962.pdf",
							"extraLocations": [],
							"authorNames": "Tiezhu Sun (University of Luxembourg, Luxembourg), Marco Alecci (University of Luxembourg, Luxembourg), Yewei Song (University of Luxembourg, Luxembourg), Xunzhu Tang (University of Luxembourg, Luxembourg), Kisub Kim (DGIST, Korea), Jordan Samhi (University of Luxembourg, Luxembourg), Tegawend\u00E9 F. Bissyand\u00E9 (University of Luxembourg, Luxembourg), Jacques Klein (University of Luxembourg, Luxembourg)",
							"abstract": "Android malware detection and family classification have been extensively studied, yet localizing the exact malicious payloads within a detected sample remains a challenging and labor-intensive task. We propose RAML, a novel Retrieval-Augmented Malicious payload Localization pipeline inspired by retrieval-augmented generation (RAG), which leverages large language models (LLMs) to bridge high-level behavior descriptions and low-level Smali code. RAML generates class-level descriptions from Smali code, embeds them into a vector database, and performs semantic retrieval via similarity search. Matched candidates are re-ranked with LLM assistance, followed by method-level LLM analysis to precisely identify malicious methods and provide insightful role explanations. Preliminary results show that RAML effectively localizes corresponding malicious payloads based on behavioral descriptions, narrows the analysis scope, and reduces manual effort\u2014offering a promising direction for automated malware forensics.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 RAML: Toward Retrieval-Augmented Localization of Malicious Payloads in Android Apps 1755770122326 10.1109/ASE63991.2025.00351 Tiezhu Sun University of Luxembourg, Luxembourg tiezhu.sun@uni.lu Marco Alecci University of Luxembourg, Luxembourg marco.alecci@uni.lu Yewei Song University of Luxembourg, Luxembourg yewei.song@uni.lu Xunzhu Tang University of Luxembourg, Luxembourg xunzhu.tang@uni.lu Kisub Kim DGIST, Korea kisub.kim@dgist.ac.kr Jordan Samhi University of Luxembourg, Luxembourg jordan.samhi@uni.lu Tegawend\u00E9 F. Bissyand\u00E9 University of Luxembourg, Luxembourg tegawende.bissyande@uni.lu Jacques Klein University of Luxembourg, Luxembourg jacques.klein@uni.lu android malware analysis malicious payload localization retrieval-augmented generation Android malware detection and family classification have been extensively studied, yet localizing the exact malicious payloads within a detected sample remains a challenging and labor-intensive task. We propose RAML, a novel Retrieval-Augmented Malicious payload Localization pipeline inspired by retrieval-augmented generation (RAG), which leverages large language models (LLMs) to bridge high-level behavior descriptions and low-level Smali code. RAML generates class-level descriptions from Smali code, embeds them into a vector database, and performs semantic retrieval via similarity search. Matched candidates are re-ranked with LLM assistance, followed by method-level LLM analysis to precisely identify malicious methods and provide insightful role explanations. Preliminary results show that RAML effectively localizes corresponding malicious payloads based on behavioral descriptions, narrows the analysis scope, and reduces manual effort\u2014offering a promising direction for automated malware forensics.",
							"pageNumber": 3962,
							"isPageNumberRoman": false
						},
						{
							"eid": "7GO2inK2JbU0jobKYnme4K",
							"type": "authorPaper",
							"text": "A Secure Mocking Approach Towards Software Supply Chain Security",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d967/573300d967.pdf",
							"extraLocations": [],
							"authorNames": "Daisuke Yamaguchi (NTT, Inc., Japan), Shinobu Saito (NTT, Inc., Japan), Takuya Iwatsuka (NTT, Inc., Japan), Nariyoshi Chida (NTT, Inc., Japan), Tachio Terauchi (Waseda University, Japan)",
							"abstract": "As software development increasingly relies on external collaboration, organizations face new risks of intellectual property leakage beyond traditional concerns about deployed software. Even when the source code is protected, adversaries may infer sensitive internal program specifications by observing the program behavior during the development and testing phases. This paper addresses the problem of specification leakage through behavioral observation in collaborative software development. We propose a novel software development method that centers on specially crafted test doubles referred to as secure mocks. Secure mocks serve as drop-in replacements for original components during development and testing while preventing the exposure of sensitive internal specifications through observable behavior. We formalize the correctness conditions for secure mocks and define the secure mock construction problem as a constraint satisfaction problem parameterized by the program to protect, the development specification, and a security policy. Our approach enables secure test-driven development (TDD) with external collaborators, bridging the gap between traditional TDD styles. We discuss the implications for secure collaboration with external developers and outline future research directions for automating secure mock generation and integrating this paradigm into real-world development pipelines.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 A Secure Mocking Approach Towards Software Supply Chain Security 1756906381116 10.1109/ASE63991.2025.00352 Daisuke Yamaguchi NTT, Inc., Japan daisuke.yamaguchi@ntt.com Shinobu Saito NTT, Inc., Japan shinobu.saito@ntt.com Takuya Iwatsuka NTT, Inc., Japan takuya.iwatsuka@ntt.com Nariyoshi Chida NTT, Inc., Japan na.chida@ntt.com Tachio Terauchi Waseda University, Japan terauchi@waseda.jp secure mock tdd information leakage As software development increasingly relies on external collaboration, organizations face new risks of intellectual property leakage beyond traditional concerns about deployed software. Even when the source code is protected, adversaries may infer sensitive internal program specifications by observing the program behavior during the development and testing phases. This paper addresses the problem of specification leakage through behavioral observation in collaborative software development. We propose a novel software development method that centers on specially crafted test doubles referred to as secure mocks. Secure mocks serve as drop-in replacements for original components during development and testing while preventing the exposure of sensitive internal specifications through observable behavior. We formalize the correctness conditions for secure mocks and define the secure mock construction problem as a constraint satisfaction problem parameterized by the program to protect, the development specification, and a security policy. Our approach enables secure test-driven development (TDD) with external collaborators, bridging the gap between traditional TDD styles. We discuss the implications for secure collaboration with external developers and outline future research directions for automating secure mock generation and integrating this paradigm into real-world development pipelines.",
							"pageNumber": 3967,
							"isPageNumberRoman": false
						}
					],
					"pageNumber": "",
					"isPageNumberRoman": false,
					"chair": null
				},
				{
					"class": "SD",
					"type": "SD_SESSION",
					"title": "Tool Demonstrations",
					"lineItems": [
						{
							"eid": "6YUoLnqkyW3n9PfBVGj3Lj",
							"type": "authorPaper",
							"text": "AndroFL: Evolutionary-Driven Fault Localization for Android Apps",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d972/573300d972.pdf",
							"extraLocations": [],
							"authorNames": "Vishal Singh (Indian Institute of Technology Kanpur, India), Ravi Shankar Das (Indian Institute of Technology Kanpur, India), Prajwal H G (InMobi, India), Subhajit Roy (Indian Institute of Technology Kanpur, India)",
							"abstract": "We present our tool, ANDROFL, that provides an infrastructure for an evolutionary algorithm-based test-suite generation backed by a statistical fault localization module for diagnosing faults. ANDROFL's evolutionary test-generator supports configurable fitness functions (e.g., coverage, diagnos ability metrics like Ulysis). The statistical fault localization engine supports popular metrics like Ochiai, Tarantula and Barinel, and allows adding custom fault localization metrics. We evaluated ANDROFL on 20 open-sourced apps from F-Droid, and demon strates significant efficiency gains: it reduces debugging effort by 74% (median EXAM score) compared to random testing\u2014 enabling developers to pinpoint faults \u22484\u00D7 faster. Furthermore, ANDROFL localizes 25% and 50% more faults compared to random testing in the top-5 and top-10 ranked list in worst case ranking scenario.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 AndroFL: Evolutionary-Driven Fault Localization for Android Apps 1759437162332 10.1109/ASE63991.2025.00353 Vishal Singh Indian Institute of Technology Kanpur, India vshlsng@cse.iitk.ac.in Ravi Shankar Das Indian Institute of Technology Kanpur, India ravishankerdas1998@gmail.com Prajwal H G InMobi, India prajwal.g@inmobi.com Subhajit Roy Indian Institute of Technology Kanpur, India subhajit@iitk.ac.in gui fault localization crash faults android testing automated debugging We present our tool, ANDROFL, that provides an infrastructure for an evolutionary algorithm-based test-suite generation backed by a statistical fault localization module for diagnosing faults. ANDROFL's evolutionary test-generator supports configurable fitness functions (e.g., coverage, diagnos ability metrics like Ulysis). The statistical fault localization engine supports popular metrics like Ochiai, Tarantula and Barinel, and allows adding custom fault localization metrics. We evaluated ANDROFL on 20 open-sourced apps from F-Droid, and demon strates significant efficiency gains: it reduces debugging effort by 74% (median EXAM score) compared to random testing\u2014 enabling developers to pinpoint faults \u22484\u00D7 faster. Furthermore, ANDROFL localizes 25% and 50% more faults compared to random testing in the top-5 and top-10 ranked list in worst case ranking scenario.",
							"pageNumber": 3972,
							"isPageNumberRoman": false
						},
						{
							"eid": "6nes2xtfZzIGuEKZBK4ugU",
							"type": "authorPaper",
							"text": "VUSC: An Extensible Research Platform for Java-Based Static Analysis",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d976/573300d976.pdf",
							"extraLocations": [],
							"authorNames": "Marc Miltenberger (Fraunhofer SIT \u2014 ATHENE, Germany), Steven Arzt (Fraunhofer SIT \u2014 ATHENE, Germany)",
							"abstract": "Detecting security vulnerabilities in backend Web applications as well as mobile apps is extremely important. Static analysis for vulnerability analysis has subsequently developed as an important field of research. Researchers need extensible frameworks to avoid starting from scratch with every new research project. Compared to commercially available scanners, open-source frameworks often only provide basic functionality. This limits the ability of researchers to evaluate novel algorithms. Lacking access to full code scanners, new building blocks are often tested in isolation. In this paper, we present VUSC, a fast, precise and extensible vulnerability scanner for Android and Java bytecode. It features a plugin architecture for commonly used static analyses such as call graph, taint and value analyses, allowing researchers to build upon our work and using VUSC as a reference platform. We show that VUSC achieves a precision of around 90% on benchmarks. Video: https://youtu.be/QpXs9hv5zGc, Dataset: https://github.com/F raunhofer-SIT/ASE2025-StaticAnalysisInfrastructure/",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 VUSC: An Extensible Research Platform for Java-Based Static Analysis 1758886647029 10.1109/ASE63991.2025.00354 Marc Miltenberger Fraunhofer SIT \u2014 ATHENE, Germany marc.miltenberger@sit.fraunhofer.de Steven Arzt Fraunhofer SIT \u2014 ATHENE, Germany steven.arzt@sit.fraunhofer.de static analysis java android Detecting security vulnerabilities in backend Web applications as well as mobile apps is extremely important. Static analysis for vulnerability analysis has subsequently developed as an important field of research. Researchers need extensible frameworks to avoid starting from scratch with every new research project. Compared to commercially available scanners, open-source frameworks often only provide basic functionality. This limits the ability of researchers to evaluate novel algorithms. Lacking access to full code scanners, new building blocks are often tested in isolation. In this paper, we present VUSC, a fast, precise and extensible vulnerability scanner for Android and Java bytecode. It features a plugin architecture for commonly used static analyses such as call graph, taint and value analyses, allowing researchers to build upon our work and using VUSC as a reference platform. We show that VUSC achieves a precision of around 90% on benchmarks. Video: https://youtu.be/QpXs9hv5zGc, Dataset: https://github.com/F raunhofer-SIT/ASE2025-StaticAnalysisInfrastructure/",
							"pageNumber": 3976,
							"isPageNumberRoman": false
						},
						{
							"eid": "31kbfVSnSxzkbOPnWKRokZ",
							"type": "authorPaper",
							"text": "DESIGNATOR: a Toolset for Automated GAN-Enhanced Search-Based Testing and Retraining of DNNs in Martian Environments",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d980/573300d980.pdf",
							"extraLocations": [],
							"authorNames": "Mohammed Oualid Attaoui (University of Luxembourg, Luxembourg), Fabrizio Pastore (University of Luxembourg, Luxembourg)",
							"abstract": "We present DESIGNATOR, a toolset for generating datasets for testing and retraining deep neural networks (DNNs) performing computer vision tasks in Martian-like environments. The toolset integrates Marsim, a simulator of the Mars environment, and DESIGNATE, a search-based approach combining simulation, generative adversarial networks (GANs), and search-based test input generation. The tool enables users to select a search strategy, launch simulations in MarsSim, and observe the evolution of simulated images, corresponding realistic images, ground truth labels, model predictions, and fitness values. Beyond supporting researchers and practitioners in generating datasets capable of identifying failures and retraining DNNs, DESIGNATOR can be used as a didactic tool to explain how image datasets can be generated using meta-heuristic search. Furthermore, MarsSim can be used standalone, through its API and GUI. MarsSim enables researchers to assess search-based approaches beyond the predominantly studied automotive context. ",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 DESIGNATOR: a Toolset for Automated GAN-Enhanced Search-Based Testing and Retraining of DNNs in Martian Environments 1759229247336 10.1109/ASE63991.2025.00355 Mohammed Oualid Attaoui University of Luxembourg, Luxembourg mohammed.attaoui@uni.lu Fabrizio Pastore University of Luxembourg, Luxembourg fabrizio.pastore@uni.lu dnn testing functional safety analysis martian simulation We present DESIGNATOR, a toolset for generating datasets for testing and retraining deep neural networks (DNNs) performing computer vision tasks in Martian-like environments. The toolset integrates Marsim, a simulator of the Mars environment, and DESIGNATE, a search-based approach combining simulation, generative adversarial networks (GANs), and search-based test input generation. The tool enables users to select a search strategy, launch simulations in MarsSim, and observe the evolution of simulated images, corresponding realistic images, ground truth labels, model predictions, and fitness values. Beyond supporting researchers and practitioners in generating datasets capable of identifying failures and retraining DNNs, DESIGNATOR can be used as a didactic tool to explain how image datasets can be generated using meta-heuristic search. Furthermore, MarsSim can be used standalone, through its API and GUI. MarsSim enables researchers to assess search-based approaches beyond the predominantly studied automotive context.",
							"pageNumber": 3980,
							"isPageNumberRoman": false
						},
						{
							"eid": "6IP2DbazO2JCTBEneEZmIJ",
							"type": "authorPaper",
							"text": "A Large-Scale Evolvable Dataset for Model Context Protocol Ecosystem and Security Analysis",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d984/573300d984.pdf",
							"extraLocations": [],
							"authorNames": "Zhiwei Lin (National University of Singapore), Bonan Ruan (National University of Singapore), Jiahao Liu (National University of Singapore), Weibo Zhao (National University of Singapore)",
							"abstract": "The Model Context Protocol (MCP) has recently emerged as a standardized interface for connecting language models with external tools and data. As the ecosystem rapidly expands, the lack of a structured, comprehensive view of existing MCP artifacts presents challenges for research. To bridge this gap, we introduce MCPCorpus, a large-scale dataset containing around 14K MCP servers and 300 MCP clients. Each artifact is annotated with 20+ normalized attributes capturing its identity, interface configuration, GitHub activity, and metadata. MCPCorpus provides a reproducible snapshot of the real-world MCP ecosystem, enabling studies of adoption trends, ecosystem health, and implementation diversity. To keep pace with the rapid evolution of the MCP ecosystem, we provide utility tools for automated data synchronization, normalization, and inspection. Furthermore, to support efficient exploration and exploitation, we release a lightweight web-based search interface. MCPCorpus is publicly available at: https://github.com/Snakinya/MCPCorpus. The video is at https://youtu.be/2a9WrHMcfxU.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 A Large-Scale Evolvable Dataset for Model Context Protocol Ecosystem and Security Analysis 1760098132014 10.1109/ASE63991.2025.00356 Zhiwei Lin National University of Singapore zhiweil@comp.nus.edu.sg Bonan Ruan National University of Singapore r-bonan@comp.nus.edu.sg Jiahao Liu National University of Singapore jiahao99@comp.nus.edu.sg Weibo Zhao National University of Singapore weibo@comp.nus.edu.sg The Model Context Protocol (MCP) has recently emerged as a standardized interface for connecting language models with external tools and data. As the ecosystem rapidly expands, the lack of a structured, comprehensive view of existing MCP artifacts presents challenges for research. To bridge this gap, we introduce MCPCorpus, a large-scale dataset containing around 14K MCP servers and 300 MCP clients. Each artifact is annotated with 20+ normalized attributes capturing its identity, interface configuration, GitHub activity, and metadata. MCPCorpus provides a reproducible snapshot of the real-world MCP ecosystem, enabling studies of adoption trends, ecosystem health, and implementation diversity. To keep pace with the rapid evolution of the MCP ecosystem, we provide utility tools for automated data synchronization, normalization, and inspection. Furthermore, to support efficient exploration and exploitation, we release a lightweight web-based search interface. MCPCorpus is publicly available at: https://github.com/Snakinya/MCPCorpus. The video is at https://youtu.be/2a9WrHMcfxU.",
							"pageNumber": 3984,
							"isPageNumberRoman": false
						},
						{
							"eid": "7KjPQEnkBJsePVGYOeckJL",
							"type": "authorPaper",
							"text": "LitterBox+: An Extensible Framework for LLM-Enhanced Scratch Static Code Analysis",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d988/573300d988.pdf",
							"extraLocations": [],
							"authorNames": "Benedikt Fein (University of Passau, Germany), Florian Oberm\u00FCller (University of Passau, Germany), Gordon Fraser (University of Passau, Germany)",
							"abstract": "Large language models (LLMs) have become an essential tool to support developers using traditional text-based programming languages, but the graphical notation of the block-based Scratch programming environment inhibits the use of LLMs. To overcome this limitation, we propose the LitterBox+ framework that extends the Scratch static code analysis tool LitterBox with the generative abilities of LLMs. By converting block-based code to a textual representation suitable for LLMs, LitterBox+ allows users to query LLMs about their programs, about quality issues reported by LitterBox, and it allows generating code fixes. Besides offering a programmatic API for these functionalities, LitterBox+ also extends the Scratch user interface to make these functionalities available directly in the environment familiar to learners. The framework is designed to be easily extensible with other prompts, LLM providers, and new features combining the program analysis capabilities of LitterBox with the generative features of LLMs. We provide a screencast demonstrating the tool at https://youtu.be/RZ6E0xgrIgQ.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 LitterBox+: An Extensible Framework for LLM-Enhanced Scratch Static Code Analysis 1759329640167 10.1109/ASE63991.2025.00357 Benedikt Fein University of Passau, Germany benedikt.fein@uni-passau.de Florian Oberm\u00FCller University of Passau, Germany florian.obermueller@uni-passau.de Gordon Fraser University of Passau, Germany gordon.fraser@uni-passau.de scratch block-based programming llm automated feedback Large language models (LLMs) have become an essential tool to support developers using traditional text-based programming languages, but the graphical notation of the block-based Scratch programming environment inhibits the use of LLMs. To overcome this limitation, we propose the LitterBox+ framework that extends the Scratch static code analysis tool LitterBox with the generative abilities of LLMs. By converting block-based code to a textual representation suitable for LLMs, LitterBox+ allows users to query LLMs about their programs, about quality issues reported by LitterBox, and it allows generating code fixes. Besides offering a programmatic API for these functionalities, LitterBox+ also extends the Scratch user interface to make these functionalities available directly in the environment familiar to learners. The framework is designed to be easily extensible with other prompts, LLM providers, and new features combining the program analysis capabilities of LitterBox with the generative features of LLMs. We provide a screencast demonstrating the tool at https://youtu.be/RZ6E0xgrIgQ.",
							"pageNumber": 3988,
							"isPageNumberRoman": false
						},
						{
							"eid": "1vIzIyX6vC77qp4CkPYdVz",
							"type": "authorPaper",
							"text": "CodeGenLink: A Tool to Find the Likely Origin and License of Automatically Generated Code",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d992/573300d992.pdf",
							"extraLocations": [],
							"authorNames": "Daniele Bifolco (University of Sannio, Italy), Guido Annicchiarico (University of Sannio, Italy), Pierluigi Barbiero (University of Sannio, Italy), Massimiliano Di Penta (University of Sannio, Italy), Fiorella  Zampetti (University of Sannio, Italy)",
							"abstract": "Large Language Models (LLMs) are widely used in software development tasks nowadays. Unlike reusing code taken from the Web, for LLMs' generated code, developers are concerned about its lack of trustworthiness and possible copyright or licensing violations, due to the lack of code provenance information. This paper proposes CodeGenLink, a GitHub CoPilot extension for Visual Studio Code aimed at (i) suggesting links containing code very similar to automatically generated code, and (ii) whenever possible, indicating the license of the likely origin of the code. CodeGenLink retrieves candidate links by combining LLMs with their web search features and then performs similarity analysis between the generated and retrieved code. Preliminary results show that CodeGenLink effectively filters unrelated links via similarity analysis and provides licensing information when available. Tool URL: https://github.com/danielebifolco/CodeGenLink Tool Video: https://youtu.be/M6nqjBf9_pw",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 CodeGenLink: A Tool to Find the Likely Origin and License of Automatically Generated Code 1758893172177 10.1109/ASE63991.2025.00358 Daniele Bifolco University of Sannio, Italy d.bifolco@studenti.unisannio.it Guido Annicchiarico University of Sannio, Italy g.annicchiarico@studenti.unisannio.it Pierluigi Barbiero University of Sannio, Italy p.barbiero3@studenti.unisannio.it Massimiliano Di Penta University of Sannio, Italy dipenta@unisannio.it Fiorella Zampetti University of Sannio, Italy fzampetti@unisannio.it large language model code provenance licensing trustworthiness Large Language Models (LLMs) are widely used in software development tasks nowadays. Unlike reusing code taken from the Web, for LLMs' generated code, developers are concerned about its lack of trustworthiness and possible copyright or licensing violations, due to the lack of code provenance information. This paper proposes CodeGenLink, a GitHub CoPilot extension for Visual Studio Code aimed at (i) suggesting links containing code very similar to automatically generated code, and (ii) whenever possible, indicating the license of the likely origin of the code. CodeGenLink retrieves candidate links by combining LLMs with their web search features and then performs similarity analysis between the generated and retrieved code. Preliminary results show that CodeGenLink effectively filters unrelated links via similarity analysis and provides licensing information when available. Tool URL: https://github.com/danielebifolco/CodeGenLink Tool Video: https://youtu.be/M6nqjBf9_pw",
							"pageNumber": 3992,
							"isPageNumberRoman": false
						},
						{
							"eid": "5s3afdKJK0PXjcxGkBXWJz",
							"type": "authorPaper",
							"text": "PyGress: Tool for Analyzing the Progression of Code Proficiency in Python OSS Projects",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d996/573300d996.pdf",
							"extraLocations": [],
							"authorNames": "Rujiphart Charatvaraphan (Mahidol University, Thailand), Bunradar Chatchaiyadech (Mahidol University, Thailand), Thitirat Sukijprasert (Mahidol University, Thailand), Chaiyong Ragkhitwetsagul (Mahidol University, Thailand), Morakot Choetkiertikul (Mahidol University, Thailand), Raula Gaikovina Kula (The University of Osaka, Japan), Thanwadee Sunetnanta (Mahidol University, Thailand), Kenichi Matsumoto (Nara Institute of Science and Technology, Japan)",
							"abstract": "Assessing developer proficiency in open-source software (OSS) projects is essential for understanding project dynamics, especially for expertise. This paper presents \"PyGress\", a web-based tool designed to automatically evaluate and visualize Python code proficiency using pycefr, a Python code proficiency analyzer. By submitting a GitHub repository link, the system extracts commit histories, analyzes source code proficiency across CEFR-aligned levels (A1\u2013C2), and generates visual summaries of individual and project-wide proficiency. The PyGress tool visualizes per-contributor proficiency distribution and tracks project code proficiency progression over time. PyGress offers an interactive way to explore contributor coding levels in Python OSS repositories. The video demonstration of the PyGress tool can be found at https://youtu.be/hxoeK-ggcWk, and the source code of the tool is publicly available at https://github.com/MUICT-SERU/PyGress.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 PyGress: Tool for Analyzing the Progression of Code Proficiency in Python OSS Projects 1759457869433 10.1109/ASE63991.2025.00359 Rujiphart Charatvaraphan Mahidol University, Thailand rujiphart.cha@gmail.com Bunradar Chatchaiyadech Mahidol University, Thailand bunradar.cha@gmail.com Thitirat Sukijprasert Mahidol University, Thailand thitirat.sukij@gmail.com Chaiyong Ragkhitwetsagul Mahidol University, Thailand chaiyong.rag@mahidol.ac.th Morakot Choetkiertikul Mahidol University, Thailand morakot.cho@mahidol.ac.th Raula Gaikovina Kula The University of Osaka, Japan raula-k@ist.osaka-u.ac.jp Thanwadee Sunetnanta Mahidol University, Thailand thanwadee.sun@mahidol.ac.th Kenichi Matsumoto Nara Institute of Science and Technology, Japan matumoto@is.naist.jp code proficiency python oss Assessing developer proficiency in open-source software (OSS) projects is essential for understanding project dynamics, especially for expertise. This paper presents \"PyGress\", a web-based tool designed to automatically evaluate and visualize Python code proficiency using pycefr, a Python code proficiency analyzer. By submitting a GitHub repository link, the system extracts commit histories, analyzes source code proficiency across CEFR-aligned levels (A1\u2013C2), and generates visual summaries of individual and project-wide proficiency. The PyGress tool visualizes per-contributor proficiency distribution and tracks project code proficiency progression over time. PyGress offers an interactive way to explore contributor coding levels in Python OSS repositories. The video demonstration of the PyGress tool can be found at https://youtu.be/hxoeK-ggcWk, and the source code of the tool is publicly available at https://github.com/MUICT-SERU/PyGress.",
							"pageNumber": 3996,
							"isPageNumberRoman": false
						},
						{
							"eid": "695CC0GytFMjtPDBW0O40N",
							"type": "authorPaper",
							"text": "FlowStrider: Low-Friction Continuous Threat Modeling",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d000/573300d000.pdf",
							"extraLocations": [],
							"authorNames": "Bernd Gruner (German Aerospace Center, Germany), Noah Erthel (German Aerospace Center, Germany), Clemens-Alexander Brust (German Aerospace Center, Germany)",
							"abstract": "Architectural threat modeling is a crucial technique for identifying and mitigating security threats in software systems, helping to prevent costly design flaws. While existing tools aim to reduce its resource-intensive nature through automation, they often lack key features\u2014such as scriptability and integration capabilities\u2014needed for practical use in development workflows. In this paper, we present FlowStrider, a tool that addresses these shortcomings by implementing a new, practice-oriented workflow and enabling CI/CD integration through scriptability. FlowStrider reduces the required manual effort, enhances the quality of analysis results, and eases integration into software development workflows, thereby lowering the adoption barrier for continuous threat modeling. Screencast: https://youtu.be/iRpeU1nubHw Repository: https://gitlab.com/dlr-dw/automated-threat-modeling/flowstrider",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 FlowStrider: Low-Friction Continuous Threat Modeling 1759396405218 10.1109/ASE63991.2025.00360 Bernd Gruner German Aerospace Center, Germany bernd.gruner@dlr.de Noah Erthel German Aerospace Center, Germany noah.erthel@dlr.de Clemens-Alexander Brust German Aerospace Center, Germany clemens-alexander.brust@dlr.de tool threat elicitation automation Architectural threat modeling is a crucial technique for identifying and mitigating security threats in software systems, helping to prevent costly design flaws. While existing tools aim to reduce its resource-intensive nature through automation, they often lack key features\u2014such as scriptability and integration capabilities\u2014needed for practical use in development workflows. In this paper, we present FlowStrider, a tool that addresses these shortcomings by implementing a new, practice-oriented workflow and enabling CI/CD integration through scriptability. FlowStrider reduces the required manual effort, enhances the quality of analysis results, and eases integration into software development workflows, thereby lowering the adoption barrier for continuous threat modeling. Screencast: https://youtu.be/iRpeU1nubHw Repository: https://gitlab.com/dlr-dw/automated-threat-modeling/flowstrider",
							"pageNumber": 4000,
							"isPageNumberRoman": false
						},
						{
							"eid": "1TWW9mqstncv2AjbSxz5Ld",
							"type": "authorPaper",
							"text": "Towards Context-Aware Mobile Privacy Notice: Implementation of A Deployable Contextual Privacy Policies Generator",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e004/573300e004.pdf",
							"extraLocations": [],
							"authorNames": "Haochen Gong (Australian National University), Zhen Tao (Australian National University; CSIRO's Data61), Shidong Pan (Australian National University; CSIRO's Data61, Australia), Zhenchang Xing (Australian National University; CSIRO's Data61, Australia), Xiaoyu Sun (Australian National University)",
							"abstract": "Lengthy and legally phrased privacy policies impede users' understanding of how mobile applications collect and process personal data. Prior work proposed Contextual Privacy Policies (CPPs) for mobile apps to display shorter policy snippets only in the corresponding user interface contexts, but the pipeline could not be deployable in real-world mobile environments. In this paper, we present PrivScan, the first deployable CPP Software Development Kit (SDK) for Android. It captures live app screenshots to identify GUI elements associated with types of personal data and displays CPPs in a concise, user-facing format. We provide a lightweight floating button that offers low-friction, on-demand control. The architecture leverages remote deployment to decouple the multimodal backend pipeline from a mobile client comprising five modular components, thereby reducing on-device resource demands and easing cross-platform portability. A feasibility-oriented evaluation shows an average execution time of 9.15s, demonstrating the practicality of our approach. The source code of PrivScan is available at https://github.com/buyanghc/PrivScan and the demo video can be found at https://www.youtube.com/watch?v=ck-25otfyHc.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Towards Context-Aware Mobile Privacy Notice: Implementation of A Deployable Contextual Privacy Policies Generator 1759495159146 10.1109/ASE63991.2025.00361 Haochen Gong Australian National University haochen.gong1@anu.edu.au Zhen Tao Australian National University; CSIRO's Data61 zhen.tao@tum.de Shidong Pan Australian National University; CSIRO's Data61, Australia shidong.pan@data61.csiro.au Zhenchang Xing Australian National University; CSIRO's Data61, Australia zhenchang.xing@data61.csiro.au Xiaoyu Sun Australian National University xiaoyu.sun1@anu.edu.au contextual privacy policy privacy notice privacy policy gui understanding Lengthy and legally phrased privacy policies impede users' understanding of how mobile applications collect and process personal data. Prior work proposed Contextual Privacy Policies (CPPs) for mobile apps to display shorter policy snippets only in the corresponding user interface contexts, but the pipeline could not be deployable in real-world mobile environments. In this paper, we present PrivScan, the first deployable CPP Software Development Kit (SDK) for Android. It captures live app screenshots to identify GUI elements associated with types of personal data and displays CPPs in a concise, user-facing format. We provide a lightweight floating button that offers low-friction, on-demand control. The architecture leverages remote deployment to decouple the multimodal backend pipeline from a mobile client comprising five modular components, thereby reducing on-device resource demands and easing cross-platform portability. A feasibility-oriented evaluation shows an average execution time of 9.15s, demonstrating the practicality of our approach. The source code of PrivScan is available at https://github.com/buyanghc/PrivScan and the demo video can be found at https://www.youtube.com/watch?v=ck-25otfyHc.",
							"pageNumber": 4004,
							"isPageNumberRoman": false
						},
						{
							"eid": "3Dvsr73fvVlDtcf66le3Wd",
							"type": "authorPaper",
							"text": "AgentDroid: A Multi-Agent Tool for Detecting Fraudulent Android Applications",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e008/573300e008.pdf",
							"extraLocations": [],
							"authorNames": "Ruwei Pan (Chongqing University, China), Hongyu Zhang (Chongqing University, China), Zhonghao Jiang (Chongqing University, China), Ran Hou (Chongqing University, China)",
							"abstract": "With the increasing prevalence of fraudulent Android applications such as fake and malicious applications, it is crucial to detect them with high accuracy and adaptability. We present AgentDroid, a novel tool for Android fraudulent application detection based on multi-modal analysis and multi-agent systems. AgentDroid overcomes the limitations of traditional detection methods such as the inability to handle multimodal data and high false alarm rates. It processes Android applications and extracts a series of multi-modal data for analysis. Multiple LLM-based agents with specialized roles analyze the relevant data and collaborate to detect complex fraud effectively. We curated a dataset containing various categories of fraudulent applications and legitimate applications and validated our tool on this dataset. Experimental results indicate that our multi-agent tool based on GPT-4o achieves an accuracy of 91.7% and an F1-Score of 91.68%, outperforming the baseline methods. A video of AgentDroid is available at https://youtu.be/YOM9Ex-nBts.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 AgentDroid: A Multi-Agent Tool for Detecting Fraudulent Android Applications 1758891613786 10.1109/ASE63991.2025.00362 Ruwei Pan Chongqing University, China panruwei666@gmail.com Hongyu Zhang Chongqing University, China hongyujohn@gmail.com Zhonghao Jiang Chongqing University, China zhonghaojiang@cqu.edu.cn Ran Hou Chongqing University, China houran@stu.cqu.edu.cn fraudulent application detection multi-agent systems With the increasing prevalence of fraudulent Android applications such as fake and malicious applications, it is crucial to detect them with high accuracy and adaptability. We present AgentDroid, a novel tool for Android fraudulent application detection based on multi-modal analysis and multi-agent systems. AgentDroid overcomes the limitations of traditional detection methods such as the inability to handle multimodal data and high false alarm rates. It processes Android applications and extracts a series of multi-modal data for analysis. Multiple LLM-based agents with specialized roles analyze the relevant data and collaborate to detect complex fraud effectively. We curated a dataset containing various categories of fraudulent applications and legitimate applications and validated our tool on this dataset. Experimental results indicate that our multi-agent tool based on GPT-4o achieves an accuracy of 91.7% and an F1-Score of 91.68%, outperforming the baseline methods. A video of AgentDroid is available at https://youtu.be/YOM9Ex-nBts.",
							"pageNumber": 4008,
							"isPageNumberRoman": false
						},
						{
							"eid": "V5B8Osyhce9kFZAy8PsLy",
							"type": "authorPaper",
							"text": "XRINTTEST: An Automated Framework for User Interaction Testing in Extended Reality Applications",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e012/573300e012.pdf",
							"extraLocations": [],
							"authorNames": "Ruizhen Gu (The University of Sheffield, UK), Jos\u00E9 Miguel Rojas (The University of Sheffield, UK), Donghwan Shin (The University of Sheffield, UK)",
							"abstract": "Extended Reality (XR) technologies offer immersive user experiences across diverse application domains, presenting unique testing challenges due to their spatial interaction paradigms. While existing works test XR applications through scene navigation and interaction triggering, they fail to synthesise realistic spatial input via specialised XR devices, such as 6 degrees of freedom controller gestures, that are essential for modern XR user experiences. To address this gap, we present XRintTest, an automated testing framework for Unity-based XR applications. XRintTest starts by constructing an XR User Interaction Graph that models interaction targets and required events. Leveraging this graph, it then automatically explores the XR scene under test and generates user interactions. We evaluated XRintTest on XRBench3D, a novel benchmark comprising seven XR scenes containing 367 distinct 3D user interactions. XRintTest shows great effectiveness, achieving 97% coverage of trigger and grab interactions across all scenes, 9x more effective and 5x more efficient than random exploration, while detecting runtime exceptions and functional defects. We open-sourced our tool and dataset at https://github.com/ruizhengu/XRintTest and https://github.com/ruizhengu/XRBench3D, respectively. A video demo is available on YouTube at https://youtu.be/K0Q6waE47Us.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 XRINTTEST: An Automated Framework for User Interaction Testing in Extended Reality Applications 1759508644650 10.1109/ASE63991.2025.00363 Ruizhen Gu The University of Sheffield, UK rgu10@sheffield.ac.uk Jos\u00E9 Miguel Rojas The University of Sheffield, UK j.rojas@sheffield.ac.uk Donghwan Shin The University of Sheffield, UK d.shin@sheffield.ac.uk extended reality software testing 3d interaction model-based testing Extended Reality (XR) technologies offer immersive user experiences across diverse application domains, presenting unique testing challenges due to their spatial interaction paradigms. While existing works test XR applications through scene navigation and interaction triggering, they fail to synthesise realistic spatial input via specialised XR devices, such as 6 degrees of freedom controller gestures, that are essential for modern XR user experiences. To address this gap, we present XRintTest, an automated testing framework for Unity-based XR applications. XRintTest starts by constructing an XR User Interaction Graph that models interaction targets and required events. Leveraging this graph, it then automatically explores the XR scene under test and generates user interactions. We evaluated XRintTest on XRBench3D, a novel benchmark comprising seven XR scenes containing 367 distinct 3D user interactions. XRintTest shows great effectiveness, achieving 97% coverage of trigger and grab interactions across all scenes, 9x more effective and 5x more efficient than random exploration, while detecting runtime exceptions and functional defects. We open-sourced our tool and dataset at https://github.com/ruizhengu/XRintTest and https://github.com/ruizhengu/XRBench3D, respectively. A video demo is available on YouTube at https://youtu.be/K0Q6waE47Us.",
							"pageNumber": 4012,
							"isPageNumberRoman": false
						},
						{
							"eid": "1O1VZDA184rKGK8THyYvDZ",
							"type": "authorPaper",
							"text": "ReFuzzer: Feedback-Driven Approach to Enhance Validity of LLM-Generated Test Programs",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e016/573300e016.pdf",
							"extraLocations": [],
							"authorNames": "Iti Shree (King's College London, United Kingdom), Karine Even-Mendoza (King's College London, United Kingdom), Tomasz  Radzik (King's College London, United Kingdom)",
							"abstract": "Existing LLM-based compiler fuzzers often produce syntactically or semantically invalid test programs, limiting their effectiveness in exercising compiler optimisations and backend components. We introduce ReFuzzer, a framework for refining LLM-generated test programs by systematically detecting and correcting compilation and runtime violations (e.g. division by zero or array out-of-bounds accesses). ReFuzzer employs a feedback loop with a local LLM to validate and filter erroneous programs before execution, improving fuzzing effectiveness beyond crash detection and enabling the generation of diverse yet valid test programs. We evaluated ReFuzzer\u2019s effectiveness across black-, greyand white-box fuzzing approaches targeting LLVM/Clang. ReFuzzer improved test programs\u2019 validity from 47.0\u201349.4% to 96.6\u201397.3%, with an average processing time of 2.9\u20133.5 s per test program on a dual-GPU machine. Further, refuzzing significantly increased code coverage in critical optimisation and IR generation components. For example, vectorization coverage had an absolute of 9.2%, 2.3%, and 7.1% improvement in black-, grey-, and white-box fuzzing, enhancing testing effectiveness",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 ReFuzzer: Feedback-Driven Approach to Enhance Validity of LLM-Generated Test Programs 1759434825597 10.1109/ASE63991.2025.00364 Iti Shree King's College London, United Kingdom iti.shree@kcl.ac.uk Karine Even-Mendoza King's College London, United Kingdom karine.even_mendoza@kcl.ac.uk Tomasz Radzik King's College London, United Kingdom tomasz.radzik@kcl.ac.uk Compiler Fuzzing Large Language Models Existing LLM-based compiler fuzzers often produce syntactically or semantically invalid test programs, limiting their effectiveness in exercising compiler optimisations and backend components. We introduce ReFuzzer, a framework for refining LLM-generated test programs by systematically detecting and correcting compilation and runtime violations (e.g. division by zero or array out-of-bounds accesses). ReFuzzer employs a feedback loop with a local LLM to validate and filter erroneous programs before execution, improving fuzzing effectiveness beyond crash detection and enabling the generation of diverse yet valid test programs. We evaluated ReFuzzer\u2019s effectiveness across black-, greyand white-box fuzzing approaches targeting LLVM/Clang. ReFuzzer improved test programs\u2019 validity from 47.0\u201349.4% to 96.6\u201397.3%, with an average processing time of 2.9\u20133.5 s per test program on a dual-GPU machine. Further, refuzzing significantly increased code coverage in critical optimisation and IR generation components. For example, vectorization coverage had an absolute of 9.2%, 2.3%, and 7.1% improvement in black-, grey-, and white-box fuzzing, enhancing testing effectiveness",
							"pageNumber": 4016,
							"isPageNumberRoman": false
						},
						{
							"eid": "1FJj44XztLFbqtUAbZhqq6",
							"type": "authorPaper",
							"text": "PrioTestCI: Efficient Test Case Prioritization in GitHub Workflows for CI Optimization",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e020/573300e020.pdf",
							"extraLocations": [],
							"authorNames": "Shubham  Vasudeo Desai (North Carolina State University, United States), Shonil Bhide (North Carolina State University, United States), Souhaila Serbout (University of Zurich, Switzerland), Luciano Marchezan (University of Montreal, Canada), Wesley K. G. Assun\u00E7\u00E3o (North Carolina State University, United States)",
							"abstract": "Continuous Integration (CI) is a widely adopted practice in software development to automatically verify code changes across diverse environments. However, executing the full test suite on every pull request update can lead to redundant runs, slower feedback loops, and inefficient utilization of CI resources. To address this issue, we introduce PrioTestCI, a prioritization technique within GitHub Actions that focuses on re-executing test cases that have previously failed. If these prioritized tests succeed, the remaining tests proceed; otherwise, the workflow terminates early, saving computation resources and providing early feedback to developers. PrioTestCI utilizes commit-to-commit test result tracking to inform future test runs, thereby reducing unnecessary repetition and accelerating validation cycles. We evaluated our technique on the Pytest project, a real-world open-source project with an extensive test matrix. PrioTestCI resulted in a CI runtime reduction of 1h57m39s compared to the normal workflow, with individual configuration improvements ranging from 63.75% to 91.94% (81.55% on average).",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 PrioTestCI: Efficient Test Case Prioritization in GitHub Workflows for CI Optimization 1759344591501 10.1109/ASE63991.2025.00365 Shubham Vasudeo Desai North Carolina State University, United States shubhamdesai303@gmail.com Shonil Bhide North Carolina State University, United States shonilsbhide@gmail.com Souhaila Serbout University of Zurich, Switzerland souhaila.serbout@uzh.ch Luciano Marchezan University of Montreal, Canada lucianomarchezan94@gmail.com Wesley K. G. Assun\u00E7\u00E3o North Carolina State University, United States wesleyklewerton@gmail.com Continuous Integration (CI) is a widely adopted practice in software development to automatically verify code changes across diverse environments. However, executing the full test suite on every pull request update can lead to redundant runs, slower feedback loops, and inefficient utilization of CI resources. To address this issue, we introduce PrioTestCI, a prioritization technique within GitHub Actions that focuses on re-executing test cases that have previously failed. If these prioritized tests succeed, the remaining tests proceed; otherwise, the workflow terminates early, saving computation resources and providing early feedback to developers. PrioTestCI utilizes commit-to-commit test result tracking to inform future test runs, thereby reducing unnecessary repetition and accelerating validation cycles. We evaluated our technique on the Pytest project, a real-world open-source project with an extensive test matrix. PrioTestCI resulted in a CI runtime reduction of 1h57m39s compared to the normal workflow, with individual configuration improvements ranging from 63.75% to 91.94% (81.55% on average).",
							"pageNumber": 4020,
							"isPageNumberRoman": false
						},
						{
							"eid": "1eV9iZTWe2aEmHJIV0i0nF",
							"type": "authorPaper",
							"text": "DeepTx: Real-Time Transaction Risk Analysis via Multi-Modal Features and LLM Reasoning",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e024/573300e024.pdf",
							"extraLocations": [],
							"authorNames": "Yixuan Liu (Nanyang Technological University, Singapore), Xinlei Li (Nanyang Technological University, Singapore), Yi Li (Nanyang Technological University, Singapore)",
							"abstract": "Phishing attacks in Web3 ecosystems are increasingly sophisticated, exploiting deceptive contract logic, malicious frontend scripts, and token approval patterns. We present DeepTx, a real-time transaction analysis system that detects such threats before user confirmation. DeepTx simulates pending transactions, extracts behavior, context, and UI features, and uses multiple large language models (LLMs) to reason about transaction intent. A consensus mechanism with self-reflection ensures robust and explainable decisions. Evaluated on our phishing dataset, DeepTx achieves high precision and recall (demo video: https://youtu.be/4OfK9KCEXUM).",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 DeepTx: Real-Time Transaction Risk Analysis via Multi-Modal Features and LLM Reasoning 1759230547093 10.1109/ASE63991.2025.00366 Yixuan Liu Nanyang Technological University, Singapore liuy0255@e.ntu.edu.sg Xinlei Li Nanyang Technological University, Singapore xinlei003@e.ntu.edu.sg Yi Li Nanyang Technological University, Singapore yi_li@ntu.edu.sg blockchain security phishing detection transaction semantics Phishing attacks in Web3 ecosystems are increasingly sophisticated, exploiting deceptive contract logic, malicious frontend scripts, and token approval patterns. We present DeepTx, a real-time transaction analysis system that detects such threats before user confirmation. DeepTx simulates pending transactions, extracts behavior, context, and UI features, and uses multiple large language models (LLMs) to reason about transaction intent. A consensus mechanism with self-reflection ensures robust and explainable decisions. Evaluated on our phishing dataset, DeepTx achieves high precision and recall (demo video: https://youtu.be/4OfK9KCEXUM).",
							"pageNumber": 4024,
							"isPageNumberRoman": false
						},
						{
							"eid": "6wpD6fjh4zz474CvXcAs6G",
							"type": "authorPaper",
							"text": "FETT: Fault Injection as an Educational and Training Tool in Cybersecurity",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e028/573300e028.pdf",
							"extraLocations": [],
							"authorNames": "Ana\u00E9 De Baets (University of Namur, Belgium), Guillaume Nguyen (University of Namur, Belgium), Xavier Devroey (University of Namur, Belgium), Fabian Gilson (University of Canterbury, New Zealand)",
							"abstract": "In this paper, we present FETT, a fault injection tool for educational and training purposes addressed to educators and students in cybersecurity. Our tool aims to analyze and inject vulnerabilities into existing Django web applications for educational purposes. Indeed, security education often relies on either abstract theoretical instruction or overly simplistic examples. This tool bridges the gap between theory and practice by modifying real web applications in a targeted, reproducible way. With its user-friendly interface and modular vulnerability injection, instructors can create challenges tailored to specific learning goals, while students engage directly with code that simulates production-level vulnerabilities. We evaluated tool based on five publicly available GitHub projects and six student projects from the last three academic years (2022-2024). We successfully managed to efficiently inject vulnerabilities inspired by the OWASP top 10:2021 while keeping the core functionalities of the target application operational.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 FETT: Fault Injection as an Educational and Training Tool in Cybersecurity 1759436504038 10.1109/ASE63991.2025.00367 Ana\u00E9 De Baets University of Namur, Belgium anae.debaets@student.unamur.be Guillaume Nguyen University of Namur, Belgium guillaume.nguyen@unamur.be Xavier Devroey University of Namur, Belgium xavier.devroey@unamur.be Fabian Gilson University of Canterbury, New Zealand fabian.gilson@canterbury.ac.nz cybersecurity education owasp vulnerability injection django web application security In this paper, we present FETT, a fault injection tool for educational and training purposes addressed to educators and students in cybersecurity. Our tool aims to analyze and inject vulnerabilities into existing Django web applications for educational purposes. Indeed, security education often relies on either abstract theoretical instruction or overly simplistic examples. This tool bridges the gap between theory and practice by modifying real web applications in a targeted, reproducible way. With its user-friendly interface and modular vulnerability injection, instructors can create challenges tailored to specific learning goals, while students engage directly with code that simulates production-level vulnerabilities. We evaluated tool based on five publicly available GitHub projects and six student projects from the last three academic years (2022-2024). We successfully managed to efficiently inject vulnerabilities inspired by the OWASP top 10:2021 while keeping the core functionalities of the target application operational.",
							"pageNumber": 4028,
							"isPageNumberRoman": false
						},
						{
							"eid": "35pmXZNvjyVbBUUGsrc8Et",
							"type": "authorPaper",
							"text": "WIBE: Watermarks for generated Images \u2013 Benchmarking & Evaluation",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e032/573300e032.pdf",
							"extraLocations": [],
							"authorNames": "Aleksey Yakushev (ISP RAS, Russia), Aleksandr Akimenkov (ISP RAS, Russia), Khaled Abud (MSU AI Institute, Russia), Dmitry Obydenkov (ISP RAS, Russia), Irina Serzhenko (MIPT, Russia), Kirill Aistov (Huawei Research Center, Russia), Egor Kovalev (MSU, Russia), Stanislav Fomin (ISP RAS, Russia), Anastasia Antsiferova (ISP RAS Research Center, Russia; MSU AI Institute, Russia), Kirill Lukianov (ISP RAS Research Center, Russia; MIPT, Russia), Yury Markin (ISP RAS, Russia)",
							"abstract": "As invisible image watermarking gains importance for verifying AI-generated content, consistency and reproducibility remain major challenges due to the diverse methods, datasets, attacks, and metrics. We aim to provide a flexible, extensible, and user-friendly framework that enables systematic testing of watermarking methods under various conditions. We developed WIBE, a framework with command-line interfaces and YAML configuration support, enabling users to evaluate a wide range of image watermarking algorithms on various datasets, apply configurable attack scenarios, and compute standard performance metrics. WIBE includes a library of pre-implemented methods and supports integration of new watermarking techniques, attacks, metrics, and datasets through a plugin-based architecture. WIBE enables rapid prototyping, reproducible experiments, and insightful comparison of watermarking robustness. In our demo, we present its core features, plugin extensibility, and interactive infographics, making it a practical tool for researchers and practitioners working at the intersection of AI and media integrity. Project on GitHub: https://github.com/ispras/wibe YouTube video: https://youtu.be/lbWWB1crrwk",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 WIBE: Watermarks for generated Images \u2013 Benchmarking & Evaluation 1759324357507 10.1109/ASE63991.2025.00368 Aleksey Yakushev ISP RAS, Russia yakushev@ispras.ru Aleksandr Akimenkov ISP RAS, Russia alexandrakimenkov@gmail.com Khaled Abud MSU AI Institute, Russia khaled.abud@graphics.cs.msu.ru Dmitry Obydenkov ISP RAS, Russia obydenkov@ispras.ru Irina Serzhenko MIPT, Russia i.f.serzhenko@gmail.com Kirill Aistov Huawei Research Center, Russia kirill.aistov@yandex.ru Egor Kovalev MSU, Russia egor.kovalev@graphics.cs.msu.ru Stanislav Fomin ISP RAS, Russia stanislav.fomin@gmail.com Anastasia Antsiferova ISP RAS Research Center, Russia; MSU AI Institute, Russia aantsiferova@graphics.cs.msu.ru Kirill Lukianov ISP RAS Research Center, Russia; MIPT, Russia lukianov@ispras.ru Yury Markin ISP RAS, Russia ustas@ispras.ru SE4AI Invisible Watermarking AI-generated Content Verification Watermark extraction attacks Trust AI As invisible image watermarking gains importance for verifying AI-generated content, consistency and reproducibility remain major challenges due to the diverse methods, datasets, attacks, and metrics. We aim to provide a flexible, extensible, and user-friendly framework that enables systematic testing of watermarking methods under various conditions. We developed WIBE, a framework with command-line interfaces and YAML configuration support, enabling users to evaluate a wide range of image watermarking algorithms on various datasets, apply configurable attack scenarios, and compute standard performance metrics. WIBE includes a library of pre-implemented methods and supports integration of new watermarking techniques, attacks, metrics, and datasets through a plugin-based architecture. WIBE enables rapid prototyping, reproducible experiments, and insightful comparison of watermarking robustness. In our demo, we present its core features, plugin extensibility, and interactive infographics, making it a practical tool for researchers and practitioners working at the intersection of AI and media integrity. Project on GitHub: https://github.com/ispras/wibe YouTube video: https://youtu.be/lbWWB1crrwk",
							"pageNumber": 4032,
							"isPageNumberRoman": false
						},
						{
							"eid": "3H7IRDYKSJX7sZJdhuEDCx",
							"type": "authorPaper",
							"text": "ORMorpher: An Interactive Framework for ORM Translation and Optimization",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e036/573300e036.pdf",
							"extraLocations": [],
							"authorNames": "Milan Abrah\u00E1m (Charles University, Czech republic), Pavel Koupil (Charles University, Czech republic)",
							"abstract": "Frequent changes in application requirements demand not only schema and query adaptation but also migration and optimization of the object-relational mapping (ORM) code. While database and query migration are well-studied, application-level translation across ORM frameworks remains largely overlooked. We present ORMorpher, a unified and extensible framework for translating and optimizing across heterogeneous ORMs. Unlike existing solutions, ORMorpher supports both structural code transformation and resource-aware framework selection under user-defined constraints. Although broadly applicable, we demonstrate its effectiveness on three widely-used.NET frameworks: Entity Framework Core, NHibernate, and Dapper over Microsoft SQL Server, enabling practical, performance-driven migration. The source code is available at: https://github.com/milan252525/orm-convertor. A demonstration video is available at: https://youtu.be/zwGGdqXtrzM.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 ORMorpher: An Interactive Framework for ORM Translation and Optimization 1759223979222 10.1109/ASE63991.2025.00369 Milan Abrah\u00E1m Charles University, Czech republic milan.abraham882@student.cuni.cz Pavel Koupil Charles University, Czech republic pavel.koupil@matfyz.cuni.cz object-relational mapping application-level migration query rewriting software evolution Frequent changes in application requirements demand not only schema and query adaptation but also migration and optimization of the object-relational mapping (ORM) code. While database and query migration are well-studied, application-level translation across ORM frameworks remains largely overlooked. We present ORMorpher, a unified and extensible framework for translating and optimizing across heterogeneous ORMs. Unlike existing solutions, ORMorpher supports both structural code transformation and resource-aware framework selection under user-defined constraints. Although broadly applicable, we demonstrate its effectiveness on three widely-used.NET frameworks: Entity Framework Core, NHibernate, and Dapper over Microsoft SQL Server, enabling practical, performance-driven migration. The source code is available at: https://github.com/milan252525/orm-convertor. A demonstration video is available at: https://youtu.be/zwGGdqXtrzM.",
							"pageNumber": 4036,
							"isPageNumberRoman": false
						},
						{
							"eid": "7cBmJDd8FWDA6hIqEHpsCv",
							"type": "authorPaper",
							"text": "BuilDroid: A Self-Correcting LLM Agent for Automated Android Builds",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e040/573300e040.pdf",
							"extraLocations": [],
							"authorNames": "Jaehyeon Kim (NYU, Abu Dhabi), Rui Rua (NYU, Abu Dhabi), Karim Ali (NYU, Abu Dhabi)",
							"abstract": "The continuous evolution of the Android ecosystem has led to a highly dynamic and fragmented development environment. This constant churn makes building Android projects, especially from open-source repositories, a notoriously difficult task. Developers and researchers encounter a daunting build barrier due to the rapid configuration drift, which results in a cascade of errors. These errors include version incompatibilities, missing dependencies, and inconsistent project configurations, hindering reproducibility and maintainability. To address these issues, we present BuilDroid, an LLM-based agent that automates the build process of Android projects. Operating within a self-contained, isolated environment, BuilDroid runs an iterative, self-correcting loop. Through this operation, BuilDroid captures errors and autonomously resolves them, either through predefined heuristics or by leveraging the reasoning capabilities of its underlying model. Across 245 open-source Android projects, BuilDroid effectively resolves complex and evolving build errors, achieving a build success rate of 90.2%, surpassing existing solutions by a margin of over 30.2%. Consequently, BuilDroid reduces the barrier for researchers and developers, fostering greater software reproducibility and enabling more extensive and reliable empirical research within the rapidly evolving Android ecosystem.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 BuilDroid: A Self-Correcting LLM Agent for Automated Android Builds 1759134956880 10.1109/ASE63991.2025.00370 Jaehyeon Kim NYU, Abu Dhabi jk7404@nyu.edu Rui Rua NYU, Abu Dhabi rui.rua@nyu.ed Karim Ali NYU, Abu Dhabi karim.ali@nyu.edu Software Maintenance AI for Software Engineering Android Empirical Software Engineering The continuous evolution of the Android ecosystem has led to a highly dynamic and fragmented development environment. This constant churn makes building Android projects, especially from open-source repositories, a notoriously difficult task. Developers and researchers encounter a daunting build barrier due to the rapid configuration drift, which results in a cascade of errors. These errors include version incompatibilities, missing dependencies, and inconsistent project configurations, hindering reproducibility and maintainability. To address these issues, we present BuilDroid, an LLM-based agent that automates the build process of Android projects. Operating within a self-contained, isolated environment, BuilDroid runs an iterative, self-correcting loop. Through this operation, BuilDroid captures errors and autonomously resolves them, either through predefined heuristics or by leveraging the reasoning capabilities of its underlying model. Across 245 open-source Android projects, BuilDroid effectively resolves complex and evolving build errors, achieving a build success rate of 90.2%, surpassing existing solutions by a margin of over 30.2%. Consequently, BuilDroid reduces the barrier for researchers and developers, fostering greater software reproducibility and enabling more extensive and reliable empirical research within the rapidly evolving Android ecosystem.",
							"pageNumber": 4040,
							"isPageNumberRoman": false
						},
						{
							"eid": "1nI6zyU3ghkWmDpkis26cS",
							"type": "authorPaper",
							"text": "Chrysalis: A Lightweight Logging and Replay Framework for Metamorphic Testing in Python",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e044/573300e044.pdf",
							"extraLocations": [],
							"authorNames": "Jai Parera (University of California, USA), Nathan Huey (University of California, USA), Ben Limpanukorn (University of California, USA), Miryung Kim (University of California, USA)",
							"abstract": "Metamorphic testing is a powerful technique for software testing. We introduce Chrysalis, a lightweight, extensible logging and replay-based metamorphic testing framework in Python. Chrysalis allows developers to define custom input transformations and their associated invariants, then execute structured metamorphic testing campaigns. Its key innovation is a lightweight logging mechanism that records the full history of transformations applied to an input. This compact representation enables developers to not only identify test failures but also to replay the exact sequence of transformations leading to a bug, facilitating debugging. We demonstrate Chrysalis's effectiveness through two case studies: auditing a machine learning model for fairness and assessing the robustness of large language models. A screencast demonstrating Chrysalis is available at: https://youtu.be/xJG4qghxlIs, and the source code is available at: https://github.com/Chrysalis-Test/Chrysalis.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Chrysalis: A Lightweight Logging and Replay Framework for Metamorphic Testing in Python 1760036939976 10.1109/ASE63991.2025.00371 Jai Parera University of California, USA jaiparera@cs.ucla.edu Nathan Huey University of California, USA njhuey@g.ucla.edu Ben Limpanukorn University of California, USA blimpan@cs.ucla.edu Miryung Kim University of California, USA miryung@cs.ucla.edu metamorphic testing Metamorphic testing is a powerful technique for software testing. We introduce Chrysalis, a lightweight, extensible logging and replay-based metamorphic testing framework in Python. Chrysalis allows developers to define custom input transformations and their associated invariants, then execute structured metamorphic testing campaigns. Its key innovation is a lightweight logging mechanism that records the full history of transformations applied to an input. This compact representation enables developers to not only identify test failures but also to replay the exact sequence of transformations leading to a bug, facilitating debugging. We demonstrate Chrysalis's effectiveness through two case studies: auditing a machine learning model for fairness and assessing the robustness of large language models. A screencast demonstrating Chrysalis is available at: https://youtu.be/xJG4qghxlIs, and the source code is available at: https://github.com/Chrysalis-Test/Chrysalis.",
							"pageNumber": 4044,
							"isPageNumberRoman": false
						},
						{
							"eid": "3KvMRADex4r2PPX9TlvVun",
							"type": "authorPaper",
							"text": "BASHIRI: Learning Failure Oracles from Execution Features",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e048/573300e048.pdf",
							"extraLocations": [],
							"authorNames": "Marius Smytzek (CISPA Helmholtz Center for Information Security, Germany), Martin Eberlein (Humboldt-Universit\u00E4t zu Berlin, Germany), Tural Mammadov (CISPA Helmholtz Center for Information Security, Germany), Lars Grunske (Humboldt-Universit\u00E4t zu Berlin, Germany), Andreas Zeller (CISPA Helmholtz Center for Information Security, China)",
							"abstract": "Program fixes must preserve passing tests while fixing failing ones. Validating these properties requires test oracles that distinguish passing from failing runs. We introduce BASHIRI, a tool that learns failure oracles from test suites with labeled outcomes using execution features. BASHIRI leverages execution-feature-driven debugging to collect program execution features and trains interpretable models as testing oracles. Our evaluation shows that BASHIRI predicts test outcomes with 95% accuracy, effectively identifying failing runs. BASHIRI is available as an open-source tool at https://github.com/smythi93/bashiri A demonstration video is available at https://youtu.be/D2mJkCtSXtM",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 BASHIRI: Learning Failure Oracles from Execution Features 1759334179548 10.1109/ASE63991.2025.00372 Marius Smytzek CISPA Helmholtz Center for Information Security, Germany marius.smytzek@cispa.de Martin Eberlein Humboldt-Universit\u00E4t zu Berlin, Germany martin.eberlein@hu-berlin.de Tural Mammadov CISPA Helmholtz Center for Information Security, Germany tural.mammadov@cispa.de Lars Grunske Humboldt-Universit\u00E4t zu Berlin, Germany grunske@hu-berlin.de Andreas Zeller CISPA Helmholtz Center for Information Security, China andreas.zeller@cispa.de testing oracles automated debugging execution features dynamic analysis Program fixes must preserve passing tests while fixing failing ones. Validating these properties requires test oracles that distinguish passing from failing runs. We introduce BASHIRI, a tool that learns failure oracles from test suites with labeled outcomes using execution features. BASHIRI leverages execution-feature-driven debugging to collect program execution features and trains interpretable models as testing oracles. Our evaluation shows that BASHIRI predicts test outcomes with 95% accuracy, effectively identifying failing runs. BASHIRI is available as an open-source tool at https://github.com/smythi93/bashiri A demonstration video is available at https://youtu.be/D2mJkCtSXtM",
							"pageNumber": 4048,
							"isPageNumberRoman": false
						},
						{
							"eid": "2g4J3OO3C8lLb1ATw8XgRg",
							"type": "authorPaper",
							"text": "GUI-ReRank: Enhancing GUI Retrieval with Multi-Modal LLM-Based Reranking",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e052/573300e052.pdf",
							"extraLocations": [],
							"authorNames": "Kristian Kolthoff (Clausthal University of Technology, Germany), Felix Kretzer (Karlsruhe Institute of Technology, Germany), Alexander Maedche (Karlsruhe Institute of Technology, Germany), Simone Paolo Ponzetto (University of Mannheim, Germany), Christian Bartelt (Clausthal University of Technology, Germany)",
							"abstract": "Graphical User Interface (GUI) prototyping is a fundamental component in the development of modern interactive systems, which are now ubiquitous across diverse application domains. GUI prototypes play a critical role in requirements elicitation by enabling stakeholders to visualize, assess, and refine system concepts collaboratively. Moreover, prototypes serve as effective tools for early testing, iterative evaluation, and validation of design ideas with both end users and development teams. Despite these advantages, the process of constructing GUI prototypes remains resource-intensive and time-consuming, frequently demanding substantial effort and expertise. Recent research has sought to alleviate this burden through natural language (NL)-based GUI retrieval approaches, which typically rely on embedding-based retrieval or tailored ranking models for specific GUI repositories. However, these methods often suffer from limited retrieval performance and struggle to generalize across arbitrary GUI datasets. In this work, we present GUI-ReRank, a novel framework that integrates rapid embedding-based constrained retrieval models with highly effective multi-modal (M) LLM-based reranking techniques. GUI-ReRank further introduces a fully customizable GUI repository annotation and embedding pipeline, enabling users to effortlessly make their own GUI repositories searchable, which allows for rapid discovery of relevant GUIs for inspiration or seamless integration into customized LLM-based retrieval-augmented generation (RAG) workflows. We evaluated our approach on an established NL-based GUI retrieval benchmark, demonstrating that GUI-ReRank significantly outperforms state-of-the-art (SOTA) tailored Learning-to-Rank (LTR) models in both retrieval accuracy and generalizability. Additionally, we conducted a comprehensive cost and efficiency analysis of employing MLLMs for reranking, providing valuable insights regarding the trade-offs between retrieval effectiveness and computational resources. Video presentation of GUI-ReRank available at: https://youtu.be/_7x9UCh82ug",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 GUI-ReRank: Enhancing GUI Retrieval with Multi-Modal LLM-Based Reranking 1759267446899 10.1109/ASE63991.2025.00373 Kristian Kolthoff Clausthal University of Technology, Germany kristian.kolthoff@tu-clausthal.de Felix Kretzer Karlsruhe Institute of Technology, Germany felix.kretzer@kit.edu Alexander Maedche Karlsruhe Institute of Technology, Germany alexander.maedche@kit.edu Simone Paolo Ponzetto University of Mannheim, Germany simone@informatik.uni-mannheim.de Christian Bartelt Clausthal University of Technology, Germany christian.bartelt@tu-clausthal.de automated gui prototyping natural-language-based gui retrieval and mllm-based gui reranking Graphical User Interface (GUI) prototyping is a fundamental component in the development of modern interactive systems, which are now ubiquitous across diverse application domains. GUI prototypes play a critical role in requirements elicitation by enabling stakeholders to visualize, assess, and refine system concepts collaboratively. Moreover, prototypes serve as effective tools for early testing, iterative evaluation, and validation of design ideas with both end users and development teams. Despite these advantages, the process of constructing GUI prototypes remains resource-intensive and time-consuming, frequently demanding substantial effort and expertise. Recent research has sought to alleviate this burden through natural language (NL)-based GUI retrieval approaches, which typically rely on embedding-based retrieval or tailored ranking models for specific GUI repositories. However, these methods often suffer from limited retrieval performance and struggle to generalize across arbitrary GUI datasets. In this work, we present GUI-ReRank, a novel framework that integrates rapid embedding-based constrained retrieval models with highly effective multi-modal (M) LLM-based reranking techniques. GUI-ReRank further introduces a fully customizable GUI repository annotation and embedding pipeline, enabling users to effortlessly make their own GUI repositories searchable, which allows for rapid discovery of relevant GUIs for inspiration or seamless integration into customized LLM-based retrieval-augmented generation (RAG) workflows. We evaluated our approach on an established NL-based GUI retrieval benchmark, demonstrating that GUI-ReRank significantly outperforms state-of-the-art (SOTA) tailored Learning-to-Rank (LTR) models in both retrieval accuracy and generalizability. Additionally, we conducted a comprehensive cost and efficiency analysis of employing MLLMs for reranking, providing valuable insights regarding the trade-offs between retrieval effectiveness and computational resources. Video presentation of GUI-ReRank available at: https://youtu.be/_7x9UCh82ug",
							"pageNumber": 4052,
							"isPageNumberRoman": false
						},
						{
							"eid": "36nz6ZjDOGMJaQbxcpeqpZ",
							"type": "authorPaper",
							"text": "EyeNav: Accessible Webpage Interaction and Testing Using Eye-Tracking and NLP",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e056/573300e056.pdf",
							"extraLocations": [],
							"authorNames": "Juan Diego Yepes-Parra (Universidad de los Andes, Colombia), Camilo Escobar-Vel\u00E1squez (Universidad de los Andes, Colombia)",
							"abstract": "In the field of human-computer interaction (HCI), alternative interaction methods are becoming increasingly popular and commercially available. From this opportunity came EyeNav, a system that combines eye-tracking and natural language processing (NLP) to enhance accessibility and enable automated test generation. The integration of these technologies for intuitive web interaction, using pointer control via gaze and natural language processing for interpreting user intentions, also presents a record-and-replay module for generating automated test scripts. Envisioned for users with motor disabilities, developers, usability testers, and general users interested in exploring novel multimodal web interactions. The ultimate goal is to demonstrate that this tool can be used not only as a possible assistive technology but also as an innovative approach to software testing. The tool is available publicly at https://thesoftwaredesignlab.github.io/EyeNav/, accompanied with a demonstration video https://thesoftwaredesignlab.github.io/EyeNav/video.html",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 EyeNav: Accessible Webpage Interaction and Testing Using Eye-Tracking and NLP 1759521682456 10.1109/ASE63991.2025.00374 Juan Diego Yepes-Parra Universidad de los Andes, Colombia j.yepes@uniandes.edu.co Camilo Escobar-Vel\u00E1squez Universidad de los Andes, Colombia ca.escobar2434@uniandes.edu.co eye-tracking automated test generation assistive technology natural language processing web applications accessibility In the field of human-computer interaction (HCI), alternative interaction methods are becoming increasingly popular and commercially available. From this opportunity came EyeNav, a system that combines eye-tracking and natural language processing (NLP) to enhance accessibility and enable automated test generation. The integration of these technologies for intuitive web interaction, using pointer control via gaze and natural language processing for interpreting user intentions, also presents a record-and-replay module for generating automated test scripts. Envisioned for users with motor disabilities, developers, usability testers, and general users interested in exploring novel multimodal web interactions. The ultimate goal is to demonstrate that this tool can be used not only as a possible assistive technology but also as an innovative approach to software testing. The tool is available publicly at https://thesoftwaredesignlab.github.io/EyeNav/, accompanied with a demonstration video https://thesoftwaredesignlab.github.io/EyeNav/video.html",
							"pageNumber": 4056,
							"isPageNumberRoman": false
						},
						{
							"eid": "6C9NPJScuW91Htb4IoKTJR",
							"type": "authorPaper",
							"text": "DSBox: A Data Selection Framework for Efficient Deep Code Learning",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e061/573300e061.pdf",
							"extraLocations": [],
							"authorNames": "Xinyang Liu (TianJin University, China), Lili Quan (TianJin University, China), Qiang Hu (TianJin University, China)",
							"abstract": "Deep Learning has achieved remarkable advancements in various software engineering tasks and gained huge attention in the community. Following a data-centric paradigm, the preparation of code models requires high-quality datasets for the model training. However, constructing such datasets, especially for software tasks, is costly mainly due to the data labeling process. To address this challenge, multiple data selection methods have been proposed to identify and label data samples that are important for training. Despite this potential, unfortunately, there are limited tools to support the flexible usage of data selection methods, hindering their practical usage and future research in this domain. To bridge this gap, we introduce DSBox, a lightweight yet extensible framework that unifies 20 published selection methods, covering three categories: uncertainty, representativeness, and quality-based methods. Evaluation demonstrates that active learning methods outperform recently proposed techniques~(designed for large language models) on the code vulnerability detection task. The tool, as well as a demonstration video, are available on the project website https://sites.google.com/view/dsbox2025.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 DSBox: A Data Selection Framework for Efficient Deep Code Learning 1759472054001 10.1109/ASE63991.2025.00375 Xinyang Liu TianJin University, China 3021244394@tju.edu.cn Lili Quan TianJin University, China quanlili@tju.edu.cn Qiang Hu TianJin University, China qianghu@tju.edu.cn Deep Learning has achieved remarkable advancements in various software engineering tasks and gained huge attention in the community. Following a data-centric paradigm, the preparation of code models requires high-quality datasets for the model training. However, constructing such datasets, especially for software tasks, is costly mainly due to the data labeling process. To address this challenge, multiple data selection methods have been proposed to identify and label data samples that are important for training. Despite this potential, unfortunately, there are limited tools to support the flexible usage of data selection methods, hindering their practical usage and future research in this domain. To bridge this gap, we introduce DSBox, a lightweight yet extensible framework that unifies 20 published selection methods, covering three categories: uncertainty, representativeness, and quality-based methods. Evaluation demonstrates that active learning methods outperform recently proposed techniques~(designed for large language models) on the code vulnerability detection task. The tool, as well as a demonstration video, are available on the project website https://sites.google.com/view/dsbox2025.",
							"pageNumber": 4061,
							"isPageNumberRoman": false
						},
						{
							"eid": "4PkFVRYSUJJyuHwmw6WdVp",
							"type": "authorPaper",
							"text": "BenGQL: An Extensible Benchmarking Framework for Automated GraphQL Testing",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e065/573300e065.pdf",
							"extraLocations": [],
							"authorNames": "Abenezer Angamo (Independent Researcher, Ethiopia), Marcello Maugeri (University of Catania, Italy)",
							"abstract": "GraphQL APIs provide a unified endpoint for retrieving and uploading data in a web application. Due to its efficient data-fetching strategy, which allows for the retrieval of only the required data, GraphQL is gaining popularity. Its software nature necessitates robust testing, both functional and non-functional. As automated testing tools, including load testers and fuzzers, are developed to assess GraphQL APIs, they lack a common set of case studies for rigorous evaluation and comparison. To address this gap, we present BenGQL, a benchmarking framework containing 23 representative open-source GraphQL server applications, spanning different underlying engines and schema complexities. BenGQL provides an extensible infrastructure for running testing tools against these case studies, enabling developers and researchers to: (i) execute testing tools against the same case studies, (ii) analyse and compare results using custom analysis modules, and (iii) extend the benchmark with new case studies, tools, or metrics. The ultimate goal of BenGQL is to foster more rigorous, reproducible research in automated GraphQL testing by providing both the case studies and the infrastructure for running experiments. As a consequence, we release the source code at https://github.com/marcellomaugeri/BenGQL, inviting other researchers to contribute. A video demonstration is also available at https://youtu.be/wZ06Xxa_Koo.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 BenGQL: An Extensible Benchmarking Framework for Automated GraphQL Testing 1759565511199 10.1109/ASE63991.2025.00376 Abenezer Angamo Independent Researcher, Ethiopia abenezer.angamo@gmail.com Marcello Maugeri University of Catania, Italy marcello.maugeri@phd.unict.it graphql benchmark automated testing GraphQL APIs provide a unified endpoint for retrieving and uploading data in a web application. Due to its efficient data-fetching strategy, which allows for the retrieval of only the required data, GraphQL is gaining popularity. Its software nature necessitates robust testing, both functional and non-functional. As automated testing tools, including load testers and fuzzers, are developed to assess GraphQL APIs, they lack a common set of case studies for rigorous evaluation and comparison. To address this gap, we present BenGQL, a benchmarking framework containing 23 representative open-source GraphQL server applications, spanning different underlying engines and schema complexities. BenGQL provides an extensible infrastructure for running testing tools against these case studies, enabling developers and researchers to: (i) execute testing tools against the same case studies, (ii) analyse and compare results using custom analysis modules, and (iii) extend the benchmark with new case studies, tools, or metrics. The ultimate goal of BenGQL is to foster more rigorous, reproducible research in automated GraphQL testing by providing both the case studies and the infrastructure for running experiments. As a consequence, we release the source code at https://github.com/marcellomaugeri/BenGQL, inviting other researchers to contribute. A video demonstration is also available at https://youtu.be/wZ06Xxa_Koo.",
							"pageNumber": 4065,
							"isPageNumberRoman": false
						},
						{
							"eid": "1AqQwUfRbUlkRc1MehGmSP",
							"type": "authorPaper",
							"text": "PyTrim: A Practical Tool for Reducing Python Dependency Bloat",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e069/573300e069.pdf",
							"extraLocations": [],
							"authorNames": "Konstantinos Karakatsanis (Athens University of Economics and Business, Greece), Georgios Alexopoulos (University of Athens, Greece), Ioannis Karyotakis (Athens University of Economics and Business, Greece), Foivos Timotheos Proestakis (Athens University of Economics and Business, Greece), Evangelos Talos (Athens University of Economics and Business, Greece), Panos Louridas (Athens University of Economics and Business, Greece), Dimitris Mitropoulos (University of Athens, Greece)",
							"abstract": "Dependency bloat is a persistent challenge in Python projects, which increases maintenance costs and security risks. While numerous tools exist for detecting unused dependencies in Python, removing these dependencies across the source code and configuration files of a project requires manual effort and expertise. To tackle this challenge we introduce PYTRIM, an end-to-end system to automate this process. PYTRIM eliminates unused imports and package declarations across a variety of file types, including Python source and configuration files such as requirements.txt and setup.py. PYTRIM's modular design makes it agnostic to the source of dependency bloat information, enabling integration with any detection tool. Beyond its contribution when it comes to automation, PYTRIM also incorporates a novel dynamic analysis component that improves dependency detection recall. Our evaluation of PYTRIM's end-to-end effectiveness on a ground-truth dataset of 37 merged pull requests from prior work, shows that PYTRIM achieves 98.3% accuracy in replicating human-made changes. To show its practical impact, we run PYTRIM on 971 open-source packages, identifying and trimming bloated dependencies in 39 of them. For each case, we submit a corresponding pull request, 6 of which have already been accepted and merged. PYTRIM is available as an open-source project, encouraging community contributions and further development. Video demonstration: https://youtu.be/LqTEdOUbJRI. Code repository: https://github.com/TrimTeam/PyTrim.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 PyTrim: A Practical Tool for Reducing Python Dependency Bloat 1759346814392 10.1109/ASE63991.2025.00377 Konstantinos Karakatsanis Athens University of Economics and Business, Greece karakatsanis@aueb.gr Georgios Alexopoulos University of Athens, Greece grgalex@ba.uoa.gr Ioannis Karyotakis Athens University of Economics and Business, Greece karyotakisg@aueb.gr Foivos Timotheos Proestakis Athens University of Economics and Business, Greece proestakis@aueb.gr Evangelos Talos Athens University of Economics and Business, Greece vtalos@aueb.gr Panos Louridas Athens University of Economics and Business, Greece louridas@aueb.gr Dimitris Mitropoulos University of Athens, Greece dimitro@ba.uoa.gr software engineering software maintenance software tools dependency bloat program analysis Dependency bloat is a persistent challenge in Python projects, which increases maintenance costs and security risks. While numerous tools exist for detecting unused dependencies in Python, removing these dependencies across the source code and configuration files of a project requires manual effort and expertise. To tackle this challenge we introduce PYTRIM, an end-to-end system to automate this process. PYTRIM eliminates unused imports and package declarations across a variety of file types, including Python source and configuration files such as requirements.txt and setup.py. PYTRIM's modular design makes it agnostic to the source of dependency bloat information, enabling integration with any detection tool. Beyond its contribution when it comes to automation, PYTRIM also incorporates a novel dynamic analysis component that improves dependency detection recall. Our evaluation of PYTRIM's end-to-end effectiveness on a ground-truth dataset of 37 merged pull requests from prior work, shows that PYTRIM achieves 98.3% accuracy in replicating human-made changes. To show its practical impact, we run PYTRIM on 971 open-source packages, identifying and trimming bloated dependencies in 39 of them. For each case, we submit a corresponding pull request, 6 of which have already been accepted and merged. PYTRIM is available as an open-source project, encouraging community contributions and further development. Video demonstration: https://youtu.be/LqTEdOUbJRI. Code repository: https://github.com/TrimTeam/PyTrim.",
							"pageNumber": 4069,
							"isPageNumberRoman": false
						},
						{
							"eid": "7LAP9j9b4Onu1yKBVf2Znk",
							"type": "authorPaper",
							"text": "OSSPREY: AI-Driven Forecasting and Intervention for OSS Project Sustainability",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e073/573300e073.pdf",
							"extraLocations": [],
							"authorNames": "Nafiz Imtiaz  Khan (University of California, Davis), Priyal Soni (University of California, Davis), Arjun Ashok (University of California, Davis), Vladimir Filkov (University of California, Davis)",
							"abstract": "Open source software (OSS) underpins modern software infrastructure, yet many projects struggle with long-term sustainability. We introduce OSSPREY, an AI-powered platform that can predict the sustainability of any GitHub-hosted project. OSSPREY collects longitudinal socio-technical data, such as: commits, issues, and contributor interactions, and uses a transformer-based model to generate month-by-month sustainability forecasts. When project downturns are detected, it recommends evidence-based interventions drawn from published software engineering studies. OSSPREY integrates scraping, forecasting, and actionable guidance into an interactive dashboard, enabling maintainers to monitor project health, anticipate decline, and respond with targeted strategies. By connecting real-time project data with research-backed insights, OSSPREY offers a practical tool for sustaining OSS projects at scale. The codebase is linked to the project website at: https: //oss-prey.github.io/OSSPREY-Website/ The screencast is available at: https://www.youtube.com/ watch?v=N7a0v4hPylU",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 OSSPREY: AI-Driven Forecasting and Intervention for OSS Project Sustainability 1758861240280 10.1109/ASE63991.2025.00378 Nafiz Imtiaz Khan University of California, Davis nikhan@ucdavis.edu Priyal Soni University of California, Davis pdsoni@ucdavis.edu Arjun Ashok University of California, Davis arjashok@ucdavis.edu Vladimir Filkov University of California, Davis vfilkov@ucdavis.edu open source software project sustainability socio-technical networks forecasting researched actionable Open source software (OSS) underpins modern software infrastructure, yet many projects struggle with long-term sustainability. We introduce OSSPREY, an AI-powered platform that can predict the sustainability of any GitHub-hosted project. OSSPREY collects longitudinal socio-technical data, such as: commits, issues, and contributor interactions, and uses a transformer-based model to generate month-by-month sustainability forecasts. When project downturns are detected, it recommends evidence-based interventions drawn from published software engineering studies. OSSPREY integrates scraping, forecasting, and actionable guidance into an interactive dashboard, enabling maintainers to monitor project health, anticipate decline, and respond with targeted strategies. By connecting real-time project data with research-backed insights, OSSPREY offers a practical tool for sustaining OSS projects at scale. The codebase is linked to the project website at: https: //oss-prey.github.io/OSSPREY-Website/ The screencast is available at: https://www.youtube.com/ watch?v=N7a0v4hPylU",
							"pageNumber": 4073,
							"isPageNumberRoman": false
						},
						{
							"eid": "1yoCGNGM7RmoK62mErnfvL",
							"type": "authorPaper",
							"text": "Evaluating Program Coverage for Code-Model Training",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e077/573300e077.pdf",
							"extraLocations": [],
							"authorNames": "Nandakishore Menon (IBM Research, India), Diptikalyan Saha (IBM Research, India)",
							"abstract": "In recent years, CodeLLMs have revolutionized the way developers interact with code. One notable application has been program translation, such as converting COBOL to Java or C to Rust. A critical challenge in this domain is ensuring that CodeLLMs are trained on programs that cover all syntactic features of the target language. This issue is especially pronounced for legacy languages like COBOL and ABAP, which are syntactically rich and have limited availability of open-source programs. In this paper, we present a tool for evaluating the syntactic coverage of COBOL programs. At the core of our approach is a representation called the Coverage Tree, which compactly and intuitively captures the syntactic constructs covered by a set of programs. Additionally, the tool can generate code statements to address uncovered syntactic gaps. Experimental results with COBOL benchmarks demonstrate the effectiveness of the tool. Screencast URL: https://youtu.be/lM0KHzcvllY.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Evaluating Program Coverage for Code-Model Training 1759573203492 10.1109/ASE63991.2025.00379 Nandakishore Menon IBM Research, India nandakishore@ibm.com Diptikalyan Saha IBM Research, India diptsaha@in.ibm.com coverage coverage tree grammar-based generation syntax coverage program coverage code-model training In recent years, CodeLLMs have revolutionized the way developers interact with code. One notable application has been program translation, such as converting COBOL to Java or C to Rust. A critical challenge in this domain is ensuring that CodeLLMs are trained on programs that cover all syntactic features of the target language. This issue is especially pronounced for legacy languages like COBOL and ABAP, which are syntactically rich and have limited availability of open-source programs. In this paper, we present a tool for evaluating the syntactic coverage of COBOL programs. At the core of our approach is a representation called the Coverage Tree, which compactly and intuitively captures the syntactic constructs covered by a set of programs. Additionally, the tool can generate code statements to address uncovered syntactic gaps. Experimental results with COBOL benchmarks demonstrate the effectiveness of the tool. Screencast URL: https://youtu.be/lM0KHzcvllY.",
							"pageNumber": 4077,
							"isPageNumberRoman": false
						},
						{
							"eid": "2gq38Vn3xy6EiBIqrOlpHB",
							"type": "authorPaper",
							"text": "TRUSTVIS: A Multi-Dimensional Trustworthiness Evaluation Framework for Large Language Models",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e081/573300e081.pdf",
							"extraLocations": [],
							"authorNames": "Ruoyu Sun (University of Alberta, Canada), Da Song (Mila - Quebec Artificial Intelligence Institute), Jiayang Song (Macau University of Science and Technology, China), Yuheng Huang (The University of Tokyo, Japan), Lei ma (The University of Tokyo, Japan; University of Alberta, Canada)",
							"abstract": "As Large Language Models (LLMs) continue to revolutionize Natural Language Processing (NLP) applications, critical concerns about their trustworthiness persist, particularly in safety and robustness. To address these challenges, we introduce TRUSTVIS, an automated evaluation framework that provides a comprehensive assessment of LLM trustworthiness. A key feature of our framework is its interactive user interface, designedto offer intuitive visualizations of trustworthiness metrics. By integrating well-known perturbation methods like AutoDAN andemploying majority voting across various evaluation methods, TRUSTVIS not only provides reliable results but also makes complex evaluation processes accessible to users. Preliminary case studies on models like Vicuna-7b, Llama2-7b, and GPT-3.5 demonstrate the effectiveness of our framework in identifying safety and robustness vulnerabilities, while the interactive interface allows users to explore results in detail, empowering targeted model improvements. Video Link: https://youtu.be/k1TrBqNVg8g",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 TRUSTVIS: A Multi-Dimensional Trustworthiness Evaluation Framework for Large Language Models 1759466783274 10.1109/ASE63991.2025.00380 Ruoyu Sun University of Alberta, Canada rsun11@ualberta.ca Da Song Mila - Quebec Artificial Intelligence Institute da.song@mila.quebec Jiayang Song Macau University of Science and Technology, China jiayang.song@ieee.org Yuheng Huang The University of Tokyo, Japan yuhenghuang42@g.ecc.u-tokyo.ac.jp Lei ma The University of Tokyo, Japan; University of Alberta, Canada ma.lei@acm.org llm automated evaluation trustworthy interface design As Large Language Models (LLMs) continue to revolutionize Natural Language Processing (NLP) applications, critical concerns about their trustworthiness persist, particularly in safety and robustness. To address these challenges, we introduce TRUSTVIS, an automated evaluation framework that provides a comprehensive assessment of LLM trustworthiness. A key feature of our framework is its interactive user interface, designedto offer intuitive visualizations of trustworthiness metrics. By integrating well-known perturbation methods like AutoDAN andemploying majority voting across various evaluation methods, TRUSTVIS not only provides reliable results but also makes complex evaluation processes accessible to users. Preliminary case studies on models like Vicuna-7b, Llama2-7b, and GPT-3.5 demonstrate the effectiveness of our framework in identifying safety and robustness vulnerabilities, while the interactive interface allows users to explore results in detail, empowering targeted model improvements. Video Link: https://youtu.be/k1TrBqNVg8g",
							"pageNumber": 4081,
							"isPageNumberRoman": false
						},
						{
							"eid": "17idbR0We5U1B2ZmupGxJ6",
							"type": "authorPaper",
							"text": "Metamorphic Testing of Deep Reinforcement Learning Agents with MDPMORPH",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e085/573300e085.pdf",
							"extraLocations": [],
							"authorNames": "Jiapeng Li (Beihang University, China), Zheng Zheng (Beihang University, China), Yuning Xing (University of Auckland, New Zealand), Daixu Ren (Beihang University, China), Steven Cho (University of Auckland, New Zealand), Valerio Terragni (University of Auckland, New Zealand)",
							"abstract": "We present MDPMORPH, a tool for metamorphic testing of Deep Reinforcement Learning (DRL) agents. MDPMORPH is based on the Markov Decision Process (MDP) and targets the core reasoning properties of DRL agents to automatically uncover potential faults. It can generate metamorphic test suites and corresponding mutants directly from the DRL system under test. MDPMORPH uses a subset of the metamorphic test suite and models to train the thresholds of the nine proposed Metamorphic Relations (MRs) using stochastic gradient descent. These MRs are based on the temporal characteristics of the MDP, and the training aims to determine the optimal threshold for each MR. After obtaining the optimal threshold, MDPMORPH leverages the MRs to compare the execution results of different metamorphic test suites on the model under test and reports whether each test passes or fails. Finally, by collecting the execution results, MDPMORPH calculates the mutant detection rate of MR to validate its effectiveness. Experimental results show that MDPMORPH and the proposed MRs are highly effective in automatically detecting seeded faults (mutants).",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Metamorphic Testing of Deep Reinforcement Learning Agents with MDPMORPH 1759215706965 10.1109/ASE63991.2025.00381 Jiapeng Li Beihang University, China jp_li@buaa.edu.cn Zheng Zheng Beihang University, China zhengz@buaa.edu.cn Yuning Xing University of Auckland, New Zealand yxin683@aucklanduni.ac.nz Daixu Ren Beihang University, China rendaixu@buaa.edu.cn Steven Cho University of Auckland, New Zealand scho518@aucklanduni.ac.nz Valerio Terragni University of Auckland, New Zealand v.terragni@auckland.ac.nz se4ai deep reinforcement learning metamorphic testing mutation testing We present MDPMORPH, a tool for metamorphic testing of Deep Reinforcement Learning (DRL) agents. MDPMORPH is based on the Markov Decision Process (MDP) and targets the core reasoning properties of DRL agents to automatically uncover potential faults. It can generate metamorphic test suites and corresponding mutants directly from the DRL system under test. MDPMORPH uses a subset of the metamorphic test suite and models to train the thresholds of the nine proposed Metamorphic Relations (MRs) using stochastic gradient descent. These MRs are based on the temporal characteristics of the MDP, and the training aims to determine the optimal threshold for each MR. After obtaining the optimal threshold, MDPMORPH leverages the MRs to compare the execution results of different metamorphic test suites on the model under test and reports whether each test passes or fails. Finally, by collecting the execution results, MDPMORPH calculates the mutant detection rate of MR to validate its effectiveness. Experimental results show that MDPMORPH and the proposed MRs are highly effective in automatically detecting seeded faults (mutants).",
							"pageNumber": 4085,
							"isPageNumberRoman": false
						},
						{
							"eid": "jfFgMQUs3YKKu2h28PXFt",
							"type": "authorPaper",
							"text": "APIDA-Chat: Structured Synthesis of API Search Dialogues to Bootstrap Conversational Agents",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e089/573300e089.pdf",
							"extraLocations": [],
							"authorNames": "Zachary Eberhart (University of Notre Dame, USA), Collin McMillan (University of Notre Dame, USA)",
							"abstract": "Large-language-model assistants are suitable for explaining popular APIs, yet they falter on niche or proprietary libraries because the multi-turn dialogue data needed for fine-tuning are scarce. We present APIDA-Chat, an open-source pipeline that converts symbolic dialogue-act \"scripts\" into realistic, domain-grounded API Search conversations using a lightweight model for inexpensive training data generation. Phase I pairs a legacy dialogue planner with a high-capability teacher LLM (o4-mini) to synthesize a \"gold set\" of realized dialogues; then, a smaller Llama 3.2 3B student model is fine-tuned on this corpus. Phase II drops the teacher and reuses the same planner with the fine-tuned model, allowing rapid, low-cost synthesis of new dialogues without exposing source code to external services. The fine-tuned student improves BLEU from 0.38 to 0.50 and BERTScore from 0.88 to 0.91 versus the base model while running entirely on a single consumer GPU. All components are modular and publicly released to serve as a conservative baseline for future work. APIDA-Chat is open-sourced at https://github.com/Zeberhart/apida-chat and a video demo is available at https://youtu.be/YqmZBHyGbPs.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 APIDA-Chat: Structured Synthesis of API Search Dialogues to Bootstrap Conversational Agents 1759564021590 10.1109/ASE63991.2025.00382 Zachary Eberhart University of Notre Dame, USA zeberhar@nd.edu Collin McMillan University of Notre Dame, USA cmc@nd.edu api search dialogue management synthetic data generation large language models (llms) Large-language-model assistants are suitable for explaining popular APIs, yet they falter on niche or proprietary libraries because the multi-turn dialogue data needed for fine-tuning are scarce. We present APIDA-Chat, an open-source pipeline that converts symbolic dialogue-act \"scripts\" into realistic, domain-grounded API Search conversations using a lightweight model for inexpensive training data generation. Phase I pairs a legacy dialogue planner with a high-capability teacher LLM (o4-mini) to synthesize a \"gold set\" of realized dialogues; then, a smaller Llama 3.2 3B student model is fine-tuned on this corpus. Phase II drops the teacher and reuses the same planner with the fine-tuned model, allowing rapid, low-cost synthesis of new dialogues without exposing source code to external services. The fine-tuned student improves BLEU from 0.38 to 0.50 and BERTScore from 0.88 to 0.91 versus the base model while running entirely on a single consumer GPU. All components are modular and publicly released to serve as a conservative baseline for future work. APIDA-Chat is open-sourced at https://github.com/Zeberhart/apida-chat and a video demo is available at https://youtu.be/YqmZBHyGbPs.",
							"pageNumber": 4089,
							"isPageNumberRoman": false
						},
						{
							"eid": "nBL3pZShPWmm28fYizkgi",
							"type": "authorPaper",
							"text": "Quirx: A Mutation-Based Framework for Evaluating Prompt Robustness in LLM-Based Software",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e093/573300e093.pdf",
							"extraLocations": [],
							"authorNames": "Souhaila Serbout (University of Zurich)",
							"abstract": "Large Language Models (LLMs) increasingly power critical business processes, yet prompt robustness remains underexplored. Small variations, such as synonym changes or instruction reordering, can cause significant output shifts, undermining reliability in domains like customer service and finance. Existing evaluations rely on ad-hoc manual testing, limiting scalability in production environments. We present Quirx, a mutation-based fuzzing framework for systematically evaluating prompt robustness across LLM providers. Quirx applies tri-dimensional mutations (lexical, semantic, structural), executes them against target models, and measures response consistency via multi-level similarity analysis. It produces robustness scores, reveals failure patterns, and supports informed model selection. We evaluate Quirx on four models (GPT-3.5-turbo, GPT-4o-mini, Claude-3.5-Sonnet, Claude-Sonnet-4) across three tasks. Results show sentiment classification is uniformly robust (1.00), summarization is highly provider-sensitive (0.23\u20130.58) with Claude models 2.5\u00D7 more robust than OpenAI, and SQL generation is consistently strong (0.80\u20131.00). Structural mutations cause 50\u201367% of summarization failures but have minimal effect on other tasks.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Quirx: A Mutation-Based Framework for Evaluating Prompt Robustness in LLM-Based Software 1759514788341 10.1109/ASE63991.2025.00383 Souhaila Serbout University of Zurich souhaila.serbout@uzh.ch Large Language Models Prompt Engineering Software Testing Fuzzing Robustness Evaluation Large Language Models (LLMs) increasingly power critical business processes, yet prompt robustness remains underexplored. Small variations, such as synonym changes or instruction reordering, can cause significant output shifts, undermining reliability in domains like customer service and finance. Existing evaluations rely on ad-hoc manual testing, limiting scalability in production environments. We present Quirx, a mutation-based fuzzing framework for systematically evaluating prompt robustness across LLM providers. Quirx applies tri-dimensional mutations (lexical, semantic, structural), executes them against target models, and measures response consistency via multi-level similarity analysis. It produces robustness scores, reveals failure patterns, and supports informed model selection. We evaluate Quirx on four models (GPT-3.5-turbo, GPT-4o-mini, Claude-3.5-Sonnet, Claude-Sonnet-4) across three tasks. Results show sentiment classification is uniformly robust (1.00), summarization is highly provider-sensitive (0.23\u20130.58) with Claude models 2.5\u00D7 more robust than OpenAI, and SQL generation is consistently strong (0.80\u20131.00). Structural mutations cause 50\u201367% of summarization failures but have minimal effect on other tasks.",
							"pageNumber": 4093,
							"isPageNumberRoman": false
						},
						{
							"eid": "1cUztFLjE641Hvg34mVE3I",
							"type": "authorPaper",
							"text": "Training-Control-as-Code: Towards a Declarative Solution to Control Training",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e097/573300e097.pdf",
							"extraLocations": [],
							"authorNames": "Padmanabha V. Seshadri (IBM Research, India), Harikrishnan Balagopal (IBM Research, India), Mehant Kammakomati (IBM Research, India), Ashok Pon Kumar (IBM Research, India), Dushyant Behl (IBM Research, India)",
							"abstract": "Training-as-a-service platforms facilitate users to deploy pre-configured Generative AI training jobs as batch workloads. The immutability of configuration offers minimal flexibility to dynamically adapt to training progress. Existing approaches invariably involve manually monitoring training progress on a dashboard, and the stop-reconfigure-restart of training does not scale well with number of experiments. Relying on pre-configuration, wastes computational resources and makes debugging of training jobs difficult. We address this gap through our training-control-as-code paradigm, which allows users to run user-defined code to analyze the training state and intervene to flag anomalies and save resource wastage. Our framework TrAC offers a declarative interface to allow for declaring desired control and for reusing it at scale. Using real-world open-source data and models we provide estimates on the savings in time and resource due to TrAC. We also provide demo video: https://youtu.be/RmhBfFjd1oA and code: https://github.com/foundation-model-stack/fms-hf-tuning/blob/main/examples/trainercontroller_configs/Readme.md",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Training-Control-as-Code: Towards a Declarative Solution to Control Training 1760030821956 10.1109/ASE63991.2025.00384 Padmanabha V. Seshadri IBM Research, India seshapad@in.ibm.com Harikrishnan Balagopal IBM Research, India harikrishnan.balagopal@ibm.com Mehant Kammakomati IBM Research, India mehant.kammakomati2@ibm.com Ashok Pon Kumar IBM Research, India ashokponkumar@in.ibm.com Dushyant Behl IBM Research, India dushyantbehl@in.ibm.com generative ai training declarative framework Training-as-a-service platforms facilitate users to deploy pre-configured Generative AI training jobs as batch workloads. The immutability of configuration offers minimal flexibility to dynamically adapt to training progress. Existing approaches invariably involve manually monitoring training progress on a dashboard, and the stop-reconfigure-restart of training does not scale well with number of experiments. Relying on pre-configuration, wastes computational resources and makes debugging of training jobs difficult. We address this gap through our training-control-as-code paradigm, which allows users to run user-defined code to analyze the training state and intervene to flag anomalies and save resource wastage. Our framework TrAC offers a declarative interface to allow for declaring desired control and for reusing it at scale. Using real-world open-source data and models we provide estimates on the savings in time and resource due to TrAC. We also provide demo video: https://youtu.be/RmhBfFjd1oA and code: https://github.com/foundation-model-stack/fms-hf-tuning/blob/main/examples/trainercontroller_configs/Readme.md",
							"pageNumber": 4097,
							"isPageNumberRoman": false
						},
						{
							"eid": "3fT81r9MynYxoQ3RU1bDjx",
							"type": "authorPaper",
							"text": "LLMORPH: Automated Metamorphic Testing of Large Language Models",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e101/573300e101.pdf",
							"extraLocations": [],
							"authorNames": "Steven Cho (University of Auckland, New Zealand), Stefano Ruberto (JRC European Commission, Italy), Valerio Terragni (University of Auckland, New Zealand)",
							"abstract": "Automated testing is essential for evaluating and improving the reliability of Large Language Models (LLMs), yet the lack of automated oracles for verifying output correctness remains a key challenge. We present LLMORPH, an automated testing tool specifically designed for LLMs performing NLP tasks, which leverages Metamorphic Testing (MT) to uncover faulty behaviors without relying on human-labeled data. MT uses Metamorphic Relations (MRs) to generate follow-up inputs from source test input, enabling detection of inconsistencies in model outputs without the need of expensive labelled data. LLMORPH is aimed at researchers and developers who want to evaluate the robustness of LLM-based NLP systems. In this paper, we detail the design, implementation, and practical usage of LLMORPH, demonstrating how it can be easily extended to any LLM, NLP task, and set of MRs. In our evaluation, we applied 36 MRs across four NLP benchmarks, testing three state-of-the-art LLMs: GPT-4, LLAMA3, and HERMES 2. This produced over 561,000 test executions. The results demonstrate LLMORPH's effectiveness in automatically exposing incorrect model behaviors at scale. The tool source code is available at https://github.com/ steven-b-cho/llmorph. A screencast demo is available at https: //youtu.be/sHmqdieCfw4.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 LLMORPH: Automated Metamorphic Testing of Large Language Models 1759450172561 10.1109/ASE63991.2025.00385 Steven Cho University of Auckland, New Zealand steven.cho@auckland.ac.nz Stefano Ruberto JRC European Commission, Italy stefano.ruberto@ec.europa.eu Valerio Terragni University of Auckland, New Zealand v.terragni@auckland.ac.nz large language models metamorphic testing machine learning testing nlp software engineering for ai Automated testing is essential for evaluating and improving the reliability of Large Language Models (LLMs), yet the lack of automated oracles for verifying output correctness remains a key challenge. We present LLMORPH, an automated testing tool specifically designed for LLMs performing NLP tasks, which leverages Metamorphic Testing (MT) to uncover faulty behaviors without relying on human-labeled data. MT uses Metamorphic Relations (MRs) to generate follow-up inputs from source test input, enabling detection of inconsistencies in model outputs without the need of expensive labelled data. LLMORPH is aimed at researchers and developers who want to evaluate the robustness of LLM-based NLP systems. In this paper, we detail the design, implementation, and practical usage of LLMORPH, demonstrating how it can be easily extended to any LLM, NLP task, and set of MRs. In our evaluation, we applied 36 MRs across four NLP benchmarks, testing three state-of-the-art LLMs: GPT-4, LLAMA3, and HERMES 2. This produced over 561,000 test executions. The results demonstrate LLMORPH's effectiveness in automatically exposing incorrect model behaviors at scale. The tool source code is available at https://github.com/ steven-b-cho/llmorph. A screencast demo is available at https: //youtu.be/sHmqdieCfw4.",
							"pageNumber": 4101,
							"isPageNumberRoman": false
						},
						{
							"eid": "lTZrpUXQj3UoEFZD0g8F4",
							"type": "authorPaper",
							"text": "StackPlagger: A System for Identifying AI-Code Plagiarism on Stack Overflow",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e105/573300e105.pdf",
							"extraLocations": [],
							"authorNames": "Aman Swaraj (Indian Institute of Technology Roorkee, India), Harsh Goyal (Indian Institute of Technology Roorkee, India), Sumit Chadgal (Indian Institute of Technology Roorkee, India), Sandeep Kumar (Indian Institute of Technology Roorkee, India)",
							"abstract": "Identifying AI code plagiarism on technical forums like Stack Overflow (SO) is critical, as it can directly impact the platform's trust and credibility. While previous studies have explored AI-generated code detection, they have focused on long, standalone samples from repositories and competitions. In contrast, SO snippets are often short, fragmented, and context-specific, which can make detection more challenging. Furthermore, existing methods have also not adequately addressed the concern of obfuscated or adversarially prompted code that are crafted to mimic human style and evade detection. To address these gaps, we first introduce a curated dataset of 8000 SO-ChatGPT snippet pairs generated using multiple adversarial prompts. While earlier methods solely relied on pre-trained models, we propose an ensemble approach combining stylometric features of code along with the pre-trained embeddings to improve detection performance. Finally, we deploy our fine-tuned model as a Google Chrome extension called 'StackPlagger', which can flag AI-generated code in SO answers and display AI confidence scores. Video demonstration and the associated artifacts of our tool can be found at https://youtu.be/6O9Urp2mvbI and https://github.com/harsh-g1/StackPlagger, respectively.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 StackPlagger: A System for Identifying AI-Code Plagiarism on Stack Overflow 1759293373511 10.1109/ASE63991.2025.00386 Aman Swaraj Indian Institute of Technology Roorkee, India aman_s@cs.iitr.ac.in Harsh Goyal Indian Institute of Technology Roorkee, India harsh_g1@cs.iitr.ac.in Sumit Chadgal Indian Institute of Technology Roorkee, India sumit_c@cs.iitr.ac.in Sandeep Kumar Indian Institute of Technology Roorkee, India sandeep.garg@cs.iitr.ac.in ai-code detection ai plagiarism chrome extension code stylometry code llms prompt engineering Identifying AI code plagiarism on technical forums like Stack Overflow (SO) is critical, as it can directly impact the platform's trust and credibility. While previous studies have explored AI-generated code detection, they have focused on long, standalone samples from repositories and competitions. In contrast, SO snippets are often short, fragmented, and context-specific, which can make detection more challenging. Furthermore, existing methods have also not adequately addressed the concern of obfuscated or adversarially prompted code that are crafted to mimic human style and evade detection. To address these gaps, we first introduce a curated dataset of 8000 SO-ChatGPT snippet pairs generated using multiple adversarial prompts. While earlier methods solely relied on pre-trained models, we propose an ensemble approach combining stylometric features of code along with the pre-trained embeddings to improve detection performance. Finally, we deploy our fine-tuned model as a Google Chrome extension called 'StackPlagger', which can flag AI-generated code in SO answers and display AI confidence scores. Video demonstration and the associated artifacts of our tool can be found at https://youtu.be/6O9Urp2mvbI and https://github.com/harsh-g1/StackPlagger, respectively.",
							"pageNumber": 4105,
							"isPageNumberRoman": false
						},
						{
							"eid": "5DwDVcLoKY2qmWvGLmUimp",
							"type": "authorPaper",
							"text": "CLARA: A Developer's Companion for Code Comprehension and Analysis",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e109/573300e109.pdf",
							"extraLocations": [],
							"authorNames": "Ahmed Adnan (Bangladesh University of Business and Technology (BUBT), Bangladesh), Mushfiqur Rahman (Bangladesh University of Business and Technology (BUBT), Bangladesh), Saad Sakib Noor (University of Dhaka, Bangladesh), Kazi Sakib (University of Dhaka, Bangladesh)",
							"abstract": "Code comprehension and analysis of open-source project codebases is a task frequently performed by developers and researchers. However, existing tools that practitioners use for assistance with such tasks often require prior project setup, lack context-awareness, and involve significant manual effort. To address this, we present CLARA, a browser extension that utilizes state-of-the-art inference model to assist developers and researchers in: (i) comprehending code files and code fragments, (ii) code refactoring, and (iii) code quality attribute detection. We qualitatively evaluated CLARA\u2019s inference model using existing datasets and methodology, and performed a comprehensive user study with 10 developers and academic researchers to assess its usability and usefulness. The results show that CLARA is useful, accurate, and practical in code comprehension and analysis tasks. CLARA is an open-source tool available at github.com/clara_tool_demo. A video showing the full capabilities of CLARA can be found at youtube.com/clara_demo_video.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 CLARA: A Developer's Companion for Code Comprehension and Analysis 1759441709214 10.1109/ASE63991.2025.00387 Ahmed Adnan Bangladesh University of Business and Technology (BUBT), Bangladesh ahmedadnan@bubt.edu.bd Mushfiqur Rahman Bangladesh University of Business and Technology (BUBT), Bangladesh Mushfiqur.Rahman@bubt.edu.bd Saad Sakib Noor University of Dhaka, Bangladesh bsse1122@iit.du.ac.bd Kazi Sakib University of Dhaka, Bangladesh sakib@iit.du.ac.bd n/a Code comprehension and analysis of open-source project codebases is a task frequently performed by developers and researchers. However, existing tools that practitioners use for assistance with such tasks often require prior project setup, lack context-awareness, and involve significant manual effort. To address this, we present CLARA, a browser extension that utilizes state-of-the-art inference model to assist developers and researchers in: (i) comprehending code files and code fragments, (ii) code refactoring, and (iii) code quality attribute detection. We qualitatively evaluated CLARA\u2019s inference model using existing datasets and methodology, and performed a comprehensive user study with 10 developers and academic researchers to assess its usability and usefulness. The results show that CLARA is useful, accurate, and practical in code comprehension and analysis tasks. CLARA is an open-source tool available at github.com/clara_tool_demo. A video showing the full capabilities of CLARA can be found at youtube.com/clara_demo_video.",
							"pageNumber": 4109,
							"isPageNumberRoman": false
						},
						{
							"eid": "1zxr9ppWGcHjoDDNdyxgYp",
							"type": "authorPaper",
							"text": "PROXiFY: A Bytecode Analysis Tool for Detecting and Classifying Proxy Contracts in Ethereum Smart Contracts",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e113/573300e113.pdf",
							"extraLocations": [],
							"authorNames": "Ilham Qasse (Reykjavik University, Iceland), Mohammad  Hamdaqa (Polytechnique Montreal, Canada), Bj\u00F6rn \u00DE\u00F3r  J\u00F3nsson (Reykjavik University, Iceland)",
							"abstract": "As Ethereum smart contracts grow in complexity, upgrades are necessary but challenging due to their immutable nature. Proxy contracts enable upgrades without changing contract state, but current detection approaches often rely on source code or transaction history and fail to detect inactive proxies. Detecting these proxies is critical because dormant upgrade paths can be reactivated, introducing risks and potential attacks. We introduce PROXiFY, a lightweight bytecode-based tool that detects and classifies proxy contracts, including inactive ones, without requiring Ethereum nodes, source code, or customized EVMs. PROXiFY achieves a precision of 98.6% and recall of 97.1% on a high-confidence benchmark dataset. A demonstration of PROXiFY can be viewed at https://youtu.be/FuYs22_vosk https://youtu.be/FuYs22\\_vosk.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 PROXiFY: A Bytecode Analysis Tool for Detecting and Classifying Proxy Contracts in Ethereum Smart Contracts 1759512290602 10.1109/ASE63991.2025.00388 Ilham Qasse Reykjavik University, Iceland ilham20@ru.is Mohammad Hamdaqa Polytechnique Montreal, Canada mhamdaqa@polymtl.ca Bj\u00F6rn \u00DE\u00F3r J\u00F3nsson Reykjavik University, Iceland bjorn@ru.is proxy contracts smart contracts bytecode analysis immutability software maintenance As Ethereum smart contracts grow in complexity, upgrades are necessary but challenging due to their immutable nature. Proxy contracts enable upgrades without changing contract state, but current detection approaches often rely on source code or transaction history and fail to detect inactive proxies. Detecting these proxies is critical because dormant upgrade paths can be reactivated, introducing risks and potential attacks. We introduce PROXiFY, a lightweight bytecode-based tool that detects and classifies proxy contracts, including inactive ones, without requiring Ethereum nodes, source code, or customized EVMs. PROXiFY achieves a precision of 98.6% and recall of 97.1% on a high-confidence benchmark dataset. A demonstration of PROXiFY can be viewed at https://youtu.be/FuYs22_vosk https://youtu.be/FuYs22\\_vosk.",
							"pageNumber": 4113,
							"isPageNumberRoman": false
						},
						{
							"eid": "5BDkc9yZKSsu3tR0x2ojQ2",
							"type": "authorPaper",
							"text": "evalSmarT: An LLM-Based Framework for Evaluating Smart Contract Generated Comments",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e117/573300e117.pdf",
							"extraLocations": [],
							"authorNames": "Fatou Ndiaye Mbodji (SnT-University of Luxembourg), Mame Marieme C. Sougoufara (Universit\u00E9 Cheikh Anta Diop), Wendkuuni A. M. Christian  Ouedraogo (SnT-University of Luxembourg), Alioune  Diallo (SnT-University of Luxembourg), Kui  Liu (Huawei), Jacques Klein (SnT-University of Luxembourg), Tegawend\u00E9 F.  Bissyande (SnT-University of Luxembourg)",
							"abstract": "Smart contract comment generation has gained traction as a means to improve code comprehension and maintainability in blockchain systems. However, evaluating the quality of generated comments remains a challenge. Traditional metrics such as BLEU and ROUGE fail to capture domain-specific nuances, while human evaluation is costly and unscalable. In this paper, we present evalSmarT, a modular and extensible framework that leverages large language models (LLMs) as evaluators. The system supports over 400 evaluator configurations by combining approximately 40 LLMs with 10 prompting strategies. We demonstrate its application in benchmarking comment generation tools and selecting the most informative outputs. Our results show that prompt design significantly impacts alignment with human judgment, and that LLM-based evaluation offers a scalable and semantically rich alternative to existing methods. Video Demo: https://youtu.be/HXS Yiszoz4 Code and Data: https://anonymous.4open.science/r/SC code summarization-4653",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 evalSmarT: An LLM-Based Framework for Evaluating Smart Contract Generated Comments 1758891698110 10.1109/ASE63991.2025.00389 Fatou Ndiaye Mbodji SnT-University of Luxembourg fatou.mbodji@uni.lu Mame Marieme C. Sougoufara Universit\u00E9 Cheikh Anta Diop mamemariemeciss.sougoufara@ucad.edu.sn Wendkuuni A. M. Christian Ouedraogo SnT-University of Luxembourg wendkuuni.ouedraogo@uni.lu Alioune Diallo SnT-University of Luxembourg alioune.diallo@uni.lu Kui Liu Huawei kui.liu@huawei.com Jacques Klein SnT-University of Luxembourg jacques.klein@uni.lu Tegawend\u00E9 F. Bissyande SnT-University of Luxembourg tegawende.bissyande@uni.lu smart contracts comment generation large language models (llms) llm as judge Smart contract comment generation has gained traction as a means to improve code comprehension and maintainability in blockchain systems. However, evaluating the quality of generated comments remains a challenge. Traditional metrics such as BLEU and ROUGE fail to capture domain-specific nuances, while human evaluation is costly and unscalable. In this paper, we present evalSmarT, a modular and extensible framework that leverages large language models (LLMs) as evaluators. The system supports over 400 evaluator configurations by combining approximately 40 LLMs with 10 prompting strategies. We demonstrate its application in benchmarking comment generation tools and selecting the most informative outputs. Our results show that prompt design significantly impacts alignment with human judgment, and that LLM-based evaluation offers a scalable and semantically rich alternative to existing methods. Video Demo: https://youtu.be/HXS Yiszoz4 Code and Data: https://anonymous.4open.science/r/SC code summarization-4653",
							"pageNumber": 4117,
							"isPageNumberRoman": false
						}
					],
					"pageNumber": "",
					"isPageNumberRoman": false,
					"chair": null
				},
				{
					"class": "SD",
					"type": "SD_SESSION",
					"title": "Student Research Competition",
					"lineItems": [
						{
							"eid": "FdyPPQkhPEbUdXINU9K3w",
							"type": "authorPaper",
							"text": "Verification and Classification of Exploits for Node.js Vulnerabilities",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e121/573300e121.pdf",
							"extraLocations": [],
							"authorNames": "Sungmin Park (Korea University)",
							"abstract": "Vulnerabilities in the Node.js ecosystem pose serious security threats. Generating exploits for such vulnerabilities is a critical and essential step for fixing the vulnerabilities and understanding attack vectors. To address this need, prior work has proposed a range of methods, including static analysis approaches, dynamic analysis approaches, and LLM-based techniques. However, most studies verify only at the end of execution whether the expected effect of each vulnerability has occurred. This approach does not confirm whether the exploit actually reaches the target vulnerable sinks. As a result, it may fail to exercise the intended vulnerability or inadvertently trigger a different sink. In this study, we propose a method for validating and classifying exploits related to Node.js vulnerabilities. Our method instruments sink APIs and related objects prior to execution to capture sink APIs calls and their arguments when a sink is triggered at runtime. This lets us verify that an exploit reaches the intended sink and classify exploits by the point at which the sink is triggered.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Verification and Classification of Exploits for Node.js Vulnerabilities 1758685033104 10.1109/ASE63991.2025.00390 Sungmin Park Korea University ryan040@korea.ac.kr exploit verification vulnerability Vulnerabilities in the Node.js ecosystem pose serious security threats. Generating exploits for such vulnerabilities is a critical and essential step for fixing the vulnerabilities and understanding attack vectors. To address this need, prior work has proposed a range of methods, including static analysis approaches, dynamic analysis approaches, and LLM-based techniques. However, most studies verify only at the end of execution whether the expected effect of each vulnerability has occurred. This approach does not confirm whether the exploit actually reaches the target vulnerable sinks. As a result, it may fail to exercise the intended vulnerability or inadvertently trigger a different sink. In this study, we propose a method for validating and classifying exploits related to Node.js vulnerabilities. Our method instruments sink APIs and related objects prior to execution to capture sink APIs calls and their arguments when a sink is triggered at runtime. This lets us verify that an exploit reaches the intended sink and classify exploits by the point at which the sink is triggered.",
							"pageNumber": 4121,
							"isPageNumberRoman": false
						},
						{
							"eid": "28zkvSqKXBIWPKuABb5DDn",
							"type": "authorPaper",
							"text": "First-Order Quantified Separator in Alloy Analyzer",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e124/573300e124.pdf",
							"extraLocations": [],
							"authorNames": "One An (University of Pennsylvania, USA)",
							"abstract": "First-Order Logic (FOL) is powerful for specifying system properties, but its complexity hinders adoption. To address this, we present Folloy, a novel tool that synthesizes FOL specifications from examples. Our core contribution is a new approach that translates the specification learning problem into a constraint satisfaction problem by declaratively modeling FOL's syntax and semantics in the Alloy Analyzer. This method is highly expressive, allowing for the synthesis of non-prenex formulas and user-defined syntactic constraints. By leveraging a Max-SAT solver, Folloy also guarantees that the learned formula is minimal in size. We evaluate our tool on a suite of benchmark problems and show that while this general approach is slower than a specialized algorithm, it solves a broader class of problems, establishing a trade-off between performance and expressive power.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 First-Order Quantified Separator in Alloy Analyzer 1760077576025 10.1109/ASE63991.2025.00391 One An University of Pennsylvania, USA onean@sas.upenn.edu invariant inference first-order logic Alloy Analyzer First-Order Logic (FOL) is powerful for specifying system properties, but its complexity hinders adoption. To address this, we present Folloy, a novel tool that synthesizes FOL specifications from examples. Our core contribution is a new approach that translates the specification learning problem into a constraint satisfaction problem by declaratively modeling FOL's syntax and semantics in the Alloy Analyzer. This method is highly expressive, allowing for the synthesis of non-prenex formulas and user-defined syntactic constraints. By leveraging a Max-SAT solver, Folloy also guarantees that the learned formula is minimal in size. We evaluate our tool on a suite of benchmark problems and show that while this general approach is slower than a specialized algorithm, it solves a broader class of problems, establishing a trade-off between performance and expressive power.",
							"pageNumber": 4124,
							"isPageNumberRoman": false
						},
						{
							"eid": "dDp1Rkk1OtRfY1eYJEZLr",
							"type": "authorPaper",
							"text": "Understanding Uncertainty In LLMs",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e127/573300e127.pdf",
							"extraLocations": [],
							"authorNames": "Chandan Kumar Sah (Beihang University, China)",
							"abstract": "Large Language Models (LLMs) have revolutionized AI, yet their inherent uncertainties pose significant challenges to reliable deployment. This paper presents a comprehensive systematic review of uncertainty in LLMs, bridging theoretical foundations and cutting-edge methodologies. We analyze over 45 papers from top venues\u2014including ASE, NeurIPS, ICML, and Nature\u2014to trace the evolution of uncertainty quantification (UQ). We categorize uncertainty into aleatoric and epistemic types, detailing probabilistic modeling, confidence estimation, and calibration techniques. Through illustrative case studies in high-stakes domains such as medical diagnosis and code generation, we demonstrate UQ's pivotal role in enhancing reliability. We further discuss limitations, ethical considerations, and future directions, emphasizing the need for granular interpretability and human-AI collaboration. This work advances the understanding of LLM uncertainty to enable safer, trustworthy, and responsible real-world integration.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Understanding Uncertainty In LLMs 1757752809483 10.1109/ASE63991.2025.00392 Chandan Kumar Sah Beihang University, China sahchandan98@buaa.edu.cn large language models uncertainty natural language processing Large Language Models (LLMs) have revolutionized AI, yet their inherent uncertainties pose significant challenges to reliable deployment. This paper presents a comprehensive systematic review of uncertainty in LLMs, bridging theoretical foundations and cutting-edge methodologies. We analyze over 45 papers from top venues\u2014including ASE, NeurIPS, ICML, and Nature\u2014to trace the evolution of uncertainty quantification (UQ). We categorize uncertainty into aleatoric and epistemic types, detailing probabilistic modeling, confidence estimation, and calibration techniques. Through illustrative case studies in high-stakes domains such as medical diagnosis and code generation, we demonstrate UQ's pivotal role in enhancing reliability. We further discuss limitations, ethical considerations, and future directions, emphasizing the need for granular interpretability and human-AI collaboration. This work advances the understanding of LLM uncertainty to enable safer, trustworthy, and responsible real-world integration.",
							"pageNumber": 4127,
							"isPageNumberRoman": false
						},
						{
							"eid": "1Sey4PIaaFUScKGBwIMGCt",
							"type": "authorPaper",
							"text": "Dynamic Testing of GUI Exercises in Headless Environments",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e130/573300e130.pdf",
							"extraLocations": [],
							"authorNames": "Benjamin Schmitz (Technical University of Munich, Germany)",
							"abstract": "Testing Graphical User Interface applications in non-graphical environments is challenging, especially for auto-graders in large-scale programming courses, where traditional approaches often depend on a graphical operating system. This paper presents a headless testing approach that simulates user interactions and verifies application state. A reference implementation demonstrates that interactive applications can be assessed reliably in headless settings. The approach ran in a large-scale introductory programming course, assessing 1,020 submissions without a graphical subsystem. A case study confirms the system meets key requirements and delivers reproducible, scalable, and pedagogically valuable feedback.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Dynamic Testing of GUI Exercises in Headless Environments 1758879868475 10.1109/ASE63991.2025.00393 Benjamin Schmitz Technical University of Munich, Germany schmitz@tum.de GUI testing automated grading headless testing JavaFX TestFX computer science education Testing Graphical User Interface applications in non-graphical environments is challenging, especially for auto-graders in large-scale programming courses, where traditional approaches often depend on a graphical operating system. This paper presents a headless testing approach that simulates user interactions and verifies application state. A reference implementation demonstrates that interactive applications can be assessed reliably in headless settings. The approach ran in a large-scale introductory programming course, assessing 1,020 submissions without a graphical subsystem. A case study confirms the system meets key requirements and delivers reproducible, scalable, and pedagogically valuable feedback.",
							"pageNumber": 4130,
							"isPageNumberRoman": false
						},
						{
							"eid": "3NOGFO3ErkgZhOsvKF0mt7",
							"type": "authorPaper",
							"text": "Detecting Vulnerabilities from Issue Reports for Internet-of-Things",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e133/573300e133.pdf",
							"extraLocations": [],
							"authorNames": "Sogol Masoumzadeh (McGill University, Canada)",
							"abstract": "Timely identification of issue reports reflecting software vulnerabilities is crucial, particularly for Internet-of-Things (IoT) where analysis is slower than non-IoT systems. While Machine Learning (ML) and Large Language Models (LLMs) detect vulnerability-indicating issues in non-IoT systems, their IoT use remains unexplored. We are the first to tackle this problem by proposing two approaches: (1) combining ML and LLMs with Natural Language Processing (NLP) techniques to detect vulnerability-indicating issues of 21 Eclipse IoT projects and (2) fine-tuning a pre-trained BERT Masked Language Model (MLM) on 11,000 GitHub issues for classifying vulnerability-indicating issues. Our best performance belongs to a Support Vector Machine (SVM) trained on BERT NLP features, achieving an Area Under the receiver operator characteristic Curve (AUC) of 0.65. The fine-tuned BERT achieves 0.26 accuracy, emphasizing the importance of exposing all data during training. Our contributions set the stage for accurately detecting IoT vulnerabilities from issue reports, similar to non-IoT systems.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Detecting Vulnerabilities from Issue Reports for Internet-of-Things 1758762502470 10.1109/ASE63991.2025.00394 Sogol Masoumzadeh McGill University, Canada sogol.masoumzadeh@mail.mcgill.ca vulnerabilities issue trackers iot machine learning fine-tuning Timely identification of issue reports reflecting software vulnerabilities is crucial, particularly for Internet-of-Things (IoT) where analysis is slower than non-IoT systems. While Machine Learning (ML) and Large Language Models (LLMs) detect vulnerability-indicating issues in non-IoT systems, their IoT use remains unexplored. We are the first to tackle this problem by proposing two approaches: (1) combining ML and LLMs with Natural Language Processing (NLP) techniques to detect vulnerability-indicating issues of 21 Eclipse IoT projects and (2) fine-tuning a pre-trained BERT Masked Language Model (MLM) on 11,000 GitHub issues for classifying vulnerability-indicating issues. Our best performance belongs to a Support Vector Machine (SVM) trained on BERT NLP features, achieving an Area Under the receiver operator characteristic Curve (AUC) of 0.65. The fine-tuned BERT achieves 0.26 accuracy, emphasizing the importance of exposing all data during training. Our contributions set the stage for accurately detecting IoT vulnerabilities from issue reports, similar to non-IoT systems.",
							"pageNumber": 4133,
							"isPageNumberRoman": false
						}
					],
					"pageNumber": "",
					"isPageNumberRoman": false,
					"chair": null
				},
				{
					"class": "SD",
					"type": "SD_SESSION",
					"title": "Doctoral Symposium",
					"lineItems": [
						{
							"eid": "5Nf80ATL05fXxjGypisQ9H",
							"type": "authorPaper",
							"text": "Human-Centered Evaluation of REST API Fuzzing Tools: Bridging Academia and Industry",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e136/573300e136.pdf",
							"extraLocations": [],
							"authorNames": "Fanny Febriani Susilo (Kristiania University of Applied Sciences, Norway)",
							"abstract": "As software systems grow in complexity\u2014especially in cloud-based microservice architectures, automated testing has become crucial for reliability and security. While academic REST API fuzzing tools (e.g., EvoMaster, Schemathesis) show strong fault detection, their adoption in industry is limited due to insufficient human-centered evaluation focusing on usability, learnability, and integration. This PhD project will address the gap through a mixed-methods, human-centered evaluation approach. Phase 1 will review current empirical methods in automated testing. Phase 2 will run controlled lab studies with students to evaluate tool usability and cognitive load. Phase 3 will bring the evaluation to real-world industrial settings. By triangulating technical performance with cognitive, behavioral, and perceptual data, this project aims to foster more usable and effective testing tools. It will contribute empirical methods and design recommendations to align academic advancements with real-world development needs.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Human-Centered Evaluation of REST API Fuzzing Tools: Bridging Academia and Industry 1758889135955 10.1109/ASE63991.2025.00395 Fanny Febriani Susilo Kristiania University of Applied Sciences, Norway fanny.susilo@kristiania.no fuzzing automated testing human factors empirical software engineering human computer interaction As software systems grow in complexity\u2014especially in cloud-based microservice architectures, automated testing has become crucial for reliability and security. While academic REST API fuzzing tools (e.g., EvoMaster, Schemathesis) show strong fault detection, their adoption in industry is limited due to insufficient human-centered evaluation focusing on usability, learnability, and integration. This PhD project will address the gap through a mixed-methods, human-centered evaluation approach. Phase 1 will review current empirical methods in automated testing. Phase 2 will run controlled lab studies with students to evaluate tool usability and cognitive load. Phase 3 will bring the evaluation to real-world industrial settings. By triangulating technical performance with cognitive, behavioral, and perceptual data, this project aims to foster more usable and effective testing tools. It will contribute empirical methods and design recommendations to align academic advancements with real-world development needs.",
							"pageNumber": 4136,
							"isPageNumberRoman": false
						},
						{
							"eid": "3OcoqwyfaLeScBaZkNN2QW",
							"type": "authorPaper",
							"text": "Testing Autonomous Driving Systems Through Blind-Spot Guided Fuzzing",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e140/573300e140.pdf",
							"extraLocations": [],
							"authorNames": "Sali Moussa (Chang'an University, China)",
							"abstract": "Autonomous Driving Systems (ADS) must reliably perceive and react to complex environments, even when sensor blind spots obscure critical objects. While existing testing methods often focus on dynamic interactions, they significantly underestimate safety risks arising from both dynamic occlusions (e.g., vehicles) and persistent static occlusions (e.g., buildings). This research proposal introduces a novel, unified framework for occlusion-aware ADS testing. We present Blind-Spot Guided Fuzzing, a technique that systematically generates critical test scenarios by leveraging Large Language Models (LLMs) to synthesize realistic seeds from accident reports and employs multi-objective optimization to evolve them. This approach is implemented in our Occlusion-Sensitive Fuzzing (OS-Fuzz) framework, which encompasses two specialized modules: BlindSpotFuzz (BSF) for dynamic occlusions and StaticOccluFuzz (SOF) for static environmental occlusions that persistently hide Vulnerable Road Users. At its core, OS-Fuzz integrates a generalized occlusion model and innovative metrics to guide test generation and quantify the exploration of obscured inputs. Preliminary results against Apollo show BSF identifies over 50% more blind-spot-related collisions. Our comprehensive evaluation plan will benchmark OS-Fuzz against state-of-the-art techniques, rigorously analyzing the relative impact of static versus dynamic occlusions. This research aims to significantly enhance ADS safety by incorporating the critical dimension of sensor and environmental limitations into automated testing.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Testing Autonomous Driving Systems Through Blind-Spot Guided Fuzzing 1759377358040 10.1109/ASE63991.2025.00396 Sali Moussa Chang'an University, China musasali@chd.edu.cn software testing autonomous driving system fuzzing Autonomous Driving Systems (ADS) must reliably perceive and react to complex environments, even when sensor blind spots obscure critical objects. While existing testing methods often focus on dynamic interactions, they significantly underestimate safety risks arising from both dynamic occlusions (e.g., vehicles) and persistent static occlusions (e.g., buildings). This research proposal introduces a novel, unified framework for occlusion-aware ADS testing. We present Blind-Spot Guided Fuzzing, a technique that systematically generates critical test scenarios by leveraging Large Language Models (LLMs) to synthesize realistic seeds from accident reports and employs multi-objective optimization to evolve them. This approach is implemented in our Occlusion-Sensitive Fuzzing (OS-Fuzz) framework, which encompasses two specialized modules: BlindSpotFuzz (BSF) for dynamic occlusions and StaticOccluFuzz (SOF) for static environmental occlusions that persistently hide Vulnerable Road Users. At its core, OS-Fuzz integrates a generalized occlusion model and innovative metrics to guide test generation and quantify the exploration of obscured inputs. Preliminary results against Apollo show BSF identifies over 50% more blind-spot-related collisions. Our comprehensive evaluation plan will benchmark OS-Fuzz against state-of-the-art techniques, rigorously analyzing the relative impact of static versus dynamic occlusions. This research aims to significantly enhance ADS safety by incorporating the critical dimension of sensor and environmental limitations into automated testing.",
							"pageNumber": 4140,
							"isPageNumberRoman": false
						},
						{
							"eid": "6ZxQ7rDEZrWMltRNB0xFPj",
							"type": "authorPaper",
							"text": "Detecting and Mitigating Inconsistencies Between Code, Documentation and Tests",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e144/573300e144.pdf",
							"extraLocations": [],
							"authorNames": "Tobias Kiecker (Humboldt-Universit\u00E4t zu Berlin)",
							"abstract": "Inconsistencies between different software artifacts, such as source code, documentation, and tests, are a common and long-standing problem in software engineering. These misalignments can degrade software quality, slow down development, and hinder maintenance. Each of these artifacts provides a distinct yet overlapping perspective of the same software behavior, forming a triangular relationship in which any one artifact can, in principle, be used to regenerate the others. In this PhD project, we aim to exploit these relationships through regeneration-based techniques to detect and ultimately mitigate inconsistencies across software artifacts. The approach focuses on building an SE-tool that leverages original and regenerated versions of artifacts to triangulate inconsistencies and improve reliability through cross-validation. A particular emphasis is placed on reducing false positives, ensuring that reported issues are trustworthy and actionable, especially when presented to developers in real-world projects.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Detecting and Mitigating Inconsistencies Between Code, Documentation and Tests 1759478156055 10.1109/ASE63991.2025.00397 Tobias Kiecker Humboldt-Universit\u00E4t zu Berlin tobias.kiecker@hu-berlin.de documentation inconsistencies test generation code generation llm Inconsistencies between different software artifacts, such as source code, documentation, and tests, are a common and long-standing problem in software engineering. These misalignments can degrade software quality, slow down development, and hinder maintenance. Each of these artifacts provides a distinct yet overlapping perspective of the same software behavior, forming a triangular relationship in which any one artifact can, in principle, be used to regenerate the others. In this PhD project, we aim to exploit these relationships through regeneration-based techniques to detect and ultimately mitigate inconsistencies across software artifacts. The approach focuses on building an SE-tool that leverages original and regenerated versions of artifacts to triangulate inconsistencies and improve reliability through cross-validation. A particular emphasis is placed on reducing false positives, ensuring that reported issues are trustworthy and actionable, especially when presented to developers in real-world projects.",
							"pageNumber": 4144,
							"isPageNumberRoman": false
						},
						{
							"eid": "34X4aHgnTeZMasyv3vQfqn",
							"type": "authorPaper",
							"text": "Secure Transaction Semantics: Analysis, Vulnerability Detection, and Attack Modeling",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e148/573300e148.pdf",
							"extraLocations": [],
							"authorNames": "Yixuan Liu (Nanyang Technical University, Singapore)",
							"abstract": "Blockchain transactions are often interpreted by off-chain systems through call traces, event logs, and storage modifications. However, these artifacts can diverge from the actual on-chain execution due to semantic mismatches caused by reverts or misleading logs. Existing tools largely assume consistency between observable effects and final state, overlooking semantic mismatches. We present a semantic framework for smart contract security analysis that models and leverages transaction-level semantics to detect vulnerabilities, synthesize attacks, and explain off-chain inconsistencies. Our approach identifies mismatches between real execution effects and intent-oblivious interpretations by off-chain systems. We plan to implement three tools: PEventCatcher for detecting log forgery vulnerabilities, RollGain for synthesizing rollback-based state-reverting attacks, and DeepTx for real-time intent detection.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Secure Transaction Semantics: Analysis, Vulnerability Detection, and Attack Modeling 1759228173116 10.1109/ASE63991.2025.00398 Yixuan Liu Nanyang Technical University, Singapore liuy0255@e.ntu.edu.sg blockchain security smart contracts transaction semantics Blockchain transactions are often interpreted by off-chain systems through call traces, event logs, and storage modifications. However, these artifacts can diverge from the actual on-chain execution due to semantic mismatches caused by reverts or misleading logs. Existing tools largely assume consistency between observable effects and final state, overlooking semantic mismatches. We present a semantic framework for smart contract security analysis that models and leverages transaction-level semantics to detect vulnerabilities, synthesize attacks, and explain off-chain inconsistencies. Our approach identifies mismatches between real execution effects and intent-oblivious interpretations by off-chain systems. We plan to implement three tools: PEventCatcher for detecting log forgery vulnerabilities, RollGain for synthesizing rollback-based state-reverting attacks, and DeepTx for real-time intent detection.",
							"pageNumber": 4148,
							"isPageNumberRoman": false
						},
						{
							"eid": "4dQB0y8dhBIQzojWNmKZF2",
							"type": "authorPaper",
							"text": "Improving Quality of LLM Code Generation in Low-Resource Programming Languages via Uncertainty Estimation",
							"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e152/573300e152.pdf",
							"extraLocations": [],
							"authorNames": "Georgii Andriushchenko (Innopolis University, Russia)",
							"abstract": "Large language models for source code (Code LLMs) demonstrate great performance on high-resource programming languages (HRPLs) but struggle with low-resource ones (LRPLs). Previous studies have improved LLM performance on LRPLs by continued training or tokenizer adaptation. However, they require costly data and can cause catastrophic forgetting. This paper proposes to address the poor performance of LLMs on LRPLs using uncertainty estimation (UE). UE methods have advanced LLM performance on natural language tasks, but are underexplored in source code settings. The research may provide three contributions: (1) a new code generation benchmark evaluating not only functional correctness but also readability, efficiency, and idiomatic style across Python, Java, Racket, and Elixir; (2) a new benchmark for evaluating uncertainty estimation when generating code; and (3) methods to improve LRPL code generation by leveraging UE. The methods utilizing UE include filtering synthetic training data by low uncertainty, an UE-driven curriculum learning strategy, uncertainty-aware decoding, and using uncertainty as an RL reward in alignment. The research may provide a comprehensive evaluation of uncertainty in code models, demonstrate that UE can improve LRPL generation, and open-source release of benchmarks and models as outcomes.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE) ASE 2025 Improving Quality of LLM Code Generation in Low-Resource Programming Languages via Uncertainty Estimation 1759339710837 10.1109/ASE63991.2025.00399 Georgii Andriushchenko Innopolis University, Russia georgyandryuschenko@gmail.com large language models code generation low-resource programming languages uncertainty estimation Large language models for source code (Code LLMs) demonstrate great performance on high-resource programming languages (HRPLs) but struggle with low-resource ones (LRPLs). Previous studies have improved LLM performance on LRPLs by continued training or tokenizer adaptation. However, they require costly data and can cause catastrophic forgetting. This paper proposes to address the poor performance of LLMs on LRPLs using uncertainty estimation (UE). UE methods have advanced LLM performance on natural language tasks, but are underexplored in source code settings. The research may provide three contributions: (1) a new code generation benchmark evaluating not only functional correctness but also readability, efficiency, and idiomatic style across Python, Java, Racket, and Elixir; (2) a new benchmark for evaluating uncertainty estimation when generating code; and (3) methods to improve LRPL code generation by leveraging UE. The methods utilizing UE include filtering synthetic training data by low uncertainty, an UE-driven curriculum learning strategy, uncertainty-aware decoding, and using uncertainty as an RL reward in alignment. The research may provide a comprehensive evaluation of uncertainty in code models, demonstrate that UE can improve LRPL generation, and open-source release of benchmarks and models as outcomes.",
							"pageNumber": 4152,
							"isPageNumberRoman": false
						}
					],
					"pageNumber": "",
					"isPageNumberRoman": false,
					"chair": null
				}
			]
		},
		{
			"title": "2025 40th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW)",
			"acronym": "ASEW",
			"year": 2025,
			"frontMatter": [
				{
					"class": "FM",
					"type": "FM_TITLE_PAGE_I",
					"text": "Title Page i",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300z001/850300z001.pdf",
					"extraLocations": [],
					"pageNumber": 1,
					"isPageNumberRoman": true
				},
				{
					"class": "FM",
					"type": "FM_TITLE_PAGE_III",
					"text": "Title Page iii",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300z003/850300z003.pdf",
					"extraLocations": [],
					"pageNumber": 3,
					"isPageNumberRoman": true
				},
				{
					"class": "FM",
					"type": "FM_COPYRIGHT_PAGE",
					"text": "Copyright Page",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300z004/850300z004.pdf",
					"extraLocations": [],
					"pageNumber": 4,
					"isPageNumberRoman": true
				},
				{
					"class": "FM",
					"type": "FM_TABLE_OF_CONTENTS",
					"text": "Table of Contents",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300z005/850300z005.pdf",
					"extraLocations": [],
					"pageNumber": 5,
					"isPageNumberRoman": true
				}
			],
			"backMatter": [
				{
					"class": "BM",
					"type": "BM_AUTHOR_INDEX",
					"text": "Author Index",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a385/850300a385.pdf",
					"extraLocations": [],
					"pageNumber": 385,
					"isPageNumberRoman": false
				}
			],
			"sections": [
				{
					"class": "SD",
					"type": "SD_SESSION",
					"title": "AISM 2025 -\u00A01st International Workshop on AI for Software Modernization",
					"lineItems": [
						{
							"eid": "66yvSRJjCC7gP8mDc4ru64",
							"type": "authorPaper",
							"text": "Message from the AISM 2025 Chairs",
							"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a001/850300a001.pdf",
							"extraLocations": [],
							"authorNames": "",
							"abstract": "",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW) ASEW 2025 Message from the AISM 2025 Chairs 10.1109/ASEW67777.2025.00009",
							"pageNumber": 1,
							"isPageNumberRoman": false
						},
						{
							"eid": "3A8WQA6FoxT6gnIeeXwpF8",
							"type": "authorPaper",
							"text": "Grammar- and Coverage-Based Augmentation of Programs for Training LLMs",
							"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a003/850300a003.pdf",
							"extraLocations": [],
							"authorNames": "Shin Saito (IBM Research - Tokyo), Takaaki Tateishi (IBM Research, Tokyo), Yasuharu Katsuno (IBM Research - Tokyo)",
							"abstract": "Training large language models (LLMs) for programming tasks, particularly code translation, requires diverse and syntactically valid code dataset. While data augmentation can enhance generalization, uncontrolled augmentation leads to overfitting or invalid examples. In this paper, we introduce a grammar- and coverage-based augmentation method that systematically generates syntactically valid code taking the coverage of grammar rules into account. This approach ensures both syntactic correctness and diversity in the code dataset, while suppressing excessive data augmentation. Our preliminary experiment demonstrates that our method produces well-distributed training data, contributing to improved representation of the underlying grammar.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW) ASEW 2025 Grammar- and Coverage-Based Augmentation of Programs for Training LLMs 1759811134964 10.1109/ASEW67777.2025.00010 Shin Saito IBM Research - Tokyo shinsa@jp.ibm.com Takaaki Tateishi IBM Research, Tokyo tate@jp.ibm.com Yasuharu Katsuno IBM Research - Tokyo katsuno@jp.ibm.com llm augmentation source code translation Training large language models (LLMs) for programming tasks, particularly code translation, requires diverse and syntactically valid code dataset. While data augmentation can enhance generalization, uncontrolled augmentation leads to overfitting or invalid examples. In this paper, we introduce a grammar- and coverage-based augmentation method that systematically generates syntactically valid code taking the coverage of grammar rules into account. This approach ensures both syntactic correctness and diversity in the code dataset, while suppressing excessive data augmentation. Our preliminary experiment demonstrates that our method produces well-distributed training data, contributing to improved representation of the underlying grammar.",
							"pageNumber": 3,
							"isPageNumberRoman": false
						},
						{
							"eid": "5PTa8Lqolll1r8IOEPvgwi",
							"type": "authorPaper",
							"text": "Uncovering Code Insights: Leveraging GitHub Artifacts for Deeper Code Understanding",
							"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a007/850300a007.pdf",
							"extraLocations": [],
							"authorNames": "Ziv Nevo (IBM Research, Israel), Orna Raz (IBM Research, Israel), Karen Yorav (IBM Research, Israel)",
							"abstract": "Understanding the purpose of source code is a critical task in software maintenance, onboarding, and modernization. While large language models (LLMs) have shown promise in generating code explanations, they often lack grounding in the broader software engineering context. We propose a novel approach that leverages natural language artifacts from GitHub\u2013such as pull request descriptions, issue descriptions and discussions, and commit messages\u2013to enhance LLM-based code understanding. Our system consists of three components: one that extracts and structures relevant GitHub context, another that uses this context to generate high-level explanations of the code's purpose, and a third that validates the explanation. We implemented this as a standalone tool, as well as a server within the Model Context Protocol (MCP), enabling integration with other AI-assisted development tools. Our main use case is that of enhancing a standard LLM-based code explanation with code insights that our system generates. To evaluate explanations' quality, we conducted a small scale user study, with developers of several open projects, as well as developers of proprietary projects. Our user study indicates that when insights are generated they often are helpful and non trivial, and are free from hallucinations.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW) ASEW 2025 Uncovering Code Insights: Leveraging GitHub Artifacts for Deeper Code Understanding 1759675214679 10.1109/ASEW67777.2025.00011 Ziv Nevo IBM Research, Israel nevo@il.ibm.com Orna Raz IBM Research, Israel ornar@il.ibm.com Karen Yorav IBM Research, Israel yorav@il.ibm.com code-understanding software-engineering git github llm laaj mcp Understanding the purpose of source code is a critical task in software maintenance, onboarding, and modernization. While large language models (LLMs) have shown promise in generating code explanations, they often lack grounding in the broader software engineering context. We propose a novel approach that leverages natural language artifacts from GitHub\u2013such as pull request descriptions, issue descriptions and discussions, and commit messages\u2013to enhance LLM-based code understanding. Our system consists of three components: one that extracts and structures relevant GitHub context, another that uses this context to generate high-level explanations of the code's purpose, and a third that validates the explanation. We implemented this as a standalone tool, as well as a server within the Model Context Protocol (MCP), enabling integration with other AI-assisted development tools. Our main use case is that of enhancing a standard LLM-based code explanation with code insights that our system generates. To evaluate explanations' quality, we conducted a small scale user study, with developers of several open projects, as well as developers of proprietary projects. Our user study indicates that when insights are generated they often are helpful and non trivial, and are free from hallucinations.",
							"pageNumber": 7,
							"isPageNumberRoman": false
						},
						{
							"eid": "10TGVGr9WUTENhMqJdJuSB",
							"type": "authorPaper",
							"text": "Leveraging LLM for Software Modernization: COBOL Functionality Extraction Case Study",
							"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a014/850300a014.pdf",
							"extraLocations": [],
							"authorNames": "ASHA RAJBHOJ (Tata Consultancy Services, INDIA), Akanksha Somase (Tata Consultancy Services, INDIA), Tanay Sant (Tata Consultancy Services, INDIA), Ajim Pathan (Tata Consultancy Services, INDIA), Purvesh Doud (Tata Consultancy Services, INDIA), Vinay Kulkarni (Tata Consultancy Services, INDIA)",
							"abstract": "Businesses are replete with applications created decades ago and are still relevant functionality wise. However, they pose significant evolution and integration challenges \u2013 the former because of paucity of skilled workforce and the latter due to high impedance mismatch with modern technology stack. The two constitute principal reasons leading to contemplation of modernization of these applications. Typical approach is to migrate existing code to the desired technology stack as a language transformation endeavor under functional equivalence. However, traditional parser-based approaches and lift-and-shift modernization methods typically add to the technology debt, thus making evolution of the modernized code even more challenging. To overcome the various lacunae in current practice in software modernization, we propose the stagewise refinement approach using LLM. In this paper, we focus on the stage of human-in-the-loop automation aided generation of functionality description specifically for Common Business-Oriented Language (COBOL) code. We illustrate the utility and efficacy of the proposed approach through validation on a small but complex business application.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW) ASEW 2025 Leveraging LLM for Software Modernization: COBOL Functionality Extraction Case Study 1759485559819 10.1109/ASEW67777.2025.00012 ASHA RAJBHOJ Tata Consultancy Services, INDIA asha.rajbhoj@tcs.com Akanksha Somase Tata Consultancy Services, INDIA akanksha.somase@tcs.com Tanay Sant Tata Consultancy Services, INDIA tanay.sant@tcs.com Ajim Pathan Tata Consultancy Services, INDIA ajim.pathan@tcs.com Purvesh Doud Tata Consultancy Services, INDIA purvesh.doud@tcs.com Vinay Kulkarni Tata Consultancy Services, INDIA vinay.vkulkarni@tcs.com Software Modernization COBOL Functionality Extraction Reverse Engineering Code Summarization Large Language Models Model-driven Engineering Businesses are replete with applications created decades ago and are still relevant functionality wise. However, they pose significant evolution and integration challenges \u2013 the former because of paucity of skilled workforce and the latter due to high impedance mismatch with modern technology stack. The two constitute principal reasons leading to contemplation of modernization of these applications. Typical approach is to migrate existing code to the desired technology stack as a language transformation endeavor under functional equivalence. However, traditional parser-based approaches and lift-and-shift modernization methods typically add to the technology debt, thus making evolution of the modernized code even more challenging. To overcome the various lacunae in current practice in software modernization, we propose the stagewise refinement approach using LLM. In this paper, we focus on the stage of human-in-the-loop automation aided generation of functionality description specifically for Common Business-Oriented Language (COBOL) code. We illustrate the utility and efficacy of the proposed approach through validation on a small but complex business application.",
							"pageNumber": 14,
							"isPageNumberRoman": false
						},
						{
							"eid": "5d1MScu8DeUsfISxZBXYBs",
							"type": "authorPaper",
							"text": "Microservices Identification Using LLM",
							"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a022/850300a022.pdf",
							"extraLocations": [],
							"authorNames": "Jay Gandhi (Tata Consultancy Services, India), Raveendra Kumar Medicherla (Tata Consultancy Services, India), Manasi Patwardhan (TCS Research, Tata Consultancy Services, India), Dipesh Sharma (AMD, India), Ravindra Naik (COEP Tech, India)",
							"abstract": "Identification of microservices within legacy monolithic applications is a critical, challenging, expert-driven task. Existing techniques often cluster technical elements of the application without aligning them with business domain. These technically inclined approaches may not fully address the larger legacy modernization objectives. To address this issue, we propose a novel approach that leverages Large Language Model (LLM) to infer the domain intent of key technical elements within the architecture. Our approach then combines these intents with architectural dependencies, and clusters them using Graph Neural Network (GNN) to identify candidate microservices that are domain-coherent. Preliminary evaluation across four benchmark applications of varying sizes and domains demonstrates the promising potential of our approach. ",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW) ASEW 2025 Microservices Identification Using LLM 1759466706734 10.1109/ASEW67777.2025.00013 Jay Gandhi Tata Consultancy Services, India gandhi.jay1@tcs.com Raveendra Kumar Medicherla Tata Consultancy Services, India raveendra.kumar@tcs.com Manasi Patwardhan TCS Research, Tata Consultancy Services, India manasi.patwardhan@tcs.com Dipesh Sharma AMD, India dipesh.sharma@amd.com Ravindra Naik COEP Tech, India rdn.comp@coeptech.ac.in microservices decomposition software modernization graph neural networks Identification of microservices within legacy monolithic applications is a critical, challenging, expert-driven task. Existing techniques often cluster technical elements of the application without aligning them with business domain. These technically inclined approaches may not fully address the larger legacy modernization objectives. To address this issue, we propose a novel approach that leverages Large Language Model (LLM) to infer the domain intent of key technical elements within the architecture. Our approach then combines these intents with architectural dependencies, and clusters them using Graph Neural Network (GNN) to identify candidate microservices that are domain-coherent. Preliminary evaluation across four benchmark applications of varying sizes and domains demonstrates the promising potential of our approach.",
							"pageNumber": 22,
							"isPageNumberRoman": false
						},
						{
							"eid": "6K6ZjU2SGMV6D3QfLtSjjC",
							"type": "authorPaper",
							"text": "Multilingual Code Explanation for Mainframe Languages",
							"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a026/850300a026.pdf",
							"extraLocations": [],
							"authorNames": "Kaoru Shinkawa (IBM Research, Japan), Ai Ishida (IBM Research, Japan), Yasuharu Katsuno (IBM Research, Japan), Fumiko Satoh (IBM Research, Japan)",
							"abstract": "Mainframe systems, written in legacy languages such as COBOL, PL/I, and JCL, continue to support mission-critical applications across various industries. Their complexity and limited documentation hinder maintenance and modernization, especially in regions where localized explanations are essential for accurate understanding. However, existing approaches predominantly generate English-only outputs and rely on resource-intensive models unsuitable for secure, on-premises environments. This study explores multilingual explanation generation for mainframe programs using lightweight language models suitable for constrained enterprise settings. We evaluate two strategies\u2014(a) direct generation in the target language and (b) translation-based generation from English\u2014across five languages: Japanese, French, German, Spanish, and Portuguese. Explanation quality is assessed using BLEU, ROUGE-L, METEOR, and semantic similarity. Preliminary results show that lightweight models can produce semantically adequate multilingual explanations. Translation-based generation generally yields higher lexical and structural quality across languages and models, while direct generation shows promise in specific scenarios. These findings demonstrate the feasibility of deploying multilingual explanation systems in enterprise environments and highlight opportunities to refine generation strategies based on language and code characteristics.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW) ASEW 2025 Multilingual Code Explanation for Mainframe Languages 1759546361769 10.1109/ASEW67777.2025.00014 Kaoru Shinkawa IBM Research, Japan kaoruma@jp.ibm.com Ai Ishida IBM Research, Japan aiishida@jp.ibm.com Yasuharu Katsuno IBM Research, Japan katsuno@jp.ibm.com Fumiko Satoh IBM Research, Japan sfumiko@jp.ibm.com mainframe systems multilingual code explanation legacy programming languages application modernization Mainframe systems, written in legacy languages such as COBOL, PL/I, and JCL, continue to support mission-critical applications across various industries. Their complexity and limited documentation hinder maintenance and modernization, especially in regions where localized explanations are essential for accurate understanding. However, existing approaches predominantly generate English-only outputs and rely on resource-intensive models unsuitable for secure, on-premises environments. This study explores multilingual explanation generation for mainframe programs using lightweight language models suitable for constrained enterprise settings. We evaluate two strategies\u2014(a) direct generation in the target language and (b) translation-based generation from English\u2014across five languages: Japanese, French, German, Spanish, and Portuguese. Explanation quality is assessed using BLEU, ROUGE-L, METEOR, and semantic similarity. Preliminary results show that lightweight models can produce semantically adequate multilingual explanations. Translation-based generation generally yields higher lexical and structural quality across languages and models, while direct generation shows promise in specific scenarios. These findings demonstrate the feasibility of deploying multilingual explanation systems in enterprise environments and highlight opportunities to refine generation strategies based on language and code characteristics.",
							"pageNumber": 26,
							"isPageNumberRoman": false
						},
						{
							"eid": "PzglwgpNkQxqzxhXDTALY",
							"type": "authorPaper",
							"text": "Vintage Code, Modern Judges: Meta-Validation in Low Data Regimes",
							"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a030/850300a030.pdf",
							"extraLocations": [],
							"authorNames": "Ora Fandina (IBM Research, Israel), Gal  Amram (IBM Research, Israel), Eitan   Farchi (IBM Research, Israel), Shmulik  Froimovich (IBM Research ), Raviv  Gal (IBM Research, Israel), Wesam  Ibraheem (IBM Research, Israel), Rami  Katan (IBM Research, Israel), Alice  Podolsky (IBM Research, Israel), Orna  Raz (IBM Research, Israel)",
							"abstract": "Application modernization in legacy languages such as COBOL, PL/I, and REXX faces an acute shortage of resources, both in expert availability and in high-quality human evaluation data. While Large Language Models as a Judge (LaaJ) offer a scalable alternative to expert review, their reliability must be validated before being trusted in high-stakes workflows. Without principled validation, organizations risk a circular evaluation loop, where unverified LaaJs are used to assess model outputs, potentially reinforcing unreliable judgments and compromising downstream deployment decisions. Although various automated approaches to validating LaaJs have been proposed, alignment with human judgment remains a widely used and conceptually grounded validation strategy. In many real-world domains, the availability of human-labeled evaluation data is severely limited, making it difficult to assess how well a LaaJ aligns with human judgment. We introduce SparseAlign, a formal framework for assessing LaaJ alignment with sparse human-labeled data. SparseAlign combines a novel pairwise-confidence concept with a scoresensitive alignment metric that jointly capture ranking consistency and score proximity, enabling reliable evaluator selection even when traditional statistical methods are ineffective due to limited annotated examples. SparseAlign was applied internally to select LaaJs for COBOL code explanation. The top-aligned evaluators were integrated into assessment workflows, guiding model release decisions",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW) ASEW 2025 Vintage Code, Modern Judges: Meta-Validation in Low Data Regimes 1759480757432 10.1109/ASEW67777.2025.00015 Ora Fandina IBM Research, Israel Ora.Nova.Fandina@ibm.com Gal Amram IBM Research, Israel gal.amram@ibm.com Eitan Farchi IBM Research, Israel FARCHI@ibm.com Shmulik Froimovich IBM Research Shmulik.Froimovich@ibm.com Raviv Gal IBM Research, Israel RAVIVG@ibm.com Wesam Ibraheem IBM Research, Israel WESAM@ibm.com Rami Katan IBM Research, Israel Rami.Katan@ibm.com Alice Podolsky IBM Research, Israel Alice.Podolsky@ibm.com Orna Raz IBM Research, Israel ORNAR@ibm.com llm-as-a-judge human evaluation sparse data code quality evaluation Application modernization in legacy languages such as COBOL, PL/I, and REXX faces an acute shortage of resources, both in expert availability and in high-quality human evaluation data. While Large Language Models as a Judge (LaaJ) offer a scalable alternative to expert review, their reliability must be validated before being trusted in high-stakes workflows. Without principled validation, organizations risk a circular evaluation loop, where unverified LaaJs are used to assess model outputs, potentially reinforcing unreliable judgments and compromising downstream deployment decisions. Although various automated approaches to validating LaaJs have been proposed, alignment with human judgment remains a widely used and conceptually grounded validation strategy. In many real-world domains, the availability of human-labeled evaluation data is severely limited, making it difficult to assess how well a LaaJ aligns with human judgment. We introduce SparseAlign, a formal framework for assessing LaaJ alignment with sparse human-labeled data. SparseAlign combines a novel pairwise-confidence concept with a scoresensitive alignment metric that jointly capture ranking consistency and score proximity, enabling reliable evaluator selection even when traditional statistical methods are ineffective due to limited annotated examples. SparseAlign was applied internally to select LaaJs for COBOL code explanation. The top-aligned evaluators were integrated into assessment workflows, guiding model release decisions",
							"pageNumber": 30,
							"isPageNumberRoman": false
						},
						{
							"eid": "68CH7iZo8ouS8HgfdgWr3o",
							"type": "authorPaper",
							"text": "LLM Agents for Automated Dependency Upgrades",
							"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a034/850300a034.pdf",
							"extraLocations": [],
							"authorNames": "Vali Tawosi (J.P. Morgan AI Research, UK), Salwa Alamir (J.P. Morgan AI Research, UK), Xiaomo Liu (J.P. Morgan AI Research, UK), Manuela Veloso (J.P. Morgan AI Research, UK)",
							"abstract": "As a codebase expands over time, its library dependencies can become outdated and require updates to maintain innovation and security. However, updating a library can introduce breaking changes in the code, necessitating significant developer time for maintenance. To address this, we introduce a framework of LLM agents to be used in combination with migration documentation to automatically recommend and apply code updates and ensure compatibility with new versions. Our solution can automatically localize updated library usages in live Java codebases and implement recommended fixes in a user-friendly manner. The system architecture consists of multiple key components: a Summary Agent, Control Agent, and Code Agent. To validate our approach, we apply the framework on an industrial use case by which we create three synthetic code repositories with major Upgrade changes and benchmark our approach against state-of-the-art methods. Results show that our approach not only performs upgrades using fewer tokens across all cases but also achieves a precision of 71.4%, highlighting its efficiency and effectiveness compared to state-of-the-art methods.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW) ASEW 2025 LLM Agents for Automated Dependency Upgrades 1759741716599 10.1109/ASEW67777.2025.00016 Vali Tawosi J.P. Morgan AI Research, UK vali.tawosi@jpmorgan.com Salwa Alamir J.P. Morgan AI Research, UK salwa.alamir@jpmchase.com Xiaomo Liu J.P. Morgan AI Research, UK xiaomo.liu@jpmchase.com Manuela Veloso J.P. Morgan AI Research, UK manuela.veloso@jpmchase.com ai for se agent-based se llm for library upgrades As a codebase expands over time, its library dependencies can become outdated and require updates to maintain innovation and security. However, updating a library can introduce breaking changes in the code, necessitating significant developer time for maintenance. To address this, we introduce a framework of LLM agents to be used in combination with migration documentation to automatically recommend and apply code updates and ensure compatibility with new versions. Our solution can automatically localize updated library usages in live Java codebases and implement recommended fixes in a user-friendly manner. The system architecture consists of multiple key components: a Summary Agent, Control Agent, and Code Agent. To validate our approach, we apply the framework on an industrial use case by which we create three synthetic code repositories with major Upgrade changes and benchmark our approach against state-of-the-art methods. Results show that our approach not only performs upgrades using fewer tokens across all cases but also achieves a precision of 71.4%, highlighting its efficiency and effectiveness compared to state-of-the-art methods.",
							"pageNumber": 34,
							"isPageNumberRoman": false
						}
					],
					"pageNumber": "",
					"isPageNumberRoman": false,
					"chair": null
				},
				{
					"class": "SD",
					"type": "SD_SESSION",
					"title": "AgenticSE 2025 -\u00A0The Autonomous Agents in Software Engineering Workshop",
					"lineItems": [
						{
							"eid": "6kyPaZx8V0a3xSDis3hHZW",
							"type": "authorPaper",
							"text": "Message from the AgenticSE 2025 Chairs",
							"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a038/850300a038.pdf",
							"extraLocations": [],
							"authorNames": "",
							"abstract": "",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW) ASEW 2025 Message from the AgenticSE 2025 Chairs 10.1109/ASEW67777.2025.00017",
							"pageNumber": 38,
							"isPageNumberRoman": false
						},
						{
							"eid": "54Sj2RsrdV4JwtckdIEBBA",
							"type": "authorPaper",
							"text": "Bridging LLM Planning Agents and Formal Methods: A Case Study in Plan Verification",
							"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a039/850300a039.pdf",
							"extraLocations": [],
							"authorNames": "Keshav Ramani (J.P. Morgan AI Research, UK), Vali Tawosi (J.P. Morgan AI Research, UK), Salwa Alamir (J.P. Morgan AI Research, UK), Daniel Borrajo (J.P. Morgan AI Research, UK)",
							"abstract": "We introduce a novel framework for evaluating the alignment between natural language plans and their expected behavior by converting them into Kripke structures and Linear Temporal Logic (LTL) using Large Language Models (LLMs) and performing model checking. We systematically evaluate this framework on a simplified version of the PlanBench plan verification dataset and report on metrics like Accuracy, Precision, Recall and F1 scores. Our experiments demonstrate that GPT-5 achieves excellent classification performance (F1 score of 96.3%) while almost always producing syntactically perfect formal representations that can act as guarantees. However, the synthesis of semantically perfect formal models remains an area for future exploration.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW) ASEW 2025 Bridging LLM Planning Agents and Formal Methods: A Case Study in Plan Verification 1759742442753 10.1109/ASEW67777.2025.00018 Keshav Ramani J.P. Morgan AI Research, UK keshav.ramani@jpmchase.com Vali Tawosi J.P. Morgan AI Research, UK vali.tawosi@jpmorgan.com Salwa Alamir J.P. Morgan AI Research, UK salwa.alamir@jpmchase.com Daniel Borrajo J.P. Morgan AI Research, UK daniel.borrajo@jpmchase.com plan verification formal methods llm for plan verification We introduce a novel framework for evaluating the alignment between natural language plans and their expected behavior by converting them into Kripke structures and Linear Temporal Logic (LTL) using Large Language Models (LLMs) and performing model checking. We systematically evaluate this framework on a simplified version of the PlanBench plan verification dataset and report on metrics like Accuracy, Precision, Recall and F1 scores. Our experiments demonstrate that GPT-5 achieves excellent classification performance (F1 score of 96.3%) while almost always producing syntactically perfect formal representations that can act as guarantees. However, the synthesis of semantically perfect formal models remains an area for future exploration.",
							"pageNumber": 39,
							"isPageNumberRoman": false
						},
						{
							"eid": "5Drc8l0UcqMO4jyh3XTG5G",
							"type": "authorPaper",
							"text": "LLMs in Debate: Does Arguing Make Them Better at Detecting Metamorphic Relations?",
							"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a043/850300a043.pdf",
							"extraLocations": [],
							"authorNames": "Dibyendu Brinto Bose (Virginia Tech), Yoseph Berhanu Alebachew (Virginia Tech), Chris Brown (Virginia Tech)",
							"abstract": "Large Language Models (LLMs) are transforming software engineering, including mobile Augmented Reality (AR) applications. AR software behavior often depends on dynamic environmental factors, making it difficult to use conventional testing and verification approaches. Metamorphic Testing (MT) offers an alternative by assessing whether expected transformations hold across varied conditions. However, there is limited work exploring how well LLMs can detect these transformations\u2014Metamorphic Relations (MRs)\u2014in applications. We propose a stability-driven evaluation framework that examines whether LLMs consistently apply MRs across rephrasings. Our study finds that StarCoder and CodeLlama exhibit higher stability in MR identification compared to the general-purpose model Gemma. Additionally, we use a multi-agent debate framework to investigate whether combining multiple perspectives improves consistency in MR identification. The debate mechanism reduces MR inconsistencies, leading to more stable MR identification across all MRs. While debate helps stabilize MR identification, our evaluation against human-labeled ground truth reveals that stability alone does not always correlate with correctness. Some models maintain stable yet incorrect predictions(CodeLlama), whereas debate enhances both consistency and correctness alignment, making LLM reasoning more reliable. This work contributes a method to evaluate LLMs in the absence of ground truth, establishing stability as a metric for assessing model reliability. Applying a multi-agent debate framework offers a promising approach to enhancing LLM reliability, especially in contexts where the ground truth is elusive.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW) ASEW 2025 LLMs in Debate: Does Arguing Make Them Better at Detecting Metamorphic Relations? 1759333986703 10.1109/ASEW67777.2025.00019 Dibyendu Brinto Bose Virginia Tech brintodibyendu@vt.edu Yoseph Berhanu Alebachew Virginia Tech yoseph@vt.edu Chris Brown Virginia Tech dcbrown@vt.edu large language models metamorphic testing augmented reality (ar) multi-agent debate stability evaluation Large Language Models (LLMs) are transforming software engineering, including mobile Augmented Reality (AR) applications. AR software behavior often depends on dynamic environmental factors, making it difficult to use conventional testing and verification approaches. Metamorphic Testing (MT) offers an alternative by assessing whether expected transformations hold across varied conditions. However, there is limited work exploring how well LLMs can detect these transformations\u2014Metamorphic Relations (MRs)\u2014in applications. We propose a stability-driven evaluation framework that examines whether LLMs consistently apply MRs across rephrasings. Our study finds that StarCoder and CodeLlama exhibit higher stability in MR identification compared to the general-purpose model Gemma. Additionally, we use a multi-agent debate framework to investigate whether combining multiple perspectives improves consistency in MR identification. The debate mechanism reduces MR inconsistencies, leading to more stable MR identification across all MRs. While debate helps stabilize MR identification, our evaluation against human-labeled ground truth reveals that stability alone does not always correlate with correctness. Some models maintain stable yet incorrect predictions(CodeLlama), whereas debate enhances both consistency and correctness alignment, making LLM reasoning more reliable. This work contributes a method to evaluate LLMs in the absence of ground truth, establishing stability as a metric for assessing model reliability. Applying a multi-agent debate framework offers a promising approach to enhancing LLM reliability, especially in contexts where the ground truth is elusive.",
							"pageNumber": 43,
							"isPageNumberRoman": false
						},
						{
							"eid": "3foGi8atEuD64wUq5WmTxE",
							"type": "authorPaper",
							"text": "A 3-Layer Agentic Model for Nonfunctional Requirements in Software Engineering",
							"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a051/850300a051.pdf",
							"extraLocations": [],
							"authorNames": "Ehsan Zabardast (Blekinge Institute of Technology and Gaetir, Sweden), Tiago Vieira (Independent Researcher, Sweden), Tony Gorschek (Blekinge Institute of Technology and fortiss, Sweden; fortiss GmbH, Germany)",
							"abstract": "Modern software-intensive systems must address a wide range of nonfunctional requirements (NFRs)\u2014such as security, compliance, and maintainability - that are critical for the long-term success of the system. With the rise of large-language-model-based agents, software engineering is entering an \"agentic\" era where AI components are not only tools but collaborators in development processes. However, leveraging these agents introduces dual challenges: ensuring that AI components themselves meet quality standards (e.g., compliance, security, maintainability), and harnessing AI effectively to support system-level NFR assurance. Our perspective explicitly spans both SE4AI, where AI components such as agents are engineered and subjected to quality assurance and AI4SE, where AI agents support the engineering of software-intensive systems. While these are conceptually distinct, our model addresses both in a unified way. This position paper introduces a conceptual, domain-agnostic three-layer model - comprising Data, Agent, and Perspective layers - for systematically embedding AI agents into NFR assurance across the software lifecycle. The model explicitly captures two complementary viewpoints: Quality for AI (ensuring AI agents are trustworthy and maintainable) and AI for Quality (using agents to support system NFRs). Through illustrative examples in compliance, security, and maintainability, the paper demonstrates how this model can guide researchers and practitioners in designing agent-based approaches to software quality. We argue that this model not only clarifies the dual roles of AI in software engineering but also provides a foundation for responsible, scalable, and effective integration of AI into NFR assurance.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW) ASEW 2025 A 3-Layer Agentic Model for Nonfunctional Requirements in Software Engineering 1759276917437 10.1109/ASEW67777.2025.00020 Ehsan Zabardast Blekinge Institute of Technology and Gaetir, Sweden ehsan.zabardast@bth.se Tiago Vieira Independent Researcher, Sweden tiagovr@gmail.com Tony Gorschek Blekinge Institute of Technology and fortiss, Sweden; fortiss GmbH, Germany tony.gorschek@bth.se ai agents in software engineering nonfunctional requirements (nfrs) software quality assurance Modern software-intensive systems must address a wide range of nonfunctional requirements (NFRs)\u2014such as security, compliance, and maintainability - that are critical for the long-term success of the system. With the rise of large-language-model-based agents, software engineering is entering an \"agentic\" era where AI components are not only tools but collaborators in development processes. However, leveraging these agents introduces dual challenges: ensuring that AI components themselves meet quality standards (e.g., compliance, security, maintainability), and harnessing AI effectively to support system-level NFR assurance. Our perspective explicitly spans both SE4AI, where AI components such as agents are engineered and subjected to quality assurance and AI4SE, where AI agents support the engineering of software-intensive systems. While these are conceptually distinct, our model addresses both in a unified way. This position paper introduces a conceptual, domain-agnostic three-layer model - comprising Data, Agent, and Perspective layers - for systematically embedding AI agents into NFR assurance across the software lifecycle. The model explicitly captures two complementary viewpoints: Quality for AI (ensuring AI agents are trustworthy and maintainable) and AI for Quality (using agents to support system NFRs). Through illustrative examples in compliance, security, and maintainability, the paper demonstrates how this model can guide researchers and practitioners in designing agent-based approaches to software quality. We argue that this model not only clarifies the dual roles of AI in software engineering but also provides a foundation for responsible, scalable, and effective integration of AI into NFR assurance.",
							"pageNumber": 51,
							"isPageNumberRoman": false
						},
						{
							"eid": "13fTC4WvOv0z1Gbk0Zi1L4",
							"type": "authorPaper",
							"text": "Leveraging Large Language Models for Cybersecurity Risk Assessment \u2014 A Case from Forestry Cyber-Physical Systems",
							"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a058/850300a058.pdf",
							"extraLocations": [],
							"authorNames": "Fikret Mert G\u00FCltekin (University of Gothenburg, Sweden), Oscar Lilja (University of Gothenburg, Sweden), Ranim Khojah (University of Gothenburg, Sweden), Rebekka Wohlrab (University of Gothenburg, Sweden; Carnegie Mellon University, USA), Marvin Damschen (RISE Research Institutes of Sweden, Sweden), Mazen Mohamad (RISE Research Institutes of Sweden, Sweden; University of Gothenburg, Sweden; University of Gothenburg, Sweden)",
							"abstract": "In safety-critical software systems, cybersecurity activities become essential, with risk assessment being one of the most critical. In many software teams, cybersecurity experts are either entirely absent or represented by only a small number of specialists. As a result, the workload for these experts becomes high, and software engineers would need to conduct cybersecurity activities themselves. This creates a need for a tool to support cybersecurity experts and engineers in evaluating vulnerabilities and threats during the risk assessment process. This paper explores the potential of leveraging locally hosted large language models (LLMs) with retrieval-augmented generation to support cybersecurity risk assessment in the forestry domain while complying with data protection and privacy requirements that limit external data sharing. We performed a design science study involving 12 experts in interviews, interactive sessions, and a survey within a large-scale project. The results demonstrate that LLMs can assist cybersecurity experts by generating initial risk assessments, identifying threats, and providing redundancy checks. The results also highlight the necessity for human oversight to ensure accuracy and compliance. Despite trust concerns, experts were willing to utilize LLMs in specific evaluation and assistance roles, rather than solely relying on their generative capabilities. This study provides insights that encourage the use of LLM-based agents to support the risk assessment process of cyber-physical systems in safety-critical domains. ",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW) ASEW 2025 Leveraging Large Language Models for Cybersecurity Risk Assessment \u2014 A Case from Forestry Cyber-Physical Systems 1759481099305 10.1109/ASEW67777.2025.00021 Fikret Mert G\u00FCltekin University of Gothenburg, Sweden fikretm@student.chalmers.se Oscar Lilja University of Gothenburg, Sweden liljao@student.chalmers.se Ranim Khojah University of Gothenburg, Sweden khojah@chalmers.se Rebekka Wohlrab University of Gothenburg, Sweden; Carnegie Mellon University, USA wohlrab@chalmers.se Marvin Damschen RISE Research Institutes of Sweden, Sweden marvin.damschen@ri.se Mazen Mohamad RISE Research Institutes of Sweden, Sweden; University of Gothenburg, Sweden; University of Gothenburg, Sweden mazen.mohamad@ri.se large language models cybersecurity risk assessment cyber-physical systems In safety-critical software systems, cybersecurity activities become essential, with risk assessment being one of the most critical. In many software teams, cybersecurity experts are either entirely absent or represented by only a small number of specialists. As a result, the workload for these experts becomes high, and software engineers would need to conduct cybersecurity activities themselves. This creates a need for a tool to support cybersecurity experts and engineers in evaluating vulnerabilities and threats during the risk assessment process. This paper explores the potential of leveraging locally hosted large language models (LLMs) with retrieval-augmented generation to support cybersecurity risk assessment in the forestry domain while complying with data protection and privacy requirements that limit external data sharing. We performed a design science study involving 12 experts in interviews, interactive sessions, and a survey within a large-scale project. The results demonstrate that LLMs can assist cybersecurity experts by generating initial risk assessments, identifying threats, and providing redundancy checks. The results also highlight the necessity for human oversight to ensure accuracy and compliance. Despite trust concerns, experts were willing to utilize LLMs in specific evaluation and assistance roles, rather than solely relying on their generative capabilities. This study provides insights that encourage the use of LLM-based agents to support the risk assessment process of cyber-physical systems in safety-critical domains.",
							"pageNumber": 58,
							"isPageNumberRoman": false
						},
						{
							"eid": "1EEUZTd2LunDGUsxpFQvhF",
							"type": "authorPaper",
							"text": "The Last Dependency Crusade: Solving Python Dependency Conflicts with LLMs",
							"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a066/850300a066.pdf",
							"extraLocations": [],
							"authorNames": "Antony Bartlett (Delft University of Technology, The Netherlands), Cynthia Liem (Delft University of Technology, The Netherlands), Annibale Panichella (Delft University of Technology, The Netherlands)",
							"abstract": "Resolving Python dependency issues remains a tedious and error-prone process, forcing developers to manually trial compatible module versions and interpreter configurations. Existing automated solutions, such as knowledge-graph-based and database-driven methods, face limitations due to the variety of dependency error types, large sets of possible module versions, and conflicts among transitive dependencies. This paper investigates the use of Large Language Models (LLMs) to automatically repair dependency issues in Python programs. We propose PLLM (pronounced \"plum\"), a novel retrieval-augmented generation (RAG) approach that iteratively infers missing or incorrect dependencies. PLLM builds a test environment where the LLM proposes module combinations, observes execution feedback, and refines its predictions using natural language processing (NLP) to parse error messages. We evaluate PLLM on the Gistable HG2.9K dataset, a curated collection of real-world Python programs. Using this benchmark, we explore multiple PLLM configurations, including six open-source LLMs evaluated both with and without RAG. Our findings show that RAG consistently improves fix rates, with the best performance achieved by Gemma-2 9B when combined with RAG. Compared to two state-of-the-art baselines, PyEGo and ReadPyE, PLLM achieves significantly higher fix rates; +15.97% more than ReadPyE and +21.58% more than PyEGo. Further analysis shows that PLLM is especially effective for projects with numerous dependencies and those using specialized numerical or machine-learning libraries.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW) ASEW 2025 The Last Dependency Crusade: Solving Python Dependency Conflicts with LLMs 1759678984523 10.1109/ASEW67777.2025.00022 Antony Bartlett Delft University of Technology, The Netherlands a.j.bartlett@tudelft.nl Cynthia Liem Delft University of Technology, The Netherlands c.c.s.liem@tudelft.nl Annibale Panichella Delft University of Technology, The Netherlands a.panichella@tudelft.nl python dependency conflicts large language models retrieval-augmented generation Resolving Python dependency issues remains a tedious and error-prone process, forcing developers to manually trial compatible module versions and interpreter configurations. Existing automated solutions, such as knowledge-graph-based and database-driven methods, face limitations due to the variety of dependency error types, large sets of possible module versions, and conflicts among transitive dependencies. This paper investigates the use of Large Language Models (LLMs) to automatically repair dependency issues in Python programs. We propose PLLM (pronounced \"plum\"), a novel retrieval-augmented generation (RAG) approach that iteratively infers missing or incorrect dependencies. PLLM builds a test environment where the LLM proposes module combinations, observes execution feedback, and refines its predictions using natural language processing (NLP) to parse error messages. We evaluate PLLM on the Gistable HG2.9K dataset, a curated collection of real-world Python programs. Using this benchmark, we explore multiple PLLM configurations, including six open-source LLMs evaluated both with and without RAG. Our findings show that RAG consistently improves fix rates, with the best performance achieved by Gemma-2 9B when combined with RAG. Compared to two state-of-the-art baselines, PyEGo and ReadPyE, PLLM achieves significantly higher fix rates; +15.97% more than ReadPyE and +21.58% more than PyEGo. Further analysis shows that PLLM is especially effective for projects with numerous dependencies and those using specialized numerical or machine-learning libraries.",
							"pageNumber": 66,
							"isPageNumberRoman": false
						},
						{
							"eid": "33L820Zsq7v9hLA2eE6rVt",
							"type": "authorPaper",
							"text": "AgentGuard: Runtime Verification of AI Agents",
							"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a074/850300a074.pdf",
							"extraLocations": [],
							"authorNames": "Roham Koohestani (JetBrains Research, The Netherlands)",
							"abstract": "The rapid evolution to autonomous, agentic AI systems introduces significant risks due to their inherent unpredictability and emergent behaviors; this also renders traditional verification methods inadequate and necessitates a shift towards probabilistic guarantees where the question is no longer if a system will fail, but the probability of its failure within given constraints. This paper presents AgentGuard, a framework for runtime verification of Agentic AI systems that provides continuous, quantitative assurance through a new paradigm called Dynamic Probabilistic Assurance. AgentGuard operates as an inspection layer that observes an agent's raw I/O and abstracts it into formal events corresponding to transitions in a state model. It then uses online learning to dynamically build and update a Markov Decision Process (MDP) that formally models the agent's emergent behavior. Using probabilistic model checking, the framework then verifies quantitative properties in real-time. ",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW) ASEW 2025 AgentGuard: Runtime Verification of AI Agents 1759729314774 10.1109/ASEW67777.2025.00023 Roham Koohestani JetBrains Research, The Netherlands roham.koohestani@jetbrains.com agentic ai formal verification probabilistic model-checking runtime verification The rapid evolution to autonomous, agentic AI systems introduces significant risks due to their inherent unpredictability and emergent behaviors; this also renders traditional verification methods inadequate and necessitates a shift towards probabilistic guarantees where the question is no longer if a system will fail, but the probability of its failure within given constraints. This paper presents AgentGuard, a framework for runtime verification of Agentic AI systems that provides continuous, quantitative assurance through a new paradigm called Dynamic Probabilistic Assurance. AgentGuard operates as an inspection layer that observes an agent's raw I/O and abstracts it into formal events corresponding to transitions in a state model. It then uses online learning to dynamically build and update a Markov Decision Process (MDP) that formally models the agent's emergent behavior. Using probabilistic model checking, the framework then verifies quantitative properties in real-time.",
							"pageNumber": 74,
							"isPageNumberRoman": false
						}
					],
					"pageNumber": "",
					"isPageNumberRoman": false,
					"chair": null
				},
				{
					"class": "SD",
					"type": "SD_SESSION",
					"title": "A-Mobile 2025 -\u00A08th International Workshop on Advances in Mobile App Analysis",
					"lineItems": [
						{
							"eid": "5mt6CzPG5TUbtLCubRCyoF",
							"type": "authorPaper",
							"text": "Message from the A-Mobile 2025 Chairs",
							"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a078/850300a078.pdf",
							"extraLocations": [],
							"authorNames": "",
							"abstract": "",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW) ASEW 2025 Message from the A-Mobile 2025 Chairs 10.1109/ASEW67777.2025.00024",
							"pageNumber": 78,
							"isPageNumberRoman": false
						},
						{
							"eid": "5LqsCXLgbTgTzw8trf2sMU",
							"type": "authorPaper",
							"text": "Reliable and Interpretable Android Malware Detection at Scale",
							"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a079/850300a079.pdf",
							"extraLocations": [],
							"authorNames": "Michael Tegegn (The University of British Columbia, Canada), Julia Rubin (The University of British Columbia, Canada)",
							"abstract": "Machine learning approaches have shown impressive performance in Android malware detection. Yet, most if not all of these approaches face tradeoffs between accuracy, interpretability, and scalability. Approaches based on simple features are interpretable but miss complex behaviors. At the same time, approaches that capture holistic application patterns obscure the exact code responsible for malicious activity. In this paper, we outline our vision for an accurate, scalable, and interpretable method-level malware detection. The core idea behind our approach is to filter out non-discriminative application parts before analyzing the remaining, application-specific behaviors at the fine level of granularity. We further discuss the key challenges that must be addressed to effectively implement our proposed approach and provide suggestions for future directions. ",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW) ASEW 2025 Reliable and Interpretable Android Malware Detection at Scale 1759989558869 10.1109/ASEW67777.2025.00025 Michael Tegegn The University of British Columbia, Canada mtegegn@ece.ubc.ca Julia Rubin The University of British Columbia, Canada mjulia@ece.ubc.ca android malware detection llm Machine learning approaches have shown impressive performance in Android malware detection. Yet, most if not all of these approaches face tradeoffs between accuracy, interpretability, and scalability. Approaches based on simple features are interpretable but miss complex behaviors. At the same time, approaches that capture holistic application patterns obscure the exact code responsible for malicious activity. In this paper, we outline our vision for an accurate, scalable, and interpretable method-level malware detection. The core idea behind our approach is to filter out non-discriminative application parts before analyzing the remaining, application-specific behaviors at the fine level of granularity. We further discuss the key challenges that must be addressed to effectively implement our proposed approach and provide suggestions for future directions.",
							"pageNumber": 79,
							"isPageNumberRoman": false
						},
						{
							"eid": "23KEeXRp8FBGuLewhz5n8n",
							"type": "authorPaper",
							"text": "Finding Keywords for Architectural Erosion Detection in GitHub Commits for Android Applications",
							"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a083/850300a083.pdf",
							"extraLocations": [],
							"authorNames": "Juan Camilo Acosta-Rojas (Universidad de los Andes, Colombia), Camilo Andr\u00E9s Escobar-Vel\u00E1squez (Universidad de los Andes, Colombia)",
							"abstract": "Architectural Erosion (AER) is a phenomenon that occurs when the implemented architecture of a software project diverges from its intended design. This can impact the quality and performance of an application. In Android applications, the effects may be amplified due to limited resources such as memory, storage, and processing power. Previous efforts have been done to tackle AER for different platforms, mainly using static code analysis and AI-based approaches using Word-embeddings. Nevertheless, no previous study has focused on Android Apps. The goal of this research is to evaluate the applicability of the proposed approaches based on word-embeddings to identify new potential keywords in GitHub commits of Android projects, using the existing list of keywords and word similarity metrics.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW) ASEW 2025 Finding Keywords for Architectural Erosion Detection in GitHub Commits for Android Applications 1759932007654 10.1109/ASEW67777.2025.00026 Juan Camilo Acosta-Rojas Universidad de los Andes, Colombia jc.acosta2@uniandes.edu.co Camilo Andr\u00E9s Escobar-Vel\u00E1squez Universidad de los Andes, Colombia ca.escobar2434@uniandes.edu.co Word Embedding AI Android GitHub Commits Software Similarity NLP Architectural Erosion (AER) is a phenomenon that occurs when the implemented architecture of a software project diverges from its intended design. This can impact the quality and performance of an application. In Android applications, the effects may be amplified due to limited resources such as memory, storage, and processing power. Previous efforts have been done to tackle AER for different platforms, mainly using static code analysis and AI-based approaches using Word-embeddings. Nevertheless, no previous study has focused on Android Apps. The goal of this research is to evaluate the applicability of the proposed approaches based on word-embeddings to identify new potential keywords in GitHub commits of Android projects, using the existing list of keywords and word similarity metrics.",
							"pageNumber": 83,
							"isPageNumberRoman": false
						},
						{
							"eid": "Ti9A6eBXmatjKc62UQm2y",
							"type": "authorPaper",
							"text": "A Data-Driven Approach for Automated Quality Concern Extraction from App Reviews",
							"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a087/850300a087.pdf",
							"extraLocations": [],
							"authorNames": "Khubaib Amjad Alam (Al Ain University, UAE), Maryam Hussain (National University of Computer and Emerging Sciences, Pakistan), Umer Daraz (National University of Computer and Emerging Sciences, Pakistan), Behjat Zuhaira (National University of Computer and Emerging Sciences, Pakistan), Muhammad Haroon (National University of Computer and Emerging Sciences, Pakistan)",
							"abstract": "User Review on App Distribution Platforms such as the Google Play Store, provide vital feedback on the software and offer several information-rich attributes such as user experience, performance, security and software reliability. However, owing to their inherently unstructured nature, informal tone, and the vague opinions, it becomes difficult to manually extract such information from App Reviews. Over the past few years, several Automated solutions using traditional machine learning (ML) and Deep learning (DL) approaches have been proposed. However, these solutions have significant methodological and scope-centric limitations including insufficient deep context understanding, and dependency on hand-crafted features, resulting in limited effectiveness in multi-label classification scenarios. This research aims at automating quality concern extraction from mobile app reviews using transformer-based language models. We benchmark mainstream Transformer-based language models against classical ML/DL baselines to highlight their relative advantages in context-aware multi-label classification. The proposed approach aims at reducing the reliance on manual feature engineering by leveraging self-attention mechanism and contextual embeddings to enhance semantic understanding of the reviews. Five selected quality concerns as part of ISO 25010 standard are targeted in this study. An annotated dataset of 20,000 real-world app reviews is used for the evaluation for performance evaluation of the proposed approach against precision, recall and F1-score. Through comprehensive empirical evaluation, the study validates the effectiveness and practicality of state-of-the-art transformer-based language models for automated extraction of software quality concerns.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW) ASEW 2025 A Data-Driven Approach for Automated Quality Concern Extraction from App Reviews 1760365621646 10.1109/ASEW67777.2025.00027 Khubaib Amjad Alam Al Ain University, UAE khubaib.alam@aau.ac.ae Maryam Hussain National University of Computer and Emerging Sciences, Pakistan i237824@isb.nu.edu.pk Umer Daraz National University of Computer and Emerging Sciences, Pakistan i237818@isb.nu.edu.pk Behjat Zuhaira National University of Computer and Emerging Sciences, Pakistan behjat.zuhaira@nu.edu.pk Muhammad Haroon National University of Computer and Emerging Sciences, Pakistan i229812@nu.edu.pk app reviews is0 25010 nlp transformers llms quality concerns User Review on App Distribution Platforms such as the Google Play Store, provide vital feedback on the software and offer several information-rich attributes such as user experience, performance, security and software reliability. However, owing to their inherently unstructured nature, informal tone, and the vague opinions, it becomes difficult to manually extract such information from App Reviews. Over the past few years, several Automated solutions using traditional machine learning (ML) and Deep learning (DL) approaches have been proposed. However, these solutions have significant methodological and scope-centric limitations including insufficient deep context understanding, and dependency on hand-crafted features, resulting in limited effectiveness in multi-label classification scenarios. This research aims at automating quality concern extraction from mobile app reviews using transformer-based language models. We benchmark mainstream Transformer-based language models against classical ML/DL baselines to highlight their relative advantages in context-aware multi-label classification. The proposed approach aims at reducing the reliance on manual feature engineering by leveraging self-attention mechanism and contextual embeddings to enhance semantic understanding of the reviews. Five selected quality concerns as part of ISO 25010 standard are targeted in this study. An annotated dataset of 20,000 real-world app reviews is used for the evaluation for performance evaluation of the proposed approach against precision, recall and F1-score. Through comprehensive empirical evaluation, the study validates the effectiveness and practicality of state-of-the-art transformer-based language models for automated extraction of software quality concerns.",
							"pageNumber": 87,
							"isPageNumberRoman": false
						},
						{
							"eid": "4KJ3X1NLAciY8l7UMbVvlv",
							"type": "authorPaper",
							"text": "DroidNative: A Greedy-Constructed Large-Scale Indexing for Android Native Libraries",
							"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a095/850300a095.pdf",
							"extraLocations": [],
							"authorNames": "Shiyang Zhang (Tianjin University, China), Chengwei Liu (Nanyang Technological University, Singapore), Sen Chen (Nankai University, China), Lyuye Zhang (Nanyang Technological University, Singapore), Yang Liu (Nanyang Technological University, Singapore)",
							"abstract": "Native libraries are widely used in Android for performance optimization, but their integration also poses security risks. Although existing research works have investigated the adoption, management, and ecosystem evolution of third-party libraries (TPLs) in Android, studies specific to Android native libraries are still rare, which makes the potential threats of native libraries in Android less concerned. The biggest barrier is that, Android native libraries are usually provided by various suppliers in different ways and sources, leading to the lack of a comprehensive registry that indexes commonly used native libraries for further investigations. To this end, by following a greedy strategy to identify possible repository sources and collect Android native libraries, we constructed the first comprehensive native library database DroidNative for Android, with over 60K libraries and 292K versions well retained. Our experiments proved its completeness that 85.1% of binaries in real-world APPs can be successfully traced in DroidNative, with 10.1% of the rest suspicious to be not third-party native libraries. Moreover, DroidNative is also evaluated to be useful regarding improving existing SCA detection (i.e., LibRARIAN) by outperforming existing state of the art tools with at least 78.4% recognition rate improvement.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW) ASEW 2025 DroidNative: A Greedy-Constructed Large-Scale Indexing for Android Native Libraries 1759744191193 10.1109/ASEW67777.2025.00028 Shiyang Zhang Tianjin University, China zsy_1@tju.edu.cn Chengwei Liu Nanyang Technological University, Singapore chengwei.liu@ntu.edu.sg Sen Chen Nankai University, China senchen@nankai.edu.cn Lyuye Zhang Nanyang Technological University, Singapore zh0004ye@e.ntu.edu.sg Yang Liu Nanyang Technological University, Singapore yangliu@ntu.edu.sg Android Native Library SCA Native libraries are widely used in Android for performance optimization, but their integration also poses security risks. Although existing research works have investigated the adoption, management, and ecosystem evolution of third-party libraries (TPLs) in Android, studies specific to Android native libraries are still rare, which makes the potential threats of native libraries in Android less concerned. The biggest barrier is that, Android native libraries are usually provided by various suppliers in different ways and sources, leading to the lack of a comprehensive registry that indexes commonly used native libraries for further investigations. To this end, by following a greedy strategy to identify possible repository sources and collect Android native libraries, we constructed the first comprehensive native library database DroidNative for Android, with over 60K libraries and 292K versions well retained. Our experiments proved its completeness that 85.1% of binaries in real-world APPs can be successfully traced in DroidNative, with 10.1% of the rest suspicious to be not third-party native libraries. Moreover, DroidNative is also evaluated to be useful regarding improving existing SCA detection (i.e., LibRARIAN) by outperforming existing state of the art tools with at least 78.4% recognition rate improvement.",
							"pageNumber": 95,
							"isPageNumberRoman": false
						},
						{
							"eid": "5qwoMmLYt70KiMOBQjwYK3",
							"type": "authorPaper",
							"text": "A Domain-Independent Framework for Effective Prioritization and Evaluation of UX Aspects in Mobile Apps",
							"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a099/850300a099.pdf",
							"extraLocations": [],
							"authorNames": "Haifa Alshammare (KFUPM, Saudi Arabia; Technical and Vocational Training Corporation, Saudi Arabia), Mohammad Alshayeb (KFUPM, Saudi Arabia; Interdisciplinary Research Center for Intelligent Secure Systems, Saudi Arabia), Malak Baslyman (KFUPM, Saudi Arabia; Interdisciplinary Research Center for Finance and Digital Economy, Saudi Arabia)",
							"abstract": "The rapid evolution of mobile applications has intensified the need to prioritize and systematically evaluate user experience (UX) aspects. This paper introduces a domain-independent hybrid framework that ranks UX aspects and their evaluation methods. The framework integrates the MOSCOW method and the Analytic Hierarchy Process (AHP) to evaluate UX based on User Profiles, App Domain Specificity, Task Complexity, and Feasibility. A Use Value\u2013Effort/Complexity matrix further supports the evaluation of methods by considering evaluation goals, user profiles, application domain, stage of development, data needs, resource availability, technical complexity, and ease of data collection and analysis. Six evaluators validated the framework with a case study, including three domains: mobile banking, gaming, and health. The framework enabled them to agree on core UX priorities, demonstrating its flexibility and practicality, offering a clear method for prioritizing and evaluating UX across mobile app domains.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW) ASEW 2025 A Domain-Independent Framework for Effective Prioritization and Evaluation of UX Aspects in Mobile Apps 1759745566888 10.1109/ASEW67777.2025.00029 Haifa Alshammare KFUPM, Saudi Arabia; Technical and Vocational Training Corporation, Saudi Arabia g202110890@email.com Mohammad Alshayeb KFUPM, Saudi Arabia; Interdisciplinary Research Center for Intelligent Secure Systems, Saudi Arabia alshayeb@kfupm.edu.sa Malak Baslyman KFUPM, Saudi Arabia; Interdisciplinary Research Center for Finance and Digital Economy, Saudi Arabia Malak.baslyman@kfupm.edu.sa interactive systems mobile applications user experience hci ux aspects ux evaluation methods moscow analytic hierarchy process (ahp) use value-effort/complexity The rapid evolution of mobile applications has intensified the need to prioritize and systematically evaluate user experience (UX) aspects. This paper introduces a domain-independent hybrid framework that ranks UX aspects and their evaluation methods. The framework integrates the MOSCOW method and the Analytic Hierarchy Process (AHP) to evaluate UX based on User Profiles, App Domain Specificity, Task Complexity, and Feasibility. A Use Value\u2013Effort/Complexity matrix further supports the evaluation of methods by considering evaluation goals, user profiles, application domain, stage of development, data needs, resource availability, technical complexity, and ease of data collection and analysis. Six evaluators validated the framework with a case study, including three domains: mobile banking, gaming, and health. The framework enabled them to agree on core UX priorities, demonstrating its flexibility and practicality, offering a clear method for prioritizing and evaluating UX across mobile app domains.",
							"pageNumber": 99,
							"isPageNumberRoman": false
						},
						{
							"eid": "49Di4V8t4KppPRe1JJPBt4",
							"type": "authorPaper",
							"text": "From Kotlin to Swift and Back: Toward Fully Automated Cross-Language Code Transpilation",
							"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a107/850300a107.pdf",
							"extraLocations": [],
							"authorNames": "Sachi Lad (University College London, UK), Carol Hanna (University College London, UK), Justyna Petke (University College London, UK)",
							"abstract": "Mobile platforms dominate software development, yet transpiling code between Kotlin (Android) and Swift (iOS) remains a major challenge. This task is essential for cross-platform accessibility, particularly when porting iOS apps to Android. Despite its importance, research on Kotlin\u2013Swift transpilation and particularly, fixing these transpilation bugs is scarce. We thus present the first large-scale study of Kotlin\u2013Swift transpilation bugs. We identify 149 real-world bugs, introduce a taxonomy of common bug types, and propose new mutation operators to address them. Combined with existing operators, our proposed operators have potential to fix 101 of these bugs. Building on the taxonomy of transpilation bugs and the mutation operators we develop to repair them, we lay out a research agenda for reliable, fully-automated, end-to-end software transpilation workflows for the mobile domain.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW) ASEW 2025 From Kotlin to Swift and Back: Toward Fully Automated Cross-Language Code Transpilation 1759745142059 10.1109/ASEW67777.2025.00030 Sachi Lad University College London, UK sachi.lad.21@alumni.ucl.ac.uk Carol Hanna University College London, UK carol.hanna.21@ucl.ac.uk Justyna Petke University College London, UK j.petke@ucl.ac.uk mobile transpilation bug repair swift kotlin Mobile platforms dominate software development, yet transpiling code between Kotlin (Android) and Swift (iOS) remains a major challenge. This task is essential for cross-platform accessibility, particularly when porting iOS apps to Android. Despite its importance, research on Kotlin\u2013Swift transpilation and particularly, fixing these transpilation bugs is scarce. We thus present the first large-scale study of Kotlin\u2013Swift transpilation bugs. We identify 149 real-world bugs, introduce a taxonomy of common bug types, and propose new mutation operators to address them. Combined with existing operators, our proposed operators have potential to fix 101 of these bugs. Building on the taxonomy of transpilation bugs and the mutation operators we develop to repair them, we lay out a research agenda for reliable, fully-automated, end-to-end software transpilation workflows for the mobile domain.",
							"pageNumber": 107,
							"isPageNumberRoman": false
						}
					],
					"pageNumber": "",
					"isPageNumberRoman": false,
					"chair": null
				},
				{
					"class": "SD",
					"type": "SD_SESSION",
					"title": "ASYDE 2025 -\u00A07th International Workshop on Automated and Verifiable Software sYstem DEvelopment",
					"lineItems": [
						{
							"eid": "2NTjzlrXVitq10ROthfSDn",
							"type": "authorPaper",
							"text": "Message from the ASYDE 2025 Chairs",
							"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a111/850300a111.pdf",
							"extraLocations": [],
							"authorNames": "",
							"abstract": "",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW) ASEW 2025 Message from the ASYDE 2025 Chairs 10.1109/ASEW67777.2025.00031",
							"pageNumber": 111,
							"isPageNumberRoman": false
						},
						{
							"eid": "4Y9DZW2uV9Q8rLfo6X36Ts",
							"type": "authorPaper",
							"text": "Pre-Filtering Code Suggestions using Developer Behavioral Telemetry to Optimize LLM-Assisted Programming",
							"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a113/850300a113.pdf",
							"extraLocations": [],
							"authorNames": "Mohammad Nour Al Awad (ITMO University), Sergey Ivanov (ITMO University), Olga Tikhonova (ITMO University)",
							"abstract": "Large Language Models (LLMs) are increasingly integrated into code editors to provide AI-powered code suggestions. Yet many of these suggestions are ignored, resulting in wasted computation, increased latency, and unnecessary interruptions. We introduce a lightweight pre-filtering model that predicts the likelihood of suggestion acceptance before invoking the LLM, using only real-time developer telemetry such as typing speed, file navigation, and editing activity. Deployed in a production-grade Visual Studio Code plugin over four months of naturalistic use, our approach nearly doubled acceptance rates (18.4% \u2192 34.2%) while suppressing 35% of low-value LLM calls. These findings demonstrate that behavioral signals alone can meaningfully improve both user experience and system efficiency in LLM-assisted programming, highlighting the value of timing-aware, privacy-preserving adaptation mechanisms. The filter operates solely on pre-invocation editor telemetry and never inspects code or prompts.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW) ASEW 2025 Pre-Filtering Code Suggestions using Developer Behavioral Telemetry to Optimize LLM-Assisted Programming 1759217886886 10.1109/ASEW67777.2025.00032 Mohammad Nour Al Awad ITMO University mohammadnouralawad@itmo.ru Sergey Ivanov ITMO University svivanov@itmo.ru Olga Tikhonova ITMO University tikhonova_ob@itmo.ru behavioral modeling adaptive systems human-computer interaction code completion Large Language Models (LLMs) are increasingly integrated into code editors to provide AI-powered code suggestions. Yet many of these suggestions are ignored, resulting in wasted computation, increased latency, and unnecessary interruptions. We introduce a lightweight pre-filtering model that predicts the likelihood of suggestion acceptance before invoking the LLM, using only real-time developer telemetry such as typing speed, file navigation, and editing activity. Deployed in a production-grade Visual Studio Code plugin over four months of naturalistic use, our approach nearly doubled acceptance rates (18.4% \u2192 34.2%) while suppressing 35% of low-value LLM calls. These findings demonstrate that behavioral signals alone can meaningfully improve both user experience and system efficiency in LLM-assisted programming, highlighting the value of timing-aware, privacy-preserving adaptation mechanisms. The filter operates solely on pre-invocation editor telemetry and never inspects code or prompts.",
							"pageNumber": 113,
							"isPageNumberRoman": false
						},
						{
							"eid": "69iRFq04ySkWddK7zcxt8K",
							"type": "authorPaper",
							"text": "On Effectiveness of Formal Model Repair by Large Language Models",
							"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a121/850300a121.pdf",
							"extraLocations": [],
							"authorNames": "Sebasti\u00E3o Carvalho (Instituto Superior T\u00E9cnico, Portugal), Tsutomu Kobayashi (Japan Aerospace Exploration Agency, Japan), Fuyuki Ishikawa (National Institute of Informatics, Japan)",
							"abstract": "The use of formal methods is a significant contribution to developing trustworthy software; however, it can be a complex task. For this, automation with generative artificial intelligence models, such as Large Language Models (LLMs), is considered a promising approach. We studied the use of LLMs to generate repairs for faulty formal models of the Event-B formalism. To repair faulty Event-B models, we propose a System Prompt that contains constraints on how to suggest repairs that respect the syntax and rules of the Event-B language. We also propose Retry Prompts, a type of prompt that aims to refine a repair suggested by an LLM by highlighting errors in previous responses. To evaluate our method, we developed a tool that generates faulty models (mutants) from existing correct models by removing a single action or guard predicate. The tool then interacts with an LLM to obtain a suggested repair for the mutant model. After modifying the model according to the suggestions from the LLM, we evaluate the correctness of the modified model. The results demonstrate that using Retry Prompts significantly increases the success rate of the suggested repairs, with over 80% of the faulty models in our dataset being successfully repaired. The results also indicated directions of possible future improvements, such as combining Generative AI with formal approaches to repair failing cases.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW) ASEW 2025 On Effectiveness of Formal Model Repair by Large Language Models 1759747755306 10.1109/ASEW67777.2025.00033 Sebasti\u00E3o Carvalho Instituto Superior T\u00E9cnico, Portugal sebastiaovscarvalho@tecnico.ulisboa.pt Tsutomu Kobayashi Japan Aerospace Exploration Agency, Japan kobayashi.tsutomu@jaxa.jp Fuyuki Ishikawa National Institute of Informatics, Japan f-ishikawa@nii.ac.jp theorem proving large language models event-b The use of formal methods is a significant contribution to developing trustworthy software; however, it can be a complex task. For this, automation with generative artificial intelligence models, such as Large Language Models (LLMs), is considered a promising approach. We studied the use of LLMs to generate repairs for faulty formal models of the Event-B formalism. To repair faulty Event-B models, we propose a System Prompt that contains constraints on how to suggest repairs that respect the syntax and rules of the Event-B language. We also propose Retry Prompts, a type of prompt that aims to refine a repair suggested by an LLM by highlighting errors in previous responses. To evaluate our method, we developed a tool that generates faulty models (mutants) from existing correct models by removing a single action or guard predicate. The tool then interacts with an LLM to obtain a suggested repair for the mutant model. After modifying the model according to the suggestions from the LLM, we evaluate the correctness of the modified model. The results demonstrate that using Retry Prompts significantly increases the success rate of the suggested repairs, with over 80% of the faulty models in our dataset being successfully repaired. The results also indicated directions of possible future improvements, such as combining Generative AI with formal approaches to repair failing cases.",
							"pageNumber": 121,
							"isPageNumberRoman": false
						},
						{
							"eid": "4WEzZ6gcjF8aaWzTOyS3vq",
							"type": "authorPaper",
							"text": "Regression Testing Skill Transfer to Industry: A Preliminary Study in Higher Education",
							"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a129/850300a129.pdf",
							"extraLocations": [],
							"authorNames": "Andrada-Mihaela-Nicoleta Moldovan (Babe\u0219-Bolyai University, Romania), Andreea Vescan (Babe\u0219-Bolyai University, Romania)",
							"abstract": "Regression testing is essential for software maintenance, but is often underrepresented in higher education. This study examines the understanding and application of regression testing among 176 third-year computer science students. Using the Goal-Question-Metric (GQM) framework, we conducted an empirical study with three tasks: test suite creation, bug fixing, and regression test selection, alongside questionnaires with open-ended, closed-ended, and Likert-scale responses. Results show that students mainly selected tests based on changes, affected methods, and dependencies, while reporting positive experiences with teamwork, problem-solving, and skill development. The findings highlight the value of hands-on, collaborative activities in reinforcing both technical and soft skills, suggesting that structured regression exercises can bridge the gap between academic instruction and industry needs.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW) ASEW 2025 Regression Testing Skill Transfer to Industry: A Preliminary Study in Higher Education 1759388166528 10.1109/ASEW67777.2025.00034 Andrada-Mihaela-Nicoleta Moldovan Babe\u0219-Bolyai University, Romania andrada.moldovan@ubbcluj.ro Andreea Vescan Babe\u0219-Bolyai University, Romania andreea.vescan@ubbcluj.ro regression testing test case design software testing education Regression testing is essential for software maintenance, but is often underrepresented in higher education. This study examines the understanding and application of regression testing among 176 third-year computer science students. Using the Goal-Question-Metric (GQM) framework, we conducted an empirical study with three tasks: test suite creation, bug fixing, and regression test selection, alongside questionnaires with open-ended, closed-ended, and Likert-scale responses. Results show that students mainly selected tests based on changes, affected methods, and dependencies, while reporting positive experiences with teamwork, problem-solving, and skill development. The findings highlight the value of hands-on, collaborative activities in reinforcing both technical and soft skills, suggesting that structured regression exercises can bridge the gap between academic instruction and industry needs.",
							"pageNumber": 129,
							"isPageNumberRoman": false
						},
						{
							"eid": "3xsZ560IlEN9N8z88uIMZz",
							"type": "authorPaper",
							"text": "ForeSPECT: A Model-Driven Framework for Validation and Traceability in Forecasting Systems",
							"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a137/850300a137.pdf",
							"extraLocations": [],
							"authorNames": "Rijul Saini (NAV CANADA, Canada)",
							"abstract": "Organizations increasingly rely on forecasting systems to anticipate future conditions and inform their strategic planning. However, current practices for specifications of these systems are scattered across workflows. Moreover, these specifications are either loosely defined or tied to data representation formats that lack domain awareness and offer only superficial validation. These limitations make it difficult to ensure correctness, enforce compliance, and trace qualitative adjustments across forecasting workflows. To address these challenges, we propose ForeSPECT, a model-driven framework for Forecasting with Semantic Provenance, Evaluation, Compliance, and Traceability. The framework introduces a metamodel that serves as the foundation for semantic validation and adjustments traceability, enabling early detection of domain-specific inconsistencies that conventional schema-based rules often miss. Our approach shows promise based on evaluation with nine unseen real-world datasets, achieving 77.7% mapping coverage between the metamodel and actual time-series record entities. It further demonstrates better performance in detecting errors earlier than pipeline-based methods, while ensuring 100% forward and 91% backward traceability of adjustments.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW) ASEW 2025 ForeSPECT: A Model-Driven Framework for Validation and Traceability in Forecasting Systems 1759749422575 10.1109/ASEW67777.2025.00035 Rijul Saini NAV CANADA, Canada Rijul.Saini@navcanada.ca forecasting scenarios analysis domain specific language modelling Organizations increasingly rely on forecasting systems to anticipate future conditions and inform their strategic planning. However, current practices for specifications of these systems are scattered across workflows. Moreover, these specifications are either loosely defined or tied to data representation formats that lack domain awareness and offer only superficial validation. These limitations make it difficult to ensure correctness, enforce compliance, and trace qualitative adjustments across forecasting workflows. To address these challenges, we propose ForeSPECT, a model-driven framework for Forecasting with Semantic Provenance, Evaluation, Compliance, and Traceability. The framework introduces a metamodel that serves as the foundation for semantic validation and adjustments traceability, enabling early detection of domain-specific inconsistencies that conventional schema-based rules often miss. Our approach shows promise based on evaluation with nine unseen real-world datasets, achieving 77.7% mapping coverage between the metamodel and actual time-series record entities. It further demonstrates better performance in detecting errors earlier than pipeline-based methods, while ensuring 100% forward and 91% backward traceability of adjustments.",
							"pageNumber": 137,
							"isPageNumberRoman": false
						},
						{
							"eid": "p9UwjZCzVrMiZf4DdSbF6",
							"type": "authorPaper",
							"text": "BMuzz: Combining Bounded Model Checking and Fuzzing to Enhance Code Coverage",
							"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a145/850300a145.pdf",
							"extraLocations": [],
							"authorNames": "Markus Krahl (University of Applied Sciences Munich, Germany), Matthias G\u00FCdemann (University of Applied Sciences Munich, Germany), Stefan Wallentowitz (University of Applied Sciences Munich, Germany)",
							"abstract": "In safety-critical domains, extensive software testing is required to validate functional properties and meet standards such as ISO-26262 and DO-178C, which mandate strict code coverage levels. Uncovered code sections may indicate insufficient testing or unreachable code, leaving latent defects undetected. Traditional coverage tools reveal such gaps but cannot determine their cause. Fuzzing effectively discovers bugs but cannot prove unreachability, while bounded model checking (BMC) can formally prove unreachability and generate test cases but inherently underapproximates program behavior due to bounded exploration. We present a hybrid testing framework, BMuzz, that combines fuzzing and BMC in a concurrent, automated workflow. It measures baseline coverage, instruments uncovered regions, and applies both techniques to either generate additional inputs or prove unreachability. The resulting tests and proofs help identify untested requirements, requirement violations, and dead code. Applied to a subset of an industrial-grade C standard library for embedded automotive systems, our approach achieves more efficient coverage than standalone fuzzing or BMC, while also identifying unreachable code and specific decision constellations, demonstrating its potential for broader adoption in safety-critical domains.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW) ASEW 2025 BMuzz: Combining Bounded Model Checking and Fuzzing to Enhance Code Coverage 1759386324798 10.1109/ASEW67777.2025.00036 Markus Krahl University of Applied Sciences Munich, Germany markus.krahl@hm.edu Matthias G\u00FCdemann University of Applied Sciences Munich, Germany matthias.guedemann@hm.edu Stefan Wallentowitz University of Applied Sciences Munich, Germany stefan.wallentowitz@hm.edu In safety-critical domains, extensive software testing is required to validate functional properties and meet standards such as ISO-26262 and DO-178C, which mandate strict code coverage levels. Uncovered code sections may indicate insufficient testing or unreachable code, leaving latent defects undetected. Traditional coverage tools reveal such gaps but cannot determine their cause. Fuzzing effectively discovers bugs but cannot prove unreachability, while bounded model checking (BMC) can formally prove unreachability and generate test cases but inherently underapproximates program behavior due to bounded exploration. We present a hybrid testing framework, BMuzz, that combines fuzzing and BMC in a concurrent, automated workflow. It measures baseline coverage, instruments uncovered regions, and applies both techniques to either generate additional inputs or prove unreachability. The resulting tests and proofs help identify untested requirements, requirement violations, and dead code. Applied to a subset of an industrial-grade C standard library for embedded automotive systems, our approach achieves more efficient coverage than standalone fuzzing or BMC, while also identifying unreachable code and specific decision constellations, demonstrating its potential for broader adoption in safety-critical domains.",
							"pageNumber": 145,
							"isPageNumberRoman": false
						},
						{
							"eid": "7znzUB8ZeMY14b6yM8t1UK",
							"type": "authorPaper",
							"text": "Improving Automated Program Verification for Java Programs with Fuzzing",
							"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a153/850300a153.pdf",
							"extraLocations": [],
							"authorNames": "Soha Hussein (Ain Shams University, Egypt), Stephen McCamant (University of Minnesota, USA)",
							"abstract": "Formal verification of programs has long been used to provide rigorous correctness guarantees on program behavior. However, the scalability of these techniques is limited, as they require appropriate encoding for various program constructs\u2014encodings that are often unavailable in practice, or may grow in complexity, making them difficult to solve using these techniques. On the other hand, coverage-guided fuzzing (CGF) is a random testing technique that uses program coverage to select and prioritize inputs. While it can scale to more complex programs\u2014as it does not require any state encoding\u2014this very characteristic makes it fall short in providing correctness guarantees, as it is, by definition, an incomplete approach. In this paper, we propose improving automated program verification for Java programs using program fuzzing to find counterexamples. More precisely, we adapt a coverage-guided fuzzing tool to be used on verification tasks from the top software verification competition (SV-COMP). Our results show the advantages of using fuzzing in verification, either due to the difficulty or absence of appropriate verification summarization for certain program functions, or when path/state explosion becomes a bottleneck. ",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW) ASEW 2025 Improving Automated Program Verification for Java Programs with Fuzzing 1759688382340 10.1109/ASEW67777.2025.00037 Soha Hussein Ain Shams University, Egypt soha.hussein@cis.asu.edu.eg Stephen McCamant University of Minnesota, USA mccamant@cs.umn.edu program verification fuzzing symbolic execution testing program analysis Formal verification of programs has long been used to provide rigorous correctness guarantees on program behavior. However, the scalability of these techniques is limited, as they require appropriate encoding for various program constructs\u2014encodings that are often unavailable in practice, or may grow in complexity, making them difficult to solve using these techniques. On the other hand, coverage-guided fuzzing (CGF) is a random testing technique that uses program coverage to select and prioritize inputs. While it can scale to more complex programs\u2014as it does not require any state encoding\u2014this very characteristic makes it fall short in providing correctness guarantees, as it is, by definition, an incomplete approach. In this paper, we propose improving automated program verification for Java programs using program fuzzing to find counterexamples. More precisely, we adapt a coverage-guided fuzzing tool to be used on verification tasks from the top software verification competition (SV-COMP). Our results show the advantages of using fuzzing in verification, either due to the difficulty or absence of appropriate verification summarization for certain program functions, or when path/state explosion becomes a bottleneck.",
							"pageNumber": 153,
							"isPageNumberRoman": false
						},
						{
							"eid": "5jTDLzBgh6Fiw4z4iv1ZtQ",
							"type": "authorPaper",
							"text": "MicroViSim: Simulation and Visualization of Kubernetes-Based Microservice Systems",
							"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a161/850300a161.pdf",
							"extraLocations": [],
							"authorNames": "Wei-Kai Lin (National Taiwan Ocean University, Taiwan), Shang-Pin Ma (National Taiwan Ocean University, Taiwan), Shin-Jie Lee (National Cheng Kung University, Taiwan), Wen-Tin Lee (National Kaohsiung Normal University, Taiwan)",
							"abstract": "Microservice architecture has emerged as the dominant architectural pattern for modern software systems, offering scalability, modularity, and fault tolerance. However, its highly distributed and interdependent nature makes evaluating architectural designs and proposed changes increasingly complex. This paper presents MicroViSim, a lightweight tool for simulating load and visualizing service dependencies and performance metrics in Kubernetes-based microservice systems. MicroViSim enables developers and operators to pre-evaluate new or evolving architectures prior to deployment by generating service dependency graphs, performance indicators, and load simulation results from user-defined YAML configurations. These visual insights help uncover potential bottlenecks and performance risks early in the design phase, thereby reducing future maintenance costs and the likelihood of system failures. Experiments using a real-world microservice application, Bookinfo, demonstrate that MicroViSim effectively identifies architectural weaknesses and supports informed deployment decisions.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW) ASEW 2025 MicroViSim: Simulation and Visualization of Kubernetes-Based Microservice Systems 1759631889889 10.1109/ASEW67777.2025.00038 Wei-Kai Lin National Taiwan Ocean University, Taiwan 11257005@mail.ntou.edu.tw Shang-Pin Ma National Taiwan Ocean University, Taiwan albert@ntou.edu.tw Shin-Jie Lee National Cheng Kung University, Taiwan jielee@mail.ncku.edu.tw Wen-Tin Lee National Kaohsiung Normal University, Taiwan wtlee@nknu.edu.tw microservices architecture visualization kubernetes load simulation system design evaluation Microservice architecture has emerged as the dominant architectural pattern for modern software systems, offering scalability, modularity, and fault tolerance. However, its highly distributed and interdependent nature makes evaluating architectural designs and proposed changes increasingly complex. This paper presents MicroViSim, a lightweight tool for simulating load and visualizing service dependencies and performance metrics in Kubernetes-based microservice systems. MicroViSim enables developers and operators to pre-evaluate new or evolving architectures prior to deployment by generating service dependency graphs, performance indicators, and load simulation results from user-defined YAML configurations. These visual insights help uncover potential bottlenecks and performance risks early in the design phase, thereby reducing future maintenance costs and the likelihood of system failures. Experiments using a real-world microservice application, Bookinfo, demonstrate that MicroViSim effectively identifies architectural weaknesses and supports informed deployment decisions.",
							"pageNumber": 161,
							"isPageNumberRoman": false
						},
						{
							"eid": "40sGwknKPPuPduvhh944Sl",
							"type": "authorPaper",
							"text": "VeriODD: From YAML to SMT-LIB \u2013 Automating Verification of Operational Design Domains",
							"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a165/850300a165.pdf",
							"extraLocations": [],
							"authorNames": "Bassel Rafie (Clausthal University of Technology, Germany), Christian Schindler (Clausthal University of Technology, Germany), Andreas Rausch (Clausthal University of Technology, Germany)",
							"abstract": "Operational Design Domains (ODDs) define the conditions under which an Automated Driving System (ADS) is allowed to operate, while Current Operational Domains (CODs) capture the actual runtime situation. Ensuring that a COD instance lies within the ODD is a crucial step in safety assurance. Today, ODD and COD specifications are frequently expressed in YAML to remain accessible for stakeholders, but such descriptions are not directly suitable for solver-based verification. Manual translation into formal languages such as SMT-LIB is slow and error-prone. We present VeriODD, a tool that automates this translation. VeriODD uses ANTLR-based compiler technology to transform YAML-based ODD/COD specifications into both human-readable propositional logic, for lightweight review on a simple basis, and solver-ready SMT-LIB. The tool integrates with SMT solvers such as Z3 to provide automated consistency checks of ODD specifications and verification of COD conformance. A graphical user interface supports editing specifications, inspecting generated formulas, and performing verification with a single click. VeriODD thereby closes the gap between stakeholder-friendly ODD/COD notations and formal verification, enabling scalable and automated assurance of operational boundaries in autonomous driving. Video demonstration: https://youtu.be/odRacNoL_Pk Tool available at: https://github.com/BasselRafie/VeriODD",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW) ASEW 2025 VeriODD: From YAML to SMT-LIB \u2013 Automating Verification of Operational Design Domains 1759580615002 10.1109/ASEW67777.2025.00039 Bassel Rafie Clausthal University of Technology, Germany bassel.rafie@tu-clausthal.de Christian Schindler Clausthal University of Technology, Germany christian.schindler@tu-clausthal.de Andreas Rausch Clausthal University of Technology, Germany andreas.rausch@tu-clausthal.de operational design domain automated driving systems safety-critical systems formal verification antlr Operational Design Domains (ODDs) define the conditions under which an Automated Driving System (ADS) is allowed to operate, while Current Operational Domains (CODs) capture the actual runtime situation. Ensuring that a COD instance lies within the ODD is a crucial step in safety assurance. Today, ODD and COD specifications are frequently expressed in YAML to remain accessible for stakeholders, but such descriptions are not directly suitable for solver-based verification. Manual translation into formal languages such as SMT-LIB is slow and error-prone. We present VeriODD, a tool that automates this translation. VeriODD uses ANTLR-based compiler technology to transform YAML-based ODD/COD specifications into both human-readable propositional logic, for lightweight review on a simple basis, and solver-ready SMT-LIB. The tool integrates with SMT solvers such as Z3 to provide automated consistency checks of ODD specifications and verification of COD conformance. A graphical user interface supports editing specifications, inspecting generated formulas, and performing verification with a single click. VeriODD thereby closes the gap between stakeholder-friendly ODD/COD notations and formal verification, enabling scalable and automated assurance of operational boundaries in autonomous driving. Video demonstration: https://youtu.be/odRacNoL_Pk Tool available at: https://github.com/BasselRafie/VeriODD",
							"pageNumber": 165,
							"isPageNumberRoman": false
						},
						{
							"eid": "4txINGo3iTGBgIrZgue1Sa",
							"type": "authorPaper",
							"text": "LLM-Assisted Tool for Joint Generation of Formulas and Functions in Rule-Based Verification of Map Transformations",
							"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a169/850300a169.pdf",
							"extraLocations": [],
							"authorNames": "Ruidi He (Technische Universit\u00E4t Clausthal, Germany), Yu Zhang (Technische Universit\u00E4t Clausthal, Germany), Meng Zhang (Technische Universit\u00E4t Clausthal, Germany), Andreas Rausch (Technische Universit\u00E4t Clausthal, Germany)",
							"abstract": "High-definition map transformations are essential in autonomous driving systems, enabling interoperability across tools. Ensuring their semantic correctness is challenging, since existing rule-based frameworks rely on manually written formulas and domain-specific functions, limiting scalability. In this paper, We present an LLM-assisted pipeline that jointly generates logical formulas and corresponding executable predicates within a computational FOL framework, extending the map verifier in CommonRoad scenario designer with elevation support. The pipeline leverages prompt-based LLM generation to produce grammar-compliant rules and predicates that integrate directly into the existing system. We implemented a prototype and evaluated it on synthetic bridge and slope scenarios. The results indicate reduced manual engineering effort while preserving correctness, demonstrating the feasibility of a scalable, semi-automated human-in-the-loop approach to map-transformation verification.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW) ASEW 2025 LLM-Assisted Tool for Joint Generation of Formulas and Functions in Rule-Based Verification of Map Transformations 1759604186305 10.1109/ASEW67777.2025.00040 Ruidi He Technische Universit\u00E4t Clausthal, Germany ruidi.he@tu-clausthal.de Yu Zhang Technische Universit\u00E4t Clausthal, Germany yu.zhang.1@tu-clausthal.de Meng Zhang Technische Universit\u00E4t Clausthal, Germany meng.zhang@tu-clausthal.de Andreas Rausch Technische Universit\u00E4t Clausthal, Germany andreas.rausch@tu-clausthal.de Autonomous driving map transformation rulebased verification large language models first-order logic High-definition map transformations are essential in autonomous driving systems, enabling interoperability across tools. Ensuring their semantic correctness is challenging, since existing rule-based frameworks rely on manually written formulas and domain-specific functions, limiting scalability. In this paper, We present an LLM-assisted pipeline that jointly generates logical formulas and corresponding executable predicates within a computational FOL framework, extending the map verifier in CommonRoad scenario designer with elevation support. The pipeline leverages prompt-based LLM generation to produce grammar-compliant rules and predicates that integrate directly into the existing system. We implemented a prototype and evaluated it on synthetic bridge and slope scenarios. The results indicate reduced manual engineering effort while preserving correctness, demonstrating the feasibility of a scalable, semi-automated human-in-the-loop approach to map-transformation verification.",
							"pageNumber": 169,
							"isPageNumberRoman": false
						}
					],
					"pageNumber": "",
					"isPageNumberRoman": false,
					"chair": null
				},
				{
					"class": "SD",
					"type": "SD_SESSION",
					"title": "Ex-ASE 2025 -\u00A01st International Workshop on Explainable Automated Software Engineering",
					"lineItems": [
						{
							"eid": "51FWiFwr820pqQi7q0AlWv",
							"type": "authorPaper",
							"text": "Message from the Ex-ASE 2025 Chairs",
							"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a173/850300a173.pdf",
							"extraLocations": [],
							"authorNames": "",
							"abstract": "",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW) ASEW 2025 Message from the Ex-ASE 2025 Chairs 10.1109/ASEW67777.2025.00041",
							"pageNumber": 173,
							"isPageNumberRoman": false
						},
						{
							"eid": "dvLkvrK8iWGIVAKeN3Jms",
							"type": "authorPaper",
							"text": "K-SNAC: Robust Neuron Coverage for OOD Generalization and Test Adequacy",
							"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a176/850300a176.pdf",
							"extraLocations": [],
							"authorNames": "Seungwon Woo (University of Seoul, South Korea), Hyunseo Shin (University of Seoul, South Korea), Eunkyung Choi (University of Seoul, South Korea), Juheon Kang (University of Seoul, South Korea), Wonseok Hwang (University of Seoul, South Korea)",
							"abstract": "The rigorous testing of Deep Neural Networks (DNNs) is essential for their deployment in safety-critical applications. Neuron coverage criteria have been widely adopted for test adequacy, yet popular metrics such as Strong Neuron Activation Coverage (SNAC) suffer from a critical flaw: their reliance on a single maximum activation value makes them unstable, sensitive to the size of test set and outliers, and weakly correlated with robustness. To address this limitation, we propose K-SNAC, a distribution-aware coverage metric that replaces the unstable maximum threshold with a statistically grounded one derived from the mean and standard deviation of neuron pre-activations. We theoretically analyze the instability of SNAC and empirically demonstrate that K-SNAC achieves significantly stronger correlations with established robustness measures, while also maintaining low dependence on test set size. Furthermore, we validate the effectiveness of K-SNAC as an indicator of Out-of-Distribution (OOD) generalization, showing that it better aligns with existing OOD metrics than prior coverage criteria. Together, these results establish K-SNAC as a reliable and robust adequacy measure that bridges test coverage, robustness evaluation, and OOD generalization.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW) ASEW 2025 K-SNAC: Robust Neuron Coverage for OOD Generalization and Test Adequacy 1759605416293 10.1109/ASEW67777.2025.00042 Seungwon Woo University of Seoul, South Korea wsw20047@uos.ac.kr Hyunseo Shin University of Seoul, South Korea hseo98@uos.ac.kr Eunkyung Choi University of Seoul, South Korea rmarud202@uos.ac.kr Juheon Kang University of Seoul, South Korea 2715wngjs@uos.ac.kr Wonseok Hwang University of Seoul, South Korea wonseok.hwang@uos.ac.kr deep learning neuron coverage test adequacy adversarial robustness ood generalization The rigorous testing of Deep Neural Networks (DNNs) is essential for their deployment in safety-critical applications. Neuron coverage criteria have been widely adopted for test adequacy, yet popular metrics such as Strong Neuron Activation Coverage (SNAC) suffer from a critical flaw: their reliance on a single maximum activation value makes them unstable, sensitive to the size of test set and outliers, and weakly correlated with robustness. To address this limitation, we propose K-SNAC, a distribution-aware coverage metric that replaces the unstable maximum threshold with a statistically grounded one derived from the mean and standard deviation of neuron pre-activations. We theoretically analyze the instability of SNAC and empirically demonstrate that K-SNAC achieves significantly stronger correlations with established robustness measures, while also maintaining low dependence on test set size. Furthermore, we validate the effectiveness of K-SNAC as an indicator of Out-of-Distribution (OOD) generalization, showing that it better aligns with existing OOD metrics than prior coverage criteria. Together, these results establish K-SNAC as a reliable and robust adequacy measure that bridges test coverage, robustness evaluation, and OOD generalization.",
							"pageNumber": 176,
							"isPageNumberRoman": false
						},
						{
							"eid": "1QoZnWw3PMw7EFtUBmv9oZ",
							"type": "authorPaper",
							"text": "SeedUI: Understanding Initial Seeds in Fuzzing",
							"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a181/850300a181.pdf",
							"extraLocations": [],
							"authorNames": "Sriteja Kummita (Paderborn University Germany), Eric Bodden (Paderborn University, Germany), Miao Miao (University of Texas at Dallas, USA), Shiyi Wei (University of Texas at Dallas, USA)",
							"abstract": "Greybox fuzzing, a widely used dynamic testing technique, iteratively tests the software using semi-randomly generated inputs that aim at reaching more code at runtime. It relies on a set of initial inputs (initial seeds) to bootstrap the fuzzing process. These initial seeds highly influence the fuzzing performance in terms of runtime coverage or finding bugs. This paper introduces SeedUI, a tool that helps in visualizing and understanding the performance of initial seeds across multiple fuzzing campaigns. It provides five different views that help a user for an in-depth initial seed analysis. In our previous work, we extracted a visualization task taxonomy for greybox fuzzing by interviewing 33 fuzzing experts and analyzing the responses. We evaluate SeedUI along with four existing tools: VisFuzz, FuzzSplore, FuzzInspector, and IjonUI, in terms of their support to the taxonomy. Our findings indicate that SeedUI complements existing tools by addressing 9 tasks in the taxonomy that are not supported by them.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW) ASEW 2025 SeedUI: Understanding Initial Seeds in Fuzzing 1759569351183 10.1109/ASEW67777.2025.00043 Sriteja Kummita Paderborn University Germany sriteja.kummita@uni-paderborn.de Eric Bodden Paderborn University, Germany eric.bodden@uni-paderborn.de Miao Miao University of Texas at Dallas, USA mmiao@utdallas.edu Shiyi Wei University of Texas at Dallas, USA swei@utdallas.edu visualization greybox fuzzing initial seeds Greybox fuzzing, a widely used dynamic testing technique, iteratively tests the software using semi-randomly generated inputs that aim at reaching more code at runtime. It relies on a set of initial inputs (initial seeds) to bootstrap the fuzzing process. These initial seeds highly influence the fuzzing performance in terms of runtime coverage or finding bugs. This paper introduces SeedUI, a tool that helps in visualizing and understanding the performance of initial seeds across multiple fuzzing campaigns. It provides five different views that help a user for an in-depth initial seed analysis. In our previous work, we extracted a visualization task taxonomy for greybox fuzzing by interviewing 33 fuzzing experts and analyzing the responses. We evaluate SeedUI along with four existing tools: VisFuzz, FuzzSplore, FuzzInspector, and IjonUI, in terms of their support to the taxonomy. Our findings indicate that SeedUI complements existing tools by addressing 9 tasks in the taxonomy that are not supported by them.",
							"pageNumber": 181,
							"isPageNumberRoman": false
						},
						{
							"eid": "3Ulg9TJmaOPmllVLCOi12T",
							"type": "authorPaper",
							"text": "From Facts to Foils: Designing and Evaluating Counterfactual Explanations for Smart Environments",
							"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a186/850300a186.pdf",
							"extraLocations": [],
							"authorNames": "Anna Trapp (University of Cologne, Germany), Mersedeh Sadeghi (University of Cologne, Germany), Andreas Vogelsang (University of Duisburg-Essen, Germany)",
							"abstract": "Explainability is increasingly seen as an essential feature of rule-based smart environments. While counterfactual explanations, which describe what could have been done differently to achieve a desired outcome, are a powerful tool in eXplainable AI (XAI), no established methods exist for generating them in these rule-based domains. In this paper, we present the first formalization and implementation of counterfactual explanations tailored to this domain. It is implemented as a plugin that extends an existing explanation engine for smart environments. We conducted a user study (N=17) to evaluate our generated counterfactuals against traditional causal explanations. The results show that user preference is highly contextual: causal explanations are favored for their linguistic simplicity and in time-pressured situations, while counterfactuals are preferred for their actionable content, particularly when a user wants to resolve a problem. Our work contributes a practical framework for a new type of explanation in smart environments and provides empirical evidence to guide the choice of when each explanation type is most effective.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW) ASEW 2025 From Facts to Foils: Designing and Evaluating Counterfactual Explanations for Smart Environments 1759457331341 10.1109/ASEW67777.2025.00044 Anna Trapp University of Cologne, Germany atrapp2@smail.uni-koeln.de Mersedeh Sadeghi University of Cologne, Germany mersedeh.sadeghi@uni-koeln.de Andreas Vogelsang University of Duisburg-Essen, Germany andreas.vogelsang@uni-due.de explanation explainable systems counterfactual explanation smart environment Explainability is increasingly seen as an essential feature of rule-based smart environments. While counterfactual explanations, which describe what could have been done differently to achieve a desired outcome, are a powerful tool in eXplainable AI (XAI), no established methods exist for generating them in these rule-based domains. In this paper, we present the first formalization and implementation of counterfactual explanations tailored to this domain. It is implemented as a plugin that extends an existing explanation engine for smart environments. We conducted a user study (N=17) to evaluate our generated counterfactuals against traditional causal explanations. The results show that user preference is highly contextual: causal explanations are favored for their linguistic simplicity and in time-pressured situations, while counterfactuals are preferred for their actionable content, particularly when a user wants to resolve a problem. Our work contributes a practical framework for a new type of explanation in smart environments and provides empirical evidence to guide the choice of when each explanation type is most effective.",
							"pageNumber": 186,
							"isPageNumberRoman": false
						},
						{
							"eid": "5KUswMvl3wTNLo6so18ZZD",
							"type": "authorPaper",
							"text": "Explaining Software Vulnerabilities with Large Language Models",
							"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a194/850300a194.pdf",
							"extraLocations": [],
							"authorNames": "Oshando Johnson (Fraunhofer IEM, Germany), Alexandra Fomina (Chapman University, United States), Ranjith Krishnamurthy (Fraunhofer IEM, Germany), Vaibhav Chaudhari (Paderborn University, Germany), Rohith Kumar Shanmuganathan (University of Oldenburg, Germany), Eric Bodden (Paderborn University and Fraunhofer IEM, Germany)",
							"abstract": "The prevalence of security vulnerabilities has prompted companies to adopt static application security testing (SAST) tools for vulnerability detection. The prevalence of security vulnerabilities has prompted companies to adopt static application security testing (SAST) tools for vulnerability detection. Nevertheless, these tools frequently exhibit usability limitations, as their generic warning messages do not sufficiently communicate important information to developers, resulting in misunderstandings or oversight of critical findings. In light of recent developments in Large Language Models (LLMs) and their text generation capabilities, our work investigates a hybrid approach that uses LLMs to tackle the SAST explainability challenges. In this paper, we present SAFE, an Integrated Development Environment (IDE) plugin that leverages GPT-4o to explain the causes, impacts, and mitigation strategies of vulnerabilities detected by SAST tools. Our expert user study findings indicate that the explanations generated by SAFE can significantly assist beginner to intermediate developers in understanding and addressing security vulnerabilities, thereby improving the overall usability of SAST tools.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW) ASEW 2025 Explaining Software Vulnerabilities with Large Language Models 1759826214443 10.1109/ASEW67777.2025.00045 Oshando Johnson Fraunhofer IEM, Germany oshando.johnson@iem.fraunhofer.de Alexandra Fomina Chapman University, United States fomina@chapman.edu Ranjith Krishnamurthy Fraunhofer IEM, Germany ranjith.krishnamurthy@iem.fraunhofer.de Vaibhav Chaudhari Paderborn University, Germany vaibhav.chaudhari@uni-paderborn.de Rohith Kumar Shanmuganathan University of Oldenburg, Germany rohith.shanmuganathan@uol.de Eric Bodden Paderborn University and Fraunhofer IEM, Germany eric.bodden@uni-paderborn.de vulnerability explanation static analysis large language models explainability vulnerability detection The prevalence of security vulnerabilities has prompted companies to adopt static application security testing (SAST) tools for vulnerability detection. The prevalence of security vulnerabilities has prompted companies to adopt static application security testing (SAST) tools for vulnerability detection. Nevertheless, these tools frequently exhibit usability limitations, as their generic warning messages do not sufficiently communicate important information to developers, resulting in misunderstandings or oversight of critical findings. In light of recent developments in Large Language Models (LLMs) and their text generation capabilities, our work investigates a hybrid approach that uses LLMs to tackle the SAST explainability challenges. In this paper, we present SAFE, an Integrated Development Environment (IDE) plugin that leverages GPT-4o to explain the causes, impacts, and mitigation strategies of vulnerabilities detected by SAST tools. Our expert user study findings indicate that the explanations generated by SAFE can significantly assist beginner to intermediate developers in understanding and addressing security vulnerabilities, thereby improving the overall usability of SAST tools.",
							"pageNumber": 194,
							"isPageNumberRoman": false
						},
						{
							"eid": "7MXG1R68FSGeBf01Te9EY0",
							"type": "authorPaper",
							"text": "Explaining Code Risk in OSS: Towards LLM-Generated Fault Prediction Interpretations",
							"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a199/850300a199.pdf",
							"extraLocations": [],
							"authorNames": "Elijah Kayode Adejumo (George Mason University, USA), Brittany  Johnson (George Mason University, USA)",
							"abstract": "Open Source Software (OSS) has become a very important and crucial infrastructure worldwide because of the value it provides. OSS typically depends on contributions from developers across diverse backgrounds and levels of experience. Making safe changes, such as fixing a bug or implementing a new feature, can be challenging, especially in object-oriented systems where components are interdependent. Static analysis and defect-prediction tools produce metrics (e.g., complexity, coupling) that flag potentially fault-prone components, but these signals are often hard for contributors new or unfamiliar with the codebase to interpret. Large Language Models (LLMs) have shown strong performance on software engineering tasks such as code summarization and documentation generation. Building on this progress, we investigate whether LLMs can translate fault-prediction metrics into clear, human-readable risk explanations and actionable guidance to help OSS contributors plan and review code modifications. We outline explanation types that an LLM-generated assistant could provide (descriptive, contextual, and actionable explanations). We also outline our next steps to assess usefulness through a task-based study with OSS contributors, comparing metric-only baselines to LLM-generated explanations on decision quality, time-to-completion, and error rates.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW) ASEW 2025 Explaining Code Risk in OSS: Towards LLM-Generated Fault Prediction Interpretations 1759696195953 10.1109/ASEW67777.2025.00046 Elijah Kayode Adejumo George Mason University, USA eadejumo@gmu.edu Brittany Johnson George Mason University, USA johnsonb@gmu.edu LLMs Open Source Software Newcomers OSS Software Fault Proneness Prediction Open Source Software (OSS) has become a very important and crucial infrastructure worldwide because of the value it provides. OSS typically depends on contributions from developers across diverse backgrounds and levels of experience. Making safe changes, such as fixing a bug or implementing a new feature, can be challenging, especially in object-oriented systems where components are interdependent. Static analysis and defect-prediction tools produce metrics (e.g., complexity, coupling) that flag potentially fault-prone components, but these signals are often hard for contributors new or unfamiliar with the codebase to interpret. Large Language Models (LLMs) have shown strong performance on software engineering tasks such as code summarization and documentation generation. Building on this progress, we investigate whether LLMs can translate fault-prediction metrics into clear, human-readable risk explanations and actionable guidance to help OSS contributors plan and review code modifications. We outline explanation types that an LLM-generated assistant could provide (descriptive, contextual, and actionable explanations). We also outline our next steps to assess usefulness through a task-based study with OSS contributors, comparing metric-only baselines to LLM-generated explanations on decision quality, time-to-completion, and error rates.",
							"pageNumber": 199,
							"isPageNumberRoman": false
						},
						{
							"eid": "1qc8O0Kf5JKMWGQXXjTvZB",
							"type": "authorPaper",
							"text": "Explainability in Automated Cross-Domain Model-Driven Brake System Development",
							"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a204/850300a204.pdf",
							"extraLocations": [],
							"authorNames": "Nathan Hagel (Karlsruhe Institute of Technology, Germany), Johannes M\u00E4kelburg (Technische Universit\u00E4t M\u00FCnchen, Germany), Claus Hammann (Karlsruhe Institute of Technology, Germany), Thomas Weber (Karlsruhe Institute of Technology, Germany), Thomas Alexander V\u00F6lk (Karlsruhe Institute of Technology, Germany), Francesco P. Urbano (Karlsruhe Institute of Technology, Germany), Patrick Grycz (Karlsruhe Institute of Technology, Germany), Katharina Bause (Karlsruhe Institute of Technology, Germany), Minakshi Kaushik (Karlsruhe Institute of Technology, Germany), Vincenzo Scotti (Karlsruhe Institute of Technology, Germany), Akhila Bairy (Karlsruhe Institute of Technology, Germany), Maike Schwammberger (Karlsruhe Institute of Technology, Germany), Maribel Acosta (Technische Universit\u00E4t M\u00FCnchen, Germany), Albert Albers (Karlsruhe Institute of Technology, Germany), Anne Koziolek (Karlsruhe Institute of Technology, Germany), Tobias D\u00FCser (Karlsruhe Institute of Technology, Germany)",
							"abstract": "Modern engineering systems often require collaboration across multiple domains, each using different models and tools. By implementing automated processes for keeping consistency, changes propagate across these models and tools, affecting the work of various stakeholders and teams. However, an explanation of these automatically propagated changes is often required. This paper presents a case study using heterogeneous models in the development and validation of a cross-domain automotive brake system. Our case study comprises a Brake Specification Model, a Computer-Aided Design Model, a Simulation Model as well as their corresponding metamodels, and a model of a real-world test bench for brake validation. We also present a set of change and explainability scenarios that occur during the development and validation process of a cyber-physical brake system. We use these scenarios to highlight the explainability requirements and challenges which should be addressed by any explainability solutions and approaches for cross-domain engineering and validation processes in the cyber-physical system context. By providing such models and metamodels, as well as the change and explainability scenarios that use them, our work will aid researchers in validating their approaches and in investigating those development challenges which arise from cross-domain consistent cyber-physical systems development.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW) ASEW 2025 Explainability in Automated Cross-Domain Model-Driven Brake System Development 1759594222392 10.1109/ASEW67777.2025.00047 Nathan Hagel Karlsruhe Institute of Technology, Germany nathan.hagel@kit.edu Johannes M\u00E4kelburg Technische Universit\u00E4t M\u00FCnchen, Germany johannes.makelburg@tum.de Claus Hammann Karlsruhe Institute of Technology, Germany claus.hammann@kit.edu Thomas Weber Karlsruhe Institute of Technology, Germany thomas.weber@kit.edu Thomas Alexander V\u00F6lk Karlsruhe Institute of Technology, Germany thomas.voelk@kit.edu Francesco P. Urbano Karlsruhe Institute of Technology, Germany francesco.urbano@kit.edu Patrick Grycz Karlsruhe Institute of Technology, Germany patrick.grycz@kit.edu Katharina Bause Karlsruhe Institute of Technology, Germany katharina.bause@kit.edu Minakshi Kaushik Karlsruhe Institute of Technology, Germany minakshi.kaushik@kit.edu Vincenzo Scotti Karlsruhe Institute of Technology, Germany vincenzo.scotti@kit.edu Akhila Bairy Karlsruhe Institute of Technology, Germany akhila.bairy@kit.edu Maike Schwammberger Karlsruhe Institute of Technology, Germany maike.schwammberger@kit.edu Maribel Acosta Technische Universit\u00E4t M\u00FCnchen, Germany maribel.acosta@tum.de Albert Albers Karlsruhe Institute of Technology, Germany albert.albers@kit.edu Anne Koziolek Karlsruhe Institute of Technology, Germany anne.koziolek@kit.edu Tobias D\u00FCser Karlsruhe Institute of Technology, Germany tobias.dueser@kit.edu explainability automation modeling consistency metamodel view-based modeling consistency preservation Modern engineering systems often require collaboration across multiple domains, each using different models and tools. By implementing automated processes for keeping consistency, changes propagate across these models and tools, affecting the work of various stakeholders and teams. However, an explanation of these automatically propagated changes is often required. This paper presents a case study using heterogeneous models in the development and validation of a cross-domain automotive brake system. Our case study comprises a Brake Specification Model, a Computer-Aided Design Model, a Simulation Model as well as their corresponding metamodels, and a model of a real-world test bench for brake validation. We also present a set of change and explainability scenarios that occur during the development and validation process of a cyber-physical brake system. We use these scenarios to highlight the explainability requirements and challenges which should be addressed by any explainability solutions and approaches for cross-domain engineering and validation processes in the cyber-physical system context. By providing such models and metamodels, as well as the change and explainability scenarios that use them, our work will aid researchers in validating their approaches and in investigating those development challenges which arise from cross-domain consistent cyber-physical systems development.",
							"pageNumber": 204,
							"isPageNumberRoman": false
						}
					],
					"pageNumber": "",
					"isPageNumberRoman": false,
					"chair": null
				},
				{
					"class": "SD",
					"type": "SD_SESSION",
					"title": "ISE 2025 - 4th International Workshop on Intelligent Software Engineering",
					"lineItems": [
						{
							"eid": "3EWr52pGAHM4sMxGewc605",
							"type": "authorPaper",
							"text": "Message from the ISE 2025 Chairs",
							"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a212/850300a212.pdf",
							"extraLocations": [],
							"authorNames": "",
							"abstract": "",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW) ASEW 2025 Message from the ISE 2025 Chairs 10.1109/ASEW67777.2025.00048",
							"pageNumber": 212,
							"isPageNumberRoman": false
						},
						{
							"eid": "6Wwojp1f0lHwnhJwqy3Wb0",
							"type": "authorPaper",
							"text": "Optimizing LLM Code Suggestions: Feedback-Driven Timing with Lightweight State Bounds",
							"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a214/850300a214.pdf",
							"extraLocations": [],
							"authorNames": "Mohammad Nour Al Awad (ITMO University, Russia), Sergey Ivanov (ITMO University, Russia), Olga Tikhonova (ITMO University, Russia)",
							"abstract": "Large Language Models (LLMs) have transformed code auto-completion by generating context-aware suggestions. Yet, deciding when to present these suggestions remains underexplored, often leading to interruptions or wasted inference calls. We propose an adaptive timing mechanism that dynamically adjusts the delay before offering a suggestion based on real-time developer feedback. Our suggested method combines a logistic transform of recent acceptance rates with a bounded delay range, anchored by a high-level binary prediction of the developer's cognitive state. In a two-month deployment with professional developers, our system improved suggestion acceptance from 4.9% with no delay to 15.4% with static delays, and to 18.6% with adaptive timing\u2014while reducing blind rejections (rejections without being read) from 8.3% to 0.36%. Together, these improvements increase acceptance and substantially reduce wasted inference calls by 75%, making LLM-based code assistants more efficient and cost-effective in practice.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW) ASEW 2025 Optimizing LLM Code Suggestions: Feedback-Driven Timing with Lightweight State Bounds 1759303537723 10.1109/ASEW67777.2025.00049 Mohammad Nour Al Awad ITMO University, Russia mohammadnouralawad@itmo.ru Sergey Ivanov ITMO University, Russia svivanov@itmo.ru Olga Tikhonova ITMO University, Russia tikhonova_ob@itmo.ru behavioral modeling adaptive systems interaction timing human-computer interaction code completion Large Language Models (LLMs) have transformed code auto-completion by generating context-aware suggestions. Yet, deciding when to present these suggestions remains underexplored, often leading to interruptions or wasted inference calls. We propose an adaptive timing mechanism that dynamically adjusts the delay before offering a suggestion based on real-time developer feedback. Our suggested method combines a logistic transform of recent acceptance rates with a bounded delay range, anchored by a high-level binary prediction of the developer's cognitive state. In a two-month deployment with professional developers, our system improved suggestion acceptance from 4.9% with no delay to 15.4% with static delays, and to 18.6% with adaptive timing\u2014while reducing blind rejections (rejections without being read) from 8.3% to 0.36%. Together, these improvements increase acceptance and substantially reduce wasted inference calls by 75%, making LLM-based code assistants more efficient and cost-effective in practice.",
							"pageNumber": 214,
							"isPageNumberRoman": false
						},
						{
							"eid": "5TQHwCLj07JvIEXylgW4Cf",
							"type": "authorPaper",
							"text": "Leveraging Large Language Models for Use Case Model Generation from Software Requirements",
							"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a222/850300a222.pdf",
							"extraLocations": [],
							"authorNames": "Tobias Eisenreich (Technical University of Munich, Germany), Nicholas Friedlaender (Technical University of Munich, Germany), Stefan Wagner (Technical University of Munich, Germany)",
							"abstract": "Use case modeling employs user-centered scenarios to outline system requirements. These help to achieve consensus among relevant stakeholders. Because the manual creation of use case models is demanding and time-consuming, it is often skipped in practice. This study explores the potential of Large Language Models (LLMs) to assist in this tedious process. The proposed method integrates an open-weight LLM to systematically extract actors and use cases from software requirements with advanced prompt engineering techniques. The method is evaluated using an exploratory study conducted with five professional software engineers, which compares traditional manual modeling to the proposed LLM-based approach. The results show a substantial acceleration, reducing the modeling time by 60%. At the same time, the model quality remains on par. Besides improving the modeling efficiency, the participants indicated that the method provided valuable guidance in the process.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW) ASEW 2025 Leveraging Large Language Models for Use Case Model Generation from Software Requirements 1759408873683 10.1109/ASEW67777.2025.00050 Tobias Eisenreich Technical University of Munich, Germany tobias.eisenreich@tum.de Nicholas Friedlaender Technical University of Munich, Germany nicholas.friedlaender@tum.de Stefan Wagner Technical University of Munich, Germany stefan.wagner@tum.de large language models requirements engineering use case modeling ai-assisted software engineering software architecture unified modeling language Use case modeling employs user-centered scenarios to outline system requirements. These help to achieve consensus among relevant stakeholders. Because the manual creation of use case models is demanding and time-consuming, it is often skipped in practice. This study explores the potential of Large Language Models (LLMs) to assist in this tedious process. The proposed method integrates an open-weight LLM to systematically extract actors and use cases from software requirements with advanced prompt engineering techniques. The method is evaluated using an exploratory study conducted with five professional software engineers, which compares traditional manual modeling to the proposed LLM-based approach. The results show a substantial acceleration, reducing the modeling time by 60%. At the same time, the model quality remains on par. Besides improving the modeling efficiency, the participants indicated that the method provided valuable guidance in the process.",
							"pageNumber": 222,
							"isPageNumberRoman": false
						},
						{
							"eid": "2qLUiqO03Hj8jXxBkxgjc3",
							"type": "authorPaper",
							"text": "Automated Evolutionary Hyperparameter Tuning for NLP-Based Test Case Generation",
							"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a229/850300a229.pdf",
							"extraLocations": [],
							"authorNames": "Ivan Malashin (Bauman Moscow State Technical University, Russia), Igor Masich (Bauman Moscow State Technical University, Russia), Sergei Kurashkin (Bauman Moscow State Technical University, Russia), Andrei Gantimurov (Bauman Moscow State Technical University, Russia), Aleksei Borodulin (Bauman Moscow State Technical University, Russia), Vladimir Neluyb (Bauman Moscow State Technical University, Russia), Vadim Tynchenko (Bauman Moscow State Technical University, Russia)",
							"abstract": "Automated generation of executable test suites from natural-language requirements remains challenging due to linguistic ambiguity and sensitivity of generative models to decoding and training hyperparameters. This paper introduces a hierarchical, multi-level evolutionary framework that treats model hyperparameters and decoding strategies as upper-level decision variables and employs lower-level fitnesses that directly measure test-quality objectives (structural coverage, semantic diversity, redundancy, and runtime efficiency). The approach integrates retrieval-augmented grounding, surrogate-assisted preselection, lightweight LoRA adaptation and optional HIL evaluation. Empirical evaluation on PURE, PROMISE_exp and FR_NFR benchmarks (repeated runs, n=10; paired two-sided t-tests, \u03B1=0.05) shows consistent gains: on PURE mean code coverage reaches 82.4% (vs. 75.1% for Bayesian optimisation and 68.9% for random search) with 145 unique scenarios and modest runtime overhead (\u224858.3,s, \u22486% above Bayesian). Ablations confirm component effects (e.g., removing diversity reduces unique scenarios \u224818%; disabling the surrogate increases wall-clock \u224842%; disabling RAG drops grounded consistency \u224812%). Results indicate that co-optimising hyperparameters for explicit test-quality metrics, together with grounding and realistic execution, yields more useful, executable test suites. Future work will explore adaptive objective weighting, transfer warm-starts and probabilistic surrogates.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW) ASEW 2025 Automated Evolutionary Hyperparameter Tuning for NLP-Based Test Case Generation 1759422435066 10.1109/ASEW67777.2025.00051 Ivan Malashin Bauman Moscow State Technical University, Russia imalashin@emtc.ru Igor Masich Bauman Moscow State Technical University, Russia imasich@emtc.ru Sergei Kurashkin Bauman Moscow State Technical University, Russia skurashkin@emtc.ru Andrei Gantimurov Bauman Moscow State Technical University, Russia agantimurov@emtc.ru Aleksei Borodulin Bauman Moscow State Technical University, Russia alexey.borodulin@emtc.ru Vladimir Neluyb Bauman Moscow State Technical University, Russia vladimir.neluyb@emtc.ru Vadim Tynchenko Bauman Moscow State Technical University, Russia vtynchenko@emtc.ru automated test generation hyperparameter optimization evolutionary algorithms Automated generation of executable test suites from natural-language requirements remains challenging due to linguistic ambiguity and sensitivity of generative models to decoding and training hyperparameters. This paper introduces a hierarchical, multi-level evolutionary framework that treats model hyperparameters and decoding strategies as upper-level decision variables and employs lower-level fitnesses that directly measure test-quality objectives (structural coverage, semantic diversity, redundancy, and runtime efficiency). The approach integrates retrieval-augmented grounding, surrogate-assisted preselection, lightweight LoRA adaptation and optional HIL evaluation. Empirical evaluation on PURE, PROMISE_exp and FR_NFR benchmarks (repeated runs, n=10; paired two-sided t-tests, \u03B1=0.05) shows consistent gains: on PURE mean code coverage reaches 82.4% (vs. 75.1% for Bayesian optimisation and 68.9% for random search) with 145 unique scenarios and modest runtime overhead (\u224858.3,s, \u22486% above Bayesian). Ablations confirm component effects (e.g., removing diversity reduces unique scenarios \u224818%; disabling the surrogate increases wall-clock \u224842%; disabling RAG drops grounded consistency \u224812%). Results indicate that co-optimising hyperparameters for explicit test-quality metrics, together with grounding and realistic execution, yields more useful, executable test suites. Future work will explore adaptive objective weighting, transfer warm-starts and probabilistic surrogates.",
							"pageNumber": 229,
							"isPageNumberRoman": false
						},
						{
							"eid": "3OVyKnrwFQrGa5NnvZd90k",
							"type": "authorPaper",
							"text": "Towards MPC-Driven Software Adaptation: A Dual-Layer Approach Combining ICNN-Based Modeling and Delta-Based Tuning",
							"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a237/850300a237.pdf",
							"extraLocations": [],
							"authorNames": "Yitong Shi (Institute of Science Tokyo, Japan), Chenyu Hu (Institute of Science Tokyo, Japan), Mingyue Zhang (Southwest University, China), Nianyu Li (ZGC National Laboratory, China), Jialong Li (Waseda University, Japan), Kenji Tei (Institute of Science Tokyo, Japan)",
							"abstract": "Proactive self-adaptation using Model Predictive Control (MPC) is well studied for software systems operating in dynamic environments. However, its practical adoption is limited by two key challenges. First, the modeling gap: traditional MPC requires state-space models that are difficult to construct for complex software systems, often demanding extensive domain expertise and incurring high computational costs. Second, the tuning gap: configuring MPC to balance abstract and competing objectives\u2014such as performance, resource efficiency, and control stability\u2014typically relies on manual, expert-driven tuning, impeding autonomous operation. To address these challenges, we propose a dual-layer MPC framework. At the lower layer, an Input Convex Neural Network (ICNN) is used to learn complex nonlinear dynamics directly from data, enabling tractable optimization and reducing the modeling burden. At the upper layer, a delta-driven controller manager adaptively tunes the lower-layer MPC by monitoring deviations in system behavior and estimating the impact of different cost components on overall utility, thereby automating the tuning process. We evaluate our approach on SIMDEX, a job scheduling simulator, where it demonstrates superior performance over both the traditional requirements-oriented MPC framework CobRA and the non-adaptive ICNN-based controller, achieving a better balance of performance, resource efficiency, and control stability.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW) ASEW 2025 Towards MPC-Driven Software Adaptation: A Dual-Layer Approach Combining ICNN-Based Modeling and Delta-Based Tuning 1759287206501 10.1109/ASEW67777.2025.00052 Yitong Shi Institute of Science Tokyo, Japan shi.y.0a6a@m.isct.ac.jp Chenyu Hu Institute of Science Tokyo, Japan chenyuhu59@gmail.com Mingyue Zhang Southwest University, China myzhangswu@swu.edu.cn Nianyu Li ZGC National Laboratory, China li nianyu@pku.edu.cn Jialong Li Waseda University, Japan lijialong@fuji.waseda.jp Kenji Tei Institute of Science Tokyo, Japan tei@comp.isct.ac.jp self-adaptive software system proactive adaptation model predictive control Proactive self-adaptation using Model Predictive Control (MPC) is well studied for software systems operating in dynamic environments. However, its practical adoption is limited by two key challenges. First, the modeling gap: traditional MPC requires state-space models that are difficult to construct for complex software systems, often demanding extensive domain expertise and incurring high computational costs. Second, the tuning gap: configuring MPC to balance abstract and competing objectives\u2014such as performance, resource efficiency, and control stability\u2014typically relies on manual, expert-driven tuning, impeding autonomous operation. To address these challenges, we propose a dual-layer MPC framework. At the lower layer, an Input Convex Neural Network (ICNN) is used to learn complex nonlinear dynamics directly from data, enabling tractable optimization and reducing the modeling burden. At the upper layer, a delta-driven controller manager adaptively tunes the lower-layer MPC by monitoring deviations in system behavior and estimating the impact of different cost components on overall utility, thereby automating the tuning process. We evaluate our approach on SIMDEX, a job scheduling simulator, where it demonstrates superior performance over both the traditional requirements-oriented MPC framework CobRA and the non-adaptive ICNN-based controller, achieving a better balance of performance, resource efficiency, and control stability.",
							"pageNumber": 237,
							"isPageNumberRoman": false
						},
						{
							"eid": "5ty0UMgBVFdKlSz7oL5iM3",
							"type": "authorPaper",
							"text": "AI for Requirements Engineering: Industry Adoption and Practitioner Perspectives",
							"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a245/850300a245.pdf",
							"extraLocations": [],
							"authorNames": "Lekshmi Murali Rani (Chalmers University of Technology; University of Gothenburg, Sweden), Richard Berntsson Svensson (Chalmers University of Technology; University of Gothenburg, Sweden), Robert Feldt (Chalmers University of Technology; University of Gothenburg, Sweden)",
							"abstract": "The integration of AI for Requirements Engineering (RE) presents significant benefits but also poses real challenges. Although RE is fundamental to software engineering, limited research has examined AI adoption in RE. We surveyed 55 software practitioners to map AI usage across four RE phases: Elicitation, Analysis, Specification, and Validation, and four approaches for decision-making: human-only decisions, AI validation, Human\u2013AI Collaboration (HAIC), and full AI automation. Participants also shared their perceptions, challenges, and opportunities when applying AI for RE tasks. Our data show that 58.2% of respondents already use AI in RE, and 69.1% view its impact as positive or very positive. HAIC dominates practice, accounting for 54.4% of all RE techniques, while full AI automation remains minimal at 5.4%. Passive AI validation (4.4\u20136.2%) lags even further behind, indicating that practitioners value AI's active support over passive oversight. These findings suggest that AI is most effective when positioned as a collaborative partner rather than a replacement for human expertise. It also highlights the need for RE-specific HAIC frameworks along with robust and responsible AI governance as AI adoption in RE grows.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW) ASEW 2025 AI for Requirements Engineering: Industry Adoption and Practitioner Perspectives 1759433498011 10.1109/ASEW67777.2025.00053 Lekshmi Murali Rani Chalmers University of Technology; University of Gothenburg, Sweden lekshmi@chalmers.se Richard Berntsson Svensson Chalmers University of Technology; University of Gothenburg, Sweden richard@cse.gu.se Robert Feldt Chalmers University of Technology; University of Gothenburg, Sweden robert.feldt@chalmers.se requirements engineering human-ai collaboration elicitation analysis validation specification The integration of AI for Requirements Engineering (RE) presents significant benefits but also poses real challenges. Although RE is fundamental to software engineering, limited research has examined AI adoption in RE. We surveyed 55 software practitioners to map AI usage across four RE phases: Elicitation, Analysis, Specification, and Validation, and four approaches for decision-making: human-only decisions, AI validation, Human\u2013AI Collaboration (HAIC), and full AI automation. Participants also shared their perceptions, challenges, and opportunities when applying AI for RE tasks. Our data show that 58.2% of respondents already use AI in RE, and 69.1% view its impact as positive or very positive. HAIC dominates practice, accounting for 54.4% of all RE techniques, while full AI automation remains minimal at 5.4%. Passive AI validation (4.4\u20136.2%) lags even further behind, indicating that practitioners value AI's active support over passive oversight. These findings suggest that AI is most effective when positioned as a collaborative partner rather than a replacement for human expertise. It also highlights the need for RE-specific HAIC frameworks along with robust and responsible AI governance as AI adoption in RE grows.",
							"pageNumber": 245,
							"isPageNumberRoman": false
						},
						{
							"eid": "2eHHJoYEw2vBawRo1nkGUI",
							"type": "authorPaper",
							"text": "Fair Developer Score: Build-Adjusted Measurement of Effort and Impact",
							"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a253/850300a253.pdf",
							"extraLocations": [],
							"authorNames": "Xinzhou Wang (Northwestern University, United States), Jiancong Zhu (Northwestern University, United States), Jinghan Feng (Northwestern University, United States), Zixuan Zhang (Northwestern University, United States), Joshua Rauvola (University of Chicago, United States), Devon  Delgado (Digital Emissions, USA), Ahmad Antar (Digital Emissions, USA), Abid  Ali (Northwestern University, United States)",
							"abstract": "Assessing developer productivity in expansive software endeavors has become a pressing concern for both academia and industry, as organizations seek reliable ways to understand how engineering effort translates into business value. Traditional metrics\u2014such as commit frequency, lines of code, or code churn\u2014have been widely adopted but remain problematic, since they conflate inconsequential edits with architecturally significant reshaping and provide little insight into task-level contributions. To address this limitation, we introduce a commit-centric analytic framework that leverages clustering to reconfigure disbursed commit logs into coherent parcels, termed builds, that align more closely with the functional level of development tasks. Unlike prior approaches that combine heterogeneous signals such as issues, reviews, or communication logs, our method relies solely on the structural and temporal properties of commits, making it lightweight and broadly applicable. Each build is evaluated along two orthogonal axes: developer effort and build importance. Effort operationalizes the scale and character of contributions, considering code proprietorship, scope, architectural centrality, novelty, and cadence. Importance quantifies the build's systemic consequence, integrating scale of alteration, distribution of changes, architectural centrality, complexity, task priority, and proximity to release milestones. The fusion of these axes produces the Fair Developer Score, a composite benchmark reconciling personal exertion with organizational value. Validation centers on exposure-controlled, matched comparisons that pair FDS-ranked developers with commit-count peers matched on churn, files changed, and builds participated. On the Linux kernel, FDS-ranked developers exhibit significantly higher Average Importance and Average Effort than volume-matched peers, with lower rework trends. Cross-repository analyses across Kubernetes, TensorFlow, Apache Kafka, and PostgreSQL demonstrate consistent Effort advantages and context-dependent Importance effects, indicating FDS surfaces impactful work beyond raw activity using commit-only data.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW) ASEW 2025 Fair Developer Score: Build-Adjusted Measurement of Effort and Impact 1759663277981 10.1109/ASEW67777.2025.00054 Xinzhou Wang Northwestern University, United States chriswang2025@u.northwestern.edu Jiancong Zhu Northwestern University, United States jiancongzhu2025@u.northwestern.edu Jinghan Feng Northwestern University, United States jinghanfeng2025@u.northwestern.edu Zixuan Zhang Northwestern University, United States zixuanzhang2025@u.northwestern.edu Joshua Rauvola University of Chicago, United States jrauvola@uchicago.edu Devon Delgado Digital Emissions, USA devondelgado12@gmail.com Ahmad Antar Digital Emissions, USA ahmad.antar@digitalemissions.org Abid Ali Northwestern University, United States abid.ali@northwestern.edu developer productivity torque clustering commit clustering fair developer score software engineering metrics Assessing developer productivity in expansive software endeavors has become a pressing concern for both academia and industry, as organizations seek reliable ways to understand how engineering effort translates into business value. Traditional metrics\u2014such as commit frequency, lines of code, or code churn\u2014have been widely adopted but remain problematic, since they conflate inconsequential edits with architecturally significant reshaping and provide little insight into task-level contributions. To address this limitation, we introduce a commit-centric analytic framework that leverages clustering to reconfigure disbursed commit logs into coherent parcels, termed builds, that align more closely with the functional level of development tasks. Unlike prior approaches that combine heterogeneous signals such as issues, reviews, or communication logs, our method relies solely on the structural and temporal properties of commits, making it lightweight and broadly applicable. Each build is evaluated along two orthogonal axes: developer effort and build importance. Effort operationalizes the scale and character of contributions, considering code proprietorship, scope, architectural centrality, novelty, and cadence. Importance quantifies the build's systemic consequence, integrating scale of alteration, distribution of changes, architectural centrality, complexity, task priority, and proximity to release milestones. The fusion of these axes produces the Fair Developer Score, a composite benchmark reconciling personal exertion with organizational value. Validation centers on exposure-controlled, matched comparisons that pair FDS-ranked developers with commit-count peers matched on churn, files changed, and builds participated. On the Linux kernel, FDS-ranked developers exhibit significantly higher Average Importance and Average Effort than volume-matched peers, with lower rework trends. Cross-repository analyses across Kubernetes, TensorFlow, Apache Kafka, and PostgreSQL demonstrate consistent Effort advantages and context-dependent Importance effects, indicating FDS surfaces impactful work beyond raw activity using commit-only data.",
							"pageNumber": 253,
							"isPageNumberRoman": false
						},
						{
							"eid": "2jndokYQSuDa4ATnJ2BxMH",
							"type": "authorPaper",
							"text": "Exploring the SECURITY.md in the Dependency Chain: Preliminary Analysis of the PyPI Ecosystem",
							"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a261/850300a261.pdf",
							"extraLocations": [],
							"authorNames": "Chayanid Termphaiboon (Mahidol University, Thailand), Raula Gaikovina Kula (The University of Osaka, Japan), Youmei Fan ( Nara Institute of Science and Technology, Japan), Morakot Choetkiertikul (Mahidol University, Thailand), Chaiyong Ragkhitwetsagul (Mahidol University, Thailand), Thanwadee Sunetnanta (Mahidol University, Thailand), Kenichi Matsumoto ( Nara Institute of Science and Technology, Japan)",
							"abstract": "Security policies, such as SECURITY.md files, are now common in open-source projects. They help guide responsible vulnerability reporting and build trust among users and contributors. Despite their growing use, it is still unclear how these policies influence the structure and evolution of software dependencies. Software dependencies are external packages or libraries that a project relies on, and their interconnected nature affects both functionality and security. This study explores the relationship between security policies and dependency management in PyPI projects. We analyzed projects with and without a SECURITY.md file by examining their dependency trees and tracking how dependencies change over time. The analysis shows that projects with a security policy tend to rely on a broader set of direct dependencies, while overall depth and transitive dependencies remain similar. Historically, projects created after the introduction of SECURITY.md, particularly later adopters, show more frequent dependency updates. These results suggest that security policies are linked to more modular and feature-rich projects, and highlight the role of SECURITY.md in promoting proactive dependency management and reducing risks in the software supply chain.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW) ASEW 2025 Exploring the SECURITY.md in the Dependency Chain: Preliminary Analysis of the PyPI Ecosystem 1759291122477 10.1109/ASEW67777.2025.00055 Chayanid Termphaiboon Mahidol University, Thailand chayanid.ter@student.mahidol.ac.th Raula Gaikovina Kula The University of Osaka, Japan raula-k@ist.osaka-u.ac.jp Youmei Fan Nara Institute of Science and Technology, Japan fan.youmei.fs2@is.naist.jp Morakot Choetkiertikul Mahidol University, Thailand morakot.cho@mahidol.ac.th Chaiyong Ragkhitwetsagul Mahidol University, Thailand chaiyong.rag@mahidol.ac.th Thanwadee Sunetnanta Mahidol University, Thailand thanwadee.sun@mahidol.ac.th Kenichi Matsumoto Nara Institute of Science and Technology, Japan matumoto@is.naist.jp open-source software security policy software dependency Security policies, such as SECURITY.md files, are now common in open-source projects. They help guide responsible vulnerability reporting and build trust among users and contributors. Despite their growing use, it is still unclear how these policies influence the structure and evolution of software dependencies. Software dependencies are external packages or libraries that a project relies on, and their interconnected nature affects both functionality and security. This study explores the relationship between security policies and dependency management in PyPI projects. We analyzed projects with and without a SECURITY.md file by examining their dependency trees and tracking how dependencies change over time. The analysis shows that projects with a security policy tend to rely on a broader set of direct dependencies, while overall depth and transitive dependencies remain similar. Historically, projects created after the introduction of SECURITY.md, particularly later adopters, show more frequent dependency updates. These results suggest that security policies are linked to more modular and feature-rich projects, and highlight the role of SECURITY.md in promoting proactive dependency management and reducing risks in the software supply chain.",
							"pageNumber": 261,
							"isPageNumberRoman": false
						},
						{
							"eid": "27d16m6H1HyPAi6DvcHSom",
							"type": "authorPaper",
							"text": "Explainable AI for Issue Classification: A Multi-Class Study with LIME and SHAP",
							"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a269/850300a269.pdf",
							"extraLocations": [],
							"authorNames": "Jueun Heo  (Gyeongsang National University, Republic of Korea), Seonah Lee (Gyeongsang National University, Republic of Korea)",
							"abstract": "Issue classification is a fundamental task in software development, enabling teams to manage issue reports. Automatic issue classification can help developers classify issue reports. However, developers should understand why each issue report is classified in such a way. A prior study has shown that explainable AI (XAI) can explain how an issue report is classified as a bug or a non-bug. However, the binary setting limits applicability to real-world issue tracking systems, where multiple categories coexist. In this paper, we replicate and extend the prior study by conducting a multi-class issue classification experiment using three categories: Bug, Enhancement, and Question. We use a fine-tuned, seBERT-based classifier and apply two widely used XAI models, LIME and SHAP, to generate explanations for issue classification. We then analyze the results of applying LIME and SHAP to multi-class issue classification, both qualitatively and quantitatively.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW) ASEW 2025 Explainable AI for Issue Classification: A Multi-Class Study with LIME and SHAP 1759751632110 10.1109/ASEW67777.2025.00056 Jueun Heo Gyeongsang National University, Republic of Korea juandeun@gnu.ac.kr Seonah Lee Gyeongsang National University, Republic of Korea saleese@gnu.ac.kr issue classification replication study lime shap explainable ai Issue classification is a fundamental task in software development, enabling teams to manage issue reports. Automatic issue classification can help developers classify issue reports. However, developers should understand why each issue report is classified in such a way. A prior study has shown that explainable AI (XAI) can explain how an issue report is classified as a bug or a non-bug. However, the binary setting limits applicability to real-world issue tracking systems, where multiple categories coexist. In this paper, we replicate and extend the prior study by conducting a multi-class issue classification experiment using three categories: Bug, Enhancement, and Question. We use a fine-tuned, seBERT-based classifier and apply two widely used XAI models, LIME and SHAP, to generate explanations for issue classification. We then analyze the results of applying LIME and SHAP to multi-class issue classification, both qualitatively and quantitatively.",
							"pageNumber": 269,
							"isPageNumberRoman": false
						},
						{
							"eid": "ju8mVL9FnxVbBbaDOzm4u",
							"type": "authorPaper",
							"text": "LLMs Choose the Right Stack: From Patterns to Tools",
							"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a277/850300a277.pdf",
							"extraLocations": [],
							"authorNames": "Sebastian Copei (Fraunhofer IEE, Germany; Fraunhofer IEE, Germany), Oliver Hohlfeld (University of Kassel, Germany), Jens Kosiol (Philipps-Universit\u00E4t Marburg, Germany), Aleksandar Ristoski (Fraunhofer IEE, Germany)",
							"abstract": "Choosing suitable architectural patterns and the technologies that implement them is a complex design task. We evaluate how well current LLMs can support such decisions by empirically evaluating six LLMs (five open-source, one closed-source) on three scenarios: (i) na\u00EFve versus prompt-engineered pattern recommendation, (ii) decision-tree-guided selection via the CAPI method, and (iii) mapping patterns to concrete tools from a supplied list. We assess reasonableness, consistency, pattern specificity, and output structure. We show that even minimal prompts yield reasonable suggestions, while prompt engineering improves focus on architectural (rather than low-level design) patterns and consistency. CAPI guidance expands coverage and approaches human-expert performance, though models exhibit a strong bias toward micro-services and tend to over-suggest patterns. All models propose plausible tools when a curated list is provided. Overall, LLMs\u2013especially when combined with structured prompts and decision-tree guidance\u2013can meaningfully augment architectural decision-making, while highlighting the need for tighter output control and broader, less biased pattern coverage.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW) ASEW 2025 LLMs Choose the Right Stack: From Patterns to Tools 1759481682106 10.1109/ASEW67777.2025.00057 Sebastian Copei Fraunhofer IEE, Germany; Fraunhofer IEE, Germany sebastian.copei@iee.fraunhofer.de Oliver Hohlfeld University of Kassel, Germany oliver.hohlfeld@uni-kassel.de Jens Kosiol Philipps-Universit\u00E4t Marburg, Germany kosiolje@mathematik.uni-marburg.de Aleksandar Ristoski Fraunhofer IEE, Germany aleksandar.ristoski@iee.fraunhofer.de llm architectural patterns decision making Choosing suitable architectural patterns and the technologies that implement them is a complex design task. We evaluate how well current LLMs can support such decisions by empirically evaluating six LLMs (five open-source, one closed-source) on three scenarios: (i) na\u00EFve versus prompt-engineered pattern recommendation, (ii) decision-tree-guided selection via the CAPI method, and (iii) mapping patterns to concrete tools from a supplied list. We assess reasonableness, consistency, pattern specificity, and output structure. We show that even minimal prompts yield reasonable suggestions, while prompt engineering improves focus on architectural (rather than low-level design) patterns and consistency. CAPI guidance expands coverage and approaches human-expert performance, though models exhibit a strong bias toward micro-services and tend to over-suggest patterns. All models propose plausible tools when a curated list is provided. Overall, LLMs\u2013especially when combined with structured prompts and decision-tree guidance\u2013can meaningfully augment architectural decision-making, while highlighting the need for tighter output control and broader, less biased pattern coverage.",
							"pageNumber": 277,
							"isPageNumberRoman": false
						}
					],
					"pageNumber": "",
					"isPageNumberRoman": false,
					"chair": null
				},
				{
					"class": "SD",
					"type": "SD_SESSION",
					"title": "MAS-GAIN 2025 - 1st International Workshop on Multi-Agent Systems using Generative Artificial INtelligence for Automated Software Engineering",
					"lineItems": [
						{
							"eid": "1TjT8vWL4H6X5OoSMHLFzn",
							"type": "authorPaper",
							"text": "Message from the MAS-GAIN 2025 Chairs",
							"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a285/850300a285.pdf",
							"extraLocations": [],
							"authorNames": "",
							"abstract": "",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW) ASEW 2025 Message from the MAS-GAIN 2025 Chairs 10.1109/ASEW67777.2025.00058",
							"pageNumber": 285,
							"isPageNumberRoman": false
						},
						{
							"eid": "3OZzx45r92ucNJY1Wa4RcQ",
							"type": "authorPaper",
							"text": "ALMAS: An Autonomous LLM-Based Multi-Agent Software Engineering Framework",
							"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a288/850300a288.pdf",
							"extraLocations": [],
							"authorNames": "Vali Tawosi (J.P. Morgan AI Research, UK), Keshav Ramani (J.P. Morgan AI Research, USA), Salwa Alamir (J.P. Morgan AI Research, UK), Xiaomo Liu (J.P. Morgan AI Research, USA)",
							"abstract": "Multi-agent Large Language Model (LLM) systems have been leading the way in applied LLM research across a number of fields. One notable area is software development, where researchers have advanced the automation of code implementation, code testing, code maintenance, inter alia, using LLM agents. However, software development is a multifaceted environment that extends beyond just code. As such, a successful LLM system must factor in multiple stages of the software development life-cycle (SDLC). In this paper, we propose a vision for ALMAS, an Autonomous LLM-based Multi-Agent Software Engineering framework, which follows the above SDLC philosophy such that it may work within an agile software development team to perform several tasks end-to-end. ALMAS aligns its agents with agile roles, and can be used in a modular fashion to seamlessly integrate with human developers and their development environment. We showcase the progress towards ALMAS through our published works and a use case demonstrating the framework, where ALMAS is able to seamlessly generate an application and add a new feature.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW) ASEW 2025 ALMAS: An Autonomous LLM-Based Multi-Agent Software Engineering Framework 1759745297617 10.1109/ASEW67777.2025.00059 Vali Tawosi J.P. Morgan AI Research, UK vali.tawosi@jpmorgan.com Keshav Ramani J.P. Morgan AI Research, USA keshav.ramani@jpmchase.com Salwa Alamir J.P. Morgan AI Research, UK salwa.alamir@jpmchase.com Xiaomo Liu J.P. Morgan AI Research, USA xiaomo.liu@jpmchase.com ai for se agent-based se llm for code Multi-agent Large Language Model (LLM) systems have been leading the way in applied LLM research across a number of fields. One notable area is software development, where researchers have advanced the automation of code implementation, code testing, code maintenance, inter alia, using LLM agents. However, software development is a multifaceted environment that extends beyond just code. As such, a successful LLM system must factor in multiple stages of the software development life-cycle (SDLC). In this paper, we propose a vision for ALMAS, an Autonomous LLM-based Multi-Agent Software Engineering framework, which follows the above SDLC philosophy such that it may work within an agile software development team to perform several tasks end-to-end. ALMAS aligns its agents with agile roles, and can be used in a modular fashion to seamlessly integrate with human developers and their development environment. We showcase the progress towards ALMAS through our published works and a use case demonstrating the framework, where ALMAS is able to seamlessly generate an application and add a new feature.",
							"pageNumber": 288,
							"isPageNumberRoman": false
						},
						{
							"eid": "5aItR51JNg26YgUPux20uo",
							"type": "authorPaper",
							"text": "GRACG: Graph Retrieval Augmented Code Generation",
							"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a292/850300a292.pdf",
							"extraLocations": [],
							"authorNames": "Konstantin Fedorov (ITMO University, Russia), Boris Zarubin (Central University, Russia), Vladimir Ivanov (Innopolis University, Russia)",
							"abstract": "While file-level context is an effective basis for many modern code generation tools powered by Large Language Models (LLMs), it may be insufficient to fully capture the structural and semantic dependencies that extend across entire repositories. To address this issue, we propose a graph-based Retrieval-Augmented Code Generation (GRACG) framework that leverages repository-level context. Our approach models the repository as a heterogeneous graph of files, classes, and functions. A Graph Neural Network (GNN) is used to generate node embeddings that incorporate information from connected nodes. These embeddings are precomputed and serve as an efficient index, allowing us to retrieve context for user queries without re-running the GNN. Retrieved nodes are then used to construct prompts for LLMs to perform repository-aware function generation. We evaluate retrieval performance on a benchmark where the goal is to identify functions likely to be called based on a natural language description. For end-to-end evaluation, we use pass@k, which measures the percentage of tasks where at least one of the top-k generated solutions passes the associated test cases. Our results show that graph-based retrieval outperforms classical methods, highlighting it as a promising direction for future research. However, in terms of end-to-end code generation, we observe non-significant improvements in the metrics, even when oracle functions are used. Importantly, the modular nature of our framework also makes it suitable as a building block in multi-agent settings, where specialized components for retrieval, generation, and verification can collaborate around repository-level knowledge.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW) ASEW 2025 GRACG: Graph Retrieval Augmented Code Generation 1759798896195 10.1109/ASEW67777.2025.00060 Konstantin Fedorov ITMO University, Russia k.fedorov@niuitmo.ru Boris Zarubin Central University, Russia b.zarubin@edu.centraluniversity.ru Vladimir Ivanov Innopolis University, Russia v.ivanov@innopolis.ru code generation graph neural networks code retrieval software repositories large language models machine learning for software engineering While file-level context is an effective basis for many modern code generation tools powered by Large Language Models (LLMs), it may be insufficient to fully capture the structural and semantic dependencies that extend across entire repositories. To address this issue, we propose a graph-based Retrieval-Augmented Code Generation (GRACG) framework that leverages repository-level context. Our approach models the repository as a heterogeneous graph of files, classes, and functions. A Graph Neural Network (GNN) is used to generate node embeddings that incorporate information from connected nodes. These embeddings are precomputed and serve as an efficient index, allowing us to retrieve context for user queries without re-running the GNN. Retrieved nodes are then used to construct prompts for LLMs to perform repository-aware function generation. We evaluate retrieval performance on a benchmark where the goal is to identify functions likely to be called based on a natural language description. For end-to-end evaluation, we use pass@k, which measures the percentage of tasks where at least one of the top-k generated solutions passes the associated test cases. Our results show that graph-based retrieval outperforms classical methods, highlighting it as a promising direction for future research. However, in terms of end-to-end code generation, we observe non-significant improvements in the metrics, even when oracle functions are used. Importantly, the modular nature of our framework also makes it suitable as a building block in multi-agent settings, where specialized components for retrieval, generation, and verification can collaborate around repository-level knowledge.",
							"pageNumber": 292,
							"isPageNumberRoman": false
						},
						{
							"eid": "3vIrPQcihjQSAUPHg9Qv0J",
							"type": "authorPaper",
							"text": "Bridging the Prototype-Production Gap: A Multi-Agent System for Notebooks Transformation",
							"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a300/850300a300.pdf",
							"extraLocations": [],
							"authorNames": "Hanya Elhashemy (Siemens AG, Germany), Youssef Lotfy (Technical University of Munich, Germany), Yongjian Tang (Siemens AG, Germany)",
							"abstract": "The increasing adoption of Jupyter notebooks in data science and machine learning workflows has created a gap between exploratory code development and production-ready software systems. While notebooks excel at iterative development and visualization, they often lack proper software engineering principles, making their transition to production environments challenging. This paper presents Codelevate, a novel multi-agent system that automatically transforms Jupyter notebooks into well-structured, maintainable Python code repositories. Our system employs three specialized agents \u2014 Architect, Developer, and Structure \u2014 working in concert through a shared dependency tree to ensure architectural coherence and code quality. Our experimental results validate Codelevate's capability to bridge the prototype-to-production gap through autonomous code transformation, yielding quantifiable improvements in code quality metrics while preserving computational semantics.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW) ASEW 2025 Bridging the Prototype-Production Gap: A Multi-Agent System for Notebooks Transformation 1759852809039 10.1109/ASEW67777.2025.00061 Hanya Elhashemy Siemens AG, Germany hanya.elhashemy@siemens.com Youssef Lotfy Technical University of Munich, Germany yousseflotfy23@gmail.com Yongjian Tang Siemens AG, Germany yongjian.tang@siemens.com task-specific agents multi-agents automated code migration prototype code evolution The increasing adoption of Jupyter notebooks in data science and machine learning workflows has created a gap between exploratory code development and production-ready software systems. While notebooks excel at iterative development and visualization, they often lack proper software engineering principles, making their transition to production environments challenging. This paper presents Codelevate, a novel multi-agent system that automatically transforms Jupyter notebooks into well-structured, maintainable Python code repositories. Our system employs three specialized agents \u2014 Architect, Developer, and Structure \u2014 working in concert through a shared dependency tree to ensure architectural coherence and code quality. Our experimental results validate Codelevate's capability to bridge the prototype-to-production gap through autonomous code transformation, yielding quantifiable improvements in code quality metrics while preserving computational semantics.",
							"pageNumber": 300,
							"isPageNumberRoman": false
						},
						{
							"eid": "6ReCoGbDS3LNRRmwAwNnFB",
							"type": "authorPaper",
							"text": "Multi-agent systems for improved information retrieval \u2013 leveraging autonomous agents and LLM models",
							"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a304/850300a304.pdf",
							"extraLocations": [],
							"authorNames": "Aneta Poniszewska-Maranda (Lodz University of Technology, Poland), Maciej Kopa (Lodz University of Technology, Poland), Bo\u017Cena Borowska (Lodz University of Technology, Poland)",
							"abstract": "In the era of dynamic technological development and growing needs for data processing and analysis, the architecture of multi-agent systems is gaining importance. These systems, combined with Large Language Models (LLMs), offer an innovative approach to the information retrieval process that can enhance the efficiency, speed, and reliability of fact-finding and question-answering. This paper proposes the use of a designed multi-agent system architecture that uses autonomous agents and LLM models to efficiently acquire and process large amounts of data. It is shown how the integration of these technologies allows for more effective and precise information acquisition, which can lead to innovative solutions in both business and science. The effectiveness of solution were evaluated using specific metrics and testing.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW) ASEW 2025 Multi-agent systems for improved information retrieval \u2013 leveraging autonomous agents and LLM models 1759782792741 10.1109/ASEW67777.2025.00062 Aneta Poniszewska-Maranda Lodz University of Technology, Poland aneta.poniszewska-maranda@p.lodz.pl Maciej Kopa Lodz University of Technology, Poland maciej.kopaa@gmail.com Bo\u017Cena Borowska Lodz University of Technology, Poland bozena.borowska@p.lodz.pl multi-agent system autonomous agents information retrieval llm models natural language processing question answering In the era of dynamic technological development and growing needs for data processing and analysis, the architecture of multi-agent systems is gaining importance. These systems, combined with Large Language Models (LLMs), offer an innovative approach to the information retrieval process that can enhance the efficiency, speed, and reliability of fact-finding and question-answering. This paper proposes the use of a designed multi-agent system architecture that uses autonomous agents and LLM models to efficiently acquire and process large amounts of data. It is shown how the integration of these technologies allows for more effective and precise information acquisition, which can lead to innovative solutions in both business and science. The effectiveness of solution were evaluated using specific metrics and testing.",
							"pageNumber": 304,
							"isPageNumberRoman": false
						},
						{
							"eid": "4WjkPTj2Tgz8Wd6OSP68bY",
							"type": "authorPaper",
							"text": "Towards Multi-Agentic AI for Automated Software Design and Modelling: Challenges and Opportunities",
							"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a312/850300a312.pdf",
							"extraLocations": [],
							"authorNames": "Hoa Khanh Dam (University of Wollongong, Australia)",
							"abstract": "Agentic AI has recently emerged as a new paradigm where autonomous AI agents, empowered with Large Language Model capabilities, are capable of perceiving, reasoning and acting independently to pursue goals. In this paper, we explore the key challenges in developing Agentic AI for automated software design and modelling. These challenges include translating natural language requirements into design models, resolving ambiguities, maintaining consistency within and between design models, and managing conflicts and inconsistencies when merging different versions of a design model. To address those challenges, we propose a conceptual Multi-Agentic AI framework in which autonomous, goal-driven AI agents capable of interpreting requirements, generating design artefacts and collaborating on software design models.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW) ASEW 2025 Towards Multi-Agentic AI for Automated Software Design and Modelling: Challenges and Opportunities 1759907147356 10.1109/ASEW67777.2025.00063 Hoa Khanh Dam University of Wollongong, Australia hoa@uowmail.edu.au agentic ai software design and modeling multi-agents Agentic AI has recently emerged as a new paradigm where autonomous AI agents, empowered with Large Language Model capabilities, are capable of perceiving, reasoning and acting independently to pursue goals. In this paper, we explore the key challenges in developing Agentic AI for automated software design and modelling. These challenges include translating natural language requirements into design models, resolving ambiguities, maintaining consistency within and between design models, and managing conflicts and inconsistencies when merging different versions of a design model. To address those challenges, we propose a conceptual Multi-Agentic AI framework in which autonomous, goal-driven AI agents capable of interpreting requirements, generating design artefacts and collaborating on software design models.",
							"pageNumber": 312,
							"isPageNumberRoman": false
						},
						{
							"eid": "99yF11aTB3XS8jUFIwf7C",
							"type": "authorPaper",
							"text": "Traceability and Accountability in Role-Specialized Multi-Agent LLM Pipelines",
							"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a316/850300a316.pdf",
							"extraLocations": [],
							"authorNames": "Amine Barrak (Oakland University, USA)",
							"abstract": "Sequential multi-agent systems built with large language models (LLMs) can automate complex software tasks, but they are hard to trust because errors quietly pass from one stage to the next. We study a traceable and accountable pipeline, meaning a system with clear roles, structured handoffs, and saved records that let us trace who did what at each step and assign blame when things go wrong. Our setting is a Planner \u2192 Executor \u2192 Critic pipeline. We evaluate eight configurations of three state-of-the-art LLMs on three benchmarks and analyze where errors start, how they spread, and how they can be fixed. Our results show: (1) adding a structured, accountable handoff between agents markedly improves accuracy and prevents the failures common in simple pipelines; (2) models have clear role-specific strengths and risks (e.g., steady planning vs. high-variance critiquing), which we quantify with repair and harm rates; and (3) accuracy\u2013cost\u2013latency trade-offs are task-dependent, with heterogeneous pipelines often the most efficient. Overall, we provide a practical, data-driven method for designing, tracing, and debugging reliable, predictable, and accountable multi-agent systems.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW) ASEW 2025 Traceability and Accountability in Role-Specialized Multi-Agent LLM Pipelines 1759769745254 10.1109/ASEW67777.2025.00064 Amine Barrak Oakland University, USA aminebarrak@oakland.edu Multi-agent LLMs Sequential pipelines Role Based Reasoning Agents Collaboration Traceable Pipeline Sequential multi-agent systems built with large language models (LLMs) can automate complex software tasks, but they are hard to trust because errors quietly pass from one stage to the next. We study a traceable and accountable pipeline, meaning a system with clear roles, structured handoffs, and saved records that let us trace who did what at each step and assign blame when things go wrong. Our setting is a Planner \u2192 Executor \u2192 Critic pipeline. We evaluate eight configurations of three state-of-the-art LLMs on three benchmarks and analyze where errors start, how they spread, and how they can be fixed. Our results show: (1) adding a structured, accountable handoff between agents markedly improves accuracy and prevents the failures common in simple pipelines; (2) models have clear role-specific strengths and risks (e.g., steady planning vs. high-variance critiquing), which we quantify with repair and harm rates; and (3) accuracy\u2013cost\u2013latency trade-offs are task-dependent, with heterogeneous pipelines often the most efficient. Overall, we provide a practical, data-driven method for designing, tracing, and debugging reliable, predictable, and accountable multi-agent systems.",
							"pageNumber": 316,
							"isPageNumberRoman": false
						}
					],
					"pageNumber": "",
					"isPageNumberRoman": false,
					"chair": null
				},
				{
					"class": "SD",
					"type": "SD_SESSION",
					"title": "VARSE 2025 - 3rd\u00A0International Workshop on Virtual and Augmented Reality Software Engineering",
					"lineItems": [
						{
							"eid": "2cMsZhnCI7Q4DtYTpoM3kp",
							"type": "authorPaper",
							"text": "Message from the VARSE 2025 Chairs",
							"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a324/850300a324.pdf",
							"extraLocations": [],
							"authorNames": "",
							"abstract": "",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW) ASEW 2025 Message from the VARSE 2025 Chairs 10.1109/ASEW67777.2025.00065",
							"pageNumber": 324,
							"isPageNumberRoman": false
						},
						{
							"eid": "2eEyypD6p9w0f5LWl8ebAS",
							"type": "authorPaper",
							"text": "A Test Automation Framework for User Interaction in Extended Reality Applications",
							"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a326/850300a326.pdf",
							"extraLocations": [],
							"authorNames": "Ruizhen Gu (University of Sheffield, UK), Jos\u00E9 Miguel Rojas (University of Sheffield, UK)",
							"abstract": "Extended Reality (XR) technologies deliver immersive user experiences across diverse application domains but pose unique testing challenges due to their spatial interaction paradigms. Existing approaches test XR applications through scene navigation and interaction triggering, yet they fail to synthesise realistic spatial input via specialised XR devices. These devices include 6 degrees of freedom controller gestures and are essential for modern XR experiences. To address this gap, we present IntenXion, a test automation framework for validating user interactions in Unity XR applications. We develop a taxonomy of XR user interactions to inform the design of IntenXion, ensuring it supports a diverse range of XR interaction types. We conduct a case study to demonstrate IntenXion's capability, using eight representative interaction object types selected from industrial XR interaction design guidelines. IntenXion provides support for developing intuitive interaction test scripts, including both action sequences and assertions for expected behaviours. Our results demonstrate that IntenXion can cover the intended functionalities of all eight object types. ",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW) ASEW 2025 A Test Automation Framework for User Interaction in Extended Reality Applications 1759745309185 10.1109/ASEW67777.2025.00066 Ruizhen Gu University of Sheffield, UK rgu10@sheffield.ac.uk Jos\u00E9 Miguel Rojas University of Sheffield, UK j.rojas@sheffield.ac.uk extended reality software testing test automation testing framework Extended Reality (XR) technologies deliver immersive user experiences across diverse application domains but pose unique testing challenges due to their spatial interaction paradigms. Existing approaches test XR applications through scene navigation and interaction triggering, yet they fail to synthesise realistic spatial input via specialised XR devices. These devices include 6 degrees of freedom controller gestures and are essential for modern XR experiences. To address this gap, we present IntenXion, a test automation framework for validating user interactions in Unity XR applications. We develop a taxonomy of XR user interactions to inform the design of IntenXion, ensuring it supports a diverse range of XR interaction types. We conduct a case study to demonstrate IntenXion's capability, using eight representative interaction object types selected from industrial XR interaction design guidelines. IntenXion provides support for developing intuitive interaction test scripts, including both action sequences and assertions for expected behaviours. Our results demonstrate that IntenXion can cover the intended functionalities of all eight object types.",
							"pageNumber": 326,
							"isPageNumberRoman": false
						},
						{
							"eid": "2ayJADw4lcR3lX71MqYzJ9",
							"type": "authorPaper",
							"text": "NavAI: A Generalizable LLM Framework for Navigation Tasks in Virtual Reality Environments",
							"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a332/850300a332.pdf",
							"extraLocations": [],
							"authorNames": "Xue Qin (Villanova University, U.S.), Matthew DiGiovanni (Villanova University, U.S.)",
							"abstract": "Navigation is one of the fundamental tasks for automated exploration in Virtual Reality (VR). Existing technologies primarily focus on path optimization in 360-degree image datasets and 3D simulators, which cannot be directly applied to immersive VR environments. To address this gap, we present NavAI, a generalizable large language model (LLM)-based navigation framework that supports both basic actions and complex goal-directed tasks across diverse VR applications. We evaluate NavAI in three distinct VR environments through goal-oriented and exploratory tasks. Results show that it achieves high accuracy, with an 89% success rate in goal-oriented tasks. Our analysis also highlights current limitations of relying entirely on LLMs, particularly in scenarios that require dynamic goal assessment. Finally, we discuss the limitations observed during the experiments and offer insights for future research directions.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW) ASEW 2025 NavAI: A Generalizable LLM Framework for Navigation Tasks in Virtual Reality Environments 1759723405813 10.1109/ASEW67777.2025.00067 Xue Qin Villanova University, U.S. xue.qin@villanova.edu Matthew DiGiovanni Villanova University, U.S. mdigio02@villanova.edu virtual reality large language model navigation Navigation is one of the fundamental tasks for automated exploration in Virtual Reality (VR). Existing technologies primarily focus on path optimization in 360-degree image datasets and 3D simulators, which cannot be directly applied to immersive VR environments. To address this gap, we present NavAI, a generalizable large language model (LLM)-based navigation framework that supports both basic actions and complex goal-directed tasks across diverse VR applications. We evaluate NavAI in three distinct VR environments through goal-oriented and exploratory tasks. Results show that it achieves high accuracy, with an 89% success rate in goal-oriented tasks. Our analysis also highlights current limitations of relying entirely on LLMs, particularly in scenarios that require dynamic goal assessment. Finally, we discuss the limitations observed during the experiments and offer insights for future research directions.",
							"pageNumber": 332,
							"isPageNumberRoman": false
						},
						{
							"eid": "4ObF882m7XBEHaEYXrTQdK",
							"type": "authorPaper",
							"text": "ARTRIP: Automatic AR Testing with Randomized Interaction Patterns",
							"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a338/850300a338.pdf",
							"extraLocations": [],
							"authorNames": "Maria Rivera (The University of Texas at San Antonio, USA), Lisette Isais (The University of Texas at San Antonio, USA), Xiaoyin Wang (The University of Texas at San Antonio, USA)",
							"abstract": "Augmented Reality (AR) applications increasingly permeate domains such as gaming, retail, education, and healthcare. Despite their rapid adoption, systematic testing of AR apps remains underexplored due to their dependence on complex real-world contexts, sensor data, and diverse user interactions. In this paper, we propose ARTRIP (Automatic AR Testing with Randomized Interaction Patterns), a novel testing technique designed to explore AR applications with randomized interaction patterns. Unlike existing random testing approaches such as Monkey, ARTRIP uses a randomized interaction pattern to enhance the chance of covering more complicated interaction sequences. We describe the methodology, present a prototype implementation, and evaluate its effectiveness through case studies on four popular AR apps. Results suggest that ARTRIP achieves higher coverage than Monkey, highlighting its potential as a practical AR testing framework.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW) ASEW 2025 ARTRIP: Automatic AR Testing with Randomized Interaction Patterns 1760037162102 10.1109/ASEW67777.2025.00068 Maria Rivera The University of Texas at San Antonio, USA Maria.Rivera@utsa.edu Lisette Isais The University of Texas at San Antonio, USA lisette.isais@utsa.edu Xiaoyin Wang The University of Texas at San Antonio, USA xiaoyin.wang@utsa.edu augmented reality random testing interaction patterns Augmented Reality (AR) applications increasingly permeate domains such as gaming, retail, education, and healthcare. Despite their rapid adoption, systematic testing of AR apps remains underexplored due to their dependence on complex real-world contexts, sensor data, and diverse user interactions. In this paper, we propose ARTRIP (Automatic AR Testing with Randomized Interaction Patterns), a novel testing technique designed to explore AR applications with randomized interaction patterns. Unlike existing random testing approaches such as Monkey, ARTRIP uses a randomized interaction pattern to enhance the chance of covering more complicated interaction sequences. We describe the methodology, present a prototype implementation, and evaluate its effectiveness through case studies on four popular AR apps. Results suggest that ARTRIP achieves higher coverage than Monkey, highlighting its potential as a practical AR testing framework.",
							"pageNumber": 338,
							"isPageNumberRoman": false
						},
						{
							"eid": "5ByECtN5aT8Feuuxw06SVj",
							"type": "authorPaper",
							"text": "Toward Static Analysis of Immersive Attacks",
							"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a343/850300a343.pdf",
							"extraLocations": [],
							"authorNames": "Kadiray Karakaya (Paderborn University, Germany), Jonas Klauke (Paderborn University, Germany), Enes Yigitbas (Paderborn University, Germany)",
							"abstract": "Immersive attacks are a novel class of security threats that emerge from the immersive nature of virtual reality (VR) interfaces. Unlike traditional cyber attacks that target users' sensitive information, immersive attacks target users' immersive experience: their visual perception and sense of direction. Despite their high damage potential, countermeasures for immersive attacks are still underexplored. In this work, we demonstrate how one can implement immersive attacks using OpenXR, a unifying standard that enables running vendor-independent VR applications on various VR platforms. We explore strategies for detecting such attacks through the perspective of static code analysis, a popular technique for application security vetting. We discuss the requirements and challenges for static analyses aimed at detecting immersive attacks, highlighting in particular the lack of cross-language support in existing tools and the absence of domain-specific knowledge needed to recognize these attacks.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW) ASEW 2025 Toward Static Analysis of Immersive Attacks 1759699760035 10.1109/ASEW67777.2025.00069 Kadiray Karakaya Paderborn University, Germany kadiray.karakaya@upb.de Jonas Klauke Paderborn University, Germany jonas.klauke@upb.de Enes Yigitbas Paderborn University, Germany enes.yigitbas@upb.de virtual reality static analysis immersive attacks openxr Immersive attacks are a novel class of security threats that emerge from the immersive nature of virtual reality (VR) interfaces. Unlike traditional cyber attacks that target users' sensitive information, immersive attacks target users' immersive experience: their visual perception and sense of direction. Despite their high damage potential, countermeasures for immersive attacks are still underexplored. In this work, we demonstrate how one can implement immersive attacks using OpenXR, a unifying standard that enables running vendor-independent VR applications on various VR platforms. We explore strategies for detecting such attacks through the perspective of static code analysis, a popular technique for application security vetting. We discuss the requirements and challenges for static analyses aimed at detecting immersive attacks, highlighting in particular the lack of cross-language support in existing tools and the absence of domain-specific knowledge needed to recognize these attacks.",
							"pageNumber": 343,
							"isPageNumberRoman": false
						},
						{
							"eid": "4BULwIzmH4NQufyYTVjJoZ",
							"type": "authorPaper",
							"text": "A Conformance Checking System for Interaction Testing in Virtual Reality",
							"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a349/850300a349.pdf",
							"extraLocations": [],
							"authorNames": "Vijay Aravynthan S.R. (International Institute of Information Technology, India), Raghu Reddy Y. (International Institute of Information Technology, India)",
							"abstract": "The rapid growth of Virtual Reality (VR) across critical sectors like healthcare, education, and gaming necessitates robust methods for quality assurance. As VR applications increase in complexity, ensuring correctness of interactions becomes challenging. This paper presents our ongoing work on a novel, cross-platform conformance checking system designed to verify that VR interactions are as specified. Our system features three key parts: a JSON-based format for defining ideal interaction specifications, an intuitive visual editor for designing the interaction flows, and a rules engine that automatically compares runtime behavior against the predefined sequences. This system is designed to streamline the testing process and ensure behavioral consistency across diverse VR platforms.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW) ASEW 2025 A Conformance Checking System for Interaction Testing in Virtual Reality 1759731944531 10.1109/ASEW67777.2025.00070 Vijay Aravynthan S.R. International Institute of Information Technology, India vijay.s@research.iiit.ac.in Raghu Reddy Y. International Institute of Information Technology, India raghu.reddy@iiit.ac.in virtual reality conformance testing process mining interaction logging quality assurance visual editor The rapid growth of Virtual Reality (VR) across critical sectors like healthcare, education, and gaming necessitates robust methods for quality assurance. As VR applications increase in complexity, ensuring correctness of interactions becomes challenging. This paper presents our ongoing work on a novel, cross-platform conformance checking system designed to verify that VR interactions are as specified. Our system features three key parts: a JSON-based format for defining ideal interaction specifications, an intuitive visual editor for designing the interaction flows, and a rules engine that automatically compares runtime behavior against the predefined sequences. This system is designed to streamline the testing process and ensure behavioral consistency across diverse VR platforms.",
							"pageNumber": 349,
							"isPageNumberRoman": false
						}
					],
					"pageNumber": "",
					"isPageNumberRoman": false,
					"chair": null
				},
				{
					"class": "SD",
					"type": "SD_SESSION",
					"title": "Workshop and Challenge on Optimization of Context Collection for Code Completion",
					"lineItems": [
						{
							"eid": "3zBojLb3HCel4b6dqDFrWe",
							"type": "authorPaper",
							"text": "Message from the Workshop and Challenge Chairs",
							"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a357/850300a357.pdf",
							"extraLocations": [],
							"authorNames": "",
							"abstract": "",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW) ASEW 2025 Message from the Workshop and Challenge Chairs 10.1109/ASEW67777.2025.00071",
							"pageNumber": 357,
							"isPageNumberRoman": false
						},
						{
							"eid": "LvL5oeccofkPMOrRIhpFy",
							"type": "authorPaper",
							"text": "Challenge on Optimization of Context Collection for Code Completion",
							"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a358/850300a358.pdf",
							"extraLocations": [],
							"authorNames": "Dmitry Ustalov (JetBrains, Serbia), Egor Bogomolov (JetBrains Research, The Netherlands), Alexander Bezzubov (JetBrains Research, The Netherlands), Yaroslav Golubev (JetBrains Research, The Netherlands), Evgeniy Glukhov (JetBrains Research, The Netherlands), Georgii Levtsov (Neapolis University Pafos, Cyprus), Vladimir Kovalenko (JetBrains Research, The Netherlands)",
							"abstract": "The rapid advancement of workflows and methods for software engineering using AI emphasizes the need for a systematic evaluation and analysis of their ability to leverage information from entire projects, particularly in large code bases. In this challenge on optimization of context collection for code completion, organized by JetBrains in collaboration with Mistral AI as part of the ASE 2025 conference, participants developed efficient mechanisms for collecting context from source code repositories to improve fill-in-the-middle code completions for Python and Kotlin. We constructed a large dataset of real-world code in these two programming languages using permissively licensed open-source projects. The submissions were evaluated based on their ability to maximize completion quality for multiple state-of-the-art neural models using the chrF metric. During the public phase of the competition, nineteen teams submitted solutions to the Python track and eight teams submitted solutions to the Kotlin track. In the private phase, six teams competed, of which five submitted papers to the workshop.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW) ASEW 2025 Challenge on Optimization of Context Collection for Code Completion 1759692565919 10.1109/ASEW67777.2025.00072 Dmitry Ustalov JetBrains, Serbia dmitry.ustalov@jetbrains.com Egor Bogomolov JetBrains Research, The Netherlands egor.bogomolov@jetbrains.com Alexander Bezzubov JetBrains Research, The Netherlands alexander.bezzubov@jetbrains.com Yaroslav Golubev JetBrains Research, The Netherlands yaroslav.golubev@jetbrains.com Evgeniy Glukhov JetBrains Research, The Netherlands evgeniy.glukhov@jetbrains.com Georgii Levtsov Neapolis University Pafos, Cyprus g.levtsov.1@nup.ac.cy Vladimir Kovalenko JetBrains Research, The Netherlands vladimir.kovalenko@jetbrains.com The rapid advancement of workflows and methods for software engineering using AI emphasizes the need for a systematic evaluation and analysis of their ability to leverage information from entire projects, particularly in large code bases. In this challenge on optimization of context collection for code completion, organized by JetBrains in collaboration with Mistral AI as part of the ASE 2025 conference, participants developed efficient mechanisms for collecting context from source code repositories to improve fill-in-the-middle code completions for Python and Kotlin. We constructed a large dataset of real-world code in these two programming languages using permissively licensed open-source projects. The submissions were evaluated based on their ability to maximize completion quality for multiple state-of-the-art neural models using the chrF metric. During the public phase of the competition, nineteen teams submitted solutions to the Python track and eight teams submitted solutions to the Kotlin track. In the private phase, six teams competed, of which five submitted papers to the workshop.",
							"pageNumber": 358,
							"isPageNumberRoman": false
						},
						{
							"eid": "1mKFgrh84i75rvae1L8yHP",
							"type": "authorPaper",
							"text": "SpareCodeSearch: Searching for Code Context When You Have No Spare GPU",
							"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a365/850300a365.pdf",
							"extraLocations": [],
							"authorNames": "Minh Nguyen (University College Dublin, Ireland)",
							"abstract": "Retrieval-Augmented Generation (RAG) frameworks aim to enhance Code Language Models (CLMs) by including another module for retrieving relevant context to construct the input prompt. However, these retrieval modules commonly use semantic search, requiring substantial computational resources for training and hosting these embedded models, making them infeasible to integrate into lightweight applications such as in-IDE AI-based code completion. In this solution paper, we prove that using keyword-search is sufficient to retrieve relevant and useful code context inside large codebases, without the need for extensive GPU resources. The usefulness of code contexts found by our solution is demonstrated through their completion results on the Code Context Competition's benchmark, reaching 0.748 and 0.725 chRF scores on Kotlin and Python tracks, respectively.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW) ASEW 2025 SpareCodeSearch: Searching for Code Context When You Have No Spare GPU 1759489345982 10.1109/ASEW67777.2025.00073 Minh Nguyen University College Dublin, Ireland minh.a.nguyen@ucdconnect.ie code context code search code language models code completion keyword-based search Retrieval-Augmented Generation (RAG) frameworks aim to enhance Code Language Models (CLMs) by including another module for retrieving relevant context to construct the input prompt. However, these retrieval modules commonly use semantic search, requiring substantial computational resources for training and hosting these embedded models, making them infeasible to integrate into lightweight applications such as in-IDE AI-based code completion. In this solution paper, we prove that using keyword-search is sufficient to retrieve relevant and useful code context inside large codebases, without the need for extensive GPU resources. The usefulness of code contexts found by our solution is demonstrated through their completion results on the Code Context Competition's benchmark, reaching 0.748 and 0.725 chRF scores on Kotlin and Python tracks, respectively.",
							"pageNumber": 365,
							"isPageNumberRoman": false
						},
						{
							"eid": "3sQlb2fzOLUEjOpiiarHZV",
							"type": "authorPaper",
							"text": "On the Importance of Context Filtering in Retrieval-Augmented Code Completion",
							"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a369/850300a369.pdf",
							"extraLocations": [],
							"authorNames": "Sergey Sedov (New York University), Vsevolod Savinskiy (Constructor University Bremen), Andrei Arzhantsev (Technical University of Munich)",
							"abstract": "We present a retrieval-augmented pipeline for code completion task developed by our NoMoreActimel team during the JetBrains & Mistral AI Context Collection Competition. Our approach separates offline index pre-processing and online query processing parts. We highlight the importance of asymmetric approach to RAG in code completion tasks, separating index-specific and query-specific heuristics. We argue that stronger embedding models should perform increasingly better than BM-25 baselines when applied on large databases, which leads us to retrieval across all repositories instead of a single one. However, as our experiments show that sometimes less context is better, retrieval over larger code-bases increases the significance of proper context filtering. Therefore, we identify the main challenges of model-based RAG in code completion as poor context relevancy and extensive generality of chunk embeddings in particular. We focus on experiments with different chunking strategies, introducing a hole-centered query chunking strategy as our first modification that controls query relevance. We propose several reweighting penalties for similarity scores in order to increase relevancy of in-context chunks, penalizing by length and distance to completion hole. Filtering by simple similarity score thresholds also helps the final model performance. Besides that, we find that generation of short textual descriptions of completion target significantly improves metrics as well. While textual descriptions can be generated with much smaller model (1.5B) and token budget (1-2 sentences), they deal with context-overfitting compared to potential code-completion generations provided in-context. The described approach achieved top results: 1st in Python and 2nd in Kotlin private phases using lightweight Qwen 0.6B embedding model. Heavier Nomic 7B model gave the substantial lead of 13% to the second-best solution in the Python public phase leaderboard. The code is available on github.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW) ASEW 2025 On the Importance of Context Filtering in Retrieval-Augmented Code Completion 1759260185237 10.1109/ASEW67777.2025.00074 Sergey Sedov New York University evolution3000futurama@gmail.com Vsevolod Savinskiy Constructor University Bremen tirlimster@gmail.com Andrei Arzhantsev Technical University of Munich arzhanandrey@gmail.com code completion retrieval rag embeddings faiss chrf context composition We present a retrieval-augmented pipeline for code completion task developed by our NoMoreActimel team during the JetBrains & Mistral AI Context Collection Competition. Our approach separates offline index pre-processing and online query processing parts. We highlight the importance of asymmetric approach to RAG in code completion tasks, separating index-specific and query-specific heuristics. We argue that stronger embedding models should perform increasingly better than BM-25 baselines when applied on large databases, which leads us to retrieval across all repositories instead of a single one. However, as our experiments show that sometimes less context is better, retrieval over larger code-bases increases the significance of proper context filtering. Therefore, we identify the main challenges of model-based RAG in code completion as poor context relevancy and extensive generality of chunk embeddings in particular. We focus on experiments with different chunking strategies, introducing a hole-centered query chunking strategy as our first modification that controls query relevance. We propose several reweighting penalties for similarity scores in order to increase relevancy of in-context chunks, penalizing by length and distance to completion hole. Filtering by simple similarity score thresholds also helps the final model performance. Besides that, we find that generation of short textual descriptions of completion target significantly improves metrics as well. While textual descriptions can be generated with much smaller model (1.5B) and token budget (1-2 sentences), they deal with context-overfitting compared to potential code-completion generations provided in-context. The described approach achieved top results: 1st in Python and 2nd in Kotlin private phases using lightweight Qwen 0.6B embedding model. Heavier Nomic 7B model gave the substantial lead of 13% to the second-best solution in the Python public phase leaderboard. The code is available on github.",
							"pageNumber": 369,
							"isPageNumberRoman": false
						},
						{
							"eid": "24azdt4det5StKoLB6vyo0",
							"type": "authorPaper",
							"text": "Beyond More Context: How Granularity and Order Drive Code Completion Quality",
							"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a372/850300a372.pdf",
							"extraLocations": [],
							"authorNames": "Uswat Yusuf (Concordia University, Canada), Genevieve Caumartin (Concordia University, Canada), Diego Elias Costa (Concordia University, Canada)",
							"abstract": "Context plays an important role in the quality of code completion, as Large Language Models (LLMs) require sufficient and relevant information to assist developers in code generation tasks. However, composing a relevant context for code completion poses challenges in large repositories: First, the limited context length of LLMs makes it impractical to include all repository files. Second, the quality of generated code is highly sensitive to noisy or irrelevant context. In this paper, we present our approach for the ASE 2025 Context Collection Challenge. The challenge entails outperforming JetBrains baselines by designing effective retrieval and context collection strategies. We develop and evaluate a series of experiments that involve retrieval strategies at both the file and chunk levels. We focus our initial experiments on examining the impact of context size and file ordering on LLM performance. Our results show that the amount and order of context can significantly influence the performance of the models. We introduce chunk-based retrieval using static analysis, achieving a 6% improvement over our best file-retrieval strategy and 16% over the no-context baseline for Python in the initial phase of the competition. Our results highlight the importance of retrieval granularity, ordering and hybrid strategies in developing effective context collection pipelines for real-world development scenarios. ",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW) ASEW 2025 Beyond More Context: How Granularity and Order Drive Code Completion Quality 1759714496571 10.1109/ASEW67777.2025.00075 Uswat Yusuf Concordia University, Canada omosewaeniola@gmail.com Genevieve Caumartin Concordia University, Canada genevieve.caumartin@mail.concordia.ca Diego Elias Costa Concordia University, Canada diego.costa@concordia.ca code completion context engineering large language models Context plays an important role in the quality of code completion, as Large Language Models (LLMs) require sufficient and relevant information to assist developers in code generation tasks. However, composing a relevant context for code completion poses challenges in large repositories: First, the limited context length of LLMs makes it impractical to include all repository files. Second, the quality of generated code is highly sensitive to noisy or irrelevant context. In this paper, we present our approach for the ASE 2025 Context Collection Challenge. The challenge entails outperforming JetBrains baselines by designing effective retrieval and context collection strategies. We develop and evaluate a series of experiments that involve retrieval strategies at both the file and chunk levels. We focus our initial experiments on examining the impact of context size and file ordering on LLM performance. Our results show that the amount and order of context can significantly influence the performance of the models. We introduce chunk-based retrieval using static analysis, achieving a 6% improvement over our best file-retrieval strategy and 16% over the no-context baseline for Python in the initial phase of the competition. Our results highlight the importance of retrieval granularity, ordering and hybrid strategies in developing effective context collection pipelines for real-world development scenarios.",
							"pageNumber": 372,
							"isPageNumberRoman": false
						},
						{
							"eid": "4I0v7tEOgMQH2eKxEiUubH",
							"type": "authorPaper",
							"text": "Exploration of Structural Code Relationship Space for Context Collection",
							"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a376/850300a376.pdf",
							"extraLocations": [],
							"authorNames": "Constantinos Sofianos (Independent Researcher, Cyprus)",
							"abstract": "This paper presents a solution to the Context Collection Competition organized by JetBrains and Mistral AI, addressing the challenge of optimizing code completion across diverse codebases and multiple LLMs. The competition includes both Kotlin and a Python tracks, and this paper represents a Kotlin submission. The problem was approached by designing a dynamic, composable framework, enabling rapid experimentation with multiple context-collection strategies. Building on the Kotlin Psi library, a semantic tree layer was introduced to capture meaningful code associations and dynamically adjust the level of detail provided in the context, such as omitting method bodies or private methods. This approach, similar to Hierarchical Context Pruning, maximizes the signal-to-noise ratio in retrieved context. Experiments show that concise structural associations and targeted pruning consistently improve performance, though results vary across LLMs, with Codestral benefiting most. The framework's adaptability allows systematic exploration of configuration parameters and the combination of multiple strategies to optimize performance. Limited computational resources constrained exhaustive exploration, motivating future work on automated large-scale evaluation to identify the upper bounds of achievable performance.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW) ASEW 2025 Exploration of Structural Code Relationship Space for Context Collection 1759589369467 10.1109/ASEW67777.2025.00076 Constantinos Sofianos Independent Researcher, Cyprus costa.sofianos@gmail.com code context collection semantic code analysis hierarchical context pruning large language models This paper presents a solution to the Context Collection Competition organized by JetBrains and Mistral AI, addressing the challenge of optimizing code completion across diverse codebases and multiple LLMs. The competition includes both Kotlin and a Python tracks, and this paper represents a Kotlin submission. The problem was approached by designing a dynamic, composable framework, enabling rapid experimentation with multiple context-collection strategies. Building on the Kotlin Psi library, a semantic tree layer was introduced to capture meaningful code associations and dynamically adjust the level of detail provided in the context, such as omitting method bodies or private methods. This approach, similar to Hierarchical Context Pruning, maximizes the signal-to-noise ratio in retrieved context. Experiments show that concise structural associations and targeted pruning consistently improve performance, though results vary across LLMs, with Codestral benefiting most. The framework's adaptability allows systematic exploration of configuration parameters and the combination of multiple strategies to optimize performance. Limited computational resources constrained exhaustive exploration, motivating future work on automated large-scale evaluation to identify the upper bounds of achievable performance.",
							"pageNumber": 376,
							"isPageNumberRoman": false
						},
						{
							"eid": "1Oi5zHEm58CVPr3CQuQcqU",
							"type": "authorPaper",
							"text": "Relative Positioning Based Code Chunking Method For Rich Context Retrieval In Repository Level Code Completion Task With Code Language Model",
							"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a380/850300a380.pdf",
							"extraLocations": [],
							"authorNames": "Imranur Rahman (North Carolina State University), Md Rayhanur Rahman (The University of Alabama)",
							"abstract": "Code completion can help developers improve efficiency and ease the development lifecycle. Although code completion is available in modern integrated development environments (IDEs), research lacks in determining what makes a good context for code completion based on the information available to the IDEs for the large language models (LLMs) to perform better. In this paper, we describe an effective context collection strategy to assist the LLMs in performing better at code completion tasks. The key idea of our strategy is to preprocess the repository into smaller code chunks and later use syntactic and semantic similarity-based code chunk retrieval with relative positioning. We found that code chunking and relative positioning of the chunks in the final context improve the performance of code completion tasks.",
							"searchText": "2025 40th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW) ASEW 2025 Relative Positioning Based Code Chunking Method For Rich Context Retrieval In Repository Level Code Completion Task With Code Language Model 1759718980848 10.1109/ASEW67777.2025.00077 Imranur Rahman North Carolina State University irahman3@ncsu.edu Md Rayhanur Rahman The University of Alabama mdrayhanur.rahman@ua.edu code completion code chunking context collection code language model large language model Code completion can help developers improve efficiency and ease the development lifecycle. Although code completion is available in modern integrated development environments (IDEs), research lacks in determining what makes a good context for code completion based on the information available to the IDEs for the large language models (LLMs) to perform better. In this paper, we describe an effective context collection strategy to assist the LLMs in performing better at code completion tasks. The key idea of our strategy is to preprocess the repository into smaller code chunks and later use syntactic and semantic similarity-based code chunk retrieval with relative positioning. We found that code chunking and relative positioning of the chunks in the final context improve the performance of code completion tasks.",
							"pageNumber": 380,
							"isPageNumberRoman": false
						}
					],
					"pageNumber": "",
					"isPageNumberRoman": false,
					"chair": null
				}
			]
		}
	],
	"authors": [
		{
			"author": {
				"givenName": "Marwan",
				"surname": "AbdElhameed"
			},
			"authorName": "AbdElhameed, Marwan",
			"articleRefs": [
				{
					"pageNumber": 3844,
					"articleName": "Detecting and Repairing Incomplete Software Requirements with Multi-LLM Ensembles",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d844/573300d844.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Milan",
				"surname": "Abrah\u00E1m"
			},
			"authorName": "Abrah\u00E1m, Milan",
			"articleRefs": [
				{
					"pageNumber": 4036,
					"articleName": "ORMorpher: An Interactive Framework for ORM Translation and Optimization",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e036/573300e036.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Rui",
				"surname": "Abreu"
			},
			"authorName": "Abreu, Rui",
			"articleRefs": [
				{
					"pageNumber": 2020,
					"articleName": "Interpretable Vulnerability Detection Reports",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c020/573300c020.pdf"
				},
				{
					"pageNumber": 3250,
					"articleName": "Metrics Driven Reengineering and Continuous Code Improvement at Meta",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d250/573300d250.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Khaled",
				"surname": "Abud"
			},
			"authorName": "Abud, Khaled",
			"articleRefs": [
				{
					"pageNumber": 4032,
					"articleName": "WIBE: Watermarks for generated Images \u2013 Benchmarking & Evaluation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e032/573300e032.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Maribel",
				"surname": "Acosta"
			},
			"authorName": "Acosta, Maribel",
			"articleRefs": [
				{
					"pageNumber": 204,
					"articleName": "Explainability in Automated Cross-Domain Model-Driven Brake System Development",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a204/850300a204.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Juan Camilo",
				"surname": "Acosta-Rojas"
			},
			"authorName": "Acosta-Rojas, Juan Camilo",
			"articleRefs": [
				{
					"pageNumber": 83,
					"articleName": "Finding Keywords for Architectural Erosion Detection in GitHub Commits for Android Applications",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a083/850300a083.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zs\u00F3fia",
				"surname": "\u00C1d\u00E1m"
			},
			"authorName": "\u00C1d\u00E1m, Zs\u00F3fia",
			"articleRefs": [
				{
					"pageNumber": 1968,
					"articleName": "Non-Termination Witnesses and Their Validation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b968/573300b968.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Elijah Kayode",
				"surname": "Adejumo"
			},
			"authorName": "Adejumo, Elijah Kayode",
			"articleRefs": [
				{
					"pageNumber": 199,
					"articleName": "Explaining Code Risk in OSS: Towards LLM-Generated Fault Prediction Interpretations",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a199/850300a199.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ahmed",
				"surname": "Adnan"
			},
			"authorName": "Adnan, Ahmed",
			"articleRefs": [
				{
					"pageNumber": 4109,
					"articleName": "CLARA: A Developer's Companion for Code Comprehension and Analysis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e109/573300e109.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Nazareno",
				"surname": "Aguirre"
			},
			"authorName": "Aguirre, Nazareno",
			"articleRefs": [
				{
					"pageNumber": 2706,
					"articleName": "State Field Coverage: A Metric for Oracle Quality",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c706/573300c706.pdf"
				},
				{
					"pageNumber": 2918,
					"articleName": "Automated Combinatorial Test Generation for Alloy",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c918/573300c918.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Kirill",
				"surname": "Aistov"
			},
			"authorName": "Aistov, Kirill",
			"articleRefs": [
				{
					"pageNumber": 4032,
					"articleName": "WIBE: Watermarks for generated Images \u2013 Benchmarking & Evaluation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e032/573300e032.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Adem",
				"surname": "Ait"
			},
			"authorName": "Ait, Adem",
			"articleRefs": [
				{
					"pageNumber": 3890,
					"articleName": "Towards Automated Governance: A DSL for Human-Agent Collaboration in Software Projects",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d890/573300d890.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Isami",
				"surname": "Akasaka"
			},
			"authorName": "Akasaka, Isami",
			"articleRefs": [
				{
					"pageNumber": 3741,
					"articleName": "LogSage: An LLM-Based Framework for CI/CD Failure Detection and Remediation with Industrial Validation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d741/573300d741.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ranit D.",
				"surname": "Akash"
			},
			"authorName": "Akash, Ranit D.",
			"articleRefs": [
				{
					"pageNumber": 1679,
					"articleName": "Uncovering Discrimination Clusters: Quantifying and Explaining Systematic Fairness Violations",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b679/573300b679.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ildar",
				"surname": "Akhmetov"
			},
			"authorName": "Akhmetov, Ildar",
			"articleRefs": [
				{
					"pageNumber": 867,
					"articleName": "An Empirical Study of Python Library Migration Using Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a867/573300a867.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Aleksandr",
				"surname": "Akimenkov"
			},
			"authorName": "Akimenkov, Aleksandr",
			"articleRefs": [
				{
					"pageNumber": 4032,
					"articleName": "WIBE: Watermarks for generated Images \u2013 Benchmarking & Evaluation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e032/573300e032.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Anatoly",
				"surname": "Akkerman"
			},
			"authorName": "Akkerman, Anatoly",
			"articleRefs": [
				{
					"pageNumber": 3250,
					"articleName": "Metrics Driven Reengineering and Continuous Code Improvement at Meta",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d250/573300d250.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Waseem",
				"surname": "Akram"
			},
			"authorName": "Akram, Waseem",
			"articleRefs": [
				{
					"pageNumber": 2758,
					"articleName": "LLM-Based Identification of Null Pointer Exception Patches",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c758/573300c758.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Khubaib Amjad",
				"surname": "Alam"
			},
			"authorName": "Alam, Khubaib Amjad",
			"articleRefs": [
				{
					"pageNumber": 87,
					"articleName": "A Data-Driven Approach for Automated Quality Concern Extraction from App Reviews",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a087/850300a087.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Salwa",
				"surname": "Alamir"
			},
			"authorName": "Alamir, Salwa",
			"articleRefs": [
				{
					"pageNumber": 34,
					"articleName": "LLM Agents for Automated Dependency Upgrades",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a034/850300a034.pdf"
				},
				{
					"pageNumber": 39,
					"articleName": "Bridging LLM Planning Agents and Formal Methods: A Case Study in Plan Verification",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a039/850300a039.pdf"
				},
				{
					"pageNumber": 288,
					"articleName": "ALMAS: An Autonomous LLM-Based Multi-Agent Software Engineering Framework",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a288/850300a288.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Mohammad Nour",
				"surname": "Al Awad"
			},
			"authorName": "Al Awad, Mohammad Nour",
			"articleRefs": [
				{
					"pageNumber": 113,
					"articleName": "Pre-Filtering Code Suggestions using Developer Behavioral Telemetry to Optimize LLM-Assisted Programming",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a113/850300a113.pdf"
				},
				{
					"pageNumber": 214,
					"articleName": "Optimizing LLM Code Suggestions: Feedback-Driven Timing with Lightweight State Bounds",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a214/850300a214.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Omar I.",
				"surname": "Al-Bataineh"
			},
			"authorName": "Al-Bataineh, Omar I.",
			"articleRefs": [
				{
					"pageNumber": 3798,
					"articleName": "Interaction-Aware Patch Assessment for Multi-Fault Automated Program Repair",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d798/573300d798.pdf"
				},
				{
					"pageNumber": 3803,
					"articleName": "Debugging the Undebuggable: Why Multi-Fault Programs Break Debugging and Repair Tools",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d803/573300d803.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Albert",
				"surname": "Albers"
			},
			"authorName": "Albers, Albert",
			"articleRefs": [
				{
					"pageNumber": 204,
					"articleName": "Explainability in Automated Cross-Domain Model-Driven Brake System Development",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a204/850300a204.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Michele",
				"surname": "Alberti "
			},
			"authorName": "Alberti, Michele",
			"articleRefs": [
				{
					"pageNumber": 291,
					"articleName": "Loupe: End-to-End Learning of Loop Unrolling Heuristics for Abstract Interpretation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a291/573300a291.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yoseph Berhanu",
				"surname": "Alebachew"
			},
			"authorName": "Alebachew, Yoseph Berhanu",
			"articleRefs": [
				{
					"pageNumber": 43,
					"articleName": "LLMs in Debate: Does Arguing Make Them Better at Detecting Metamorphic Relations?",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a043/850300a043.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Marco",
				"surname": "Alecci"
			},
			"authorName": "Alecci, Marco",
			"articleRefs": [
				{
					"pageNumber": 3962,
					"articleName": "RAML: Toward Retrieval-Augmented Localization of Malicious Payloads in Android Apps",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d962/573300d962.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Aldeida",
				"surname": "Aleti"
			},
			"authorName": "Aleti, Aldeida",
			"articleRefs": [
				{
					"pageNumber": 3333,
					"articleName": "Multi-Modal Requirements Data-Based Acceptance Criteria Generation Using LLMs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d333/573300d333.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Georgios",
				"surname": "Alexopoulos"
			},
			"authorName": "Alexopoulos, Georgios",
			"articleRefs": [
				{
					"pageNumber": 4069,
					"articleName": "PyTrim: A Practical Tool for Reducing Python Dependency Bloat",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e069/573300e069.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Mahmoud ",
				"surname": "Alfadel"
			},
			"authorName": "Alfadel, Mahmoud",
			"articleRefs": [
				{
					"pageNumber": 2931,
					"articleName": "The Cost of Downgrading Build Systems A Case Study of Kubernetes",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c931/573300c931.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Abid ",
				"surname": "Ali"
			},
			"authorName": "Ali, Abid",
			"articleRefs": [
				{
					"pageNumber": 253,
					"articleName": "Fair Developer Score: Build-Adjusted Measurement of Effort and Impact",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a253/850300a253.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Karim",
				"surname": "Ali"
			},
			"authorName": "Ali, Karim",
			"articleRefs": [
				{
					"pageNumber": 4040,
					"articleName": "BuilDroid: A Self-Correcting LLM Agent for Automated Android Builds",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e040/573300e040.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Shaukat",
				"surname": "Ali"
			},
			"authorName": "Ali, Shaukat",
			"articleRefs": [
				{
					"pageNumber": 3402,
					"articleName": "Out of Distribution Detection in Self-Adaptive Robots with AI-Powered Digital Twins",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d402/573300d402.pdf"
				},
				{
					"pageNumber": 3694,
					"articleName": "Quantum Machine Learning-Based Test Oracle for Autonomous Mobile Robots",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d694/573300d694.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Nicholas",
				"surname": "Allen"
			},
			"authorName": "Allen, Nicholas",
			"articleRefs": [
				{
					"pageNumber": 3391,
					"articleName": "Unlocking Reproducibility: Automating re-Build Process for Open-Source Software",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d391/573300d391.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Juan C.",
				"surname": "Alonso"
			},
			"authorName": "Alonso, Juan C.",
			"articleRefs": [
				{
					"pageNumber": 1363,
					"articleName": "SATORI: Static Test Oracle Generation for REST APIs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b363/573300b363.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Tamjid",
				"surname": "Al Rahat"
			},
			"authorName": "Al Rahat, Tamjid",
			"articleRefs": [
				{
					"pageNumber": 2260,
					"articleName": "Automated Repair of OpenID Connect Programs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c260/573300c260.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Haifa",
				"surname": "Alshammare"
			},
			"authorName": "Alshammare, Haifa",
			"articleRefs": [
				{
					"pageNumber": 99,
					"articleName": "A Domain-Independent Framework for Effective Prioritization and Evaluation of UX Aspects in Mobile Apps",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a099/850300a099.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Mohammad",
				"surname": "Alshayeb"
			},
			"authorName": "Alshayeb, Mohammad",
			"articleRefs": [
				{
					"pageNumber": 99,
					"articleName": "A Domain-Independent Framework for Effective Prioritization and Evaluation of UX Aspects in Mobile Apps",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a099/850300a099.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Nicolas",
				"surname": "Amat"
			},
			"authorName": "Amat, Nicolas",
			"articleRefs": [
				{
					"pageNumber": 2669,
					"articleName": "How Big is the Automaton? Certified Lower Bounds on the Size of Presburger DFAs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c669/573300c669.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ardalan",
				"surname": "Amiri Sani"
			},
			"authorName": "Amiri Sani, Ardalan",
			"articleRefs": [
				{
					"pageNumber": 2170,
					"articleName": "Spinner: Detecting Locking Violations in the eBPF Runtime",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c170/573300c170.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Gal ",
				"surname": "Amram"
			},
			"authorName": "Amram, Gal",
			"articleRefs": [
				{
					"pageNumber": 30,
					"articleName": "Vintage Code, Modern Judges: Meta-Validation in Low Data Regimes",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a030/850300a030.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "One",
				"surname": "An"
			},
			"authorName": "An, One",
			"articleRefs": [
				{
					"pageNumber": 4124,
					"articleName": "First-Order Quantified Separator in Alloy Analyzer",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e124/573300e124.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Georgii",
				"surname": "Andriushchenko"
			},
			"authorName": "Andriushchenko, Georgii",
			"articleRefs": [
				{
					"pageNumber": 4152,
					"articleName": "Improving Quality of LLM Code Generation in Low-Resource Programming Languages via Uncertainty Estimation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e152/573300e152.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Abenezer",
				"surname": "Angamo"
			},
			"authorName": "Angamo, Abenezer",
			"articleRefs": [
				{
					"pageNumber": 4065,
					"articleName": "BenGQL: An Extensible Benchmarking Framework for Automated GraphQL Testing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e065/573300e065.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Guido",
				"surname": "Annicchiarico"
			},
			"authorName": "Annicchiarico, Guido",
			"articleRefs": [
				{
					"pageNumber": 3992,
					"articleName": "CodeGenLink: A Tool to Find the Likely Origin and License of Automatically Generated Code",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d992/573300d992.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ahmad",
				"surname": "Antar"
			},
			"authorName": "Antar, Ahmad",
			"articleRefs": [
				{
					"pageNumber": 253,
					"articleName": "Fair Developer Score: Build-Adjusted Measurement of Effort and Impact",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a253/850300a253.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Timos",
				"surname": "Antonopoulos"
			},
			"authorName": "Antonopoulos, Timos",
			"articleRefs": [
				{
					"pageNumber": 1324,
					"articleName": "Efficient and Verifiable Proof Logging for MaxSAT Solving",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b324/573300b324.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Anastasia",
				"surname": "Antsiferova"
			},
			"authorName": "Antsiferova, Anastasia",
			"articleRefs": [
				{
					"pageNumber": 4032,
					"articleName": "WIBE: Watermarks for generated Images \u2013 Benchmarking & Evaluation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e032/573300e032.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Sven",
				"surname": "Apel"
			},
			"authorName": "Apel, Sven",
			"articleRefs": [
				{
					"pageNumber": 166,
					"articleName": "An Empirical Study of Knowledge Transfer in AI Pair Programming",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a166/573300a166.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Paolo",
				"surname": "Arcaini"
			},
			"authorName": "Arcaini, Paolo",
			"articleRefs": [
				{
					"pageNumber": 3694,
					"articleName": "Quantum Machine Learning-Based Test Oracle for Autonomous Mobile Robots",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d694/573300d694.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Chetan",
				"surname": "Arora"
			},
			"authorName": "Arora, Chetan",
			"articleRefs": [
				{
					"pageNumber": 3333,
					"articleName": "Multi-Modal Requirements Data-Based Acceptance Criteria Generation Using LLMs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d333/573300d333.pdf"
				},
				{
					"pageNumber": 3380,
					"articleName": "AdaptiveGuard: Towards Adaptive Runtime Safety for LLM-Powered Software",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d380/573300d380.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Andrei",
				"surname": "Arzhantsev"
			},
			"authorName": "Arzhantsev, Andrei",
			"articleRefs": [
				{
					"pageNumber": 369,
					"articleName": "On the Importance of Context Filtering in Retrieval-Augmented Code Completion",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a369/850300a369.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Steven",
				"surname": "Arzt"
			},
			"authorName": "Arzt, Steven",
			"articleRefs": [
				{
					"pageNumber": 1615,
					"articleName": "Terminator: Enabling Efficient Fuzzing of Closed-Source GUI Programs by Automatic Coverage-Guided Termination",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b615/573300b615.pdf"
				},
				{
					"pageNumber": 3976,
					"articleName": "VUSC: An Extensible Research Platform for Java-Based Static Analysis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d976/573300d976.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Mari",
				"surname": "Ashiga"
			},
			"authorName": "Ashiga, Mari",
			"articleRefs": [
				{
					"pageNumber": 3568,
					"articleName": "Tuning LLM-Based Code Optimization via Meta-Prompting: An Industrial Perspective",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d568/573300d568.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Priyam",
				"surname": "Ashish Shah"
			},
			"authorName": "Ashish Shah, Priyam",
			"articleRefs": [
				{
					"pageNumber": 2362,
					"articleName": "Polyglot: An Extensible Framework to Benchmark Code Translation with LLMs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c362/573300c362.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Arjun",
				"surname": "Ashok"
			},
			"authorName": "Ashok, Arjun",
			"articleRefs": [
				{
					"pageNumber": 4073,
					"articleName": "OSSPREY: AI-Driven Forecasting and Intervention for OSS Project Sustainability",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e073/573300e073.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Wesley K. G.",
				"surname": "Assun\u00E7\u00E3o"
			},
			"authorName": "Assun\u00E7\u00E3o, Wesley K. G.",
			"articleRefs": [
				{
					"pageNumber": 4020,
					"articleName": "PrioTestCI: Efficient Test Case Prioritization in GitHub Workflows for CI Optimization",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e020/573300e020.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Mohammed Oualid",
				"surname": "Attaoui"
			},
			"authorName": "Attaoui, Mohammed Oualid",
			"articleRefs": [
				{
					"pageNumber": 3980,
					"articleName": "DESIGNATOR: a Toolset for Automated GAN-Enhanced Search-Based Testing and Retraining of DNNs in Martian Environments",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d980/573300d980.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Marco",
				"surname": "Autili"
			},
			"authorName": "Autili, Marco",
			"articleRefs": [
				{
					"pageNumber": 2451,
					"articleName": "Advancing Automated Ethical Profiling in SE: a Zero-Shot Evaluation of LLM Reasoning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c451/573300c451.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Paul\u00EDna",
				"surname": "Ayaziov\u00E1"
			},
			"authorName": "Ayaziov\u00E1, Paul\u00EDna",
			"articleRefs": [
				{
					"pageNumber": 1968,
					"articleName": "Non-Termination Witnesses and Their Validation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b968/573300b968.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Alberto",
				"surname": "Bacchelli"
			},
			"authorName": "Bacchelli, Alberto",
			"articleRefs": [
				{
					"pageNumber": 1311,
					"articleName": "Detecting Semantic Clones of Unseen Functionality",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b311/573300b311.pdf"
				},
				{
					"pageNumber": 1981,
					"articleName": "Automated Generation of Issue-Reproducing Tests by Combining LLMs and Search-Based Testing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b981/573300b981.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Doehyun",
				"surname": "Baek"
			},
			"authorName": "Baek, Doehyun",
			"articleRefs": [
				{
					"pageNumber": 816,
					"articleName": "Execution-Aware Program Reduction for WebAssembly via Record and Replay",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a816/573300a816.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Rafael",
				"surname": "Baez"
			},
			"authorName": "Baez, Rafael",
			"articleRefs": [
				{
					"pageNumber": 342,
					"articleName": "Risk Estimation in Differential Fuzzing via Extreme Value Theory",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a342/573300a342.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Mehdi",
				"surname": "Bagherzadeh"
			},
			"authorName": "Bagherzadeh, Mehdi",
			"articleRefs": [
				{
					"pageNumber": 752,
					"articleName": "Speculative Automated Refactoring of Imperative Deep Learning Programs to Graph Execution",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a752/573300a752.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xiaolong",
				"surname": "Bai"
			},
			"authorName": "Bai, Xiaolong",
			"articleRefs": [
				{
					"pageNumber": 217,
					"articleName": "R3-Bench: Reproducible Real-World Reverse Engineering Dataset for Symbol Recovery",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a217/573300a217.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yiyuan",
				"surname": "Bai"
			},
			"authorName": "Bai, Yiyuan",
			"articleRefs": [
				{
					"pageNumber": 547,
					"articleName": "DNAFuzz: Descriptor-Aware Fuzzing for USB Drivers",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a547/573300a547.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yubo",
				"surname": "Bai"
			},
			"authorName": "Bai, Yubo",
			"articleRefs": [
				{
					"pageNumber": 534,
					"articleName": "RustAssure: Differential Symbolic Testing for LLM-Transpiled C-to-Rust Code",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a534/573300a534.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jongmoon",
				"surname": "Baik"
			},
			"authorName": "Baik, Jongmoon",
			"articleRefs": [
				{
					"pageNumber": 1057,
					"articleName": "LOSVER: Line-Level Modifiability Signal-Guided Vulnerability Detection and Classification",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b057/573300b057.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Akhila",
				"surname": "Bairy"
			},
			"authorName": "Bairy, Akhila",
			"articleRefs": [
				{
					"pageNumber": 204,
					"articleName": "Explainability in Automated Cross-Domain Model-Driven Brake System Development",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a204/850300a204.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Levente",
				"surname": "Bajczi"
			},
			"authorName": "Bajczi, Levente",
			"articleRefs": [
				{
					"pageNumber": 1968,
					"articleName": "Non-Termination Witnesses and Their Validation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b968/573300b968.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yasharth",
				"surname": "Bajpai"
			},
			"authorName": "Bajpai, Yasharth",
			"articleRefs": [
				{
					"pageNumber": 432,
					"articleName": "Why AI Agents Still Need You: Findings from Developer-Agent Collaborations in the Wild",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a432/573300a432.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Harikrishnan",
				"surname": "Balagopal"
			},
			"authorName": "Balagopal, Harikrishnan",
			"articleRefs": [
				{
					"pageNumber": 4097,
					"articleName": "Training-Control-as-Code: Towards a Declarative Solution to Control Training",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e097/573300e097.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Aakash",
				"surname": "Bansal"
			},
			"authorName": "Bansal, Aakash",
			"articleRefs": [
				{
					"pageNumber": 1020,
					"articleName": "Programmers' Visual Attention on Function Call Graphs During Code Summarization",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b020/573300b020.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Chetan",
				"surname": "Bansal"
			},
			"authorName": "Bansal, Chetan",
			"articleRefs": [
				{
					"pageNumber": 674,
					"articleName": "Triangle: Empowering Incident Triage with Multi-Agent",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a674/573300a674.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Lingfeng",
				"surname": "Bao"
			},
			"authorName": "Bao, Lingfeng",
			"articleRefs": [
				{
					"pageNumber": 1337,
					"articleName": "FGIT: Fault-Guided Fine-Tuning for Code Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b337/573300b337.pdf"
				},
				{
					"pageNumber": 2554,
					"articleName": "ACTaint: Agent-Based Taint Analysis for Access Control Vulnerabilities in Smart Contracts",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c554/573300c554.pdf"
				},
				{
					"pageNumber": 2857,
					"articleName": "SolContractEval: A Benchmark for Evaluating Contract-Level Solidity Code Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c857/573300c857.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Pierluigi",
				"surname": "Barbiero"
			},
			"authorName": "Barbiero, Pierluigi",
			"articleRefs": [
				{
					"pageNumber": 3992,
					"articleName": "CodeGenLink: A Tool to Find the Likely Origin and License of Automatically Generated Code",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d992/573300d992.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Earl T.",
				"surname": "Barr"
			},
			"authorName": "Barr, Earl T.",
			"articleRefs": [
				{
					"pageNumber": 1426,
					"articleName": "Rechecking Recheck Requests in Continuous Integration: An Empirical Study of OpenStack",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b426/573300b426.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Amine",
				"surname": "Barrak"
			},
			"authorName": "Barrak, Amine",
			"articleRefs": [
				{
					"pageNumber": 316,
					"articleName": "Traceability and Accountability in Role-Specialized Multi-Agent LLM Pipelines",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a316/850300a316.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Alexandre",
				"surname": "Bartel"
			},
			"authorName": "Bartel, Alexandre",
			"articleRefs": [
				{
					"pageNumber": 3906,
					"articleName": "ConfuseTaint: Exploiting Vulnerabilities to Bypass Dynamic Taint Analysis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d906/573300d906.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Christian",
				"surname": "Bartelt"
			},
			"authorName": "Bartelt, Christian",
			"articleRefs": [
				{
					"pageNumber": 4052,
					"articleName": "GUI-ReRank: Enhancing GUI Retrieval with Multi-Modal LLM-Based Reranking",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e052/573300e052.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Antony",
				"surname": "Bartlett"
			},
			"authorName": "Bartlett, Antony",
			"articleRefs": [
				{
					"pageNumber": 66,
					"articleName": "The Last Dependency Crusade: Solving Python Dependency Conflicts with LLMs",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a066/850300a066.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ezio",
				"surname": "Bartocci"
			},
			"authorName": "Bartocci, Ezio",
			"articleRefs": [
				{
					"pageNumber": 3833,
					"articleName": "Fault Injection for Simulink-Based CPS Models: Insights and Future Directions",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d833/573300d833.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Claudio",
				"surname": "Bartolini"
			},
			"authorName": "Bartolini, Claudio",
			"articleRefs": [
				{
					"pageNumber": 2400,
					"articleName": "LLMs for Automated Unit Test Generation and Assessment in Java: The AgoneTest Framework",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c400/573300c400.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Mike",
				"surname": "Basios"
			},
			"authorName": "Basios, Mike",
			"articleRefs": [
				{
					"pageNumber": 3568,
					"articleName": "Tuning LLM-Based Code Optimization via Meta-Prompting: An Industrial Perspective",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d568/573300d568.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Malak",
				"surname": "Baslyman"
			},
			"authorName": "Baslyman, Malak",
			"articleRefs": [
				{
					"pageNumber": 99,
					"articleName": "A Domain-Independent Framework for Effective Prioritization and Evaluation of UX Aspects in Mobile Apps",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a099/850300a099.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Katharina",
				"surname": "Bause"
			},
			"authorName": "Bause, Katharina",
			"articleRefs": [
				{
					"pageNumber": 204,
					"articleName": "Explainability in Automated Cross-Domain Model-Driven Brake System Development",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a204/850300a204.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Gabriele",
				"surname": "Bavota"
			},
			"authorName": "Bavota, Gabriele",
			"articleRefs": [
				{
					"pageNumber": 1363,
					"articleName": "SATORI: Static Test Oracle Generation for REST APIs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b363/573300b363.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Dushyant",
				"surname": "Behl"
			},
			"authorName": "Behl, Dushyant",
			"articleRefs": [
				{
					"pageNumber": 4097,
					"articleName": "Training-Control-as-Code: Towards a Declarative Solution to Control Training",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e097/573300e097.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ali",
				"surname": "Behnaz"
			},
			"authorName": "Behnaz, Ali",
			"articleRefs": [
				{
					"pageNumber": 3759,
					"articleName": "What Types of Code Review Comments Do Developers Most Frequently Resolve?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d759/573300d759.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Farnaz",
				"surname": "Behrang"
			},
			"authorName": "Behrang, Farnaz",
			"articleRefs": [
				{
					"pageNumber": 2157,
					"articleName": "FlakyGuard: Automatically Fixing Flaky Tests at Industry Scale",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c157/573300c157.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Emery D.",
				"surname": "Berger"
			},
			"authorName": "Berger, Emery D.",
			"articleRefs": [
				{
					"pageNumber": 1552,
					"articleName": "It's Not Easy Being Green: On the Energy Efficiency of Programming Languages",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b552/573300b552.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Richard",
				"surname": "Berntsson Svensson"
			},
			"authorName": "Berntsson Svensson, Richard",
			"articleRefs": [
				{
					"pageNumber": 245,
					"articleName": "AI for Requirements Engineering: Industry Adoption and Practitioner Perspectives",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a245/850300a245.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Raheem",
				"surname": "Beyah"
			},
			"authorName": "Beyah, Raheem",
			"articleRefs": [
				{
					"pageNumber": 1044,
					"articleName": "PROMFUZZ: Leveraging LLM-Driven and Bug-Oriented Composite Analysis for Detecting Functional Bugs in Smart Contracts",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b044/573300b044.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Dirk",
				"surname": "Beyer"
			},
			"authorName": "Beyer, Dirk",
			"articleRefs": [
				{
					"pageNumber": 1968,
					"articleName": "Non-Termination Witnesses and Their Validation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b968/573300b968.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Alexander",
				"surname": "Bezzubov"
			},
			"authorName": "Bezzubov, Alexander",
			"articleRefs": [
				{
					"pageNumber": 358,
					"articleName": "Challenge on Optimization of Context Collection for Code Completion",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a358/850300a358.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Aaditya",
				"surname": "Bhatia"
			},
			"authorName": "Bhatia, Aaditya",
			"articleRefs": [
				{
					"pageNumber": 2324,
					"articleName": "SPICE\uD83C\uDF36\uFE0F: An Automated SWE-Bench Labeling Pipeline for Issue Clarity, Test Coverage, and Effort Estimation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c324/573300c324.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Shonil",
				"surname": "Bhide"
			},
			"authorName": "Bhide, Shonil",
			"articleRefs": [
				{
					"pageNumber": 4020,
					"articleName": "PrioTestCI: Efficient Test Case Prioritization in GitHub Workflows for CI Optimization",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e020/573300e020.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yogesh",
				"surname": "Bhootada"
			},
			"authorName": "Bhootada, Yogesh",
			"articleRefs": [
				{
					"pageNumber": 3250,
					"articleName": "Metrics Driven Reengineering and Continuous Code Improvement at Meta",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d250/573300d250.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Payal",
				"surname": "Bhuptani"
			},
			"authorName": "Bhuptani, Payal",
			"articleRefs": [
				{
					"pageNumber": 3250,
					"articleName": "Metrics Driven Reengineering and Continuous Code Improvement at Meta",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d250/573300d250.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Domenico",
				"surname": "Bianculli"
			},
			"authorName": "Bianculli, Domenico",
			"articleRefs": [
				{
					"pageNumber": 3833,
					"articleName": "Fault Injection for Simulink-Based CPS Models: Insights and Future Directions",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d833/573300d833.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Daniele",
				"surname": "Bifolco"
			},
			"authorName": "Bifolco, Daniele",
			"articleRefs": [
				{
					"pageNumber": 3992,
					"articleName": "CodeGenLink: A Tool to Find the Likely Origin and License of Automatically Generated Code",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d992/573300d992.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xiangrong",
				"surname": "Bin"
			},
			"authorName": "Bin, Xiangrong",
			"articleRefs": [
				{
					"pageNumber": 2349,
					"articleName": "Incremental Program Analysis in the Wild: An Empirical Study on Real-World Program Changes",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c349/573300c349.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Tegawend\u00E9 F.",
				"surname": "Bissyand\u00E9"
			},
			"authorName": "Bissyand\u00E9, Tegawend\u00E9 F.",
			"articleRefs": [
				{
					"pageNumber": 3921,
					"articleName": "Measuring LLM Code Generation Stability via Structural Entropy",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d921/573300d921.pdf"
				},
				{
					"pageNumber": 3962,
					"articleName": "RAML: Toward Retrieval-Augmented Localization of Malicious Payloads in Android Apps",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d962/573300d962.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Tegawend\u00E9 F. ",
				"surname": "Bissyande"
			},
			"authorName": "Bissyande, Tegawend\u00E9 F.",
			"articleRefs": [
				{
					"pageNumber": 4117,
					"articleName": "evalSmarT: An LLM-Based Framework for Evaluating Smart Contract Generated Comments",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e117/573300e117.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jakob",
				"surname": "Bleier"
			},
			"authorName": "Bleier, Jakob",
			"articleRefs": [
				{
					"pageNumber": 906,
					"articleName": "Profile Coverage: Using Android Compilation Profiles to Evaluate Dynamic Testing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a906/573300a906.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Defang",
				"surname": "Bo"
			},
			"authorName": "Bo, Defang",
			"articleRefs": [
				{
					"pageNumber": 2681,
					"articleName": "Understanding Resource Injection Vulnerabilities in Kubernetes Ecosystems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c681/573300c681.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Eric",
				"surname": "Bodden"
			},
			"authorName": "Bodden, Eric",
			"articleRefs": [
				{
					"pageNumber": 181,
					"articleName": "SeedUI: Understanding Initial Seeds in Fuzzing",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a181/850300a181.pdf"
				},
				{
					"pageNumber": 194,
					"articleName": "Explaining Software Vulnerabilities with Large Language Models",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a194/850300a194.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Egor",
				"surname": "Bogomolov"
			},
			"authorName": "Bogomolov, Egor",
			"articleRefs": [
				{
					"pageNumber": 358,
					"articleName": "Challenge on Optimization of Context Collection for Code Completion",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a358/850300a358.pdf"
				},
				{
					"pageNumber": 3509,
					"articleName": "TreeRanker: Fast and Model-Agnostic Ranking System for Code Suggestions in IDEs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d509/573300d509.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Agust\u00EDn",
				"surname": "Borda"
			},
			"authorName": "Borda, Agust\u00EDn",
			"articleRefs": [
				{
					"pageNumber": 2918,
					"articleName": "Automated Combinatorial Test Generation for Alloy",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c918/573300c918.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Aleksei",
				"surname": "Borodulin"
			},
			"authorName": "Borodulin, Aleksei",
			"articleRefs": [
				{
					"pageNumber": 229,
					"articleName": "Automated Evolutionary Hyperparameter Tuning for NLP-Based Test Case Generation",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a229/850300a229.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Bo\u017Cena",
				"surname": "Borowska"
			},
			"authorName": "Borowska, Bo\u017Cena",
			"articleRefs": [
				{
					"pageNumber": 304,
					"articleName": "Multi-agent systems for improved information retrieval \u2013 leveraging autonomous agents and LLM models",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a304/850300a304.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Daniel",
				"surname": "Borrajo"
			},
			"authorName": "Borrajo, Daniel",
			"articleRefs": [
				{
					"pageNumber": 39,
					"articleName": "Bridging LLM Planning Agents and Formal Methods: A Case Study in Plan Verification",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a039/850300a039.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Mikl\u00F3s",
				"surname": "Borsi"
			},
			"authorName": "Borsi, Mikl\u00F3s",
			"articleRefs": [
				{
					"pageNumber": 2643,
					"articleName": "Using Active Learning to Train Predictive Mutation Testing with Minimal Data",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c643/573300c643.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Dibyendu Brinto",
				"surname": "Bose"
			},
			"authorName": "Bose, Dibyendu Brinto",
			"articleRefs": [
				{
					"pageNumber": 43,
					"articleName": "LLMs in Debate: Does Arguing Make Them Better at Detecting Metamorphic Relations?",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a043/850300a043.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Islem",
				"surname": "Bouzenia"
			},
			"authorName": "Bouzenia, Islem",
			"articleRefs": [
				{
					"pageNumber": 2845,
					"articleName": "Understanding Software Engineering Agents: A Study of Thought-Action-Result Trajectories",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c845/573300c845.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Paul",
				"surname": "Brookes"
			},
			"authorName": "Brookes, Paul",
			"articleRefs": [
				{
					"pageNumber": 3568,
					"articleName": "Tuning LLM-Based Code Optimization via Meta-Prompting: An Industrial Perspective",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d568/573300d568.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Chris",
				"surname": "Brown"
			},
			"authorName": "Brown, Chris",
			"articleRefs": [
				{
					"pageNumber": 43,
					"articleName": "LLMs in Debate: Does Arguing Make Them Better at Detecting Metamorphic Relations?",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a043/850300a043.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Alexander",
				"surname": "Brownlee"
			},
			"authorName": "Brownlee, Alexander",
			"articleRefs": [
				{
					"pageNumber": 3901,
					"articleName": "LLM-Guided Genetic Improvement: Envisioning Semantic Aware Automated Software Evolution",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d901/573300d901.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Stefan",
				"surname": "Brunthaler"
			},
			"authorName": "Brunthaler, Stefan",
			"articleRefs": [
				{
					"pageNumber": 2732,
					"articleName": "TEPHRA: Principled Discovery of Fuzzer Limitations",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c732/573300c732.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yelizaveta",
				"surname": "Brus"
			},
			"authorName": "Brus, Yelizaveta",
			"articleRefs": [
				{
					"pageNumber": 1426,
					"articleName": "Rechecking Recheck Requests in Continuous Integration: An Empirical Study of OpenStack",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b426/573300b426.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Clemens-Alexander",
				"surname": "Brust"
			},
			"authorName": "Brust, Clemens-Alexander",
			"articleRefs": [
				{
					"pageNumber": 4000,
					"articleName": "FlowStrider: Low-Friction Continuous Threat Modeling",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d000/573300d000.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Lei",
				"surname": "Bu"
			},
			"authorName": "Bu, Lei",
			"articleRefs": [
				{
					"pageNumber": 2349,
					"articleName": "Incremental Program Analysis in the Wild: An Empirical Study on Real-World Program Changes",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c349/573300c349.pdf"
				},
				{
					"pageNumber": 2944,
					"articleName": "EPSO: A Caching-Based Efficient Superoptimizer for BPF Bytecode",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c944/573300c944.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Thanh-Long",
				"surname": "Bui"
			},
			"authorName": "Bui, Thanh-Long",
			"articleRefs": [
				{
					"pageNumber": 1032,
					"articleName": "An LLM-Based Multi-Agent Framework for Agile Effort Estimation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b032/573300b032.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Mike",
				"surname": "Buller"
			},
			"authorName": "Buller, Mike",
			"articleRefs": [
				{
					"pageNumber": 3759,
					"articleName": "What Types of Code Review Comments Do Developers Most Frequently Resolve?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d759/573300d759.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Matthew",
				"surname": "Burrows"
			},
			"authorName": "Burrows, Matthew",
			"articleRefs": [
				{
					"pageNumber": 2995,
					"articleName": "Your Build Scripts Stink: The State of Code Smells in Build Scripts",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c995/573300c995.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Joseph",
				"surname": "Bursey"
			},
			"authorName": "Bursey, Joseph",
			"articleRefs": [
				{
					"pageNumber": 2170,
					"articleName": "Spinner: Detecting Locking Violations in the eBPF Runtime",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c170/573300c170.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Alexis",
				"surname": "Butler"
			},
			"authorName": "Butler, Alexis",
			"articleRefs": [
				{
					"pageNumber": 3793,
					"articleName": "Measuring Software Resilience Using Socially Aware Truck Factor Estimation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d793/573300d793.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jordi",
				"surname": "Cabot"
			},
			"authorName": "Cabot, Jordi",
			"articleRefs": [
				{
					"pageNumber": 3765,
					"articleName": "Towards Reliable LLM-Based Exam Generation Lessons Learned and Open Challenges in an Industrial Project",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d765/573300d765.pdf"
				},
				{
					"pageNumber": 3890,
					"articleName": "Towards Automated Governance: A DSL for Human-Agent Collaboration in Software Projects",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d890/573300d890.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Hatice K\u00FCbra",
				"surname": "\u00C7a\u011Flar"
			},
			"authorName": "\u00C7a\u011Flar, Hatice K\u00FCbra",
			"articleRefs": [
				{
					"pageNumber": 1008,
					"articleName": "Automated Inline Comment Smell Detection and Repair with Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b008/573300b008.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Semih",
				"surname": "\u00C7a\u011Flar"
			},
			"authorName": "\u00C7a\u011Flar, Semih",
			"articleRefs": [
				{
					"pageNumber": 1008,
					"articleName": "Automated Inline Comment Smell Detection and Repair with Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b008/573300b008.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Miaoying",
				"surname": "Cai"
			},
			"authorName": "Cai, Miaoying",
			"articleRefs": [
				{
					"pageNumber": 521,
					"articleName": "GlassWing: A Tailored Static Analysis Approach for Flutter Android Apps",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a521/573300a521.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Peng",
				"surname": "Cai"
			},
			"authorName": "Cai, Peng",
			"articleRefs": [
				{
					"pageNumber": 3741,
					"articleName": "LogSage: An LLM-Based Framework for CI/CD Failure Detection and Remediation with Industrial Validation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d741/573300d741.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Saihua",
				"surname": "Cai"
			},
			"authorName": "Cai, Saihua",
			"articleRefs": [
				{
					"pageNumber": 3937,
					"articleName": "IDBFuzz: Web Storage DataBase Fuzzing with Controllable Semantics",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d937/573300d937.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Shaowei",
				"surname": "Cai"
			},
			"authorName": "Cai, Shaowei",
			"articleRefs": [
				{
					"pageNumber": 1272,
					"articleName": "SMTgazer: Learning to Schedule SMT Algorithms via Bayesian Optimization",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b272/573300b272.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Shiyu",
				"surname": "Cai"
			},
			"authorName": "Cai, Shiyu",
			"articleRefs": [
				{
					"pageNumber": 1414,
					"articleName": "VeriExploit: Automatic Bug Reproduction in Smart Contracts via LLMs and Formal Methods",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b414/573300b414.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xinyue",
				"surname": "Cai"
			},
			"authorName": "Cai, Xinyue",
			"articleRefs": [
				{
					"pageNumber": 2969,
					"articleName": "Vulnerability-Affected Versions Identification: How Far Are We?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c969/573300c969.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yi",
				"surname": "Cai"
			},
			"authorName": "Cai, Yi",
			"articleRefs": [
				{
					"pageNumber": 2247,
					"articleName": "Mixture-of-Experts Low-Rank Adaptation for Multilingual Code Summarization",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c247/573300c247.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yufan",
				"surname": "Cai"
			},
			"authorName": "Cai, Yufan",
			"articleRefs": [
				{
					"pageNumber": 2121,
					"articleName": "PAT-Agent: Autoformalization for Model Checking",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c121/573300c121.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jos\u00E9",
				"surname": "Campos"
			},
			"authorName": "Campos, Jos\u00E9",
			"articleRefs": [
				{
					"pageNumber": 2020,
					"articleName": "Interpretable Vulnerability Detection Reports",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c020/573300c020.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Gerardo",
				"surname": "Canfora"
			},
			"authorName": "Canfora, Gerardo",
			"articleRefs": [
				{
					"pageNumber": 3828,
					"articleName": "The Future of Software Transparency: Bridging Understanding, Measurement, and Practice",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d828/573300d828.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Javier Luis",
				"surname": "C\u00E1novas Izquierdo"
			},
			"authorName": "C\u00E1novas Izquierdo, Javier Luis",
			"articleRefs": [
				{
					"pageNumber": 3890,
					"articleName": "Towards Automated Governance: A DSL for Human-Agent Collaboration in Software Projects",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d890/573300d890.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Bin",
				"surname": "Cao"
			},
			"authorName": "Cao, Bin",
			"articleRefs": [
				{
					"pageNumber": 3777,
					"articleName": "SGCR: A Specification-Grounded Framework for Trustworthy LLM Code Review",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d777/573300d777.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Hongchen",
				"surname": "Cao"
			},
			"authorName": "Cao, Hongchen",
			"articleRefs": [
				{
					"pageNumber": 3942,
					"articleName": "STaint: Detecting Second-Order Vulnerabilities in PHP Applications with LLM-Assisted Bi-Directional Static Taint Analysis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d942/573300d942.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jialun",
				"surname": "Cao"
			},
			"authorName": "Cao, Jialun",
			"articleRefs": [
				{
					"pageNumber": 2969,
					"articleName": "Vulnerability-Affected Versions Identification: How Far Are We?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c969/573300c969.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Luyang",
				"surname": "Cao"
			},
			"authorName": "Cao, Luyang",
			"articleRefs": [
				{
					"pageNumber": 3414,
					"articleName": "Data Dependency-Aware Code Generation from Enhanced UML Sequence Diagrams",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d414/573300d414.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Rongyu",
				"surname": "Cao"
			},
			"authorName": "Cao, Rongyu",
			"articleRefs": [
				{
					"pageNumber": 3729,
					"articleName": "Thinking Longer, Not Larger: Enhancing Software Engineering Agents via Scaling Test-Time Compute",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d729/573300d729.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Shaoheng",
				"surname": "Cao"
			},
			"authorName": "Cao, Shaoheng",
			"articleRefs": [
				{
					"pageNumber": 1389,
					"articleName": "NATE: A Network-Aware Testing Enhancer for Network-Related Fault Detection in Android Apps",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b389/573300b389.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yiheng",
				"surname": "Cao"
			},
			"authorName": "Cao, Yiheng",
			"articleRefs": [
				{
					"pageNumber": 419,
					"articleName": "ProfMal: Detecting Malicious NPM Packages by the Synergy between Static and Dynamic Analysis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a419/573300a419.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yuan",
				"surname": "Cao"
			},
			"authorName": "Cao, Yuan",
			"articleRefs": [
				{
					"pageNumber": 3144,
					"articleName": "Practical Escape of Exploration Tarpits for Mini-Game Testing in an Industrial Setting",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d144/573300d144.pdf"
				},
				{
					"pageNumber": 3580,
					"articleName": "Element-Aware Fine-Tuning of Vision-Language Models for Cost-Efficient GUI Testing in an Industrial Setting",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d580/573300d580.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Sebasti\u00E3o",
				"surname": "Carvalho"
			},
			"authorName": "Carvalho, Sebasti\u00E3o",
			"articleRefs": [
				{
					"pageNumber": 121,
					"articleName": "On Effectiveness of Formal Model Repair by Large Language Models",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a121/850300a121.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Marco",
				"surname": "Castelluccio"
			},
			"authorName": "Castelluccio, Marco",
			"articleRefs": [
				{
					"pageNumber": 1981,
					"articleName": "Automated Generation of Issue-Reproducing Tests by Combining LLMs and Search-Based Testing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b981/573300b981.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Genevieve",
				"surname": "Caumartin"
			},
			"authorName": "Caumartin, Genevieve",
			"articleRefs": [
				{
					"pageNumber": 372,
					"articleName": "Beyond More Context: How Granularity and Order Drive Code Completion Quality",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a372/850300a372.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Sumit",
				"surname": "Chadgal"
			},
			"authorName": "Chadgal, Sumit",
			"articleRefs": [
				{
					"pageNumber": 4105,
					"articleName": "StackPlagger: A System for Identifying AI-Code Plagiarism on Stack Overflow",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e105/573300e105.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Avishak",
				"surname": "Chakroborty"
			},
			"authorName": "Chakroborty, Avishak",
			"articleRefs": [
				{
					"pageNumber": 1955,
					"articleName": "VRTestSniffer: Test Smell Detector for Virtual Reality (VR) Software Projects",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b955/573300b955.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Erick",
				"surname": "Chandra"
			},
			"authorName": "Chandra, Erick",
			"articleRefs": [
				{
					"pageNumber": 3895,
					"articleName": "Simulated Interactive Debugging",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d895/573300d895.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yash",
				"surname": "Chandrani"
			},
			"authorName": "Chandrani, Yash",
			"articleRefs": [
				{
					"pageNumber": 2995,
					"articleName": "Your Build Scripts Stink: The State of Code Smells in Build Scripts",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c995/573300c995.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Srinidhi",
				"surname": "Chandrashekar"
			},
			"authorName": "Chandrashekar, Srinidhi",
			"articleRefs": [
				{
					"pageNumber": 3895,
					"articleName": "Simulated Interactive Debugging",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d895/573300d895.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ee-Chien ",
				"surname": "Chang"
			},
			"authorName": "Chang, Ee-Chien",
			"articleRefs": [
				{
					"pageNumber": 726,
					"articleName": "Improving LLM-Based Log Parsing by Learning from Errors in Reasoning Traces",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a726/573300a726.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jianming",
				"surname": "Chang"
			},
			"authorName": "Chang, Jianming",
			"articleRefs": [
				{
					"pageNumber": 191,
					"articleName": "\"My Productivity is Boosted, but \u2026\" Demystifying Users' Perception on AI Coding Assistants",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a191/573300a191.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jiaxin",
				"surname": "Chang"
			},
			"authorName": "Chang, Jiaxin",
			"articleRefs": [
				{
					"pageNumber": 1376,
					"articleName": "Learning Project-Wise Subsequent Code Edits via Interleaving Neural-Based Induction and Tool-Based Deduction",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b376/573300b376.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Shi",
				"surname": "Chang"
			},
			"authorName": "Chang, Shi",
			"articleRefs": [
				{
					"pageNumber": 3286,
					"articleName": "Context-Aware CodeLLM Eviction for AI-Assisted Coding",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d286/573300d286.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Wanli",
				"surname": "Chang"
			},
			"authorName": "Chang, Wanli",
			"articleRefs": [
				{
					"pageNumber": 3226,
					"articleName": "TRON: Fuzzing Linux Network Stack via Protocol-System Call Payload Synthesis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d226/573300d226.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Oscar",
				"surname": "Chaparro"
			},
			"authorName": "Chaparro, Oscar",
			"articleRefs": [
				{
					"pageNumber": 2195,
					"articleName": "Generating Failure-Based Oracles to Support Testing of Reported Bugs in Android Apps",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c195/573300c195.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yiannis",
				"surname": "Charalambous"
			},
			"authorName": "Charalambous, Yiannis",
			"articleRefs": [
				{
					"pageNumber": 1414,
					"articleName": "VeriExploit: Automatic Bug Reproduction in Smart Contracts via LLMs and Formal Methods",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b414/573300b414.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Rujiphart",
				"surname": "Charatvaraphan"
			},
			"authorName": "Charatvaraphan, Rujiphart",
			"articleRefs": [
				{
					"pageNumber": 3996,
					"articleName": "PyGress: Tool for Analyzing the Progression of Code Proficiency in Python OSS Projects",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d996/573300d996.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Bunradar",
				"surname": "Chatchaiyadech"
			},
			"authorName": "Chatchaiyadech, Bunradar",
			"articleRefs": [
				{
					"pageNumber": 3996,
					"articleName": "PyGress: Tool for Analyzing the Progression of Code Proficiency in Python OSS Projects",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d996/573300d996.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Preetha",
				"surname": "Chatterjee"
			},
			"authorName": "Chatterjee, Preetha",
			"articleRefs": [
				{
					"pageNumber": 1439,
					"articleName": "Hierarchical Knowledge Injection for Improving LLM-Based Program Repair",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b439/573300b439.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Vaibhav",
				"surname": "Chaudhari"
			},
			"authorName": "Chaudhari, Vaibhav",
			"articleRefs": [
				{
					"pageNumber": 194,
					"articleName": "Explaining Software Vulnerabilities with Large Language Models",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a194/850300a194.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jiarui",
				"surname": "Che"
			},
			"authorName": "Che, Jiarui",
			"articleRefs": [
				{
					"pageNumber": 2145,
					"articleName": "Don't Mess with Bro's Cheese! An Empirical Study of Resource Conflict in Android Multi-Window",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c145/573300c145.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zeyu",
				"surname": "Che"
			},
			"authorName": "Che, Zeyu",
			"articleRefs": [
				{
					"pageNumber": 2221,
					"articleName": "LLM-Powered Multi-Agent Collaboration for Intelligent Industrial On-Call Automation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c221/573300c221.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xiaoyin ",
				"surname": "Che "
			},
			"authorName": "Che, Xiaoyin",
			"articleRefs": [
				{
					"pageNumber": 3592,
					"articleName": "AutoPLC: Generating Vendor-Aware Structured Text for Programmable Logic Controllers",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d592/573300d592.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Bihuan",
				"surname": "Chen"
			},
			"authorName": "Chen, Bihuan",
			"articleRefs": [
				{
					"pageNumber": 13,
					"articleName": "Argus: Resilience-Oriented Safety Assurance Framework for End-to-End ADSs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a013/573300a013.pdf"
				},
				{
					"pageNumber": 419,
					"articleName": "ProfMal: Detecting Malicious NPM Packages by the Synergy between Static and Dynamic Analysis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a419/573300a419.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Bofei",
				"surname": "Chen"
			},
			"authorName": "Chen, Bofei",
			"articleRefs": [
				{
					"pageNumber": 932,
					"articleName": "Exploring Static Taint Analysis in LLMs: A Dynamic Benchmarking Framework for Measurement and Enhancement",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a932/573300a932.pdf"
				},
				{
					"pageNumber": 2869,
					"articleName": "LLMPort: Cross-File Patch Porting via Task Decomposition and Self-Correction",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c869/573300c869.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Boyuan ",
				"surname": "Chen"
			},
			"authorName": "Chen, Boyuan",
			"articleRefs": [
				{
					"pageNumber": 2324,
					"articleName": "SPICE\uD83C\uDF36\uFE0F: An Automated SWE-Bench Labeling Pipeline for Issue Clarity, Test Coverage, and Effort Estimation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c324/573300c324.pdf"
				},
				{
					"pageNumber": 3286,
					"articleName": "Context-Aware CodeLLM Eviction for AI-Assisted Coding",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d286/573300d286.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Chunyang",
				"surname": "Chen"
			},
			"authorName": "Chen, Chunyang",
			"articleRefs": [
				{
					"pageNumber": 1155,
					"articleName": "Seeing is Fixing: Cross-Modal Reasoning with Multimodal LLMs for Visual Software Issue Repair",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b155/573300b155.pdf"
				},
				{
					"pageNumber": 1602,
					"articleName": "Beyond Static GUI Agent: Evolving LLM-Based GUI Testing via Dynamic Memory",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b602/573300b602.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Dajun",
				"surname": "Chen"
			},
			"authorName": "Chen, Dajun",
			"articleRefs": [
				{
					"pageNumber": 1830,
					"articleName": "PEACE: Towards Efficient Project-Level Efficiency Optimization via Hybrid Code Editing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b830/573300b830.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Haiming",
				"surname": "Chen"
			},
			"authorName": "Chen, Haiming",
			"articleRefs": [
				{
					"pageNumber": 2969,
					"articleName": "Vulnerability-Affected Versions Identification: How Far Are We?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c969/573300c969.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Haoxuan",
				"surname": "Chen"
			},
			"authorName": "Chen, Haoxuan",
			"articleRefs": [
				{
					"pageNumber": 3020,
					"articleName": "RealisticCodeBench: Towards More Realistic Evaluation of Large Language Models for Code Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d020/573300d020.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Hongbo",
				"surname": "Chen"
			},
			"authorName": "Chen, Hongbo",
			"articleRefs": [
				{
					"pageNumber": 893,
					"articleName": "LineBreaker: Finding Token-Inconsistency Bugs with Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a893/573300a893.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Hongqiao",
				"surname": "Chen"
			},
			"authorName": "Chen, Hongqiao",
			"articleRefs": [
				{
					"pageNumber": 854,
					"articleName": "DLBENCH: A Comprehensive Benchmark for SQL Translation with Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a854/573300a854.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Huaming",
				"surname": "Chen"
			},
			"authorName": "Chen, Huaming",
			"articleRefs": [
				{
					"pageNumber": 3818,
					"articleName": "Uncovering Systematic Failures of LLMs in Verifying Code Against Natural Language Specifications",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d818/573300d818.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jiachi",
				"surname": "Chen"
			},
			"authorName": "Chen, Jiachi",
			"articleRefs": [
				{
					"pageNumber": 571,
					"articleName": "SSR: Safeguarding Staking Rewards by Defining and Detecting Logical Defects in DeFi Staking",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a571/573300a571.pdf"
				},
				{
					"pageNumber": 778,
					"articleName": "DrainCode: Stealthy Energy Consumption Attacks on Retrieval-Augmented Code Generation via Context Poisoning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a778/573300a778.pdf"
				},
				{
					"pageNumber": 971,
					"articleName": "AlignCoder: Aligning Retrieval with Target Intent for Repository-Level Code Completion",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a971/573300a971.pdf"
				},
				{
					"pageNumber": 2554,
					"articleName": "ACTaint: Agent-Based Taint Analysis for Access Control Vulnerabilities in Smart Contracts",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c554/573300c554.pdf"
				},
				{
					"pageNumber": 2857,
					"articleName": "SolContractEval: A Benchmark for Evaluating Contract-Level Solidity Code Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c857/573300c857.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jianjun",
				"surname": "Chen"
			},
			"authorName": "Chen, Jianjun",
			"articleRefs": [
				{
					"pageNumber": 2095,
					"articleName": "SPEC2CODE: Mapping Protocol Specification to Function-Level Code Implementation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c095/573300c095.pdf"
				},
				{
					"pageNumber": 3298,
					"articleName": "LogPilot: Intent-Aware and Scalable Alert Diagnosis for Large-Scale Online Service Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d298/573300d298.pdf"
				},
				{
					"pageNumber": 3425,
					"articleName": "Automated Proactive Logging Quality Improvement for Large-Scale Codebases ",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d425/573300d425.pdf"
				},
				{
					"pageNumber": 3533,
					"articleName": "ErrorPrism: Reconstructing Error Propagation Paths in Cloud Service Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d533/573300d533.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jiapeng",
				"surname": "Chen"
			},
			"authorName": "Chen, Jiapeng",
			"articleRefs": [
				{
					"pageNumber": 3753,
					"articleName": "KAIR: A Statistical and Causal Approach to Pinpointing Stragglers in Distributed Model Training",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d753/573300d753.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jinfu",
				"surname": "Chen"
			},
			"authorName": "Chen, Jinfu",
			"articleRefs": [
				{
					"pageNumber": 3937,
					"articleName": "IDBFuzz: Web Storage DataBase Fuzzing with Controllable Semantics",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d937/573300d937.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jingting",
				"surname": "Chen"
			},
			"authorName": "Chen, Jingting",
			"articleRefs": [
				{
					"pageNumber": 2681,
					"articleName": "Understanding Resource Injection Vulnerabilities in Kubernetes Ecosystems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c681/573300c681.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jingyi",
				"surname": "Chen"
			},
			"authorName": "Chen, Jingyi",
			"articleRefs": [
				{
					"pageNumber": 3937,
					"articleName": "IDBFuzz: Web Storage DataBase Fuzzing with Controllable Semantics",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d937/573300d937.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jiongyi",
				"surname": "Chen"
			},
			"authorName": "Chen, Jiongyi",
			"articleRefs": [
				{
					"pageNumber": 2057,
					"articleName": "FirmProj: Detecting Firmware Leakage in IoT Update Processes via Companion App Analysis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c057/573300c057.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jue",
				"surname": "Chen"
			},
			"authorName": "Chen, Jue",
			"articleRefs": [
				{
					"pageNumber": 3729,
					"articleName": "Thinking Longer, Not Larger: Enhancing Software Engineering Agents via Scaling Test-Time Compute",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d729/573300d729.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Junjie",
				"surname": "Chen"
			},
			"authorName": "Chen, Junjie",
			"articleRefs": [
				{
					"pageNumber": 2375,
					"articleName": "Interleaved Learning and Exploration: A Self-Adaptive Fuzz Testing Framework for MLIR",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c375/573300c375.pdf"
				},
				{
					"pageNumber": 2833,
					"articleName": "Reflective Unit Test Generation for Precise Type Error Detection with Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c833/573300c833.pdf"
				},
				{
					"pageNumber": 3045,
					"articleName": "Clarifying Semantics of In-Context Examples for Unit Test Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d045/573300d045.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Kai",
				"surname": "Chen"
			},
			"authorName": "Chen, Kai",
			"articleRefs": [
				{
					"pageNumber": 3368,
					"articleName": "A Characterization Study of Bugs in LLM Agent Workflow Orchestration Frameworks",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d368/573300d368.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Kexin",
				"surname": "Chen"
			},
			"authorName": "Chen, Kexin",
			"articleRefs": [
				{
					"pageNumber": 1868,
					"articleName": "ORFUZZ: Fuzzing the \"Other Side\" of LLM Safety \u2013 Testing Over-Refusal",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b868/573300b868.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Liehang",
				"surname": "Chen"
			},
			"authorName": "Chen, Liehang",
			"articleRefs": [
				{
					"pageNumber": 854,
					"articleName": "DLBENCH: A Comprehensive Benchmark for SQL Translation with Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a854/573300a854.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ligeng",
				"surname": "Chen"
			},
			"authorName": "Chen, Ligeng",
			"articleRefs": [
				{
					"pageNumber": 457,
					"articleName": "Uncovering Prompt Elements: Cloning System Prompts from Behavioral Traces",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a457/573300a457.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Liqian",
				"surname": "Chen"
			},
			"authorName": "Chen, Liqian",
			"articleRefs": [
				{
					"pageNumber": 804,
					"articleName": "Let the Code Speak: Incorporating Program Dynamic State for Better Method-Level Fault Localization",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a804/573300a804.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Liushan",
				"surname": "Chen"
			},
			"authorName": "Chen, Liushan",
			"articleRefs": [
				{
					"pageNumber": 623,
					"articleName": "Enhancing LLM's Ability to Generate More Repository-Aware Unit Tests Through Precise Context Injection",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a623/573300a623.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Longfei",
				"surname": "Chen"
			},
			"authorName": "Chen, Longfei",
			"articleRefs": [
				{
					"pageNumber": 228,
					"articleName": "RELIA: Accelerating the Analysis of Cloud Access Control Policies",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a228/573300a228.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Mengzhuo",
				"surname": "Chen"
			},
			"authorName": "Chen, Mengzhuo",
			"articleRefs": [
				{
					"pageNumber": 1602,
					"articleName": "Beyond Static GUI Agent: Evolving LLM-Based GUI Testing via Dynamic Memory",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b602/573300b602.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Pengfei",
				"surname": "Chen"
			},
			"authorName": "Chen, Pengfei",
			"articleRefs": [
				{
					"pageNumber": 1,
					"articleName": "AlertGuardian: Intelligent Alert Life-Cycle Management for Large-Scale Cloud Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a001/573300a001.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Sen",
				"surname": "Chen"
			},
			"authorName": "Chen, Sen",
			"articleRefs": [
				{
					"pageNumber": 95,
					"articleName": "DroidNative: A Greedy-Constructed Large-Scale Indexing for Android Native Libraries",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a095/850300a095.pdf"
				},
				{
					"pageNumber": 521,
					"articleName": "GlassWing: A Tailored Static Analysis Approach for Flutter Android Apps",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a521/573300a521.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Sirong",
				"surname": "Chen"
			},
			"authorName": "Chen, Sirong",
			"articleRefs": [
				{
					"pageNumber": 3414,
					"articleName": "Data Dependency-Aware Code Generation from Enhanced UML Sequence Diagrams",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d414/573300d414.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Songqiang",
				"surname": "Chen"
			},
			"authorName": "Chen, Songqiang",
			"articleRefs": [
				{
					"pageNumber": 2208,
					"articleName": "LSPFuzz: Hunting Bugs in Language Servers",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c208/573300c208.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Tao",
				"surname": "Chen"
			},
			"authorName": "Chen, Tao",
			"articleRefs": [
				{
					"pageNumber": 1489,
					"articleName": "CoTune: Co-Evolutionary Configuration Tuning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b489/573300b489.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Taolue",
				"surname": "Chen"
			},
			"authorName": "Chen, Taolue",
			"articleRefs": [
				{
					"pageNumber": 154,
					"articleName": "CODE-DITING: Automatic Evaluation of Code Generation Without References or Test Cases",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a154/573300a154.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Tse-Hsun Peter",
				"surname": "Chen"
			},
			"authorName": "Chen, Tse-Hsun Peter",
			"articleRefs": [
				{
					"pageNumber": 3718,
					"articleName": "MobileUPReg: Identifying User-Perceived Performance Regressions in Mobile OS Versions",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d718/573300d718.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Wenting",
				"surname": "Chen"
			},
			"authorName": "Chen, Wenting",
			"articleRefs": [
				{
					"pageNumber": 2905,
					"articleName": "Metamorphic Testing for Audio Content Moderation Software",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c905/573300c905.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xiang",
				"surname": "Chen"
			},
			"authorName": "Chen, Xiang",
			"articleRefs": [
				{
					"pageNumber": 154,
					"articleName": "CODE-DITING: Automatic Evaluation of Code Generation Without References or Test Cases",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a154/573300a154.pdf"
				},
				{
					"pageNumber": 2477,
					"articleName": "Evaluating and Improving Framework-Based Parallel Code Completion with Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c477/573300c477.pdf"
				},
				{
					"pageNumber": 2554,
					"articleName": "ACTaint: Agent-Based Taint Analysis for Access Control Vulnerabilities in Smart Contracts",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c554/573300c554.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xin",
				"surname": "Chen"
			},
			"authorName": "Chen, Xin",
			"articleRefs": [
				{
					"pageNumber": 2082,
					"articleName": "Breaking the Traffic Barrier: Unveiling Multi-Format of Protocols via Autonomous Program Exploration",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c082/573300c082.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xingchu",
				"surname": "Chen"
			},
			"authorName": "Chen, Xingchu",
			"articleRefs": [
				{
					"pageNumber": 1069,
					"articleName": "A Large Scale Study of AI-Based Binary Function Similarity Detection Techniques for Security Researchers and Practitioners",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b069/573300b069.pdf"
				},
				{
					"pageNumber": 2969,
					"articleName": "Vulnerability-Affected Versions Identification: How Far Are We?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c969/573300c969.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xun",
				"surname": "Chen"
			},
			"authorName": "Chen, Xun",
			"articleRefs": [
				{
					"pageNumber": 893,
					"articleName": "LineBreaker: Finding Token-Inconsistency Bugs with Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a893/573300a893.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yanju",
				"surname": "Chen"
			},
			"authorName": "Chen, Yanju",
			"articleRefs": [
				{
					"pageNumber": 2260,
					"articleName": "Automated Repair of OpenID Connect Programs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c260/573300c260.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yifan",
				"surname": "Chen"
			},
			"authorName": "Chen, Yifan",
			"articleRefs": [
				{
					"pageNumber": 1565,
					"articleName": "Belief Propagation with Local Structure and Its Applications in Program Analysis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b565/573300b565.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yifei",
				"surname": "Chen"
			},
			"authorName": "Chen, Yifei",
			"articleRefs": [
				{
					"pageNumber": 39,
					"articleName": "MIMIC: Integrating Diverse Personality Traits for Better Game Testing Using Large Language Model",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a039/573300a039.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yihao",
				"surname": "Chen"
			},
			"authorName": "Chen, Yihao",
			"articleRefs": [
				{
					"pageNumber": 2324,
					"articleName": "SPICE\uD83C\uDF36\uFE0F: An Automated SWE-Bench Labeling Pipeline for Issue Clarity, Test Coverage, and Effort Estimation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c324/573300c324.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yixiang",
				"surname": "Chen"
			},
			"authorName": "Chen, Yixiang",
			"articleRefs": [
				{
					"pageNumber": 945,
					"articleName": "Demystifying OpenZeppelin's Own Vulnerabilities and Analyzing Their Propagation in Smart Contracts",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a945/573300a945.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yongle",
				"surname": "Chen"
			},
			"authorName": "Chen, Yongle",
			"articleRefs": [
				{
					"pageNumber": 304,
					"articleName": "Advancing Binary Code Similarity Detection via Context-Content Fusion and LLM Verification",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a304/573300a304.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yu",
				"surname": "Chen"
			},
			"authorName": "Chen, Yu",
			"articleRefs": [
				{
					"pageNumber": 129,
					"articleName": "Diagnosing Performance Differences in Model Checkers via Runtime-Guided Problem Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a129/573300a129.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yuanliang",
				"surname": "Chen"
			},
			"authorName": "Chen, Yuanliang",
			"articleRefs": [
				{
					"pageNumber": 547,
					"articleName": "DNAFuzz: Descriptor-Aware Fuzzing for USB Drivers",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a547/573300a547.pdf"
				},
				{
					"pageNumber": 765,
					"articleName": "DualFuzz: Detecting Vulnerability in Wi-Fi NICs through Dual-Directional Fuzzing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a765/573300a765.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yueyan",
				"surname": "Chen"
			},
			"authorName": "Chen, Yueyan",
			"articleRefs": [
				{
					"pageNumber": 3485,
					"articleName": "BitsAI-Fix: LLM-Driven Approach for Automated Lint Error Resolution in Practice",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d485/573300d485.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yufeng",
				"surname": "Chen"
			},
			"authorName": "Chen, Yufeng",
			"articleRefs": [
				{
					"pageNumber": 1069,
					"articleName": "A Large Scale Study of AI-Based Binary Function Similarity Detection Techniques for Security Researchers and Practitioners",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b069/573300b069.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yuhan",
				"surname": "Chen"
			},
			"authorName": "Chen, Yuhan",
			"articleRefs": [
				{
					"pageNumber": 3156,
					"articleName": "Industry Practice of LLM-Assisted Protocol Fuzzing for Commercial Communication Modules",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d156/573300d156.pdf"
				},
				{
					"pageNumber": 3615,
					"articleName": "RPG: Linux Kernel Fuzzing Guided by Distribution-Specific Runtime Parameter Interfaces",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d615/573300d615.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yujia",
				"surname": "Chen"
			},
			"authorName": "Chen, Yujia",
			"articleRefs": [
				{
					"pageNumber": 3449,
					"articleName": "Automated Prompt Generation for Code Intelligence: An Empirical Study and Experience in WeChat",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d449/573300d449.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yujing",
				"surname": "Chen"
			},
			"authorName": "Chen, Yujing",
			"articleRefs": [
				{
					"pageNumber": 2070,
					"articleName": "Why Is My Transaction Risky? Understanding Smart Contract Semantics and Interactions in the NFT Ecosystem",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c070/573300c070.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yuxuan",
				"surname": "Chen"
			},
			"authorName": "Chen, Yuxuan",
			"articleRefs": [
				{
					"pageNumber": 610,
					"articleName": "RustRepoTrans: Repository-Level Context Code Translation Benchmark Targeting Rust",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a610/573300a610.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zehan",
				"surname": "Chen"
			},
			"authorName": "Chen, Zehan",
			"articleRefs": [
				{
					"pageNumber": 495,
					"articleName": "RSFuzz: A Robustness-Guided Swarm Fuzzing Framework Based on Behavioral Constraints",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a495/573300a495.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zhenyu ",
				"surname": "Chen"
			},
			"authorName": "Chen, Zhenyu",
			"articleRefs": [
				{
					"pageNumber": 1168,
					"articleName": "When Autonomous Vehicle Meets V2X Cooperative Perception: How Far Are We?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b168/573300b168.pdf"
				},
				{
					"pageNumber": 1793,
					"articleName": "Multi-Dimensional Assessment of Crowdsourced Testing Reports via LLMs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b793/573300b793.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zhilong",
				"surname": "Chen"
			},
			"authorName": "Chen, Zhilong",
			"articleRefs": [
				{
					"pageNumber": 2324,
					"articleName": "SPICE\uD83C\uDF36\uFE0F: An Automated SWE-Bench Labeling Pipeline for Issue Clarity, Test Coverage, and Effort Estimation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c324/573300c324.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zhuangbin",
				"surname": "Chen"
			},
			"authorName": "Chen, Zhuangbin",
			"articleRefs": [
				{
					"pageNumber": 3425,
					"articleName": "Automated Proactive Logging Quality Improvement for Large-Scale Codebases ",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d425/573300d425.pdf"
				},
				{
					"pageNumber": 3533,
					"articleName": "ErrorPrism: Reconstructing Error Propagation Paths in Cloud Service Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d533/573300d533.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zhuoru",
				"surname": "Chen"
			},
			"authorName": "Chen, Zhuoru",
			"articleRefs": [
				{
					"pageNumber": 3144,
					"articleName": "Practical Escape of Exploration Tarpits for Mini-Game Testing in an Industrial Setting",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d144/573300d144.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Shaoyin",
				"surname": "Cheng"
			},
			"authorName": "Cheng, Shaoyin",
			"articleRefs": [
				{
					"pageNumber": 841,
					"articleName": "PseudoFix: Refactoring Distorted Structures in Decompiled C Pseudocode",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a841/573300a841.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Shing-Chi",
				"surname": "Cheung"
			},
			"authorName": "Cheung, Shing-Chi",
			"articleRefs": [
				{
					"pageNumber": 1743,
					"articleName": "CROSS2OH: Enabling Seamless Porting of C/C++ Software Libraries to OpenHarmony",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b743/573300b743.pdf"
				},
				{
					"pageNumber": 1767,
					"articleName": "Demystifying Cross-Language C/C++ Binaries: A Robust Software Component Analysis Approach",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b767/573300b767.pdf"
				},
				{
					"pageNumber": 2208,
					"articleName": "LSPFuzz: Hunting Bugs in Language Servers",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c208/573300c208.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Shu",
				"surname": "Chi"
			},
			"authorName": "Chi, Shu",
			"articleRefs": [
				{
					"pageNumber": 674,
					"articleName": "Triangle: Empowering Incident Triage with Multi-Agent",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a674/573300a674.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Tianyang",
				"surname": "Chi"
			},
			"authorName": "Chi, Tianyang",
			"articleRefs": [
				{
					"pageNumber": 3660,
					"articleName": "The Gold Digger in the Dark Forest: Industrial-Scale MEV Analysis in Ethereum",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d660/573300d660.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ben-Hau",
				"surname": "Chia"
			},
			"authorName": "Chia, Ben-Hau",
			"articleRefs": [
				{
					"pageNumber": 3911,
					"articleName": "Human-In-The-Loop Oracle Learning for Simulation-Based Testing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d911/573300d911.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Nariyoshi",
				"surname": "Chida"
			},
			"authorName": "Chida, Nariyoshi",
			"articleRefs": [
				{
					"pageNumber": 3967,
					"articleName": "A Secure Mocking Approach Towards Software Supply Chain Security",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d967/573300d967.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Murali",
				"surname": "Chintalapati"
			},
			"authorName": "Chintalapati, Murali",
			"articleRefs": [
				{
					"pageNumber": 674,
					"articleName": "Triangle: Empowering Incident Triage with Multi-Agent",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a674/573300a674.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Seogyeong",
				"surname": "Cho"
			},
			"authorName": "Cho, Seogyeong",
			"articleRefs": [
				{
					"pageNumber": 1577,
					"articleName": "CRYPTBARA: Dependency-Guided Detection of Python Cryptographic API Misuses",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b577/573300b577.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Steven",
				"surname": "Cho"
			},
			"authorName": "Cho, Steven",
			"articleRefs": [
				{
					"pageNumber": 4085,
					"articleName": "Metamorphic Testing of Deep Reinforcement Learning Agents with MDPMORPH",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e085/573300e085.pdf"
				},
				{
					"pageNumber": 4101,
					"articleName": "LLMORPH: Automated Metamorphic Testing of Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e101/573300e101.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Morakot",
				"surname": "Choetkiertikul"
			},
			"authorName": "Choetkiertikul, Morakot",
			"articleRefs": [
				{
					"pageNumber": 261,
					"articleName": "Exploring the SECURITY.md in the Dependency Chain: Preliminary Analysis of the PyPI Ecosystem",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a261/850300a261.pdf"
				},
				{
					"pageNumber": 3996,
					"articleName": "PyGress: Tool for Analyzing the Progression of Code Proficiency in Python OSS Projects",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d996/573300d996.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Eunkyung",
				"surname": "Choi"
			},
			"authorName": "Choi, Eunkyung",
			"articleRefs": [
				{
					"pageNumber": 176,
					"articleName": "K-SNAC: Robust Neuron Coverage for OOD Generalization and Test Adequacy",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a176/850300a176.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Hongjun",
				"surname": "Choi"
			},
			"authorName": "Choi, Hongjun",
			"articleRefs": [
				{
					"pageNumber": 1590,
					"articleName": "IMUFUZZER: Resilience-Based Discovery of Signal Injection Attacks on Robotic Aerial Vehicles",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b590/573300b590.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Chun Yong ",
				"surname": "Chong"
			},
			"authorName": "Chong, Chun Yong",
			"articleRefs": [
				{
					"pageNumber": 1893,
					"articleName": "Diplomatist: What Do Cross-Language Dependencies Reflect Software Ecosystem Health?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b893/573300b893.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Kenny",
				"surname": "Choo"
			},
			"authorName": "Choo, Kenny",
			"articleRefs": [
				{
					"pageNumber": 3895,
					"articleName": "Simulated Interactive Debugging",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d895/573300d895.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Bei",
				"surname": "Chu"
			},
			"authorName": "Chu, Bei",
			"articleRefs": [
				{
					"pageNumber": 2719,
					"articleName": "PALM: Synergizing Program Analysis and LLMs to Enhance Rust Unit Test Coverage",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c719/573300c719.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yifei",
				"surname": "Chu"
			},
			"authorName": "Chu, Yifei",
			"articleRefs": [
				{
					"pageNumber": 3226,
					"articleName": "TRON: Fuzzing Linux Network Stack via Protocol-System Call Payload Synthesis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d226/573300d226.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Joey",
				"surname": "Chua"
			},
			"authorName": "Chua, Joey",
			"articleRefs": [
				{
					"pageNumber": 3380,
					"articleName": "AdaptiveGuard: Towards Adaptive Runtime Safety for LLM-Powered Software",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d380/573300d380.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Daniele",
				"surname": "Cipollone"
			},
			"authorName": "Cipollone, Daniele",
			"articleRefs": [
				{
					"pageNumber": 3509,
					"articleName": "TreeRanker: Fast and Model-Agnostic Ranking System for Code Suggestions in IDEs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d509/573300d509.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "J\u00FCrgen",
				"surname": "Cito"
			},
			"authorName": "Cito, J\u00FCrgen",
			"articleRefs": [
				{
					"pageNumber": 906,
					"articleName": "Profile Coverage: Using Android Compilation Profiles to Evaluate Dynamic Testing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a906/573300a906.pdf"
				},
				{
					"pageNumber": 1942,
					"articleName": "Efficient Understanding of Machine Learning Model Mispredictions",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b942/573300b942.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Tristan",
				"surname": "Coignion"
			},
			"authorName": "Coignion, Tristan",
			"articleRefs": [
				{
					"pageNumber": 1654,
					"articleName": "When Faster Isn't Greener: The Hidden Costs of LLM-Based Code Optimization",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b654/573300b654.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Sebastian",
				"surname": "Copei"
			},
			"authorName": "Copei, Sebastian",
			"articleRefs": [
				{
					"pageNumber": 277,
					"articleName": "LLMs Choose the Right Stack: From Patterns to Tools",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a277/850300a277.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Lucas",
				"surname": "Cordeiro"
			},
			"authorName": "Cordeiro, Lucas",
			"articleRefs": [
				{
					"pageNumber": 1414,
					"articleName": "VeriExploit: Automatic Bug Reproduction in Smart Contracts via LLMs and Formal Methods",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b414/573300b414.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Diego Elias",
				"surname": "Costa"
			},
			"authorName": "Costa, Diego Elias",
			"articleRefs": [
				{
					"pageNumber": 372,
					"articleName": "Beyond More Context: How Granularity and Order Drive Code Completion Quality",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a372/850300a372.pdf"
				},
				{
					"pageNumber": 1704,
					"articleName": "ADPerf: Investigating and Testing Performance in Autonomous Driving Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b704/573300b704.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Shaoke",
				"surname": "Cui"
			},
			"authorName": "Cui, Shaoke",
			"articleRefs": [
				{
					"pageNumber": 1272,
					"articleName": "SMTgazer: Learning to Schedule SMT Algorithms via Bayesian Optimization",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b272/573300b272.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Enze",
				"surname": "Dai"
			},
			"authorName": "Dai, Enze",
			"articleRefs": [
				{
					"pageNumber": 2579,
					"articleName": "WINGMUZZ: Blackbox Testing of IoT Protocols via Two-Dimensional Fuzzing Schedule",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c579/573300c579.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Hong-Ning",
				"surname": "Dai"
			},
			"authorName": "Dai, Hong-Ning",
			"articleRefs": [
				{
					"pageNumber": 482,
					"articleName": "VRExplorer: A Model-Based Approach for Semi-Automated Testing of Virtual Reality Scenes",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a482/573300a482.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jiarun",
				"surname": "Dai"
			},
			"authorName": "Dai, Jiarun",
			"articleRefs": [
				{
					"pageNumber": 559,
					"articleName": "Security Debt in LLM Agent Applications: A Measurement Study of Vulnerabilities and Mitigation Trade-Offs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a559/573300a559.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Gregorio",
				"surname": "Dalia"
			},
			"authorName": "Dalia, Gregorio",
			"articleRefs": [
				{
					"pageNumber": 3828,
					"articleName": "The Future of Software Transparency: Bridging Understanding, Measurement, and Practice",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d828/573300d828.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Hoa Khanh",
				"surname": "Dam"
			},
			"authorName": "Dam, Hoa Khanh",
			"articleRefs": [
				{
					"pageNumber": 312,
					"articleName": "Towards Multi-Agentic AI for Automated Software Design and Modelling: Challenges and Opportunities",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a312/850300a312.pdf"
				},
				{
					"pageNumber": 1032,
					"articleName": "An LLM-Based Multi-Agent Framework for Agile Effort Estimation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b032/573300b032.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Marvin",
				"surname": "Damschen"
			},
			"authorName": "Damschen, Marvin",
			"articleRefs": [
				{
					"pageNumber": 58,
					"articleName": "Leveraging Large Language Models for Cybersecurity Risk Assessment \u2014 A Case from Forestry Cyber-Physical Systems",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a058/850300a058.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Lan Hoang ",
				"surname": "Dao"
			},
			"authorName": "Dao, Lan Hoang",
			"articleRefs": [
				{
					"pageNumber": 3250,
					"articleName": "Metrics Driven Reengineering and Continuous Code Improvement at Meta",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d250/573300d250.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Umer",
				"surname": "Daraz"
			},
			"authorName": "Daraz, Umer",
			"articleRefs": [
				{
					"pageNumber": 87,
					"articleName": "A Data-Driven Approach for Automated Quality Concern Extraction from App Reviews",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a087/850300a087.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ravi Shankar",
				"surname": "Das"
			},
			"authorName": "Das, Ravi Shankar",
			"articleRefs": [
				{
					"pageNumber": 3972,
					"articleName": "AndroFL: Evolutionary-Driven Fault Localization for Android Apps",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d972/573300d972.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Santanu Kumar",
				"surname": "Dash"
			},
			"authorName": "Dash, Santanu Kumar",
			"articleRefs": [
				{
					"pageNumber": 3793,
					"articleName": "Measuring Software Resilience Using Socially Aware Truck Factor Estimation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d793/573300d793.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ana\u00E9",
				"surname": "De Baets"
			},
			"authorName": "De Baets, Ana\u00E9",
			"articleRefs": [
				{
					"pageNumber": 4028,
					"articleName": "FETT: Fault Injection as an Educational and Training Tool in Cybersecurity",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e028/573300e028.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Renzo",
				"surname": "Degiovanni"
			},
			"authorName": "Degiovanni, Renzo",
			"articleRefs": [
				{
					"pageNumber": 3765,
					"articleName": "Towards Reliable LLM-Based Exam Generation Lessons Learned and Open Challenges in an Industrial Project",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d765/573300d765.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Benjamin",
				"surname": "Delaware"
			},
			"authorName": "Delaware, Benjamin",
			"articleRefs": [
				{
					"pageNumber": 3107,
					"articleName": "LLM-Assisted Synthesis of High-Assurance C Programs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d107/573300d107.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Devon ",
				"surname": "Delgado"
			},
			"authorName": "Delgado, Devon",
			"articleRefs": [
				{
					"pageNumber": 253,
					"articleName": "Fair Developer Score: Build-Adjusted Measurement of Effort and Impact",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a253/850300a253.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Brian",
				"surname": "Demsky"
			},
			"authorName": "Demsky, Brian",
			"articleRefs": [
				{
					"pageNumber": 2528,
					"articleName": "Automated Insertion of Flushes and Fences for Persistency",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c528/573300c528.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Bowen",
				"surname": "Deng"
			},
			"authorName": "Deng, Bowen",
			"articleRefs": [
				{
					"pageNumber": 3497,
					"articleName": "Adaptive Performance Regression Detection Using A Semi-Supervised Siamese Network",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d497/573300d497.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jiapeng",
				"surname": "Deng"
			},
			"authorName": "Deng, Jiapeng",
			"articleRefs": [
				{
					"pageNumber": 3167,
					"articleName": "HarmoBridge: Bridging ArkTS and C/C++ for Cross-Language Static Analysis on HarmonyOS",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d167/573300d167.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Peng",
				"surname": "Deng"
			},
			"authorName": "Deng, Peng",
			"articleRefs": [
				{
					"pageNumber": 2869,
					"articleName": "LLMPort: Cross-File Patch Porting via Task Decomposition and Self-Correction",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c869/573300c869.pdf"
				},
				{
					"pageNumber": 3082,
					"articleName": "Algernon: A Flag-Guided Hybrid Fuzzer for Unlocking Hidden Program Paths",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d082/573300d082.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Wenjing",
				"surname": "Deng"
			},
			"authorName": "Deng, Wenjing",
			"articleRefs": [
				{
					"pageNumber": 129,
					"articleName": "Diagnosing Performance Differences in Model Checkers via Runtime-Guided Problem Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a129/573300a129.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yuetang ",
				"surname": "Deng"
			},
			"authorName": "Deng, Yuetang",
			"articleRefs": [
				{
					"pageNumber": 3132,
					"articleName": "JSidentify-V2: Leveraging Dynamic Memory Fingerprinting for Mini-Game Plagiarism Detection",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d132/573300d132.pdf"
				},
				{
					"pageNumber": 3144,
					"articleName": "Practical Escape of Exploration Tarpits for Mini-Game Testing in an Industrial Setting",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d144/573300d144.pdf"
				},
				{
					"pageNumber": 3449,
					"articleName": "Automated Prompt Generation for Code Intelligence: An Empirical Study and Experience in WeChat",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d449/573300d449.pdf"
				},
				{
					"pageNumber": 3580,
					"articleName": "Element-Aware Fine-Tuning of Vision-Language Models for Cost-Efficient GUI Testing in an Industrial Setting",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d580/573300d580.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zehang",
				"surname": "Deng"
			},
			"authorName": "Deng, Zehang",
			"articleRefs": [
				{
					"pageNumber": 2387,
					"articleName": "FailMapper: Automated Generation of Unit Tests Guided by Failure Scenarios",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c387/573300c387.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zhiwen",
				"surname": "Deng"
			},
			"authorName": "Deng, Zhiwen",
			"articleRefs": [
				{
					"pageNumber": 3671,
					"articleName": "RepoMasterEval: Evaluating Code Completion via Real-World Repositories",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d671/573300d671.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Alex",
				"surname": "Derr"
			},
			"authorName": "Derr, Alex",
			"articleRefs": [
				{
					"pageNumber": 3947,
					"articleName": "Vessel: A Taxonomy of Reproducibility Issues for Container Images",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d947/573300d947.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ronnie",
				"surname": "de Souza Santos"
			},
			"authorName": "de Souza Santos, Ronnie",
			"articleRefs": [
				{
					"pageNumber": 3916,
					"articleName": "Tether: A Personalized Support Assistant for Software Engineers with ADHD",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d916/573300d916.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xavier",
				"surname": "Devroey"
			},
			"authorName": "Devroey, Xavier",
			"articleRefs": [
				{
					"pageNumber": 4028,
					"articleName": "FETT: Fault Injection as an Educational and Training Tool in Cybersecurity",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e028/573300e028.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Alioune ",
				"surname": "Diallo"
			},
			"authorName": "Diallo, Alioune",
			"articleRefs": [
				{
					"pageNumber": 4117,
					"articleName": "evalSmarT: An LLM-Based Framework for Evaluating Smart Contract Generated Comments",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e117/573300e117.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Nathan K.",
				"surname": "Diamond"
			},
			"authorName": "Diamond, Nathan K.",
			"articleRefs": [
				{
					"pageNumber": 342,
					"articleName": "Risk Estimation in Differential Fuzzing via Extreme Value Theory",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a342/573300a342.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Wenrui",
				"surname": "Diao"
			},
			"authorName": "Diao, Wenrui",
			"articleRefs": [
				{
					"pageNumber": 2057,
					"articleName": "FirmProj: Detecting Firmware Leakage in IoT Update Processes via Companion App Analysis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c057/573300c057.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Tobias",
				"surname": "Dick "
			},
			"authorName": "Dick, Tobias",
			"articleRefs": [
				{
					"pageNumber": 166,
					"articleName": "An Empirical Study of Knowledge Transfer in AI Pair Programming",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a166/573300a166.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jens",
				"surname": "Dietrich"
			},
			"authorName": "Dietrich, Jens",
			"articleRefs": [
				{
					"pageNumber": 3627,
					"articleName": "DALEQ - Explainable Equivalence for Java Bytecode",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d627/573300d627.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Matthew",
				"surname": "DiGiovanni"
			},
			"authorName": "DiGiovanni, Matthew",
			"articleRefs": [
				{
					"pageNumber": 332,
					"articleName": "NavAI: A Generalizable LLM Framework for Navigation Tasks in Virtual Reality Environments",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a332/850300a332.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Luca",
				"surname": "Di Grazia"
			},
			"authorName": "Di Grazia, Luca",
			"articleRefs": [
				{
					"pageNumber": 278,
					"articleName": "Do LLMs Generate Useful Test Oracles? An Empirical Study with an Unbiased Dataset",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a278/573300a278.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Daniel",
				"surname": "Ding"
			},
			"authorName": "Ding, Daniel",
			"articleRefs": [
				{
					"pageNumber": 1628,
					"articleName": "Characterizing Multi-Hunk Patches: Divergence, Proximity, and LLM Repair Challenges",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b628/573300b628.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Fan",
				"surname": "Ding"
			},
			"authorName": "Ding, Fan",
			"articleRefs": [
				{
					"pageNumber": 3615,
					"articleName": "RPG: Linux Kernel Fuzzing Guided by Distribution-Specific Runtime Parameter Interfaces",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d615/573300d615.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Liang",
				"surname": "Ding"
			},
			"authorName": "Ding, Liang",
			"articleRefs": [
				{
					"pageNumber": 1730,
					"articleName": "Function Clustering-Based Fuzzing Termination: Toward Smarter Early Stopping",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b730/573300b730.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yuan",
				"surname": "Ding"
			},
			"authorName": "Ding, Yuan",
			"articleRefs": [
				{
					"pageNumber": 3156,
					"articleName": "Industry Practice of LLM-Assisted Protocol Fuzzing for Commercial Communication Modules",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d156/573300d156.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yujie",
				"surname": "Ding"
			},
			"authorName": "Ding, Yujie",
			"articleRefs": [
				{
					"pageNumber": 3777,
					"articleName": "SGCR: A Specification-Grounded Framework for Trustworthy LLM Code Review",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d777/573300d777.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zishuo",
				"surname": "Ding"
			},
			"authorName": "Ding, Zishuo",
			"articleRefs": [
				{
					"pageNumber": 1930,
					"articleName": "Defects4Log: Benchmarking LLMs for Logging Code Defect Detection and Reasoning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b930/573300b930.pdf"
				},
				{
					"pageNumber": 3057,
					"articleName": "Who's to Blame? Rethinking the Brittleness of Automated Web GUI Testing from a Pragmatic Perspective",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d057/573300d057.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Massimiliano",
				"surname": "Di Penta"
			},
			"authorName": "Di Penta, Massimiliano",
			"articleRefs": [
				{
					"pageNumber": 3992,
					"articleName": "CodeGenLink: A Tool to Find the Likely Origin and License of Automatically Generated Code",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d992/573300d992.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Andrea",
				"surname": "Di Sorbo"
			},
			"authorName": "Di Sorbo, Andrea",
			"articleRefs": [
				{
					"pageNumber": 3828,
					"articleName": "The Future of Software Transparency: Bridging Understanding, Measurement, and Practice",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d828/573300d828.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Josiah",
				"surname": "Dodds"
			},
			"authorName": "Dodds, Josiah",
			"articleRefs": [
				{
					"pageNumber": 1452,
					"articleName": "VERT: Polyglot Verified Equivalent Rust Transpilation with Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b452/573300b452.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Chaopeng",
				"surname": "Dong"
			},
			"authorName": "Dong, Chaopeng",
			"articleRefs": [
				{
					"pageNumber": 304,
					"articleName": "Advancing Binary Code Similarity Detection via Context-Content Fusion and LLM Verification",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a304/573300a304.pdf"
				},
				{
					"pageNumber": 919,
					"articleName": "Lares: LLM-Driven Code Slice Semantic Search for Patch Presence Testing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a919/573300a919.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Chunhao",
				"surname": "Dong"
			},
			"authorName": "Dong, Chunhao",
			"articleRefs": [
				{
					"pageNumber": 178,
					"articleName": "Wired for Reuse: Automating Context-Aware Code Adaptation in IDEs via LLM-Based Agent",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a178/573300a178.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jin Song ",
				"surname": "Dong"
			},
			"authorName": "Dong, Jin Song",
			"articleRefs": [
				{
					"pageNumber": 1376,
					"articleName": "Learning Project-Wise Subsequent Code Edits via Interleaving Neural-Based Induction and Tool-Based Deduction",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b376/573300b376.pdf"
				},
				{
					"pageNumber": 2121,
					"articleName": "PAT-Agent: Autoformalization for Model Checking",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c121/573300c121.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Qingqing",
				"surname": "Dong"
			},
			"authorName": "Dong, Qingqing",
			"articleRefs": [
				{
					"pageNumber": 2145,
					"articleName": "Don't Mess with Bro's Cheese! An Empirical Study of Resource Conflict in Android Multi-Window",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c145/573300c145.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ruiqi",
				"surname": "Dong"
			},
			"authorName": "Dong, Ruiqi",
			"articleRefs": [
				{
					"pageNumber": 2387,
					"articleName": "FailMapper: Automated Generation of Unit Tests Guided by Failure Scenarios",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c387/573300c387.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xiaogang",
				"surname": "Dong"
			},
			"authorName": "Dong, Xiaogang",
			"articleRefs": [
				{
					"pageNumber": 3521,
					"articleName": "Evaluating Large Language Models for Time Series Anomaly Detection in Aerospace Software",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d521/573300d521.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yibo",
				"surname": "Dong"
			},
			"authorName": "Dong, Yibo",
			"articleRefs": [
				{
					"pageNumber": 129,
					"articleName": "Diagnosing Performance Differences in Model Checkers via Runtime-Guided Problem Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a129/573300a129.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yihong",
				"surname": "Dong"
			},
			"authorName": "Dong, Yihong",
			"articleRefs": [
				{
					"pageNumber": 1476,
					"articleName": "Aligning LLMs to Fully Utilize the Cross-File Context in Repository-Level Code Completion",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b476/573300b476.pdf"
				},
				{
					"pageNumber": 3729,
					"articleName": "Thinking Longer, Not Larger: Enhancing Software Engineering Agents via Scaling Test-Time Compute",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d729/573300d729.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zikan",
				"surname": "Dong"
			},
			"authorName": "Dong, Zikan",
			"articleRefs": [
				{
					"pageNumber": 1818,
					"articleName": "On the (In)Security of Non-Resettable Device Identifiers in Custom Android Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b818/573300b818.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Naipeng",
				"surname": " Dong"
			},
			"authorName": "Dong, Naipeng",
			"articleRefs": [
				{
					"pageNumber": 2145,
					"articleName": "Don't Mess with Bro's Cheese! An Empirical Study of Resource Conflict in Android Multi-Window",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c145/573300c145.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Johannes",
				"surname": "Dorn"
			},
			"authorName": "Dorn, Johannes",
			"articleRefs": [
				{
					"pageNumber": 2515,
					"articleName": "On Automating Configuration Dependency Validation via Retrieval-Augmented Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c515/573300c515.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Purvesh",
				"surname": "Doud"
			},
			"authorName": "Doud, Purvesh",
			"articleRefs": [
				{
					"pageNumber": 14,
					"articleName": "Leveraging LLM for Software Modernization: COBOL Functionality Extraction Case Study",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a014/850300a014.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Kohei",
				"surname": "Dozono"
			},
			"authorName": "Dozono, Kohei",
			"articleRefs": [
				{
					"pageNumber": 3215,
					"articleName": "Should We Evaluate LLM Based Security Analysis Approaches on Open Source Systems?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d215/573300d215.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Hang",
				"surname": "Du"
			},
			"authorName": "Du, Hang",
			"articleRefs": [
				{
					"pageNumber": 1259,
					"articleName": "What's DAT Smell? Untangling and Weaving the Disjoint Assertion Tangle Test Smell",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b259/573300b259.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Quanwei",
				"surname": "Du"
			},
			"authorName": "Du, Quanwei",
			"articleRefs": [
				{
					"pageNumber": 1142,
					"articleName": "Hypergraph Neural Network-Based Multi-Granular Root Cause Localization for Microservice Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b142/573300b142.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xiaoning",
				"surname": "Du"
			},
			"authorName": "Du, Xiaoning",
			"articleRefs": [
				{
					"pageNumber": 2387,
					"articleName": "FailMapper: Automated Generation of Unit Tests Guided by Failure Scenarios",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c387/573300c387.pdf"
				},
				{
					"pageNumber": 2439,
					"articleName": "Token Sugar: Making Source Code Sweeter for LLMs Through Token-Efficient Shorthand",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c439/573300c439.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xu",
				"surname": "Du"
			},
			"authorName": "Du, Xu",
			"articleRefs": [
				{
					"pageNumber": 228,
					"articleName": "RELIA: Accelerating the Analysis of Cloud Access Control Policies",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a228/573300a228.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Chiming",
				"surname": "Duan"
			},
			"authorName": "Duan, Chiming",
			"articleRefs": [
				{
					"pageNumber": 661,
					"articleName": "United We Stand: Towards End-to-End Log-Based Fault Diagnosis via Interactive Multi-Task Learning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a661/573300a661.pdf"
				},
				{
					"pageNumber": 700,
					"articleName": "LogAction: Consistent Cross-System Anomaly Detection Through Logs via Active Domain Adaptation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a700/573300a700.pdf"
				},
				{
					"pageNumber": 1118,
					"articleName": "CoorLog: Efficient-Generalizable Log Anomaly Detection via Adaptive Coordinator in Software Evolution",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b118/573300b118.pdf"
				},
				{
					"pageNumber": 3783,
					"articleName": "Walk the Talk: Is Your Log-Based Software Reliability Maintenance System Really Reliable?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d783/573300d783.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Shuoshuo",
				"surname": "Duan"
			},
			"authorName": "Duan, Shuoshuo",
			"articleRefs": [
				{
					"pageNumber": 547,
					"articleName": "DNAFuzz: Descriptor-Aware Fuzzing for USB Drivers",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a547/573300a547.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Wenbo",
				"surname": "Duan"
			},
			"authorName": "Duan, Wenbo",
			"articleRefs": [
				{
					"pageNumber": 3485,
					"articleName": "BitsAI-Fix: LLM-Driven Approach for Automated Lint Error Resolution in Practice",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d485/573300d485.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Tobias",
				"surname": "D\u00FCser"
			},
			"authorName": "D\u00FCser, Tobias",
			"articleRefs": [
				{
					"pageNumber": 204,
					"articleName": "Explainability in Automated Cross-Domain Model-Driven Brake System Development",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a204/850300a204.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Saikat",
				"surname": "Dutta"
			},
			"authorName": "Dutta, Saikat",
			"articleRefs": [
				{
					"pageNumber": 2285,
					"articleName": "Faster Runtime Verification During Testing via Feedback-Guided Selective Monitoring",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c285/573300c285.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zachary",
				"surname": "Eberhart"
			},
			"authorName": "Eberhart, Zachary",
			"articleRefs": [
				{
					"pageNumber": 4089,
					"articleName": "APIDA-Chat: Structured Synthesis of API Search Dialogues to Bootstrap Conversational Agents",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e089/573300e089.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Martin",
				"surname": "Eberlein"
			},
			"authorName": "Eberlein, Martin",
			"articleRefs": [
				{
					"pageNumber": 1942,
					"articleName": "Efficient Understanding of Machine Learning Model Mispredictions",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b942/573300b942.pdf"
				},
				{
					"pageNumber": 4048,
					"articleName": "BASHIRI: Learning Failure Oracles from Execution Features",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e048/573300e048.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Sebasti\u00E1n",
				"surname": "Echeverr\u00EDa"
			},
			"authorName": "Echeverr\u00EDa, Sebasti\u00E1n",
			"articleRefs": [
				{
					"pageNumber": 3947,
					"articleName": "Vessel: A Taxonomy of Reproducibility Issues for Container Images",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d947/573300d947.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ramtin",
				"surname": "Ehsani"
			},
			"authorName": "Ehsani, Ramtin",
			"articleRefs": [
				{
					"pageNumber": 1439,
					"articleName": "Hierarchical Knowledge Injection for Improving LLM-Based Program Repair",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b439/573300b439.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Eric",
				"surname": "Eide"
			},
			"authorName": "Eide, Eric",
			"articleRefs": [
				{
					"pageNumber": 204,
					"articleName": "Finding Bugs in WebAssembly Interface Type Binding Generators",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a204/573300a204.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Tobias",
				"surname": "Eisenreich"
			},
			"authorName": "Eisenreich, Tobias",
			"articleRefs": [
				{
					"pageNumber": 222,
					"articleName": "Leveraging Large Language Models for Use Case Model Generation from Software Requirements",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a222/850300a222.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Hanya",
				"surname": "Elhashemy"
			},
			"authorName": "Elhashemy, Hanya",
			"articleRefs": [
				{
					"pageNumber": 300,
					"articleName": "Bridging the Prototype-Production Gap: A Multi-Agent System for Notebooks Transformation",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a300/850300a300.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "William",
				"surname": "Enck"
			},
			"authorName": "Enck, William",
			"articleRefs": [
				{
					"pageNumber": 2794,
					"articleName": "Which Is Better For Reducing Outdated and Vulnerable Dependencies: Pinning or Floating?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c794/573300c794.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jonas",
				"surname": "Engesser"
			},
			"authorName": "Engesser, Jonas",
			"articleRefs": [
				{
					"pageNumber": 3215,
					"articleName": "Should We Evaluate LLM Based Security Analysis Approaches on Open Source Systems?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d215/573300d215.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ar\u00E7in \u00DClk\u00FC",
				"surname": "Erg\u00FCzen"
			},
			"authorName": "Erg\u00FCzen, Ar\u00E7in \u00DClk\u00FC",
			"articleRefs": [
				{
					"pageNumber": 3957,
					"articleName": "Are We SOLID Yet? An Empirical Study on Prompting LLMs to Detect Design Principle Violations",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d957/573300d957.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Michael D.",
				"surname": "Ernst"
			},
			"authorName": "Ernst, Michael D.",
			"articleRefs": [
				{
					"pageNumber": 278,
					"articleName": "Do LLMs Generate Useful Test Oracles? An Empirical Study with an Unbiased Dataset",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a278/573300a278.pdf"
				},
				{
					"pageNumber": 828,
					"articleName": "Repairing Leaks in Resource Wrappers",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a828/573300a828.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Noah",
				"surname": "Erthel"
			},
			"authorName": "Erthel, Noah",
			"articleRefs": [
				{
					"pageNumber": 4000,
					"articleName": "FlowStrider: Low-Friction Continuous Threat Modeling",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d000/573300d000.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Camilo",
				"surname": "Escobar-Vel\u00E1squez"
			},
			"authorName": "Escobar-Vel\u00E1squez, Camilo",
			"articleRefs": [
				{
					"pageNumber": 3952,
					"articleName": "Autonomous Agents for Accessibility: Simulating Visual Impairments in Web Interfaces",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d952/573300d952.pdf"
				},
				{
					"pageNumber": 4056,
					"articleName": "EyeNav: Accessible Webpage Interaction and Testing Using Eye-Tracking and NLP",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e056/573300e056.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Camilo Andr\u00E9s",
				"surname": "Escobar-Vel\u00E1squez"
			},
			"authorName": "Escobar-Vel\u00E1squez, Camilo Andr\u00E9s",
			"articleRefs": [
				{
					"pageNumber": 83,
					"articleName": "Finding Keywords for Architectural Erosion Detection in GitHub Commits for Android Applications",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a083/850300a083.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Karine",
				"surname": "Even-Mendoza"
			},
			"authorName": "Even-Mendoza, Karine",
			"articleRefs": [
				{
					"pageNumber": 3901,
					"articleName": "LLM-Guided Genetic Improvement: Envisioning Semantic Aware Automated Software Evolution",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d901/573300d901.pdf"
				},
				{
					"pageNumber": 4016,
					"articleName": "ReFuzzer: Feedback-Driven Approach to Enhance Validity of LLM-Generated Test Programs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e016/573300e016.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Chao",
				"surname": "Fan"
			},
			"authorName": "Fan, Chao",
			"articleRefs": [
				{
					"pageNumber": 3156,
					"articleName": "Industry Practice of LLM-Assisted Protocol Fuzzing for Commercial Communication Modules",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d156/573300d156.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Hongcheng",
				"surname": "Fan"
			},
			"authorName": "Fan, Hongcheng",
			"articleRefs": [
				{
					"pageNumber": 1246,
					"articleName": "Protecting Source Code Privacy When Hunting Memory Bugs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b246/573300b246.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Lingling",
				"surname": "Fan"
			},
			"authorName": "Fan, Lingling",
			"articleRefs": [
				{
					"pageNumber": 521,
					"articleName": "GlassWing: A Tailored Static Analysis Approach for Flutter Android Apps",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a521/573300a521.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Lishui",
				"surname": "Fan"
			},
			"authorName": "Fan, Lishui",
			"articleRefs": [
				{
					"pageNumber": 1337,
					"articleName": "FGIT: Fault-Guided Fine-Tuning for Code Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b337/573300b337.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Youmei",
				"surname": "Fan"
			},
			"authorName": "Fan, Youmei",
			"articleRefs": [
				{
					"pageNumber": 261,
					"articleName": "Exploring the SECURITY.md in the Dependency Chain: Preliminary Analysis of the PyPI Ecosystem",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a261/850300a261.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ora",
				"surname": "Fandina"
			},
			"authorName": "Fandina, Ora",
			"articleRefs": [
				{
					"pageNumber": 30,
					"articleName": "Vintage Code, Modern Judges: Meta-Validation in Low Data Regimes",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a030/850300a030.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Aoyang",
				"surname": "Fang"
			},
			"authorName": "Fang, Aoyang",
			"articleRefs": [
				{
					"pageNumber": 674,
					"articleName": "Triangle: Empowering Incident Triage with Multi-Agent",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a674/573300a674.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Chunrong ",
				"surname": "Fang"
			},
			"authorName": "Fang, Chunrong",
			"articleRefs": [
				{
					"pageNumber": 1168,
					"articleName": "When Autonomous Vehicle Meets V2X Cooperative Perception: How Far Are We?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b168/573300b168.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Dongliang",
				"surname": "Fang"
			},
			"authorName": "Fang, Dongliang",
			"articleRefs": [
				{
					"pageNumber": 304,
					"articleName": "Advancing Binary Code Similarity Detection via Context-Content Fusion and LLM Verification",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a304/573300a304.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zihan",
				"surname": "Fang"
			},
			"authorName": "Fang, Zihan",
			"articleRefs": [
				{
					"pageNumber": 3870,
					"articleName": "CodeACT-R: A Cognitive Simulation Framework for Human Attention in Code Reading",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d870/573300d870.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Eitan ",
				"surname": " Farchi"
			},
			"authorName": "Farchi, Eitan",
			"articleRefs": [
				{
					"pageNumber": 30,
					"articleName": "Vintage Code, Modern Judges: Meta-Validation in Low Data Regimes",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a030/850300a030.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Mattia",
				"surname": "Fazzini"
			},
			"authorName": "Fazzini, Mattia",
			"articleRefs": [
				{
					"pageNumber": 2195,
					"articleName": "Generating Failure-Based Oracles to Support Testing of Reported Bugs in Android Apps",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c195/573300c195.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Konstantin",
				"surname": "Fedorov"
			},
			"authorName": "Fedorov, Konstantin",
			"articleRefs": [
				{
					"pageNumber": 292,
					"articleName": "GRACG: Graph Retrieval Augmented Code Generation",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a292/850300a292.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Benedikt",
				"surname": "Fein"
			},
			"authorName": "Fein, Benedikt",
			"articleRefs": [
				{
					"pageNumber": 3988,
					"articleName": "LitterBox+: An Extensible Framework for LLM-Enhanced Scratch Static Code Analysis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d988/573300d988.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Robert",
				"surname": "Feldt"
			},
			"authorName": "Feldt, Robert",
			"articleRefs": [
				{
					"pageNumber": 245,
					"articleName": "AI for Requirements Engineering: Industry Adoption and Practitioner Perspectives",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a245/850300a245.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jinghan",
				"surname": "Feng"
			},
			"authorName": "Feng, Jinghan",
			"articleRefs": [
				{
					"pageNumber": 253,
					"articleName": "Fair Developer Score: Build-Adjusted Measurement of Effort and Impact",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a253/850300a253.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Shiwei",
				"surname": "Feng"
			},
			"authorName": "Feng, Shiwei",
			"articleRefs": [
				{
					"pageNumber": 1220,
					"articleName": "RFCAudit: AI Agent for Auditing Protocol Implementations Against RFC Specifications",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b220/573300b220.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xiaotao",
				"surname": "Feng"
			},
			"authorName": "Feng, Xiaotao",
			"articleRefs": [
				{
					"pageNumber": 2579,
					"articleName": "WINGMUZZ: Blackbox Testing of IoT Protocols via Two-Dimensional Fuzzing Schedule",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c579/573300c579.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yalin",
				"surname": "Feng"
			},
			"authorName": "Feng, Yalin",
			"articleRefs": [
				{
					"pageNumber": 2820,
					"articleName": "PoliCond: Condition-Aware Ontology-Driven LLMs for Privacy Policy Contradiction Analysis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c820/573300c820.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yang",
				"surname": "Feng"
			},
			"authorName": "Feng, Yang",
			"articleRefs": [
				{
					"pageNumber": 1246,
					"articleName": "Protecting Source Code Privacy When Hunting Memory Bugs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b246/573300b246.pdf"
				},
				{
					"pageNumber": 2719,
					"articleName": "PALM: Synergizing Program Analysis and LLMs to Enhance Rust Unit Test Coverage",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c719/573300c719.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yebo",
				"surname": "Feng"
			},
			"authorName": "Feng, Yebo",
			"articleRefs": [
				{
					"pageNumber": 52,
					"articleName": "Learning from the Past: Real-World Exploit Migration for Smart Contract PoC Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a052/573300a052.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yifei",
				"surname": "Feng"
			},
			"authorName": "Feng, Yifei",
			"articleRefs": [
				{
					"pageNumber": 3120,
					"articleName": "How Can Infrastructure as Code Accelerate Data Center Bring-ups? A Case Study at ByteDance",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d120/573300d120.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yigui",
				"surname": "Feng"
			},
			"authorName": "Feng, Yigui",
			"articleRefs": [
				{
					"pageNumber": 2477,
					"articleName": "Evaluating and Improving Framework-Based Parallel Code Completion with Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c477/573300c477.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yu",
				"surname": "Feng"
			},
			"authorName": "Feng, Yu",
			"articleRefs": [
				{
					"pageNumber": 2260,
					"articleName": "Automated Repair of OpenID Connect Programs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c260/573300c260.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yuming",
				"surname": "Feng"
			},
			"authorName": "Feng, Yuming",
			"articleRefs": [
				{
					"pageNumber": 571,
					"articleName": "SSR: Safeguarding Staking Rewards by Defining and Detecting Logical Defects in DeFi Staking",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a571/573300a571.pdf"
				},
				{
					"pageNumber": 1528,
					"articleName": "Finding Insecure State Dependency in DApps via Multi-Source Tracing and Semantic Enrichment",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b528/573300b528.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Vladimir",
				"surname": "Filkov"
			},
			"authorName": "Filkov, Vladimir",
			"articleRefs": [
				{
					"pageNumber": 4073,
					"articleName": "OSSPREY: AI-Driven Forecasting and Intervention for OSS Project Sustainability",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e073/573300e073.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Mirena",
				"surname": "Flores Valdez"
			},
			"authorName": "Flores Valdez, Mirena",
			"articleRefs": [
				{
					"pageNumber": 2807,
					"articleName": "A Multi-Modality Evaluation of the Reality Gap in Autonomous Driving Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c807/573300c807.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Stanislav",
				"surname": "Fomin"
			},
			"authorName": "Fomin, Stanislav",
			"articleRefs": [
				{
					"pageNumber": 4032,
					"articleName": "WIBE: Watermarks for generated Images \u2013 Benchmarking & Evaluation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e032/573300e032.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Alexandra",
				"surname": "Fomina"
			},
			"authorName": "Fomina, Alexandra",
			"articleRefs": [
				{
					"pageNumber": 194,
					"articleName": "Explaining Software Vulnerabilities with Large Language Models",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a194/850300a194.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Pedro Lu\u00EDs",
				"surname": "Fonseca"
			},
			"authorName": "Fonseca, Pedro Lu\u00EDs",
			"articleRefs": [
				{
					"pageNumber": 3310,
					"articleName": "Streamlining Acceptance Test Generation for Mobile Applications Through Large Language Models: An Industrial Case Study",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d310/573300d310.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Gordon",
				"surname": "Fraser"
			},
			"authorName": "Fraser, Gordon",
			"articleRefs": [
				{
					"pageNumber": 3988,
					"articleName": "LitterBox+: An Extensible Framework for LLM-Enhanced Scratch Static Code Analysis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d988/573300d988.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Leon",
				"surname": "Freudenthaler"
			},
			"authorName": "Freudenthaler, Leon",
			"articleRefs": [
				{
					"pageNumber": 2694,
					"articleName": "From Characters to Structure: Rethinking Real-Time Collaborative Programming Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c694/573300c694.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Marcelo",
				"surname": "Frias"
			},
			"authorName": "Frias, Marcelo",
			"articleRefs": [
				{
					"pageNumber": 342,
					"articleName": "Risk Estimation in Differential Fuzzing via Extreme Value Theory",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a342/573300a342.pdf"
				},
				{
					"pageNumber": 2918,
					"articleName": "Automated Combinatorial Test Generation for Alloy",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c918/573300c918.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Nicholas",
				"surname": "Friedlaender"
			},
			"authorName": "Friedlaender, Nicholas",
			"articleRefs": [
				{
					"pageNumber": 222,
					"articleName": "Leveraging Large Language Models for Use Case Model Generation from Software Requirements",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a222/850300a222.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Shmulik",
				"surname": " Froimovich"
			},
			"authorName": "Froimovich, Shmulik",
			"articleRefs": [
				{
					"pageNumber": 30,
					"articleName": "Vintage Code, Modern Judges: Meta-Validation in Low Data Regimes",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a030/850300a030.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "An",
				"surname": "Fu"
			},
			"authorName": "Fu, An",
			"articleRefs": [
				{
					"pageNumber": 2618,
					"articleName": "EfficientEdit: Accelerating Code Editing via Edit-Oriented Speculative Decoding",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c618/573300c618.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jingzhou",
				"surname": "Fu"
			},
			"authorName": "Fu, Jingzhou",
			"articleRefs": [
				{
					"pageNumber": 1806,
					"articleName": "ARG: Testing Query Rewriters via Abstract Rule Guided Fuzzing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b806/573300b806.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Qiang",
				"surname": "Fu"
			},
			"authorName": "Fu, Qiang",
			"articleRefs": [
				{
					"pageNumber": 3156,
					"articleName": "Industry Practice of LLM-Assisted Protocol Fuzzing for Commercial Communication Modules",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d156/573300d156.pdf"
				},
				{
					"pageNumber": 3615,
					"articleName": "RPG: Linux Kernel Fuzzing Guided by Distribution-Specific Runtime Parameter Interfaces",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d615/573300d615.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ruowei",
				"surname": "Fu"
			},
			"authorName": "Fu, Ruowei",
			"articleRefs": [
				{
					"pageNumber": 2221,
					"articleName": "LLM-Powered Multi-Agent Collaboration for Intelligent Industrial On-Call Automation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c221/573300c221.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Shiyun",
				"surname": "Fu"
			},
			"authorName": "Fu, Shiyun",
			"articleRefs": [
				{
					"pageNumber": 3449,
					"articleName": "Automated Prompt Generation for Code Intelligence: An Empirical Study and Experience in WeChat",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d449/573300d449.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yeqi",
				"surname": "Fu"
			},
			"authorName": "Fu, Yeqi",
			"articleRefs": [
				{
					"pageNumber": 1094,
					"articleName": "ZendDiff: Differential Testing of PHP Interpreter",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b094/573300b094.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ying",
				"surname": "Fu"
			},
			"authorName": "Fu, Ying",
			"articleRefs": [
				{
					"pageNumber": 3156,
					"articleName": "Industry Practice of LLM-Assisted Protocol Fuzzing for Commercial Communication Modules",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d156/573300d156.pdf"
				},
				{
					"pageNumber": 3545,
					"articleName": "LLM-Assisted Industrial-Scale Differential Testing of Package Incompatibilities in Linux Distributions",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d545/573300d545.pdf"
				},
				{
					"pageNumber": 3615,
					"articleName": "RPG: Linux Kernel Fuzzing Guided by Distribution-Specific Runtime Parameter Interfaces",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d615/573300d615.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yu-Fu",
				"surname": "Fu"
			},
			"authorName": "Fu, Yu-Fu",
			"articleRefs": [
				{
					"pageNumber": 1285,
					"articleName": "Agentic Specification Generator for Move Programs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b285/573300b285.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yulai",
				"surname": "Fu"
			},
			"authorName": "Fu, Yulai",
			"articleRefs": [
				{
					"pageNumber": 3156,
					"articleName": "Industry Practice of LLM-Assisted Protocol Fuzzing for Commercial Communication Modules",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d156/573300d156.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Michael",
				"surname": " Fu"
			},
			"authorName": "Fu, Michael",
			"articleRefs": [
				{
					"pageNumber": 3380,
					"articleName": "AdaptiveGuard: Towards Adaptive Runtime Safety for LLM-Powered Software",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d380/573300d380.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Carol",
				"surname": "Fung"
			},
			"authorName": "Fung, Carol",
			"articleRefs": [
				{
					"pageNumber": 330,
					"articleName": "LogMoE: Lightweight Expert Mixture for Cross-System Log Anomaly Detection",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a330/573300a330.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Raula",
				"surname": "Gaikovina Kula"
			},
			"authorName": "Gaikovina Kula, Raula",
			"articleRefs": [
				{
					"pageNumber": 261,
					"articleName": "Exploring the SECURITY.md in the Dependency Chain: Preliminary Analysis of the PyPI Ecosystem",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a261/850300a261.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Raviv ",
				"surname": "Gal"
			},
			"authorName": "Gal, Raviv",
			"articleRefs": [
				{
					"pageNumber": 30,
					"articleName": "Vintage Code, Modern Judges: Meta-Validation in Low Data Regimes",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a030/850300a030.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Keheliya",
				"surname": "Gallaba"
			},
			"authorName": "Gallaba, Keheliya",
			"articleRefs": [
				{
					"pageNumber": 1628,
					"articleName": "Characterizing Multi-Hunk Patches: Divergence, Proximity, and LLM Repair Challenges",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b628/573300b628.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Kiev",
				"surname": "Gama"
			},
			"authorName": "Gama, Kiev",
			"articleRefs": [
				{
					"pageNumber": 3916,
					"articleName": "Tether: A Personalized Support Assistant for Software Engineers with ADHD",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d916/573300d916.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Haoyu",
				"surname": "Gan"
			},
			"authorName": "Gan, Haoyu",
			"articleRefs": [
				{
					"pageNumber": 3671,
					"articleName": "RepoMasterEval: Evaluating Code Completion via Real-World Repositories",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d671/573300d671.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jay",
				"surname": "Gandhi"
			},
			"authorName": "Gandhi, Jay",
			"articleRefs": [
				{
					"pageNumber": 22,
					"articleName": "Microservices Identification Using LLM",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a022/850300a022.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Andrei",
				"surname": "Gantimurov"
			},
			"authorName": "Gantimurov, Andrei",
			"articleRefs": [
				{
					"pageNumber": 229,
					"articleName": "Automated Evolutionary Hyperparameter Tuning for NLP-Based Test Case Generation",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a229/850300a229.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Pierre",
				"surname": "Ganty"
			},
			"authorName": "Ganty, Pierre",
			"articleRefs": [
				{
					"pageNumber": 2669,
					"articleName": "How Big is the Automaton? Certified Lower Bounds on the Size of Presburger DFAs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c669/573300c669.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Chang",
				"surname": "Gao"
			},
			"authorName": "Gao, Chang",
			"articleRefs": [
				{
					"pageNumber": 3545,
					"articleName": "LLM-Assisted Industrial-Scale Differential Testing of Package Incompatibilities in Linux Distributions",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d545/573300d545.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Cuiyun",
				"surname": "Gao"
			},
			"authorName": "Gao, Cuiyun",
			"articleRefs": [
				{
					"pageNumber": 26,
					"articleName": "Vul-R2: A Reasoning LLM for Automated Vulnerability Repair",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a026/573300a026.pdf"
				},
				{
					"pageNumber": 2426,
					"articleName": "An Agent-Based Evaluation Framework for Complex Code Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c426/573300c426.pdf"
				},
				{
					"pageNumber": 3132,
					"articleName": "JSidentify-V2: Leveraging Dynamic Memory Fingerprinting for Mini-Game Plagiarism Detection",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d132/573300d132.pdf"
				},
				{
					"pageNumber": 3414,
					"articleName": "Data Dependency-Aware Code Generation from Enhanced UML Sequence Diagrams",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d414/573300d414.pdf"
				},
				{
					"pageNumber": 3449,
					"articleName": "Automated Prompt Generation for Code Intelligence: An Empirical Study and Experience in WeChat",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d449/573300d449.pdf"
				},
				{
					"pageNumber": 3604,
					"articleName": "IntelliTopo: An IaC Generation Service for Industrial Network Topology Construction",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d604/573300d604.pdf"
				},
				{
					"pageNumber": 3671,
					"articleName": "RepoMasterEval: Evaluating Code Completion via Real-World Repositories",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d671/573300d671.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Gege",
				"surname": "Gao"
			},
			"authorName": "Gao, Gege",
			"articleRefs": [
				{
					"pageNumber": 1118,
					"articleName": "CoorLog: Efficient-Generalizable Log Anomaly Detection via Adaptive Coordinator in Software Evolution",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b118/573300b118.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Kai ",
				"surname": "Gao"
			},
			"authorName": "Gao, Kai",
			"articleRefs": [
				{
					"pageNumber": 2881,
					"articleName": "DIFFFIX: Incrementally Fixing AST Diffs via Context and Type Information",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c881/573300c881.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Pengfei",
				"surname": "Gao"
			},
			"authorName": "Gao, Pengfei",
			"articleRefs": [
				{
					"pageNumber": 2426,
					"articleName": "An Agent-Based Evaluation Framework for Complex Code Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c426/573300c426.pdf"
				},
				{
					"pageNumber": 3671,
					"articleName": "RepoMasterEval: Evaluating Code Completion via Real-World Repositories",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d671/573300d671.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Shuzheng ",
				"surname": "Gao"
			},
			"authorName": "Gao, Shuzheng",
			"articleRefs": [
				{
					"pageNumber": 3132,
					"articleName": "JSidentify-V2: Leveraging Dynamic Memory Fingerprinting for Mini-Game Plagiarism Detection",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d132/573300d132.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yufei",
				"surname": "Gao"
			},
			"authorName": "Gao, Yufei",
			"articleRefs": [
				{
					"pageNumber": 3120,
					"articleName": "How Can Infrastructure as Code Accelerate Data Center Bring-ups? A Case Study at ByteDance",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d120/573300d120.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zeyu",
				"surname": "Gao"
			},
			"authorName": "Gao, Zeyu",
			"articleRefs": [
				{
					"pageNumber": 726,
					"articleName": "Improving LLM-Based Log Parsing by Learning from Errors in Reasoning Traces",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a726/573300a726.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zhipeng",
				"surname": "Gao"
			},
			"authorName": "Gao, Zhipeng",
			"articleRefs": [
				{
					"pageNumber": 2554,
					"articleName": "ACTaint: Agent-Based Taint Analysis for Access Control Vulnerabilities in Smart Contracts",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c554/573300c554.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xinyu",
				"surname": " Gao"
			},
			"authorName": "Gao, Xinyu",
			"articleRefs": [
				{
					"pageNumber": 1168,
					"articleName": "When Autonomous Vehicle Meets V2X Cooperative Perception: How Far Are We?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b168/573300b168.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Alina",
				"surname": "Geiger"
			},
			"authorName": "Geiger, Alina",
			"articleRefs": [
				{
					"pageNumber": 3901,
					"articleName": "LLM-Guided Genetic Improvement: Envisioning Semantic Aware Automated Software Evolution",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d901/573300d901.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jie",
				"surname": "Geng"
			},
			"authorName": "Geng, Jie",
			"articleRefs": [
				{
					"pageNumber": 3741,
					"articleName": "LogSage: An LLM-Based Framework for CI/CD Failure Detection and Remediation with Industrial Validation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d741/573300d741.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Lu",
				"surname": "Geng"
			},
			"authorName": "Geng, Lu",
			"articleRefs": [
				{
					"pageNumber": 3485,
					"articleName": "BitsAI-Fix: LLM-Driven Approach for Automated Lint Error Resolution in Practice",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d485/573300d485.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ali",
				"surname": "Ghanbari"
			},
			"authorName": "Ghanbari, Ali",
			"articleRefs": [
				{
					"pageNumber": 2108,
					"articleName": "Using Fourier Analysis and Mutant Clustering to Accelerate DNN Mutation Testing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c108/573300c108.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Gurnit",
				"surname": "Ghardhora"
			},
			"authorName": "Ghardhora, Gurnit",
			"articleRefs": [
				{
					"pageNumber": 3250,
					"articleName": "Metrics Driven Reengineering and Continuous Code Improvement at Meta",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d250/573300d250.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Seyedhamed",
				"surname": "Ghavamnia"
			},
			"authorName": "Ghavamnia, Seyedhamed",
			"articleRefs": [
				{
					"pageNumber": 1298,
					"articleName": "AMPLE: Fine-Grained File Access Policies for Server Applications",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b298/573300b298.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Rafail",
				"surname": "Giavrimis"
			},
			"authorName": "Giavrimis, Rafail",
			"articleRefs": [
				{
					"pageNumber": 3568,
					"articleName": "Tuning LLM-Based Code Optimization via Meta-Prompting: An Industrial Perspective",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d568/573300d568.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Fabian",
				"surname": "Gilson"
			},
			"authorName": "Gilson, Fabian",
			"articleRefs": [
				{
					"pageNumber": 4028,
					"articleName": "FETT: Fault Injection as an Educational and Training Tool in Cybersecurity",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e028/573300e028.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Evgeniy",
				"surname": "Glukhov"
			},
			"authorName": "Glukhov, Evgeniy",
			"articleRefs": [
				{
					"pageNumber": 358,
					"articleName": "Challenge on Optimization of Context Collection for Code Completion",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a358/850300a358.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Sangharatna",
				"surname": "Godboley"
			},
			"authorName": "Godboley, Sangharatna",
			"articleRefs": [
				{
					"pageNumber": 1414,
					"articleName": "VeriExploit: Automatic Bug Reproduction in Smart Contracts via LLMs and Formal Methods",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b414/573300b414.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Saul",
				"surname": "Goldman"
			},
			"authorName": "Goldman, Saul",
			"articleRefs": [
				{
					"pageNumber": 3759,
					"articleName": "What Types of Code Review Comments Do Developers Most Frequently Resolve?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d759/573300d759.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yaroslav",
				"surname": "Golubev"
			},
			"authorName": "Golubev, Yaroslav",
			"articleRefs": [
				{
					"pageNumber": 358,
					"articleName": "Challenge on Optimization of Context Collection for Code Completion",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a358/850300a358.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Lu\u00EDs F.",
				"surname": "Gomes"
			},
			"authorName": "Gomes, Lu\u00EDs F.",
			"articleRefs": [
				{
					"pageNumber": 2605,
					"articleName": "SE-Jury: An LLM-as-Ensemble-Judge Metric for Narrowing the Gap with Human Evaluation in SE",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c605/573300c605.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Haochen",
				"surname": "Gong"
			},
			"authorName": "Gong, Haochen",
			"articleRefs": [
				{
					"pageNumber": 4004,
					"articleName": "Towards Context-Aware Mobile Privacy Notice: Implementation of A Deployable Contextual Privacy Policies Generator",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e004/573300e004.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jingzhi",
				"surname": "Gong"
			},
			"authorName": "Gong, Jingzhi",
			"articleRefs": [
				{
					"pageNumber": 3568,
					"articleName": "Tuning LLM-Based Code Optimization via Meta-Prompting: An Industrial Perspective",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d568/573300d568.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Lina",
				"surname": "Gong"
			},
			"authorName": "Gong, Lina",
			"articleRefs": [
				{
					"pageNumber": 1880,
					"articleName": "Coding-Fuse: Efficient Fusion of Code Pre-Trained Models for Classification Tasks",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b880/573300b880.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Colin S.",
				"surname": "Gordon"
			},
			"authorName": "Gordon, Colin S.",
			"articleRefs": [
				{
					"pageNumber": 3849,
					"articleName": "Linguistic Theories Coincide with Misformalization in Temporal Logic",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d849/573300d849.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Alessandra",
				"surname": "Gorla"
			},
			"authorName": "Gorla, Alessandra",
			"articleRefs": [
				{
					"pageNumber": 2706,
					"articleName": "State Field Coverage: A Metric for Oracle Quality",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c706/573300c706.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Tony",
				"surname": "Gorschek"
			},
			"authorName": "Gorschek, Tony",
			"articleRefs": [
				{
					"pageNumber": 51,
					"articleName": "A 3-Layer Agentic Model for Nonfunctional Requirements in Software Engineering",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a051/850300a051.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Karl Michael",
				"surname": "G\u00F6schka"
			},
			"authorName": "G\u00F6schka, Karl Michael",
			"articleRefs": [
				{
					"pageNumber": 2694,
					"articleName": "From Characters to Structure: Rethinking Real-Time Collaborative Programming Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c694/573300c694.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Priya",
				"surname": "Govindasamy"
			},
			"authorName": "Govindasamy, Priya",
			"articleRefs": [
				{
					"pageNumber": 2170,
					"articleName": "Spinner: Detecting Locking Violations in the eBPF Runtime",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c170/573300c170.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Harsh",
				"surname": "Goyal"
			},
			"authorName": "Goyal, Harsh",
			"articleRefs": [
				{
					"pageNumber": 4105,
					"articleName": "StackPlagger: A System for Identifying AI-Code Plagiarism on Stack Overflow",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e105/573300e105.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Bernd",
				"surname": "Gruner"
			},
			"authorName": "Gruner, Bernd",
			"articleRefs": [
				{
					"pageNumber": 4000,
					"articleName": "FlowStrider: Low-Friction Continuous Threat Modeling",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d000/573300d000.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Lars",
				"surname": "Grunske"
			},
			"authorName": "Grunske, Lars",
			"articleRefs": [
				{
					"pageNumber": 1942,
					"articleName": "Efficient Understanding of Machine Learning Model Mispredictions",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b942/573300b942.pdf"
				},
				{
					"pageNumber": 4048,
					"articleName": "BASHIRI: Learning Failure Oracles from Execution Features",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e048/573300e048.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Patrick",
				"surname": "Grycz"
			},
			"authorName": "Grycz, Patrick",
			"articleRefs": [
				{
					"pageNumber": 204,
					"articleName": "Explainability in Automated Cross-Domain Model-Driven Brake System Development",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a204/850300a204.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Bin",
				"surname": "Gu"
			},
			"authorName": "Gu, Bin",
			"articleRefs": [
				{
					"pageNumber": 3521,
					"articleName": "Evaluating Large Language Models for Time Series Anomaly Detection in Aerospace Software",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d521/573300d521.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jiahao",
				"surname": "Gu"
			},
			"authorName": "Gu, Jiahao",
			"articleRefs": [
				{
					"pageNumber": 2032,
					"articleName": "Characterizing and Repairing Color-Related Accessibility Issues in Android Apps",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c032/573300c032.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jingjing",
				"surname": "Gu"
			},
			"authorName": "Gu, Jingjing",
			"articleRefs": [
				{
					"pageNumber": 2133,
					"articleName": "Towards Generalizable Instruction Vulnerability Prediction via LLM-Enhanced Code Representation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c133/573300c133.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ruizhen",
				"surname": "Gu"
			},
			"authorName": "Gu, Ruizhen",
			"articleRefs": [
				{
					"pageNumber": 326,
					"articleName": "A Test Automation Framework for User Interaction in Extended Reality Applications",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a326/850300a326.pdf"
				},
				{
					"pageNumber": 4012,
					"articleName": "XRINTTEST: An Automated Framework for User Interaction Testing in Extended Reality Applications",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e012/573300e012.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Wenwei",
				"surname": "Gu"
			},
			"authorName": "Gu, Wenwei",
			"articleRefs": [
				{
					"pageNumber": 3497,
					"articleName": "Adaptive Performance Regression Detection Using A Semi-Supervised Siamese Network",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d497/573300d497.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xiaodong",
				"surname": "Gu"
			},
			"authorName": "Gu, Xiaodong",
			"articleRefs": [
				{
					"pageNumber": 141,
					"articleName": "LongCodeZip: Compress Long Context for Code Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a141/573300a141.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zhenrong",
				"surname": "Gu"
			},
			"authorName": "Gu, Zhenrong",
			"articleRefs": [
				{
					"pageNumber": 228,
					"articleName": "RELIA: Accelerating the Analysis of Cloud Access Control Policies",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a228/573300a228.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xiaohong",
				"surname": "Guan"
			},
			"authorName": "Guan, Xiaohong",
			"articleRefs": [
				{
					"pageNumber": 228,
					"articleName": "RELIA: Accelerating the Analysis of Cloud Access Control Policies",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a228/573300a228.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zhanming",
				"surname": "Guan"
			},
			"authorName": "Guan, Zhanming",
			"articleRefs": [
				{
					"pageNumber": 3671,
					"articleName": "RepoMasterEval: Evaluating Code Completion via Real-World Repositories",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d671/573300d671.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Matthias",
				"surname": "G\u00FCdemann"
			},
			"authorName": "G\u00FCdemann, Matthias",
			"articleRefs": [
				{
					"pageNumber": 145,
					"articleName": "BMuzz: Combining Bounded Model Checking and Fuzzing to Enhance Code Coverage",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a145/850300a145.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Gunel",
				"surname": "Gulmammadova"
			},
			"authorName": "Gulmammadova, Gunel",
			"articleRefs": [
				{
					"pageNumber": 3380,
					"articleName": "AdaptiveGuard: Towards Adaptive Runtime Safety for LLM-Powered Software",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d380/573300d380.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Fikret Mert",
				"surname": "G\u00FCltekin"
			},
			"authorName": "G\u00FCltekin, Fikret Mert",
			"articleRefs": [
				{
					"pageNumber": 58,
					"articleName": "Leveraging Large Language Models for Cybersecurity Risk Assessment \u2014 A Case from Forestry Cyber-Physical Systems",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a058/850300a058.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Sumit",
				"surname": "Gulwani"
			},
			"authorName": "Gulwani, Sumit",
			"articleRefs": [
				{
					"pageNumber": 432,
					"articleName": "Why AI Agents Still Need You: Findings from Developer-Agent Collaborations in the Wild",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a432/573300a432.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "An",
				"surname": "Guo"
			},
			"authorName": "Guo, An",
			"articleRefs": [
				{
					"pageNumber": 1168,
					"articleName": "When Autonomous Vehicle Meets V2X Cooperative Perception: How Far Are We?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b168/573300b168.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Chao",
				"surname": "Guo"
			},
			"authorName": "Guo, Chao",
			"articleRefs": [
				{
					"pageNumber": 3144,
					"articleName": "Practical Escape of Exploration Tarpits for Mini-Game Testing in an Industrial Setting",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d144/573300d144.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Chenkai",
				"surname": "Guo"
			},
			"authorName": "Guo, Chenkai",
			"articleRefs": [
				{
					"pageNumber": 2145,
					"articleName": "Don't Mess with Bro's Cheese! An Empirical Study of Resource Conflict in Android Multi-Window",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c145/573300c145.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Daya",
				"surname": "Guo"
			},
			"authorName": "Guo, Daya",
			"articleRefs": [
				{
					"pageNumber": 971,
					"articleName": "AlignCoder: Aligning Retrieval with Target Intent for Repository-Level Code Completion",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a971/573300a971.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Hanyang",
				"surname": "Guo"
			},
			"authorName": "Guo, Hanyang",
			"articleRefs": [
				{
					"pageNumber": 482,
					"articleName": "VRExplorer: A Model-Based Approach for Semi-Automated Testing of Virtual Reality Scenes",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a482/573300a482.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jialong",
				"surname": "Guo"
			},
			"authorName": "Guo, Jialong",
			"articleRefs": [
				{
					"pageNumber": 2057,
					"articleName": "FirmProj: Detecting Firmware Leakage in IoT Update Processes via Companion App Analysis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c057/573300c057.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jingdong",
				"surname": "Guo"
			},
			"authorName": "Guo, Jingdong",
			"articleRefs": [
				{
					"pageNumber": 304,
					"articleName": "Advancing Binary Code Similarity Detection via Context-Content Fusion and LLM Verification",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a304/573300a304.pdf"
				},
				{
					"pageNumber": 919,
					"articleName": "Lares: LLM-Driven Code Slice Semantic Search for Patch Presence Testing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a919/573300a919.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jinyao",
				"surname": "Guo"
			},
			"authorName": "Guo, Jinyao",
			"articleRefs": [
				{
					"pageNumber": 1220,
					"articleName": "RFCAudit: AI Agent for Auditing Protocol Implementations Against RFC Specifications",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b220/573300b220.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Luchuan",
				"surname": "Guo"
			},
			"authorName": "Guo, Luchuan",
			"articleRefs": [
				{
					"pageNumber": 3120,
					"articleName": "How Can Infrastructure as Code Accelerate Data Center Bring-ups? A Case Study at ByteDance",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d120/573300d120.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Mingda",
				"surname": "Guo"
			},
			"authorName": "Guo, Mingda",
			"articleRefs": [
				{
					"pageNumber": 2869,
					"articleName": "LLMPort: Cross-File Patch Porting via Task Decomposition and Self-Correction",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c869/573300c869.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Shiyu",
				"surname": "Guo"
			},
			"authorName": "Guo, Shiyu",
			"articleRefs": [
				{
					"pageNumber": 3273,
					"articleName": "Minuku: Detecting Diverse Display Issues in Mobile Apps with Small-Scale Dataset",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d273/573300d273.pdf"
				},
				{
					"pageNumber": 3437,
					"articleName": "From Redundancy to Efficiency: Exploiting Shared UI Interactions Towards Efficient LLM-Based Testing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d437/573300d437.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Wenbo",
				"surname": "Guo"
			},
			"authorName": "Guo, Wenbo",
			"articleRefs": [
				{
					"pageNumber": 648,
					"articleName": "BinStruct: Binary Structure Recovery Combining Static Analysis and Semantics",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a648/573300a648.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xiaoyu",
				"surname": "Guo"
			},
			"authorName": "Guo, Xiaoyu",
			"articleRefs": [
				{
					"pageNumber": 2656,
					"articleName": "QuanBench: Benchmarking Quantum Code Generation with Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c656/573300c656.pdf"
				},
				{
					"pageNumber": 3638,
					"articleName": "M2QCode: A Model-Driven Framework for Generating Multi-Platform Quantum Programs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d638/573300d638.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yutong",
				"surname": "Guo"
			},
			"authorName": "Guo, Yutong",
			"articleRefs": [
				{
					"pageNumber": 2528,
					"articleName": "Automated Insertion of Flushes and Fences for Persistency",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c528/573300c528.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yuxiao",
				"surname": "Guo"
			},
			"authorName": "Guo, Yuxiao",
			"articleRefs": [
				{
					"pageNumber": 1806,
					"articleName": "ARG: Testing Query Rewriters via Abstract Rule Guided Fuzzing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b806/573300b806.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yuzhe",
				"surname": "Guo"
			},
			"authorName": "Guo, Yuzhe",
			"articleRefs": [
				{
					"pageNumber": 3580,
					"articleName": "Element-Aware Fine-Tuning of Vision-Language Models for Cost-Efficient GUI Testing in an Industrial Setting",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d580/573300d580.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zhaoqiang",
				"surname": "Guo"
			},
			"authorName": "Guo, Zhaoqiang",
			"articleRefs": [
				{
					"pageNumber": 2719,
					"articleName": "PALM: Synergizing Program Analysis and LLMs to Enhance Rust Unit Test Coverage",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c719/573300c719.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Faraz",
				"surname": "Gurramkonda"
			},
			"authorName": "Gurramkonda, Faraz",
			"articleRefs": [
				{
					"pageNumber": 1955,
					"articleName": "VRTestSniffer: Test Smell Detector for Virtual Reality (VR) Software Projects",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b955/573300b955.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Sarra",
				"surname": "Habchi"
			},
			"authorName": "Habchi, Sarra",
			"articleRefs": [
				{
					"pageNumber": 39,
					"articleName": "MIMIC: Integrating Diverse Personality Traits for Better Game Testing Using Large Language Model",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a039/573300a039.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Nathan",
				"surname": "Hagel"
			},
			"authorName": "Hagel, Nathan",
			"articleRefs": [
				{
					"pageNumber": 204,
					"articleName": "Explainability in Automated Cross-Domain Model-Driven Brake System Development",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a204/850300a204.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Sonia",
				"surname": "Haiduc"
			},
			"authorName": "Haiduc, Sonia",
			"articleRefs": [
				{
					"pageNumber": 1439,
					"articleName": "Hierarchical Knowledge Injection for Improving LLM-Based Program Repair",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b439/573300b439.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Mohammad ",
				"surname": "Hamdaqa"
			},
			"authorName": "Hamdaqa, Mohammad",
			"articleRefs": [
				{
					"pageNumber": 4113,
					"articleName": "PROXiFY: A Bytecode Analysis Tool for Detecting and Classifying Proxy Contracts in Ethereum Smart Contracts",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e113/573300e113.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Claus",
				"surname": "Hammann"
			},
			"authorName": "Hammann, Claus",
			"articleRefs": [
				{
					"pageNumber": 204,
					"articleName": "Explainability in Automated Cross-Domain Model-Driven Brake System Development",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a204/850300a204.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Dongming",
				"surname": "Han"
			},
			"authorName": "Han, Dongming",
			"articleRefs": [
				{
					"pageNumber": 3777,
					"articleName": "SGCR: A Specification-Grounded Framework for Trustworthy LLM Code Review",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d777/573300d777.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Haocheng",
				"surname": "Han"
			},
			"authorName": "Han, Haocheng",
			"articleRefs": [
				{
					"pageNumber": 495,
					"articleName": "RSFuzz: A Robustness-Guided Swarm Fuzzing Framework Based on Behavioral Constraints",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a495/573300a495.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jin",
				"surname": "Han"
			},
			"authorName": "Han, Jin",
			"articleRefs": [
				{
					"pageNumber": 661,
					"articleName": "United We Stand: Towards End-to-End Log-Based Fault Diagnosis via Interactive Multi-Task Learning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a661/573300a661.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Weihong",
				"surname": "Han"
			},
			"authorName": "Han, Weihong",
			"articleRefs": [
				{
					"pageNumber": 3604,
					"articleName": "IntelliTopo: An IaC Generation Service for Industrial Network Topology Construction",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d604/573300d604.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xin",
				"surname": "Han"
			},
			"authorName": "Han, Xin",
			"articleRefs": [
				{
					"pageNumber": 3485,
					"articleName": "BitsAI-Fix: LLM-Driven Approach for Automated Lint Error Resolution in Practice",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d485/573300d485.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xing",
				"surname": "Han"
			},
			"authorName": "Han, Xing",
			"articleRefs": [
				{
					"pageNumber": 893,
					"articleName": "LineBreaker: Finding Token-Inconsistency Bugs with Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a893/573300a893.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Carol",
				"surname": "Hanna"
			},
			"authorName": "Hanna, Carol",
			"articleRefs": [
				{
					"pageNumber": 107,
					"articleName": "From Kotlin to Swift and Back: Toward Fully Automated Cross-Language Code Transpilation",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a107/850300a107.pdf"
				},
				{
					"pageNumber": 3901,
					"articleName": "LLM-Guided Genetic Improvement: Envisioning Semantic Aware Automated Software Evolution",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d901/573300d901.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Shuo",
				"surname": "Hao"
			},
			"authorName": "Hao, Shuo",
			"articleRefs": [
				{
					"pageNumber": 13,
					"articleName": "Argus: Resilience-Oriented Safety Assurance Framework for End-to-End ADSs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a013/573300a013.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xuran",
				"surname": "Hao"
			},
			"authorName": "Hao, Xuran",
			"articleRefs": [
				{
					"pageNumber": 3144,
					"articleName": "Practical Escape of Exploration Tarpits for Mini-Game Testing in an Industrial Setting",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d144/573300d144.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yaniv",
				"surname": "Harel"
			},
			"authorName": "Harel, Yaniv",
			"articleRefs": [
				{
					"pageNumber": 1181,
					"articleName": "Backdoors in Code Summarizers: How Bad Is It?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b181/573300b181.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Muhammad",
				"surname": "Haroon"
			},
			"authorName": "Haroon, Muhammad",
			"articleRefs": [
				{
					"pageNumber": 87,
					"articleName": "A Data-Driven Approach for Automated Quality Concern Extraction from App Reviews",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a087/850300a087.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Masatomo",
				"surname": "Hashimoto"
			},
			"authorName": "Hashimoto, Masatomo",
			"articleRefs": [
				{
					"pageNumber": 2337,
					"articleName": "On the Correctness of Software Merge",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c337/573300c337.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ahmed E.",
				"surname": "Hassan"
			},
			"authorName": "Hassan, Ahmed E.",
			"articleRefs": [
				{
					"pageNumber": 739,
					"articleName": "Watson: A Cognitive Observability Framework for the Reasoning of LLM-Powered Agents",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a739/573300a739.pdf"
				},
				{
					"pageNumber": 1628,
					"articleName": "Characterizing Multi-Hunk Patches: Divergence, Proximity, and LLM Repair Challenges",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b628/573300b628.pdf"
				},
				{
					"pageNumber": 2324,
					"articleName": "SPICE\uD83C\uDF36\uFE0F: An Automated SWE-Bench Labeling Pipeline for Issue Clarity, Test Coverage, and Effort Estimation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c324/573300c324.pdf"
				},
				{
					"pageNumber": 3286,
					"articleName": "Context-Aware CodeLLM Eviction for AI-Assisted Coding",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d286/573300d286.pdf"
				},
				{
					"pageNumber": 3718,
					"articleName": "MobileUPReg: Identifying User-Perceived Performance Regressions in Mobile OS Versions",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d718/573300d718.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Foyzul",
				"surname": "Hassan"
			},
			"authorName": "Hassan, Foyzul",
			"articleRefs": [
				{
					"pageNumber": 1955,
					"articleName": "VRTestSniffer: Test Smell Detector for Virtual Reality (VR) Software Projects",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b955/573300b955.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Behnaz",
				"surname": "Hassanshahi"
			},
			"authorName": "Hassanshahi, Behnaz",
			"articleRefs": [
				{
					"pageNumber": 3391,
					"articleName": "Unlocking Reproducibility: Automating re-Build Process for Open-Source Software",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d391/573300d391.pdf"
				},
				{
					"pageNumber": 3627,
					"articleName": "DALEQ - Explainable Equivalence for Java Bytecode",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d627/573300d627.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Chris",
				"surname": "Hawley "
			},
			"authorName": "Hawley, Chris",
			"articleRefs": [
				{
					"pageNumber": 3250,
					"articleName": "Metrics Driven Reengineering and Continuous Code Improvement at Meta",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d250/573300d250.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jingzhu",
				"surname": "He"
			},
			"authorName": "He, Jingzhu",
			"articleRefs": [
				{
					"pageNumber": 3942,
					"articleName": "STaint: Detecting Second-Order Vulnerabilities in PHP Applications with LLM-Assisted Bi-Directional Static Taint Analysis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d942/573300d942.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Minghua",
				"surname": "He"
			},
			"authorName": "He, Minghua",
			"articleRefs": [
				{
					"pageNumber": 661,
					"articleName": "United We Stand: Towards End-to-End Log-Based Fault Diagnosis via Interactive Multi-Task Learning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a661/573300a661.pdf"
				},
				{
					"pageNumber": 700,
					"articleName": "LogAction: Consistent Cross-System Anomaly Detection Through Logs via Active Domain Adaptation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a700/573300a700.pdf"
				},
				{
					"pageNumber": 1118,
					"articleName": "CoorLog: Efficient-Generalizable Log Anomaly Detection via Adaptive Coordinator in Software Evolution",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b118/573300b118.pdf"
				},
				{
					"pageNumber": 3783,
					"articleName": "Walk the Talk: Is Your Log-Based Software Reliability Maintenance System Really Reliable?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d783/573300d783.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ningyu",
				"surname": "He"
			},
			"authorName": "He, Ningyu",
			"articleRefs": [
				{
					"pageNumber": 3660,
					"articleName": "The Gold Digger in the Dark Forest: Industrial-Scale MEV Analysis in Ethereum",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d660/573300d660.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Peng",
				"surname": "He"
			},
			"authorName": "He, Peng",
			"articleRefs": [
				{
					"pageNumber": 547,
					"articleName": "DNAFuzz: Descriptor-Aware Fuzzing for USB Drivers",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a547/573300a547.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Pinjia ",
				"surname": "He"
			},
			"authorName": "He, Pinjia",
			"articleRefs": [
				{
					"pageNumber": 674,
					"articleName": "Triangle: Empowering Incident Triage with Multi-Agent",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a674/573300a674.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Renzhi ",
				"surname": "He"
			},
			"authorName": "He, Renzhi",
			"articleRefs": [
				{
					"pageNumber": 3250,
					"articleName": "Metrics Driven Reengineering and Continuous Code Improvement at Meta",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d250/573300d250.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ruidi",
				"surname": "He"
			},
			"authorName": "He, Ruidi",
			"articleRefs": [
				{
					"pageNumber": 169,
					"articleName": "LLM-Assisted Tool for Joint Generation of Formulas and Functions in Rule-Based Verification of Map Transformations",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a169/850300a169.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xiao",
				"surname": "He"
			},
			"authorName": "He, Xiao",
			"articleRefs": [
				{
					"pageNumber": 3298,
					"articleName": "LogPilot: Intent-Aware and Scalable Alert Diagnosis for Large-Scale Online Service Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d298/573300d298.pdf"
				},
				{
					"pageNumber": 3425,
					"articleName": "Automated Proactive Logging Quality Improvement for Large-Scale Codebases ",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d425/573300d425.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xu",
				"surname": "He"
			},
			"authorName": "He, Xu",
			"articleRefs": [
				{
					"pageNumber": 3485,
					"articleName": "BitsAI-Fix: LLM-Driven Approach for Automated Lint Error Resolution in Practice",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d485/573300d485.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zhu",
				"surname": "He"
			},
			"authorName": "He, Zhu",
			"articleRefs": [
				{
					"pageNumber": 228,
					"articleName": "RELIA: Accelerating the Analysis of Cloud Access Control Policies",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a228/573300a228.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ziyao",
				"surname": "He"
			},
			"authorName": "He, Ziyao",
			"articleRefs": [
				{
					"pageNumber": 1905,
					"articleName": "Automated Detection of Web Application Navigation Barriers for Screen Reader Users",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b905/573300b905.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yi Wen",
				"surname": "Heng"
			},
			"authorName": "Heng, Yi Wen",
			"articleRefs": [
				{
					"pageNumber": 3718,
					"articleName": "MobileUPReg: Identifying User-Perceived Performance Regressions in Mobile OS Versions",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d718/573300d718.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jueun",
				"surname": "Heo "
			},
			"authorName": "Heo, Jueun",
			"articleRefs": [
				{
					"pageNumber": 269,
					"articleName": "Explainable AI for Issue Classification: A Multi-Class Study with LIME and SHAP",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a269/850300a269.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Prajwal",
				"surname": "H G"
			},
			"authorName": "H G, Prajwal",
			"articleRefs": [
				{
					"pageNumber": 3972,
					"articleName": "AndroFL: Evolutionary-Driven Fault Localization for Android Apps",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d972/573300d972.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Rashina",
				"surname": "Hoda"
			},
			"authorName": "Hoda, Rashina",
			"articleRefs": [
				{
					"pageNumber": 1032,
					"articleName": "An LLM-Based Multi-Agent Framework for Agile Effort Estimation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b032/573300b032.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Oliver",
				"surname": "Hohlfeld"
			},
			"authorName": "Hohlfeld, Oliver",
			"articleRefs": [
				{
					"pageNumber": 277,
					"articleName": "LLMs Choose the Right Stack: From Patterns to Tools",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a277/850300a277.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jaemin",
				"surname": "Hong"
			},
			"authorName": "Hong, Jaemin",
			"articleRefs": [
				{
					"pageNumber": 1540,
					"articleName": "Forcrat: Automatic I/O API Translation from C to Rust via Origin and Capability Analysis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b540/573300b540.pdf"
				},
				{
					"pageNumber": 2464,
					"articleName": "Exact Inference for Quantum Circuits: A Testing Oracle for Quantum Software Stacks",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c464/573300c464.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Sanghyun",
				"surname": "Hong"
			},
			"authorName": "Hong, Sanghyun",
			"articleRefs": [
				{
					"pageNumber": 2956,
					"articleName": "When Does Wasm Malware Detection Fail? A Systematic Analysis of Their Robustness to Evasion",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c956/573300c956.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Weijie",
				"surname": "Hong"
			},
			"authorName": "Hong, Weijie",
			"articleRefs": [
				{
					"pageNumber": 661,
					"articleName": "United We Stand: Towards End-to-End Log-Based Fault Diagnosis via Interactive Multi-Task Learning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a661/573300a661.pdf"
				},
				{
					"pageNumber": 700,
					"articleName": "LogAction: Consistent Cross-System Anomaly Detection Through Logs via Active Domain Adaptation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a700/573300a700.pdf"
				},
				{
					"pageNumber": 1118,
					"articleName": "CoorLog: Efficient-Generalizable Log Anomaly Detection via Adaptive Coordinator in Software Evolution",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b118/573300b118.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Wenzheng",
				"surname": "Hong"
			},
			"authorName": "Hong, Wenzheng",
			"articleRefs": [
				{
					"pageNumber": 3082,
					"articleName": "Algernon: A Flag-Guided Hybrid Fuzzer for Unlocking Hidden Program Paths",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d082/573300d082.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ran",
				"surname": "Hou"
			},
			"authorName": "Hou, Ran",
			"articleRefs": [
				{
					"pageNumber": 4008,
					"articleName": "AgentDroid: A Multi-Agent Tool for Detecting Fraudulent Android Applications",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e008/573300e008.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xizhi",
				"surname": "Hou"
			},
			"authorName": "Hou, Xizhi",
			"articleRefs": [
				{
					"pageNumber": 1666,
					"articleName": "Leveraging Mixture-of-Experts Framework for Smart Contract Vulnerability Repair with Large Language Model",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b666/573300b666.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zhe",
				"surname": "Hou"
			},
			"authorName": "Hou, Zhe",
			"articleRefs": [
				{
					"pageNumber": 2121,
					"articleName": "PAT-Agent: Autoformalization for Model Checking",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c121/573300c121.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Chenyu",
				"surname": "Hu"
			},
			"authorName": "Hu, Chenyu",
			"articleRefs": [
				{
					"pageNumber": 237,
					"articleName": "Towards MPC-Driven Software Adaptation: A Dual-Layer Approach Combining ICNN-Based Modeling and Delta-Based Tuning",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a237/850300a237.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Chunming",
				"surname": "Hu"
			},
			"authorName": "Hu, Chunming",
			"articleRefs": [
				{
					"pageNumber": 1272,
					"articleName": "SMTgazer: Learning to Schedule SMT Algorithms via Bayesian Optimization",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b272/573300b272.pdf"
				},
				{
					"pageNumber": 3191,
					"articleName": "KAIOps: A Platform Solution of End-to-End Multi-Modal AIOps for AI Training at Scale",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d191/573300d191.pdf"
				},
				{
					"pageNumber": 3753,
					"articleName": "KAIR: A Statistical and Causal Approach to Pinpointing Stragglers in Distributed Model Training",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d753/573300d753.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Li",
				"surname": "Hu"
			},
			"authorName": "Hu, Li",
			"articleRefs": [
				{
					"pageNumber": 841,
					"articleName": "PseudoFix: Refactoring Distorted Structures in Decompiled C Pseudocode",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a841/573300a841.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ming",
				"surname": "Hu"
			},
			"authorName": "Hu, Ming",
			"articleRefs": [
				{
					"pageNumber": 3931,
					"articleName": "Requirements Development and Formalization for Reliable Code Generation: A Multi-Agent Vision",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d931/573300d931.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ruida",
				"surname": "Hu"
			},
			"authorName": "Hu, Ruida",
			"articleRefs": [
				{
					"pageNumber": 2426,
					"articleName": "An Agent-Based Evaluation Framework for Complex Code Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c426/573300c426.pdf"
				},
				{
					"pageNumber": 3671,
					"articleName": "RepoMasterEval: Evaluating Code Completion via Real-World Repositories",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d671/573300d671.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xiaohui",
				"surname": "Hu"
			},
			"authorName": "Hu, Xiaohui",
			"articleRefs": [
				{
					"pageNumber": 3660,
					"articleName": "The Gold Digger in the Dark Forest: Industrial-Scale MEV Analysis in Ethereum",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d660/573300d660.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xing",
				"surname": "Hu"
			},
			"authorName": "Hu, Xing",
			"articleRefs": [
				{
					"pageNumber": 91,
					"articleName": "When AllClose Fails: Round-Off Error Estimation for Deep Learning Programs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a091/573300a091.pdf"
				},
				{
					"pageNumber": 154,
					"articleName": "CODE-DITING: Automatic Evaluation of Code Generation Without References or Test Cases",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a154/573300a154.pdf"
				},
				{
					"pageNumber": 2745,
					"articleName": "HFuzzer: Testing Large Language Models for Package Hallucinations via Phrase-Based Fuzzing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c745/573300c745.pdf"
				},
				{
					"pageNumber": 3020,
					"articleName": "RealisticCodeBench: Towards More Realistic Evaluation of Large Language Models for Code Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d020/573300d020.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yongning",
				"surname": "Hu"
			},
			"authorName": "Hu, Yongning",
			"articleRefs": [
				{
					"pageNumber": 3120,
					"articleName": "How Can Infrastructure as Code Accelerate Data Center Bring-ups? A Case Study at ByteDance",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d120/573300d120.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yongxiang",
				"surname": "Hu"
			},
			"authorName": "Hu, Yongxiang",
			"articleRefs": [
				{
					"pageNumber": 3273,
					"articleName": "Minuku: Detecting Diverse Display Issues in Mobile Apps with Small-Scale Dataset",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d273/573300d273.pdf"
				},
				{
					"pageNumber": 3437,
					"articleName": "From Redundancy to Efficiency: Exploiting Shared UI Interactions Towards Efficient LLM-Based Testing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d437/573300d437.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yuhao",
				"surname": "Hu"
			},
			"authorName": "Hu, Yuhao",
			"articleRefs": [
				{
					"pageNumber": 1106,
					"articleName": "BCFuzz: Bytecode-Driven Fuzzing for JavaScript Engines",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b106/573300b106.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "qiang",
				"surname": "hu"
			},
			"authorName": "hu, qiang",
			"articleRefs": [
				{
					"pageNumber": 254,
					"articleName": "Defects4C: Benchmarking Large Language Model Repair Capability with C/C++ Bugs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a254/573300a254.pdf"
				},
				{
					"pageNumber": 4061,
					"articleName": "DSBox: A Data Selection Framework for Efficient Deep Code Learning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e061/573300e061.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Shaohan",
				"surname": "Huang "
			},
			"authorName": "Huang, Shaohan",
			"articleRefs": [
				{
					"pageNumber": 330,
					"articleName": "LogMoE: Lightweight Expert Mixture for Cross-System Log Anomaly Detection",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a330/573300a330.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Fei",
				"surname": "Huang"
			},
			"authorName": "Huang, Fei",
			"articleRefs": [
				{
					"pageNumber": 3729,
					"articleName": "Thinking Longer, Not Larger: Enhancing Software Engineering Agents via Scaling Test-Time Compute",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d729/573300d729.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Gang",
				"surname": "Huang"
			},
			"authorName": "Huang, Gang",
			"articleRefs": [
				{
					"pageNumber": 661,
					"articleName": "United We Stand: Towards End-to-End Log-Based Fault Diagnosis via Interactive Multi-Task Learning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a661/573300a661.pdf"
				},
				{
					"pageNumber": 700,
					"articleName": "LogAction: Consistent Cross-System Anomaly Detection Through Logs via Active Domain Adaptation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a700/573300a700.pdf"
				},
				{
					"pageNumber": 1118,
					"articleName": "CoorLog: Efficient-Generalizable Log Anomaly Detection via Adaptive Coordinator in Software Evolution",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b118/573300b118.pdf"
				},
				{
					"pageNumber": 3783,
					"articleName": "Walk the Talk: Is Your Log-Based Software Reliability Maintenance System Really Reliable?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d783/573300d783.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Hailing",
				"surname": "Huang"
			},
			"authorName": "Huang, Hailing",
			"articleRefs": [
				{
					"pageNumber": 2247,
					"articleName": "Mixture-of-Experts Low-Rank Adaptation for Multilingual Code Summarization",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c247/573300c247.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Haiyu",
				"surname": "Huang"
			},
			"authorName": "Huang, Haiyu",
			"articleRefs": [
				{
					"pageNumber": 3298,
					"articleName": "LogPilot: Intent-Aware and Scalable Alert Diagnosis for Large-Scale Online Service Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d298/573300d298.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Huaxun",
				"surname": "Huang"
			},
			"authorName": "Huang, Huaxun",
			"articleRefs": [
				{
					"pageNumber": 2032,
					"articleName": "Characterizing and Repairing Color-Related Accessibility Issues in Android Apps",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c032/573300c032.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jiangping",
				"surname": "Huang"
			},
			"authorName": "Huang, Jiangping",
			"articleRefs": [
				{
					"pageNumber": 3875,
					"articleName": "Envisioning Intelligent Requirements Engineering via Knowledge-Guided Multi-Agent Collaboration",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d875/573300d875.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jie",
				"surname": "Huang"
			},
			"authorName": "Huang, Jie",
			"articleRefs": [
				{
					"pageNumber": 3120,
					"articleName": "How Can Infrastructure as Code Accelerate Data Center Bring-ups? A Case Study at ByteDance",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d120/573300d120.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Junjie",
				"surname": "Huang"
			},
			"authorName": "Huang, Junjie",
			"articleRefs": [
				{
					"pageNumber": 958,
					"articleName": "iKnow: an Intent-Guided Chatbot for Cloud Operations with Retrieval-Augmented Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a958/573300a958.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Kai",
				"surname": "Huang"
			},
			"authorName": "Huang, Kai",
			"articleRefs": [
				{
					"pageNumber": 1155,
					"articleName": "Seeing is Fixing: Cross-Modal Reasoning with Multimodal LLMs for Visual Software Issue Repair",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b155/573300b155.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Kaicheng",
				"surname": "Huang"
			},
			"authorName": "Huang, Kaicheng",
			"articleRefs": [
				{
					"pageNumber": 3333,
					"articleName": "Multi-Modal Requirements Data-Based Acceptance Criteria Generation Using LLMs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d333/573300d333.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Lanxin",
				"surname": "Huang"
			},
			"authorName": "Huang, Lanxin",
			"articleRefs": [
				{
					"pageNumber": 2349,
					"articleName": "Incremental Program Analysis in the Wild: An Empirical Study on Real-World Program Changes",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c349/573300c349.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Lin",
				"surname": "Huang"
			},
			"authorName": "Huang, Lin",
			"articleRefs": [
				{
					"pageNumber": 3683,
					"articleName": "Securing Millions of Decentralized Identities in Alipay Super App with End-to-End Formal Verification",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d683/573300d683.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Shan",
				"surname": "Huang"
			},
			"authorName": "Huang, Shan",
			"articleRefs": [
				{
					"pageNumber": 636,
					"articleName": "Finding Bugs in MLIR Compiler Infrastructure via Lowering Space Exploration",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a636/573300a636.pdf"
				},
				{
					"pageNumber": 2311,
					"articleName": "Effective Code Membership Inference for Code Completion Models via Adversarial Prompts",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c311/573300c311.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Tao",
				"surname": "Huang"
			},
			"authorName": "Huang, Tao",
			"articleRefs": [
				{
					"pageNumber": 1918,
					"articleName": "SemGuard: Real-Time Semantic Evaluator for Correcting LLM-Generated Code",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b918/573300b918.pdf"
				},
				{
					"pageNumber": 3741,
					"articleName": "LogSage: An LLM-Based Framework for CI/CD Failure Detection and Remediation with Industrial Validation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d741/573300d741.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yiheng",
				"surname": "Huang"
			},
			"authorName": "Huang, Yiheng",
			"articleRefs": [
				{
					"pageNumber": 419,
					"articleName": "ProfMal: Detecting Malicious NPM Packages by the Synergy between Static and Dynamic Analysis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a419/573300a419.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yu",
				"surname": "Huang"
			},
			"authorName": "Huang, Yu",
			"articleRefs": [
				{
					"pageNumber": 1020,
					"articleName": "Programmers' Visual Attention on Function Call Graphs During Code Summarization",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b020/573300b020.pdf"
				},
				{
					"pageNumber": 3870,
					"articleName": "CodeACT-R: A Cognitive Simulation Framework for Human Attention in Code Reading",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d870/573300d870.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yuekai",
				"surname": "Huang"
			},
			"authorName": "Huang, Yuekai",
			"articleRefs": [
				{
					"pageNumber": 1602,
					"articleName": "Beyond Static GUI Agent: Evolving LLM-Based GUI Testing via Dynamic Memory",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b602/573300b602.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yuheng",
				"surname": "Huang"
			},
			"authorName": "Huang, Yuheng",
			"articleRefs": [
				{
					"pageNumber": 4081,
					"articleName": "TRUSTVIS: A Multi-Dimensional Trustworthiness Evaluation Framework for Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e081/573300e081.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yuhuan",
				"surname": "Huang"
			},
			"authorName": "Huang, Yuhuan",
			"articleRefs": [
				{
					"pageNumber": 1376,
					"articleName": "Learning Project-Wise Subsequent Code Edits via Interleaving Neural-Based Induction and Tool-Based Deduction",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b376/573300b376.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zhiqiu",
				"surname": "Huang"
			},
			"authorName": "Huang, Zhiqiu",
			"articleRefs": [
				{
					"pageNumber": 1880,
					"articleName": "Coding-Fuse: Efficient Fusion of Code Pre-Trained Models for Classification Tasks",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b880/573300b880.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zhiyong ",
				"surname": "Huang"
			},
			"authorName": "Huang, Zhiyong",
			"articleRefs": [
				{
					"pageNumber": 1376,
					"articleName": "Learning Project-Wise Subsequent Code Edits via Interleaving Neural-Based Induction and Tool-Based Deduction",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b376/573300b376.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Nathan",
				"surname": "Huey"
			},
			"authorName": "Huey, Nathan",
			"articleRefs": [
				{
					"pageNumber": 4044,
					"articleName": "Chrysalis: A Lightweight Logging and Replay Framework for Metamorphic Testing in Python",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e044/573300e044.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Mingxuan",
				"surname": "Hui"
			},
			"authorName": "Hui, Mingxuan",
			"articleRefs": [
				{
					"pageNumber": 1142,
					"articleName": "Hypergraph Neural Network-Based Multi-Granular Root Cause Localization for Microservice Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b142/573300b142.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Benjamin",
				"surname": "Hummel"
			},
			"authorName": "Hummel, Benjamin",
			"articleRefs": [
				{
					"pageNumber": 3215,
					"articleName": "Should We Evaluate LLM Based Security Analysis Approaches on Open Source Systems?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d215/573300d215.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Hsin-Wei",
				"surname": "Hung"
			},
			"authorName": "Hung, Hsin-Wei",
			"articleRefs": [
				{
					"pageNumber": 2170,
					"articleName": "Spinner: Detecting Locking Violations in the eBPF Runtime",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c170/573300c170.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Wei",
				"surname": "Huo"
			},
			"authorName": "Huo, Wei",
			"articleRefs": [
				{
					"pageNumber": 1069,
					"articleName": "A Large Scale Study of AI-Based Binary Function Similarity Detection Techniques for Security Researchers and Practitioners",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b069/573300b069.pdf"
				},
				{
					"pageNumber": 2681,
					"articleName": "Understanding Resource Injection Vulnerabilities in Kubernetes Ecosystems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c681/573300c681.pdf"
				},
				{
					"pageNumber": 2969,
					"articleName": "Vulnerability-Affected Versions Identification: How Far Are We?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c969/573300c969.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yintong",
				"surname": "Huo"
			},
			"authorName": "Huo, Yintong",
			"articleRefs": [
				{
					"pageNumber": 241,
					"articleName": "Interaction2Code: Benchmarking MLLM-Based Interactive Webpage Code Generation from Interactive Prototyping",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a241/573300a241.pdf"
				},
				{
					"pageNumber": 3855,
					"articleName": "Exploring Autonomous Agents: A Closer Look at Why They Fail When Completing Tasks",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d855/573300d855.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Syed Fatiul",
				"surname": "Huq"
			},
			"authorName": "Huq, Syed Fatiul",
			"articleRefs": [
				{
					"pageNumber": 1905,
					"articleName": "Automated Detection of Web Application Navigation Barriers for Screen Reader Users",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b905/573300b905.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Maryam",
				"surname": "Hussain"
			},
			"authorName": "Hussain, Maryam",
			"articleRefs": [
				{
					"pageNumber": 87,
					"articleName": "A Data-Driven Approach for Automated Quality Concern Extraction from App Reviews",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a087/850300a087.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Syed Rafiul",
				"surname": "Hussain"
			},
			"authorName": "Hussain, Syed Rafiul",
			"articleRefs": [
				{
					"pageNumber": 2893,
					"articleName": "Better Safe than Sorry: Preventing Policy Violations Through Predictive Root-Cause-Analysis for IoT Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c893/573300c893.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Soha",
				"surname": "Hussein"
			},
			"authorName": "Hussein, Soha",
			"articleRefs": [
				{
					"pageNumber": 153,
					"articleName": "Improving Automated Program Verification for Java Programs with Fuzzing",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a153/850300a153.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Wonseok",
				"surname": "Hwang"
			},
			"authorName": "Hwang, Wonseok",
			"articleRefs": [
				{
					"pageNumber": 176,
					"articleName": "K-SNAC: Robust Neuron Coverage for OOD Generalization and Test Adequacy",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a176/850300a176.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Wesam ",
				"surname": "Ibraheem"
			},
			"authorName": "Ibraheem, Wesam",
			"articleRefs": [
				{
					"pageNumber": 30,
					"articleName": "Vintage Code, Modern Judges: Meta-Validation in Low Data Regimes",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a030/850300a030.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Takahiro",
				"surname": "Iida"
			},
			"authorName": "Iida, Takahiro",
			"articleRefs": [
				{
					"pageNumber": 3771,
					"articleName": "Acceleration of Automotive Software Development by Retrieval Augmented Integration Test Script Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d771/573300d771.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Hiroki",
				"surname": "Ikeuchi"
			},
			"authorName": "Ikeuchi, Hiroki",
			"articleRefs": [
				{
					"pageNumber": 3860,
					"articleName": "LLM-Powered Fully Automated Chaos Engineering: Towards Enabling Anyone to Build Resilient Software Systems at Low Cost",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d860/573300d860.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Paola",
				"surname": "Inverardi"
			},
			"authorName": "Inverardi, Paola",
			"articleRefs": [
				{
					"pageNumber": 2451,
					"articleName": "Advancing Automated Ethical Profiling in SE: a Zero-Shot Evaluation of LLM Reasoning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c451/573300c451.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Lisette",
				"surname": "Isais"
			},
			"authorName": "Isais, Lisette",
			"articleRefs": [
				{
					"pageNumber": 338,
					"articleName": "ARTRIP: Automatic AR Testing with Randomized Interaction Patterns",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a338/850300a338.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Erblin",
				"surname": "Isaku"
			},
			"authorName": "Isaku, Erblin",
			"articleRefs": [
				{
					"pageNumber": 3402,
					"articleName": "Out of Distribution Detection in Self-Adaptive Robots with AI-Powered Digital Twins",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d402/573300d402.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ai",
				"surname": "Ishida"
			},
			"authorName": "Ishida, Ai",
			"articleRefs": [
				{
					"pageNumber": 26,
					"articleName": "Multilingual Code Explanation for Mainframe Languages",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a026/850300a026.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Fuyuki",
				"surname": "Ishikawa"
			},
			"authorName": "Ishikawa, Fuyuki",
			"articleRefs": [
				{
					"pageNumber": 121,
					"articleName": "On Effectiveness of Formal Model Repair by Large Language Models",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a121/850300a121.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Mohayeminul",
				"surname": "Islam"
			},
			"authorName": "Islam, Mohayeminul",
			"articleRefs": [
				{
					"pageNumber": 867,
					"articleName": "An Empirical Study of Python Library Migration Using Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a867/573300a867.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Sergey",
				"surname": "Ivanov"
			},
			"authorName": "Ivanov, Sergey",
			"articleRefs": [
				{
					"pageNumber": 113,
					"articleName": "Pre-Filtering Code Suggestions using Developer Behavioral Telemetry to Optimize LLM-Assisted Programming",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a113/850300a113.pdf"
				},
				{
					"pageNumber": 214,
					"articleName": "Optimizing LLM Code Suggestions: Feedback-Driven Timing with Lightweight State Bounds",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a214/850300a214.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Vladimir",
				"surname": "Ivanov"
			},
			"authorName": "Ivanov, Vladimir",
			"articleRefs": [
				{
					"pageNumber": 292,
					"articleName": "GRACG: Graph Retrieval Augmented Code Generation",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a292/850300a292.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Takuya",
				"surname": "Iwatsuka"
			},
			"authorName": "Iwatsuka, Takuya",
			"articleRefs": [
				{
					"pageNumber": 3967,
					"articleName": "A Secure Mocking Approach Towards Software Supply Chain Security",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d967/573300d967.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Maliheh",
				"surname": "Izadi"
			},
			"authorName": "Izadi, Maliheh",
			"articleRefs": [
				{
					"pageNumber": 3345,
					"articleName": "Prompt-With-Me: in-IDE Structured Prompt Management for LLM-Driven Software Engineering",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d345/573300d345.pdf"
				},
				{
					"pageNumber": 3474,
					"articleName": "Evaluating Large Language Models for Functional and Maintainable Code in Industrial Settings: A Case Study at ASML",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d474/573300d474.pdf"
				},
				{
					"pageNumber": 3509,
					"articleName": "TreeRanker: Fast and Model-Agnostic Ranking System for Code Suggestions in IDEs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d509/573300d509.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Sadia",
				"surname": "Jahan"
			},
			"authorName": "Jahan, Sadia",
			"articleRefs": [
				{
					"pageNumber": 3808,
					"articleName": "How Does ChatGPT Make Assumptions When Creating Erroneous Programs?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d808/573300d808.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Shubhi",
				"surname": "Jain"
			},
			"authorName": "Jain, Shubhi",
			"articleRefs": [
				{
					"pageNumber": 1905,
					"articleName": "Automated Detection of Web Application Navigation Barriers for Screen Reader Users",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b905/573300b905.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Marek",
				"surname": "Jankola"
			},
			"authorName": "Jankola, Marek",
			"articleRefs": [
				{
					"pageNumber": 1968,
					"articleName": "Non-Termination Witnesses and Their Validation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b968/573300b968.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Cyrille",
				"surname": "Jegourel"
			},
			"authorName": "Jegourel, Cyrille",
			"articleRefs": [
				{
					"pageNumber": 3895,
					"articleName": "Simulated Interactive Debugging",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d895/573300d895.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Minwoo",
				"surname": "Jeong"
			},
			"authorName": "Jeong, Minwoo",
			"articleRefs": [
				{
					"pageNumber": 3759,
					"articleName": "What Types of Code Review Comments Do Developers Most Frequently Resolve?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d759/573300d759.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ajay Kumar",
				"surname": " Jha"
			},
			"authorName": "Jha, Ajay Kumar",
			"articleRefs": [
				{
					"pageNumber": 867,
					"articleName": "An Empirical Study of Python Library Migration Using Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a867/573300a867.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Kaihang",
				"surname": "Ji"
			},
			"authorName": "Ji, Kaihang",
			"articleRefs": [
				{
					"pageNumber": 65,
					"articleName": "Propagation-Based Vulnerability Impact Assessment for Software Supply Chains",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a065/573300a065.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Kexing",
				"surname": "Ji"
			},
			"authorName": "Ji, Kexing",
			"articleRefs": [
				{
					"pageNumber": 3449,
					"articleName": "Automated Prompt Generation for Code Intelligence: An Empirical Study and Experience in WeChat",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d449/573300d449.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Shouling",
				"surname": "Ji"
			},
			"authorName": "Ji, Shouling",
			"articleRefs": [
				{
					"pageNumber": 1044,
					"articleName": "PROMFUZZ: Leveraging LLM-Driven and Bug-Oriented Composite Analysis for Detecting Functional Bugs in Smart Contracts",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b044/573300b044.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yuchen",
				"surname": "Ji"
			},
			"authorName": "Ji, Yuchen",
			"articleRefs": [
				{
					"pageNumber": 3942,
					"articleName": "STaint: Detecting Second-Order Vulnerabilities in PHP Applications with LLM-Assisted Bi-Directional Static Taint Analysis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d942/573300d942.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Haoxiang",
				"surname": "Jia"
			},
			"authorName": "Jia, Haoxiang",
			"articleRefs": [
				{
					"pageNumber": 367,
					"articleName": "Automated Repair of Ambiguous Problem Descriptions for LLM-Based Code Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a367/573300a367.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jinghao",
				"surname": "Jia"
			},
			"authorName": "Jia, Jinghao",
			"articleRefs": [
				{
					"pageNumber": 1082,
					"articleName": "DebCovDiff: Differential Testing of Coverage Measurement Tools on Real-World Projects",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b082/573300b082.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Nan",
				"surname": "Jia"
			},
			"authorName": "Jia, Nan",
			"articleRefs": [
				{
					"pageNumber": 752,
					"articleName": "Speculative Automated Refactoring of Imperative Deep Learning Programs to Graph Execution",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a752/573300a752.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Shuai",
				"surname": "Jia"
			},
			"authorName": "Jia, Shuai",
			"articleRefs": [
				{
					"pageNumber": 3777,
					"articleName": "SGCR: A Specification-Grounded Framework for Trustworthy LLM Code Review",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d777/573300d777.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Tong",
				"surname": "Jia"
			},
			"authorName": "Jia, Tong",
			"articleRefs": [
				{
					"pageNumber": 661,
					"articleName": "United We Stand: Towards End-to-End Log-Based Fault Diagnosis via Interactive Multi-Task Learning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a661/573300a661.pdf"
				},
				{
					"pageNumber": 700,
					"articleName": "LogAction: Consistent Cross-System Anomaly Detection Through Logs via Active Domain Adaptation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a700/573300a700.pdf"
				},
				{
					"pageNumber": 1118,
					"articleName": "CoorLog: Efficient-Generalizable Log Anomaly Detection via Adaptive Coordinator in Software Evolution",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b118/573300b118.pdf"
				},
				{
					"pageNumber": 3783,
					"articleName": "Walk the Talk: Is Your Log-Based Software Reliability Maintenance System Really Reliable?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d783/573300d783.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Bo ",
				"surname": "Jiang"
			},
			"authorName": "Jiang, Bo",
			"articleRefs": [
				{
					"pageNumber": 1376,
					"articleName": "Learning Project-Wise Subsequent Code Edits via Interleaving Neural-Based Induction and Tool-Based Deduction",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b376/573300b376.pdf"
				},
				{
					"pageNumber": 3671,
					"articleName": "RepoMasterEval: Evaluating Code Completion via Real-World Repositories",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d671/573300d671.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Bowen",
				"surname": "Jiang"
			},
			"authorName": "Jiang, Bowen",
			"articleRefs": [
				{
					"pageNumber": 2082,
					"articleName": "Breaking the Traffic Barrier: Unveiling Multi-Format of Protocols via Autonomous Program Exploration",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c082/573300c082.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Fan",
				"surname": "Jiang"
			},
			"authorName": "Jiang, Fan",
			"articleRefs": [
				{
					"pageNumber": 3759,
					"articleName": "What Types of Code Review Comments Do Developers Most Frequently Resolve?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d759/573300d759.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Haowen",
				"surname": "Jiang"
			},
			"authorName": "Jiang, Haowen",
			"articleRefs": [
				{
					"pageNumber": 13,
					"articleName": "Argus: Resilience-Oriented Safety Assurance Framework for End-to-End ADSs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a013/573300a013.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jinan",
				"surname": "Jiang"
			},
			"authorName": "Jiang, Jinan",
			"articleRefs": [
				{
					"pageNumber": 1463,
					"articleName": "ScaleCirc: Scaling the Analysis over Circom Circuits",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b463/573300b463.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jing",
				"surname": "Jiang"
			},
			"authorName": "Jiang, Jing",
			"articleRefs": [
				{
					"pageNumber": 2007,
					"articleName": "Explainable Fault Localization for Programming Assignments via LLM-Guided Annotation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c007/573300c007.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ryan",
				"surname": "Jiang"
			},
			"authorName": "Jiang, Ryan",
			"articleRefs": [
				{
					"pageNumber": 3759,
					"articleName": "What Types of Code Review Comments Do Developers Most Frequently Resolve?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d759/573300d759.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Shibiao",
				"surname": "Jiang"
			},
			"authorName": "Jiang, Shibiao",
			"articleRefs": [
				{
					"pageNumber": 228,
					"articleName": "RELIA: Accelerating the Analysis of Cloud Access Control Policies",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a228/573300a228.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Siyuan",
				"surname": "Jiang"
			},
			"authorName": "Jiang, Siyuan",
			"articleRefs": [
				{
					"pageNumber": 1476,
					"articleName": "Aligning LLMs to Fully Utilize the Cross-File Context in Repository-Level Code Completion",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b476/573300b476.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Tianyue",
				"surname": "Jiang"
			},
			"authorName": "Jiang, Tianyue",
			"articleRefs": [
				{
					"pageNumber": 778,
					"articleName": "DrainCode: Stealthy Energy Consumption Attacks on Retrieval-Augmented Code Generation via Context Poisoning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a778/573300a778.pdf"
				},
				{
					"pageNumber": 971,
					"articleName": "AlignCoder: Aligning Retrieval with Target Intent for Repository-Level Code Completion",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a971/573300a971.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Wei",
				"surname": "Jiang"
			},
			"authorName": "Jiang, Wei",
			"articleRefs": [
				{
					"pageNumber": 1830,
					"articleName": "PEACE: Towards Efficient Project-Level Efficiency Optimization via Hybrid Code Editing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b830/573300b830.pdf"
				},
				{
					"pageNumber": 3033,
					"articleName": "Issue Localization via LLM-Driven Iterative Code Graph Searching",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d033/573300d033.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xue",
				"surname": "Jiang"
			},
			"authorName": "Jiang, Xue",
			"articleRefs": [
				{
					"pageNumber": 3729,
					"articleName": "Thinking Longer, Not Larger: Enhancing Software Engineering Agents via Scaling Test-Time Compute",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d729/573300d729.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yanjie",
				"surname": "Jiang"
			},
			"authorName": "Jiang, Yanjie",
			"articleRefs": [
				{
					"pageNumber": 178,
					"articleName": "Wired for Reuse: Automating Context-Aware Code Adaptation in IDEs via LLM-Based Agent",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a178/573300a178.pdf"
				},
				{
					"pageNumber": 2833,
					"articleName": "Reflective Unit Test Generation for Precise Type Error Detection with Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c833/573300c833.pdf"
				},
				{
					"pageNumber": 2982,
					"articleName": "LAURA: Enhancing Code Review Generation with Context-Enriched Retrieval-Augmented LLM",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c982/573300c982.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yu",
				"surname": "Jiang"
			},
			"authorName": "Jiang, Yu",
			"articleRefs": [
				{
					"pageNumber": 547,
					"articleName": "DNAFuzz: Descriptor-Aware Fuzzing for USB Drivers",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a547/573300a547.pdf"
				},
				{
					"pageNumber": 765,
					"articleName": "DualFuzz: Detecting Vulnerability in Wi-Fi NICs through Dual-Directional Fuzzing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a765/573300a765.pdf"
				},
				{
					"pageNumber": 1806,
					"articleName": "ARG: Testing Query Rewriters via Abstract Rule Guided Fuzzing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b806/573300b806.pdf"
				},
				{
					"pageNumber": 3226,
					"articleName": "TRON: Fuzzing Linux Network Stack via Protocol-System Call Payload Synthesis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d226/573300d226.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yuan",
				"surname": "Jiang"
			},
			"authorName": "Jiang, Yuan",
			"articleRefs": [
				{
					"pageNumber": 2311,
					"articleName": "Effective Code Membership Inference for Code Completion Models via Adversarial Prompts",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c311/573300c311.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yuancheng",
				"surname": "Jiang"
			},
			"authorName": "Jiang, Yuancheng",
			"articleRefs": [
				{
					"pageNumber": 1094,
					"articleName": "ZendDiff: Differential Testing of PHP Interpreter",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b094/573300b094.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zhihan",
				"surname": "Jiang"
			},
			"authorName": "Jiang, Zhihan",
			"articleRefs": [
				{
					"pageNumber": 958,
					"articleName": "iKnow: an Intent-Guided Chatbot for Cloud Operations with Retrieval-Augmented Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a958/573300a958.pdf"
				},
				{
					"pageNumber": 3298,
					"articleName": "LogPilot: Intent-Aware and Scalable Alert Diagnosis for Large-Scale Online Service Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d298/573300d298.pdf"
				},
				{
					"pageNumber": 3425,
					"articleName": "Automated Proactive Logging Quality Improvement for Large-Scale Codebases ",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d425/573300d425.pdf"
				},
				{
					"pageNumber": 3533,
					"articleName": "ErrorPrism: Reconstructing Error Propagation Paths in Cloud Service Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d533/573300d533.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zhonghao",
				"surname": "Jiang"
			},
			"authorName": "Jiang, Zhonghao",
			"articleRefs": [
				{
					"pageNumber": 3033,
					"articleName": "Issue Localization via LLM-Driven Iterative Code Graph Searching",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d033/573300d033.pdf"
				},
				{
					"pageNumber": 4008,
					"articleName": "AgentDroid: A Multi-Agent Tool for Detecting Fraudulent Android Applications",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e008/573300e008.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zongze",
				"surname": "Jiang"
			},
			"authorName": "Jiang, Zongze",
			"articleRefs": [
				{
					"pageNumber": 1641,
					"articleName": "Fact-Aligned and Template-Constrained Static Analyzer Rule Enhancement with LLMs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b641/573300b641.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Rui",
				"surname": "Jiao"
			},
			"authorName": "Jiao, Rui",
			"articleRefs": [
				{
					"pageNumber": 791,
					"articleName": "Hit The Bullseye On The First Shot: Improving LLMs Using Multi-Sample Self-Reward Feedback for Vulnerability Repair",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a791/573300a791.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ziqian",
				"surname": "Jiao"
			},
			"authorName": "Jiao, Ziqian",
			"articleRefs": [
				{
					"pageNumber": 2298,
					"articleName": "FastCoder: Accelerating Repository-Level Code Generation via Efficient Retrieval and Verification",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c298/573300c298.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Dongmin",
				"surname": "Jin"
			},
			"authorName": "Jin, Dongmin",
			"articleRefs": [
				{
					"pageNumber": 3875,
					"articleName": "Envisioning Intelligent Requirements Engineering via Knowledge-Guided Multi-Agent Collaboration",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d875/573300d875.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Feiyu",
				"surname": "Jin"
			},
			"authorName": "Jin, Feiyu",
			"articleRefs": [
				{
					"pageNumber": 393,
					"articleName": "Democratizing the Cryptocurrency Ecosystem by Just-In-Time Transformation of Mining Programs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a393/573300a393.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Hai",
				"surname": "Jin"
			},
			"authorName": "Jin, Hai",
			"articleRefs": [
				{
					"pageNumber": 1641,
					"articleName": "Fact-Aligned and Template-Constrained Static Analyzer Rule Enhancement with LLMs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b641/573300b641.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Hailiang",
				"surname": "Jin"
			},
			"authorName": "Jin, Hailiang",
			"articleRefs": [
				{
					"pageNumber": 3273,
					"articleName": "Minuku: Detecting Diverse Display Issues in Mobile Apps with Small-Scale Dataset",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d273/573300d273.pdf"
				},
				{
					"pageNumber": 3437,
					"articleName": "From Redundancy to Efficiency: Exploiting Shared UI Interactions Towards Efficient LLM-Based Testing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d437/573300d437.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Haolin",
				"surname": "Jin"
			},
			"authorName": "Jin, Haolin",
			"articleRefs": [
				{
					"pageNumber": 3818,
					"articleName": "Uncovering Systematic Failures of LLMs in Verifying Code Against Natural Language Specifications",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d818/573300d818.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Tiancheng",
				"surname": "Jin"
			},
			"authorName": "Jin, Tiancheng",
			"articleRefs": [
				{
					"pageNumber": 3880,
					"articleName": "NovaQ: Improving Quantum Program Testing through Diversity-Guided Test Case Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d880/573300d880.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xianhao",
				"surname": "Jin"
			},
			"authorName": "Jin, Xianhao",
			"articleRefs": [
				{
					"pageNumber": 3120,
					"articleName": "How Can Infrastructure as Code Accelerate Data Center Bring-ups? A Case Study at ByteDance",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d120/573300d120.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yuchen",
				"surname": "Jin"
			},
			"authorName": "Jin, Yuchen",
			"articleRefs": [
				{
					"pageNumber": 1880,
					"articleName": "Coding-Fuse: Efficient Fusion of Code Pre-Trained Models for Classification Tasks",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b880/573300b880.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zhi",
				"surname": "Jin"
			},
			"authorName": "Jin, Zhi",
			"articleRefs": [
				{
					"pageNumber": 1476,
					"articleName": "Aligning LLMs to Fully Utilize the Cross-File Context in Repository-Level Code Completion",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b476/573300b476.pdf"
				},
				{
					"pageNumber": 1918,
					"articleName": "SemGuard: Real-Time Semantic Evaluator for Correcting LLM-Generated Code",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b918/573300b918.pdf"
				},
				{
					"pageNumber": 3414,
					"articleName": "Data Dependency-Aware Code Generation from Enhanced UML Sequence Diagrams",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d414/573300d414.pdf"
				},
				{
					"pageNumber": 3521,
					"articleName": "Evaluating Large Language Models for Time Series Anomaly Detection in Aerospace Software",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d521/573300d521.pdf"
				},
				{
					"pageNumber": 3875,
					"articleName": "Envisioning Intelligent Requirements Engineering via Knowledge-Guided Multi-Agent Collaboration",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d875/573300d875.pdf"
				},
				{
					"pageNumber": 3931,
					"articleName": "Requirements Development and Formalization for Reliable Code Generation: A Multi-Agent Vision",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d931/573300d931.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Brittany ",
				"surname": "Johnson"
			},
			"authorName": "Johnson, Brittany",
			"articleRefs": [
				{
					"pageNumber": 199,
					"articleName": "Explaining Code Risk in OSS: Towards LLM-Generated Fault Prediction Interpretations",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a199/850300a199.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jack",
				"surname": "Johnson"
			},
			"authorName": "Johnson, Jack",
			"articleRefs": [
				{
					"pageNumber": 2195,
					"articleName": "Generating Failure-Based Oracles to Support Testing of Reported Bugs in Android Apps",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c195/573300c195.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Oshando",
				"surname": "Johnson"
			},
			"authorName": "Johnson, Oshando",
			"articleRefs": [
				{
					"pageNumber": 194,
					"articleName": "Explaining Software Vulnerabilities with Large Language Models",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a194/850300a194.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "James A.",
				"surname": "Jones"
			},
			"authorName": "Jones, James A.",
			"articleRefs": [
				{
					"pageNumber": 1259,
					"articleName": "What's DAT Smell? Untangling and Weaving the Disjoint Assertion Tangle Test Smell",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b259/573300b259.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Bj\u00F6rn \u00DE\u00F3r ",
				"surname": "J\u00F3nsson"
			},
			"authorName": "J\u00F3nsson, Bj\u00F6rn \u00DE\u00F3r",
			"articleRefs": [
				{
					"pageNumber": 4113,
					"articleName": "PROXiFY: A Bytecode Analysis Tool for Detecting and Classifying Proxy Contracts in Ethereum Smart Contracts",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e113/573300e113.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Gwendal",
				"surname": "Jouneaux"
			},
			"authorName": "Jouneaux, Gwendal",
			"articleRefs": [
				{
					"pageNumber": 3890,
					"articleName": "Towards Automated Governance: A DSL for Human-Agent Collaboration in Software Projects",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d890/573300d890.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Mehant",
				"surname": "Kammakomati"
			},
			"authorName": "Kammakomati, Mehant",
			"articleRefs": [
				{
					"pageNumber": 3926,
					"articleName": "Multiple Schema-Conformant Declarative Code Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d926/573300d926.pdf"
				},
				{
					"pageNumber": 4097,
					"articleName": "Training-Control-as-Code: Towards a Declarative Solution to Control Training",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e097/573300e097.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Eunsuk",
				"surname": "Kang"
			},
			"authorName": "Kang, Eunsuk",
			"articleRefs": [
				{
					"pageNumber": 3911,
					"articleName": "Human-In-The-Loop Oracle Learning for Simulation-Based Testing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d911/573300d911.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Juheon",
				"surname": "Kang"
			},
			"authorName": "Kang, Juheon",
			"articleRefs": [
				{
					"pageNumber": 176,
					"articleName": "K-SNAC: Robust Neuron Coverage for OOD Generalization and Test Adequacy",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a176/850300a176.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Liangyi",
				"surname": "Kang"
			},
			"authorName": "Kang, Liangyi",
			"articleRefs": [
				{
					"pageNumber": 2771,
					"articleName": "Root Cause Analysis of RISC-V Build Failures via LLM and MCTS Reasoning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c771/573300c771.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yan",
				"surname": "Kang"
			},
			"authorName": "Kang, Yan",
			"articleRefs": [
				{
					"pageNumber": 1106,
					"articleName": "BCFuzz: Bytecode-Driven Fuzzing for JavaScript Engines",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b106/573300b106.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Leslie",
				"surname": "Kanthan"
			},
			"authorName": "Kanthan, Leslie",
			"articleRefs": [
				{
					"pageNumber": 3568,
					"articleName": "Tuning LLM-Based Code Optimization via Meta-Prompting: An Industrial Perspective",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d568/573300d568.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Konstantinos",
				"surname": "Karakatsanis"
			},
			"authorName": "Karakatsanis, Konstantinos",
			"articleRefs": [
				{
					"pageNumber": 4069,
					"articleName": "PyTrim: A Practical Tool for Reducing Python Dependency Bloat",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e069/573300e069.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Kadiray",
				"surname": "Karakaya"
			},
			"authorName": "Karakaya, Kadiray",
			"articleRefs": [
				{
					"pageNumber": 343,
					"articleName": "Toward Static Analysis of Immersive Attacks",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a343/850300a343.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zachary",
				"surname": "Karas"
			},
			"authorName": "Karas, Zachary",
			"articleRefs": [
				{
					"pageNumber": 1020,
					"articleName": "Programmers' Visual Attention on Function Call Graphs During Code Summarization",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b020/573300b020.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ioannis",
				"surname": "Karyotakis"
			},
			"authorName": "Karyotakis, Ioannis",
			"articleRefs": [
				{
					"pageNumber": 4069,
					"articleName": "PyTrim: A Practical Tool for Reducing Python Dependency Bloat",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e069/573300e069.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Mohamad",
				"surname": "Kassab"
			},
			"authorName": "Kassab, Mohamad",
			"articleRefs": [
				{
					"pageNumber": 3844,
					"articleName": "Detecting and Repairing Incomplete Software Requirements with Multi-LLM Ensembles",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d844/573300d844.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Rami",
				"surname": " Katan"
			},
			"authorName": "Katan, Rami",
			"articleRefs": [
				{
					"pageNumber": 30,
					"articleName": "Vintage Code, Modern Judges: Meta-Validation in Low Data Regimes",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a030/850300a030.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yasuharu",
				"surname": "Katsuno"
			},
			"authorName": "Katsuno, Yasuharu",
			"articleRefs": [
				{
					"pageNumber": 3,
					"articleName": "Grammar- and Coverage-Based Augmentation of Programs for Training LLMs",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a003/850300a003.pdf"
				},
				{
					"pageNumber": 26,
					"articleName": "Multilingual Code Explanation for Mainframe Languages",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a026/850300a026.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Minakshi",
				"surname": "Kaushik"
			},
			"authorName": "Kaushik, Minakshi",
			"articleRefs": [
				{
					"pageNumber": 204,
					"articleName": "Explainability in Automated Cross-Domain Model-Driven Brake System Development",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a204/850300a204.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Felix",
				"surname": "Kehrer"
			},
			"authorName": "Kehrer, Felix",
			"articleRefs": [
				{
					"pageNumber": 906,
					"articleName": "Profile Coverage: Using Android Compilation Profiles to Evaluate Dynamic Testing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a906/573300a906.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Martin",
				"surname": "Kellogg"
			},
			"authorName": "Kellogg, Martin",
			"articleRefs": [
				{
					"pageNumber": 828,
					"articleName": "Repairing Leaks in Resource Wrappers",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a828/573300a828.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jacky",
				"surname": "Keung"
			},
			"authorName": "Keung, Jacky",
			"articleRefs": [
				{
					"pageNumber": 1855,
					"articleName": "Can Mamba Be Better? An Experimental Evaluation of Mamba in Code Intelligence",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b855/573300b855.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jacky Wai",
				"surname": "Keung"
			},
			"authorName": "Keung, Jacky Wai",
			"articleRefs": [
				{
					"pageNumber": 3020,
					"articleName": "RealisticCodeBench: Towards More Realistic Evaluation of Large Language Models for Code Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d020/573300d020.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Fiza",
				"surname": "Khaliq"
			},
			"authorName": "Khaliq, Fiza",
			"articleRefs": [
				{
					"pageNumber": 2758,
					"articleName": "LLM-Based Identification of Null Pointer Exception Patches",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c758/573300c758.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Nafiz Imtiaz ",
				"surname": "Khan"
			},
			"authorName": "Khan, Nafiz Imtiaz",
			"articleRefs": [
				{
					"pageNumber": 4073,
					"articleName": "OSSPREY: AI-Driven Forecasting and Intervention for OSS Project Sustainability",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e073/573300e073.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Raffi",
				"surname": "Khatchadourian"
			},
			"authorName": "Khatchadourian, Raffi",
			"articleRefs": [
				{
					"pageNumber": 752,
					"articleName": "Speculative Automated Refactoring of Imperative Deep Learning Programs to Graph Execution",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a752/573300a752.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Sajad",
				"surname": "Khatiri"
			},
			"authorName": "Khatiri, Sajad",
			"articleRefs": [
				{
					"pageNumber": 3356,
					"articleName": "Bridging Research and Practice in Simulation-Based Testing of Industrial Robot Navigation Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d356/573300d356.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ranim",
				"surname": "Khojah"
			},
			"authorName": "Khojah, Ranim",
			"articleRefs": [
				{
					"pageNumber": 58,
					"articleName": "Leveraging Large Language Models for Cybersecurity Risk Assessment \u2014 A Case from Forestry Cyber-Physical Systems",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a058/850300a058.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Foutse",
				"surname": "Khomh"
			},
			"authorName": "Khomh, Foutse",
			"articleRefs": [
				{
					"pageNumber": 3461,
					"articleName": "From Technical Excellence to Practical Adoption: Lessons Learned Building an ML-Enhanced Trace Analysis Tool",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d461/573300d461.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Matthew",
				"surname": "Khouzam"
			},
			"authorName": "Khouzam, Matthew",
			"articleRefs": [
				{
					"pageNumber": 3461,
					"articleName": "From Technical Excellence to Practical Adoption: Lessons Learned Building an ML-Enhanced Trace Analysis Tool",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d461/573300d461.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Tobias",
				"surname": "Kiecker"
			},
			"authorName": "Kiecker, Tobias",
			"articleRefs": [
				{
					"pageNumber": 4144,
					"articleName": "Detecting and Mitigating Inconsistencies Between Code, Documentation and Tests",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e144/573300e144.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Daisuke",
				"surname": "Kikuta"
			},
			"authorName": "Kikuta, Daisuke",
			"articleRefs": [
				{
					"pageNumber": 3860,
					"articleName": "LLM-Powered Fully Automated Chaos Engineering: Towards Enabling Anyone to Build Resilient Software Systems at Low Cost",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d860/573300d860.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Chung Hwan",
				"surname": "Kim"
			},
			"authorName": "Kim, Chung Hwan",
			"articleRefs": [
				{
					"pageNumber": 1590,
					"articleName": "IMUFUZZER: Resilience-Based Discovery of Signal Injection Attacks on Robotic Aerial Vehicles",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b590/573300b590.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Hyoungshick",
				"surname": "Kim"
			},
			"authorName": "Kim, Hyoungshick",
			"articleRefs": [
				{
					"pageNumber": 2956,
					"articleName": "When Does Wasm Malware Detection Fail? A Systematic Analysis of Their Robustness to Evasion",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c956/573300c956.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jaehyeon",
				"surname": "Kim"
			},
			"authorName": "Kim, Jaehyeon",
			"articleRefs": [
				{
					"pageNumber": 4040,
					"articleName": "BuilDroid: A Self-Correcting LLM Agent for Automated Android Builds",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e040/573300e040.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jinyoung",
				"surname": "Kim"
			},
			"authorName": "Kim, Jinyoung",
			"articleRefs": [
				{
					"pageNumber": 3070,
					"articleName": "Amur: Fixing Multi-Resource Leaks Guided by Resource Flow Analysis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d070/573300d070.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Kisub",
				"surname": "Kim"
			},
			"authorName": "Kim, Kisub",
			"articleRefs": [
				{
					"pageNumber": 2605,
					"articleName": "SE-Jury: An LLM-as-Ensemble-Judge Metric for Narrowing the Gap with Human Evaluation in SE",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c605/573300c605.pdf"
				},
				{
					"pageNumber": 3203,
					"articleName": "iCodeReviewer: Improving Secure Code Review with Mixture of Prompts",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d203/573300d203.pdf"
				},
				{
					"pageNumber": 3962,
					"articleName": "RAML: Toward Retrieval-Augmented Localization of Malicious Payloads in Android Apps",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d962/573300d962.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Miryung",
				"surname": "Kim"
			},
			"authorName": "Kim, Miryung",
			"articleRefs": [
				{
					"pageNumber": 4044,
					"articleName": "Chrysalis: A Lightweight Logging and Replay Framework for Metamorphic Testing in Python",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e044/573300e044.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Seojin",
				"surname": "Kim"
			},
			"authorName": "Kim, Seojin",
			"articleRefs": [
				{
					"pageNumber": 78,
					"articleName": "Debun: Detecting Bundled JavaScript Libraries on Web using Property-Order Graphs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a078/573300a078.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Shinhae",
				"surname": "Kim"
			},
			"authorName": "Kim, Shinhae",
			"articleRefs": [
				{
					"pageNumber": 2285,
					"articleName": "Faster Runtime Verification During Testing via Feedback-Guided Selective Monitoring",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c285/573300c285.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Taesoo",
				"surname": "Kim"
			},
			"authorName": "Kim, Taesoo",
			"articleRefs": [
				{
					"pageNumber": 1285,
					"articleName": "Agentic Specification Generator for Move Programs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b285/573300b285.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Taeyoung",
				"surname": "Kim"
			},
			"authorName": "Kim, Taeyoung",
			"articleRefs": [
				{
					"pageNumber": 2956,
					"articleName": "When Does Wasm Malware Detection Fail? A Systematic Analysis of Their Robustness to Evasion",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c956/573300c956.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Engin",
				"surname": "Kirda"
			},
			"authorName": "Kirda, Engin",
			"articleRefs": [
				{
					"pageNumber": 2567,
					"articleName": "DRIFT: Debug-Based Trace Inference for Firmware Testing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c567/573300c567.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Konstantinos",
				"surname": "Kitsios"
			},
			"authorName": "Kitsios, Konstantinos",
			"articleRefs": [
				{
					"pageNumber": 1311,
					"articleName": "Detecting Semantic Clones of Unseen Functionality",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b311/573300b311.pdf"
				},
				{
					"pageNumber": 1981,
					"articleName": "Automated Generation of Issue-Reproducing Tests by Combining LLMs and Search-Based Testing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b981/573300b981.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jonas",
				"surname": "Klauke"
			},
			"authorName": "Klauke, Jonas",
			"articleRefs": [
				{
					"pageNumber": 343,
					"articleName": "Toward Static Analysis of Immersive Attacks",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a343/850300a343.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jacques",
				"surname": "Klein"
			},
			"authorName": "Klein, Jacques",
			"articleRefs": [
				{
					"pageNumber": 3921,
					"articleName": "Measuring LLM Code Generation Stability via Structural Entropy",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d921/573300d921.pdf"
				},
				{
					"pageNumber": 3962,
					"articleName": "RAML: Toward Retrieval-Augmented Localization of Malicious Payloads in Android Apps",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d962/573300d962.pdf"
				},
				{
					"pageNumber": 4117,
					"articleName": "evalSmarT: An LLM-Based Framework for Evaluating Smart Contract Generated Comments",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e117/573300e117.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Tsutomu",
				"surname": "Kobayashi"
			},
			"authorName": "Kobayashi, Tsutomu",
			"articleRefs": [
				{
					"pageNumber": 121,
					"articleName": "On Effectiveness of Formal Model Repair by Large Language Models",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a121/850300a121.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Kristian",
				"surname": "Kolthoff"
			},
			"authorName": "Kolthoff, Kristian",
			"articleRefs": [
				{
					"pageNumber": 4052,
					"articleName": "GUI-ReRank: Enhancing GUI Retrieval with Multi-Modal LLM-Based Reranking",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e052/573300e052.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Philip",
				"surname": "Kolvenbach"
			},
			"authorName": "Kolvenbach, Philip",
			"articleRefs": [
				{
					"pageNumber": 1615,
					"articleName": "Terminator: Enabling Efficient Fuzzing of Closed-Source GUI Programs by Automatic Coverage-Guided Termination",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b615/573300b615.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jiaolong",
				"surname": "Kong"
			},
			"authorName": "Kong, Jiaolong",
			"articleRefs": [
				{
					"pageNumber": 254,
					"articleName": "Defects4C: Benchmarking Large Language Model Repair Capability with C/C++ Bugs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a254/573300a254.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zelun",
				"surname": "Kong"
			},
			"authorName": "Kong, Zelun",
			"articleRefs": [
				{
					"pageNumber": 1590,
					"articleName": "IMUFUZZER: Resilience-Based Discovery of Signal Injection Attacks on Robotic Aerial Vehicles",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b590/573300b590.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Roham",
				"surname": "Koohestani"
			},
			"authorName": "Koohestani, Roham",
			"articleRefs": [
				{
					"pageNumber": 74,
					"articleName": "AgentGuard: Runtime Verification of AI Agents",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a074/850300a074.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Maciej",
				"surname": "Kopa"
			},
			"authorName": "Kopa, Maciej",
			"articleRefs": [
				{
					"pageNumber": 304,
					"articleName": "Multi-agent systems for improved information retrieval \u2013 leveraging autonomous agents and LLM models",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a304/850300a304.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jens",
				"surname": "Kosiol"
			},
			"authorName": "Kosiol, Jens",
			"articleRefs": [
				{
					"pageNumber": 277,
					"articleName": "LLMs Choose the Right Stack: From Patterns to Tools",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a277/850300a277.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Pavel",
				"surname": "Koupil"
			},
			"authorName": "Koupil, Pavel",
			"articleRefs": [
				{
					"pageNumber": 4036,
					"articleName": "ORMorpher: An Interactive Framework for ORM Translation and Optimization",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e036/573300e036.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Vladimir",
				"surname": "Kovalenko"
			},
			"authorName": "Kovalenko, Vladimir",
			"articleRefs": [
				{
					"pageNumber": 358,
					"articleName": "Challenge on Optimization of Context Collection for Code Completion",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a358/850300a358.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Egor",
				"surname": "Kovalev"
			},
			"authorName": "Kovalev, Egor",
			"articleRefs": [
				{
					"pageNumber": 4032,
					"articleName": "WIBE: Watermarks for generated Images \u2013 Benchmarking & Evaluation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e032/573300e032.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Anil",
				"surname": "Koyuncu"
			},
			"authorName": "Koyuncu, Anil",
			"articleRefs": [
				{
					"pageNumber": 3957,
					"articleName": "Are We SOLID Yet? An Empirical Study on Prompting LLMs to Detect Design Principle Violations",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d957/573300d957.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Anne",
				"surname": "Koziolek"
			},
			"authorName": "Koziolek, Anne",
			"articleRefs": [
				{
					"pageNumber": 204,
					"articleName": "Explainability in Automated Cross-Domain Model-Driven Brake System Development",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a204/850300a204.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Markus",
				"surname": "Krahl"
			},
			"authorName": "Krahl, Markus",
			"articleRefs": [
				{
					"pageNumber": 145,
					"articleName": "BMuzz: Combining Bounded Model Checking and Fuzzing to Enhance Code Coverage",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a145/850300a145.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Rrezarta",
				"surname": "Krasniqi"
			},
			"authorName": "Krasniqi, Rrezarta",
			"articleRefs": [
				{
					"pageNumber": 2362,
					"articleName": "Polyglot: An Extensible Framework to Benchmark Code Translation with LLMs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c362/573300c362.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Sergei",
				"surname": "Krauze"
			},
			"authorName": "Krauze, Sergei",
			"articleRefs": [
				{
					"pageNumber": 3250,
					"articleName": "Metrics Driven Reengineering and Continuous Code Improvement at Meta",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d250/573300d250.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Felix",
				"surname": "Kretzer"
			},
			"authorName": "Kretzer, Felix",
			"articleRefs": [
				{
					"pageNumber": 4052,
					"articleName": "GUI-ReRank: Enhancing GUI Retrieval with Multi-Modal LLM-Based Reranking",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e052/573300e052.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Sagar",
				"surname": "Krishnamoorthy"
			},
			"authorName": "Krishnamoorthy, Sagar",
			"articleRefs": [
				{
					"pageNumber": 3250,
					"articleName": "Metrics Driven Reengineering and Continuous Code Improvement at Meta",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d250/573300d250.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ranjith",
				"surname": "Krishnamurthy"
			},
			"authorName": "Krishnamurthy, Ranjith",
			"articleRefs": [
				{
					"pageNumber": 194,
					"articleName": "Explaining Software Vulnerabilities with Large Language Models",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a194/850300a194.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Daniel",
				"surname": "Kroening"
			},
			"authorName": "Kroening, Daniel",
			"articleRefs": [
				{
					"pageNumber": 1452,
					"articleName": "VERT: Polyglot Verified Equivalent Rust Transpilation with Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b452/573300b452.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Junhua",
				"surname": "Kuang"
			},
			"authorName": "Kuang, Junhua",
			"articleRefs": [
				{
					"pageNumber": 3497,
					"articleName": "Adaptive Performance Regression Detection Using A Semi-Supervised Siamese Network",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d497/573300d497.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Raula Gaikovina",
				"surname": "Kula"
			},
			"authorName": "Kula, Raula Gaikovina",
			"articleRefs": [
				{
					"pageNumber": 3996,
					"articleName": "PyGress: Tool for Analyzing the Progression of Code Proficiency in Python OSS Projects",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d996/573300d996.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Vinay",
				"surname": "Kulkarni"
			},
			"authorName": "Kulkarni, Vinay",
			"articleRefs": [
				{
					"pageNumber": 14,
					"articleName": "Leveraging LLM for Software Modernization: COBOL Functionality Extraction Case Study",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a014/850300a014.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Aayush",
				"surname": "Kumar"
			},
			"authorName": "Kumar, Aayush",
			"articleRefs": [
				{
					"pageNumber": 432,
					"articleName": "Why AI Agents Still Need You: Findings from Developer-Agent Collaborations in the Wild",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a432/573300a432.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ashish",
				"surname": "Kumar"
			},
			"authorName": "Kumar, Ashish",
			"articleRefs": [
				{
					"pageNumber": 1679,
					"articleName": "Uncovering Discrimination Clusters: Quantifying and Explaining Systematic Fairness Violations",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b679/573300b679.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ashok Pon",
				"surname": "Kumar"
			},
			"authorName": "Kumar, Ashok Pon",
			"articleRefs": [
				{
					"pageNumber": 4097,
					"articleName": "Training-Control-as-Code: Towards a Declarative Solution to Control Training",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e097/573300e097.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Sandeep",
				"surname": "Kumar"
			},
			"authorName": "Kumar, Sandeep",
			"articleRefs": [
				{
					"pageNumber": 4105,
					"articleName": "StackPlagger: A System for Identifying AI-Code Plagiarism on Stack Overflow",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e105/573300e105.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Prateek",
				"surname": "Kumar Rajput"
			},
			"authorName": "Kumar Rajput, Prateek",
			"articleRefs": [
				{
					"pageNumber": 3921,
					"articleName": "Measuring LLM Code Generation Stability via Structural Entropy",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d921/573300d921.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Sriteja",
				"surname": "Kummita"
			},
			"authorName": "Kummita, Sriteja",
			"articleRefs": [
				{
					"pageNumber": 181,
					"articleName": "SeedUI: Understanding Initial Seeds in Fuzzing",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a181/850300a181.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Sergei",
				"surname": "Kurashkin"
			},
			"authorName": "Kurashkin, Sergei",
			"articleRefs": [
				{
					"pageNumber": 229,
					"articleName": "Automated Evolutionary Hyperparameter Tuning for NLP-Based Test Case Generation",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a229/850300a229.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Oka",
				"surname": "Kurniawan"
			},
			"authorName": "Kurniawan, Oka",
			"articleRefs": [
				{
					"pageNumber": 3895,
					"articleName": "Simulated Interactive Debugging",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d895/573300d895.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Hyuk-Je",
				"surname": "Kwon"
			},
			"authorName": "Kwon, Hyuk-Je",
			"articleRefs": [
				{
					"pageNumber": 1552,
					"articleName": "It's Not Easy Being Green: On the Energy Efficiency of Programming Languages",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b552/573300b552.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yonghwi",
				"surname": "Kwon"
			},
			"authorName": "Kwon, Yonghwi",
			"articleRefs": [
				{
					"pageNumber": 1590,
					"articleName": "IMUFUZZER: Resilience-Based Discovery of Signal Injection Attacks on Robotic Aerial Vehicles",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b590/573300b590.pdf"
				},
				{
					"pageNumber": 2956,
					"articleName": "When Does Wasm Malware Detection Fail? A Systematic Analysis of Their Robustness to Evasion",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c956/573300c956.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Sachi",
				"surname": "Lad"
			},
			"authorName": "Lad, Sachi",
			"articleRefs": [
				{
					"pageNumber": 107,
					"articleName": "From Kotlin to Swift and Back: Toward Fully Automated Cross-Language Code Transpilation",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a107/850300a107.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yuanming",
				"surname": "Lai"
			},
			"authorName": "Lai, Yuanming",
			"articleRefs": [
				{
					"pageNumber": 1106,
					"articleName": "BCFuzz: Bytecode-Driven Fuzzing for JavaScript Engines",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b106/573300b106.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Kwok-Yan",
				"surname": "Lam"
			},
			"authorName": "Lam, Kwok-Yan",
			"articleRefs": [
				{
					"pageNumber": 2579,
					"articleName": "WINGMUZZ: Blackbox Testing of IoT Protocols via Two-Dimensional Fuzzing Schedule",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c579/573300c579.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Stefano Carlo",
				"surname": "Lambertenghi"
			},
			"authorName": "Lambertenghi, Stefano Carlo",
			"articleRefs": [
				{
					"pageNumber": 2807,
					"articleName": "A Multi-Modality Evaluation of the Reality Gap in Autonomous Driving Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c807/573300c807.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Mayasah",
				"surname": "Lami"
			},
			"authorName": "Lami, Mayasah",
			"articleRefs": [
				{
					"pageNumber": 3957,
					"articleName": "Are We SOLID Yet? An Empirical Study on Prompting LLMs to Detect Design Principle Violations",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d957/573300d957.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Maxime",
				"surname": "Lamothe"
			},
			"authorName": "Lamothe, Maxime",
			"articleRefs": [
				{
					"pageNumber": 3461,
					"articleName": "From Technical Excellence to Practical Adoption: Lessons Learned Building an ML-Enhanced Trace Analysis Tool",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d461/573300d461.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yuanhong",
				"surname": "Lan"
			},
			"authorName": "Lan, Yuanhong",
			"articleRefs": [
				{
					"pageNumber": 1389,
					"articleName": "NATE: A Network-Aware Testing Enhancer for Network-Related Fault Detection in Android Apps",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b389/573300b389.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zhe",
				"surname": "Lang"
			},
			"authorName": "Lang, Zhe",
			"articleRefs": [
				{
					"pageNumber": 648,
					"articleName": "BinStruct: Binary Structure Recovery Combining Static Analysis and Semantics",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a648/573300a648.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Kevin",
				"surname": "Leach"
			},
			"authorName": "Leach, Kevin",
			"articleRefs": [
				{
					"pageNumber": 3870,
					"articleName": "CodeACT-R: A Cognitive Simulation Framework for Human Attention in Code Reading",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d870/573300d870.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Eunseok",
				"surname": "Lee"
			},
			"authorName": "Lee, Eunseok",
			"articleRefs": [
				{
					"pageNumber": 3070,
					"articleName": "Amur: Fixing Multi-Resource Leaks Guided by Resource Flow Analysis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d070/573300d070.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Heejo",
				"surname": "Lee"
			},
			"authorName": "Lee, Heejo",
			"articleRefs": [
				{
					"pageNumber": 1590,
					"articleName": "IMUFUZZER: Resilience-Based Discovery of Signal Injection Attacks on Robotic Aerial Vehicles",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b590/573300b590.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Hyeonmin",
				"surname": "Lee"
			},
			"authorName": "Lee, Hyeonmin",
			"articleRefs": [
				{
					"pageNumber": 1233,
					"articleName": "RFCScope: Detecting Logical Ambiguities in Internet Protocol Specifications",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b233/573300b233.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Kanguk",
				"surname": "Lee"
			},
			"authorName": "Lee, Kanguk",
			"articleRefs": [
				{
					"pageNumber": 2464,
					"articleName": "Exact Inference for Quantum Circuits: A Testing Oracle for Quantum Software Stacks",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c464/573300c464.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Kiho",
				"surname": "Lee"
			},
			"authorName": "Lee, Kiho",
			"articleRefs": [
				{
					"pageNumber": 2956,
					"articleName": "When Does Wasm Malware Detection Fail? A Systematic Analysis of Their Robustness to Evasion",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c956/573300c956.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Sang In",
				"surname": "Lee"
			},
			"authorName": "Lee, Sang In",
			"articleRefs": [
				{
					"pageNumber": 3865,
					"articleName": "Unseen Data Detection using Routing Entropy in Mixture-of-Experts for Autonomous Vehicles",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d865/573300d865.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Seonah",
				"surname": "Lee"
			},
			"authorName": "Lee, Seonah",
			"articleRefs": [
				{
					"pageNumber": 269,
					"articleName": "Explainable AI for Issue Classification: A Multi-Class Study with LIME and SHAP",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a269/850300a269.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Shin-Jie",
				"surname": "Lee"
			},
			"authorName": "Lee, Shin-Jie",
			"articleRefs": [
				{
					"pageNumber": 161,
					"articleName": "MicroViSim: Simulation and Visualization of Kubernetes-Based Microservice Systems",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a161/850300a161.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Wen-Tin",
				"surname": "Lee"
			},
			"authorName": "Lee, Wen-Tin",
			"articleRefs": [
				{
					"pageNumber": 161,
					"articleName": "MicroViSim: Simulation and Visualization of Kubernetes-Based Microservice Systems",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a161/850300a161.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Claire",
				"surname": "Le Goues"
			},
			"authorName": "Le Goues, Claire",
			"articleRefs": [
				{
					"pageNumber": 2020,
					"articleName": "Interpretable Vulnerability Detection Reports",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c020/573300c020.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Owolabi",
				"surname": "Legunsen"
			},
			"authorName": "Legunsen, Owolabi",
			"articleRefs": [
				{
					"pageNumber": 2285,
					"articleName": "Faster Runtime Verification During Testing via Feedback-Guided Selective Monitoring",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c285/573300c285.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Daniel",
				"surname": "Lehmann"
			},
			"authorName": "Lehmann, Daniel",
			"articleRefs": [
				{
					"pageNumber": 816,
					"articleName": "Execution-Aware Program Reduction for WebAssembly via Record and Replay",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a816/573300a816.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yan",
				"surname": "Lei"
			},
			"authorName": "Lei, Yan",
			"articleRefs": [
				{
					"pageNumber": 406,
					"articleName": "From Sparse to Structured: A Diffusion-Enhanced and Feature-Aligned Framework for Coincidental Correctness Detection",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a406/573300a406.pdf"
				},
				{
					"pageNumber": 1502,
					"articleName": "Sifting Truth from Coincidences: A Two-Stage Positive and Unlabeled Learning Model for Coincidental Correctness Detection",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b502/573300b502.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Arthur",
				"surname": "Leung"
			},
			"authorName": "Leung, Arthur",
			"articleRefs": [
				{
					"pageNumber": 2324,
					"articleName": "SPICE\uD83C\uDF36\uFE0F: An Automated SWE-Bench Labeling Pipeline for Issue Clarity, Test Coverage, and Effort Estimation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c324/573300c324.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Daniel",
				"surname": "Levin"
			},
			"authorName": "Levin, Daniel",
			"articleRefs": [
				{
					"pageNumber": 3870,
					"articleName": "CodeACT-R: A Cognitive Simulation Framework for Human Attention in Code Reading",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d870/573300d870.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Georgii",
				"surname": "Levtsov"
			},
			"authorName": "Levtsov, Georgii",
			"articleRefs": [
				{
					"pageNumber": 358,
					"articleName": "Challenge on Optimization of Context Collection for Code Completion",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a358/850300a358.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Binhua",
				"surname": "Li"
			},
			"authorName": "Li, Binhua",
			"articleRefs": [
				{
					"pageNumber": 3729,
					"articleName": "Thinking Longer, Not Larger: Enhancing Software Engineering Agents via Scaling Test-Time Compute",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d729/573300d729.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Chengpeng",
				"surname": "Li"
			},
			"authorName": "Li, Chengpeng",
			"articleRefs": [
				{
					"pageNumber": 2157,
					"articleName": "FlakyGuard: Automatically Fixing Flaky Tests at Industry Scale",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c157/573300c157.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Cong",
				"surname": "Li"
			},
			"authorName": "Li, Cong",
			"articleRefs": [
				{
					"pageNumber": 469,
					"articleName": "Comprehend, Imitate, and then Update: Unleashing the Power of LLMs in Test Suite Evolution",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a469/573300a469.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Dawei",
				"surname": "Li"
			},
			"authorName": "Li, Dawei",
			"articleRefs": [
				{
					"pageNumber": 1806,
					"articleName": "ARG: Testing Query Rewriters via Abstract Rule Guided Fuzzing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b806/573300b806.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Fan",
				"surname": "Li"
			},
			"authorName": "Li, Fan",
			"articleRefs": [
				{
					"pageNumber": 2057,
					"articleName": "FirmProj: Detecting Firmware Leakage in IoT Update Processes via Companion App Analysis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c057/573300c057.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Feng",
				"surname": "Li"
			},
			"authorName": "Li, Feng",
			"articleRefs": [
				{
					"pageNumber": 2681,
					"articleName": "Understanding Resource Injection Vulnerabilities in Kubernetes Ecosystems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c681/573300c681.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Gangyang",
				"surname": "Li"
			},
			"authorName": "Li, Gangyang",
			"articleRefs": [
				{
					"pageNumber": 841,
					"articleName": "PseudoFix: Refactoring Distorted Structures in Decompiled C Pseudocode",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a841/573300a841.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ge",
				"surname": "Li"
			},
			"authorName": "Li, Ge",
			"articleRefs": [
				{
					"pageNumber": 1476,
					"articleName": "Aligning LLMs to Fully Utilize the Cross-File Context in Repository-Level Code Completion",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b476/573300b476.pdf"
				},
				{
					"pageNumber": 1918,
					"articleName": "SemGuard: Real-Time Semantic Evaluator for Correcting LLM-Generated Code",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b918/573300b918.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Guoyuan",
				"surname": "Li"
			},
			"authorName": "Li, Guoyuan",
			"articleRefs": [
				{
					"pageNumber": 3402,
					"articleName": "Out of Distribution Detection in Self-Adaptive Robots with AI-Powered Digital Twins",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d402/573300d402.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Haonan",
				"surname": "Li"
			},
			"authorName": "Li, Haonan",
			"articleRefs": [
				{
					"pageNumber": 380,
					"articleName": "Towards More Accurate Static Analysis for Taint-Style Bug Detection in Linux Kernel",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a380/573300a380.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Heng",
				"surname": "Li"
			},
			"authorName": "Li, Heng",
			"articleRefs": [
				{
					"pageNumber": 3461,
					"articleName": "From Technical Excellence to Practical Adoption: Lessons Learned Building an ML-Enhanced Trace Analysis Tool",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d461/573300d461.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Hong",
				"surname": "Li"
			},
			"authorName": "Li, Hong",
			"articleRefs": [
				{
					"pageNumber": 919,
					"articleName": "Lares: LLM-Driven Code Slice Semantic Search for Patch Presence Testing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a919/573300a919.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Hui",
				"surname": "Li"
			},
			"authorName": "Li, Hui",
			"articleRefs": [
				{
					"pageNumber": 2771,
					"articleName": "Root Cause Analysis of RISC-V Build Failures via LLM and MCTS Reasoning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c771/573300c771.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jia",
				"surname": "Li"
			},
			"authorName": "Li, Jia",
			"articleRefs": [
				{
					"pageNumber": 2298,
					"articleName": "FastCoder: Accelerating Repository-Level Code Generation via Efficient Retrieval and Verification",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c298/573300c298.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jiajun",
				"surname": "Li"
			},
			"authorName": "Li, Jiajun",
			"articleRefs": [
				{
					"pageNumber": 2782,
					"articleName": "Understanding Feature Request Practice on GitHub via a Large-Scale Empirical Study",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c782/573300c782.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jialong",
				"surname": "Li"
			},
			"authorName": "Li, Jialong",
			"articleRefs": [
				{
					"pageNumber": 237,
					"articleName": "Towards MPC-Driven Software Adaptation: A Dual-Layer Approach Combining ICNN-Based Modeling and Delta-Based Tuning",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a237/850300a237.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jianmin",
				"surname": "Li"
			},
			"authorName": "Li, Jianmin",
			"articleRefs": [
				{
					"pageNumber": 3250,
					"articleName": "Metrics Driven Reengineering and Continuous Code Improvement at Meta",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d250/573300d250.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jianwen",
				"surname": "Li"
			},
			"authorName": "Li, Jianwen",
			"articleRefs": [
				{
					"pageNumber": 129,
					"articleName": "Diagnosing Performance Differences in Model Checkers via Runtime-Guided Problem Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a129/573300a129.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jiapeng",
				"surname": "Li"
			},
			"authorName": "Li, Jiapeng",
			"articleRefs": [
				{
					"pageNumber": 4085,
					"articleName": "Metamorphic Testing of Deep Reinforcement Learning Agents with MDPMORPH",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e085/573300e085.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jiliang",
				"surname": "Li"
			},
			"authorName": "Li, Jiliang",
			"articleRefs": [
				{
					"pageNumber": 1044,
					"articleName": "PROMFUZZ: Leveraging LLM-Driven and Bug-Oriented Composite Analysis for Detecting Functional Bugs in Smart Contracts",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b044/573300b044.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jinku",
				"surname": "Li"
			},
			"authorName": "Li, Jinku",
			"articleRefs": [
				{
					"pageNumber": 791,
					"articleName": "Hit The Bullseye On The First Shot: Improving LLMs Using Multi-Sample Self-Reward Feedback for Vulnerability Repair",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a791/573300a791.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jun",
				"surname": "Li"
			},
			"authorName": "Li, Jun",
			"articleRefs": [
				{
					"pageNumber": 228,
					"articleName": "RELIA: Accelerating the Analysis of Cloud Access Control Policies",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a228/573300a228.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Kaixuan",
				"surname": "Li"
			},
			"authorName": "Li, Kaixuan",
			"articleRefs": [
				{
					"pageNumber": 52,
					"articleName": "Learning from the Past: Real-World Exploit Migration for Smart Contract PoC Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a052/573300a052.pdf"
				},
				{
					"pageNumber": 104,
					"articleName": "FAULTSEEKER: LLM-Empowered Framework for Blockchain Transaction Fault Localization",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a104/573300a104.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Keyang",
				"surname": "Li"
			},
			"authorName": "Li, Keyang",
			"articleRefs": [
				{
					"pageNumber": 1142,
					"articleName": "Hypergraph Neural Network-Based Multi-Granular Root Cause Localization for Microservice Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b142/573300b142.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Li",
				"surname": "Li"
			},
			"authorName": "Li, Li",
			"articleRefs": [
				{
					"pageNumber": 1743,
					"articleName": "CROSS2OH: Enabling Seamless Porting of C/C++ Software Libraries to OpenHarmony",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b743/573300b743.pdf"
				},
				{
					"pageNumber": 2439,
					"articleName": "Token Sugar: Making Source Code Sweeter for LLMs Through Token-Efficient Shorthand",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c439/573300c439.pdf"
				},
				{
					"pageNumber": 3167,
					"articleName": "HarmoBridge: Bridging ArkTS and C/C++ for Cross-Language Static Analysis on HarmonyOS",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d167/573300d167.pdf"
				},
				{
					"pageNumber": 3261,
					"articleName": "Context-Sensitive Pointer Analysis for ArkTS",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d261/573300d261.pdf"
				},
				{
					"pageNumber": 3321,
					"articleName": "An Empirical Study on UI Overlap in OpenHarmony Applications",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d321/573300d321.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Linhan",
				"surname": "Li"
			},
			"authorName": "Li, Linhan",
			"articleRefs": [
				{
					"pageNumber": 1350,
					"articleName": "Destabilizing Neurons to Generate Challenging Neural Network Verification Benchmarks",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b350/573300b350.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Mengyao",
				"surname": "Li"
			},
			"authorName": "Li, Mengyao",
			"articleRefs": [
				{
					"pageNumber": 3497,
					"articleName": "Adaptive Performance Regression Detection Using A Semi-Supervised Siamese Network",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d497/573300d497.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Minxiao",
				"surname": "Li"
			},
			"authorName": "Li, Minxiao",
			"articleRefs": [
				{
					"pageNumber": 2618,
					"articleName": "EfficientEdit: Accelerating Code Editing via Edit-Oriented Speculative Decoding",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c618/573300c618.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Nianyu",
				"surname": "Li"
			},
			"authorName": "Li, Nianyu",
			"articleRefs": [
				{
					"pageNumber": 237,
					"articleName": "Towards MPC-Driven Software Adaptation: A Dual-Layer Approach Combining ICNN-Based Modeling and Delta-Based Tuning",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a237/850300a237.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "O Jia",
				"surname": "Li"
			},
			"authorName": "Li, O Jia",
			"articleRefs": [
				{
					"pageNumber": 1476,
					"articleName": "Aligning LLMs to Fully Utilize the Cross-File Context in Repository-Level Code Completion",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b476/573300b476.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Qingshan",
				"surname": "Li"
			},
			"authorName": "Li, Qingshan",
			"articleRefs": [
				{
					"pageNumber": 1142,
					"articleName": "Hypergraph Neural Network-Based Multi-Granular Root Cause Localization for Microservice Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b142/573300b142.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ruipeng",
				"surname": "Li"
			},
			"authorName": "Li, Ruipeng",
			"articleRefs": [
				{
					"pageNumber": 1,
					"articleName": "AlertGuardian: Intelligent Alert Life-Cycle Management for Large-Scale Cloud Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a001/573300a001.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Shanping",
				"surname": "Li"
			},
			"authorName": "Li, Shanping",
			"articleRefs": [
				{
					"pageNumber": 91,
					"articleName": "When AllClose Fails: Round-Off Error Estimation for Deep Learning Programs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a091/573300a091.pdf"
				},
				{
					"pageNumber": 1337,
					"articleName": "FGIT: Fault-Guided Fine-Tuning for Code Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b337/573300b337.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Shuqing",
				"surname": "Li"
			},
			"authorName": "Li, Shuqing",
			"articleRefs": [
				{
					"pageNumber": 2905,
					"articleName": "Metamorphic Testing for Audio Content Moderation Software",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c905/573300c905.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Siyuan",
				"surname": "Li"
			},
			"authorName": "Li, Siyuan",
			"articleRefs": [
				{
					"pageNumber": 919,
					"articleName": "Lares: LLM-Driven Code Slice Semantic Search for Patch Presence Testing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a919/573300a919.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Tingting",
				"surname": "Li"
			},
			"authorName": "Li, Tingting",
			"articleRefs": [
				{
					"pageNumber": 2630,
					"articleName": "AutoFid: Adaptive and Noise-Aware Fidelity Measurement for Quantum Programs via Circuit Graph Analysis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c630/573300c630.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Tsz-On",
				"surname": "Li"
			},
			"authorName": "Li, Tsz-On",
			"articleRefs": [
				{
					"pageNumber": 1743,
					"articleName": "CROSS2OH: Enabling Seamless Porting of C/C++ Software Libraries to OpenHarmony",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b743/573300b743.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Wei",
				"surname": "Li"
			},
			"authorName": "Li, Wei",
			"articleRefs": [
				{
					"pageNumber": 1528,
					"articleName": "Finding Insecure State Dependency in DApps via Multi-Source Tracing and Semantic Enrichment",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b528/573300b528.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Wenzhi",
				"surname": "Li"
			},
			"authorName": "Li, Wenzhi",
			"articleRefs": [
				{
					"pageNumber": 2057,
					"articleName": "FirmProj: Detecting Firmware Leakage in IoT Update Processes via Companion App Analysis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c057/573300c057.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xiaofeng",
				"surname": "Li"
			},
			"authorName": "Li, Xiaofeng",
			"articleRefs": [
				{
					"pageNumber": 3521,
					"articleName": "Evaluating Large Language Models for Time Series Anomaly Detection in Aerospace Software",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d521/573300d521.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xiaoyu",
				"surname": "Li"
			},
			"authorName": "Li, Xiaoyu",
			"articleRefs": [
				{
					"pageNumber": 419,
					"articleName": "ProfMal: Detecting Malicious NPM Packages by the Synergy between Static and Dynamic Analysis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a419/573300a419.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xinlei",
				"surname": "Li"
			},
			"authorName": "Li, Xinlei",
			"articleRefs": [
				{
					"pageNumber": 4024,
					"articleName": "DeepTx: Real-Time Transaction Risk Analysis via Multi-Modal Features and LLM Reasoning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e024/573300e024.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xinrui",
				"surname": "Li"
			},
			"authorName": "Li, Xinrui",
			"articleRefs": [
				{
					"pageNumber": 623,
					"articleName": "Enhancing LLM's Ability to Generate More Repository-Aware Unit Tests Through Precise Context Injection",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a623/573300a623.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xinyue",
				"surname": "Li"
			},
			"authorName": "Li, Xinyue",
			"articleRefs": [
				{
					"pageNumber": 1142,
					"articleName": "Hypergraph Neural Network-Based Multi-Granular Root Cause Localization for Microservice Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b142/573300b142.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xuandong",
				"surname": "Li"
			},
			"authorName": "Li, Xuandong",
			"articleRefs": [
				{
					"pageNumber": 1389,
					"articleName": "NATE: A Network-Aware Testing Enhancer for Network-Related Fault Detection in Android Apps",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b389/573300b389.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xuyang",
				"surname": "Li"
			},
			"authorName": "Li, Xuyang",
			"articleRefs": [
				{
					"pageNumber": 1142,
					"articleName": "Hypergraph Neural Network-Based Multi-Granular Root Cause Localization for Microservice Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b142/573300b142.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yanhao",
				"surname": "Li"
			},
			"authorName": "Li, Yanhao",
			"articleRefs": [
				{
					"pageNumber": 3729,
					"articleName": "Thinking Longer, Not Larger: Enhancing Software Engineering Agents via Scaling Test-Time Compute",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d729/573300d729.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yaxiao",
				"surname": "Li"
			},
			"authorName": "Li, Yaxiao",
			"articleRefs": [
				{
					"pageNumber": 1142,
					"articleName": "Hypergraph Neural Network-Based Multi-Granular Root Cause Localization for Microservice Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b142/573300b142.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yeting",
				"surname": "Li"
			},
			"authorName": "Li, Yeting",
			"articleRefs": [
				{
					"pageNumber": 1069,
					"articleName": "A Large Scale Study of AI-Based Binary Function Similarity Detection Techniques for Security Researchers and Practitioners",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b069/573300b069.pdf"
				},
				{
					"pageNumber": 2681,
					"articleName": "Understanding Resource Injection Vulnerabilities in Kubernetes Ecosystems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c681/573300c681.pdf"
				},
				{
					"pageNumber": 2969,
					"articleName": "Vulnerability-Affected Versions Identification: How Far Are We?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c969/573300c969.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yi",
				"surname": "Li"
			},
			"authorName": "Li, Yi",
			"articleRefs": [
				{
					"pageNumber": 254,
					"articleName": "Defects4C: Benchmarking Large Language Model Repair Capability with C/C++ Bugs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a254/573300a254.pdf"
				},
				{
					"pageNumber": 304,
					"articleName": "Advancing Binary Code Similarity Detection via Context-Content Fusion and LLM Verification",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a304/573300a304.pdf"
				},
				{
					"pageNumber": 1780,
					"articleName": "Detecting Various DeFi Price Manipulations with LLM Reasoning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b780/573300b780.pdf"
				},
				{
					"pageNumber": 3298,
					"articleName": "LogPilot: Intent-Aware and Scalable Alert Diagnosis for Large-Scale Online Service Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d298/573300d298.pdf"
				},
				{
					"pageNumber": 3425,
					"articleName": "Automated Proactive Logging Quality Improvement for Large-Scale Codebases ",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d425/573300d425.pdf"
				},
				{
					"pageNumber": 4024,
					"articleName": "DeepTx: Real-Time Transaction Risk Analysis via Multi-Modal Features and LLM Reasoning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e024/573300e024.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yichen",
				"surname": "Li"
			},
			"authorName": "Li, Yichen",
			"articleRefs": [
				{
					"pageNumber": 3298,
					"articleName": "LogPilot: Intent-Aware and Scalable Alert Diagnosis for Large-Scale Online Service Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d298/573300d298.pdf"
				},
				{
					"pageNumber": 3425,
					"articleName": "Automated Proactive Logging Quality Improvement for Large-Scale Codebases ",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d425/573300d425.pdf"
				},
				{
					"pageNumber": 3533,
					"articleName": "ErrorPrism: Reconstructing Error Propagation Paths in Cloud Service Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d533/573300d533.pdf"
				},
				{
					"pageNumber": 3855,
					"articleName": "Exploring Autonomous Agents: A Closer Look at Why They Fail When Completing Tasks",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d855/573300d855.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ying",
				"surname": "Li"
			},
			"authorName": "Li, Ying",
			"articleRefs": [
				{
					"pageNumber": 661,
					"articleName": "United We Stand: Towards End-to-End Log-Based Fault Diagnosis via Interactive Multi-Task Learning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a661/573300a661.pdf"
				},
				{
					"pageNumber": 700,
					"articleName": "LogAction: Consistent Cross-System Anomaly Detection Through Logs via Active Domain Adaptation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a700/573300a700.pdf"
				},
				{
					"pageNumber": 1118,
					"articleName": "CoorLog: Efficient-Generalizable Log Anomaly Detection via Adaptive Coordinator in Software Evolution",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b118/573300b118.pdf"
				},
				{
					"pageNumber": 3783,
					"articleName": "Walk the Talk: Is Your Log-Based Software Reliability Maintenance System Really Reliable?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d783/573300d783.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yong",
				"surname": "Li"
			},
			"authorName": "Li, Yong",
			"articleRefs": [
				{
					"pageNumber": 1830,
					"articleName": "PEACE: Towards Efficient Project-Level Efficiency Optimization via Hybrid Code Editing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b830/573300b830.pdf"
				},
				{
					"pageNumber": 3033,
					"articleName": "Issue Localization via LLM-Driven Iterative Code Graph Searching",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d033/573300d033.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yongbin",
				"surname": "Li"
			},
			"authorName": "Li, Yongbin",
			"articleRefs": [
				{
					"pageNumber": 3729,
					"articleName": "Thinking Longer, Not Larger: Enhancing Software Engineering Agents via Scaling Test-Time Compute",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d729/573300d729.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yuanpeng",
				"surname": "Li"
			},
			"authorName": "Li, Yuanpeng",
			"articleRefs": [
				{
					"pageNumber": 3485,
					"articleName": "BitsAI-Fix: LLM-Driven Approach for Automated Lint Error Resolution in Practice",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d485/573300d485.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yuanyi",
				"surname": "Li"
			},
			"authorName": "Li, Yuanyi",
			"articleRefs": [
				{
					"pageNumber": 765,
					"articleName": "DualFuzz: Detecting Vulnerability in Wi-Fi NICs through Dual-Directional Fuzzing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a765/573300a765.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yue",
				"surname": "Li"
			},
			"authorName": "Li, Yue",
			"articleRefs": [
				{
					"pageNumber": 597,
					"articleName": "Automatic Fixing of Missing Dependency Errors",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a597/573300a597.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yuekang",
				"surname": "Li"
			},
			"authorName": "Li, Yuekang",
			"articleRefs": [
				{
					"pageNumber": 1069,
					"articleName": "A Large Scale Study of AI-Based Binary Function Similarity Detection Techniques for Security Researchers and Practitioners",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b069/573300b069.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ze",
				"surname": "Li"
			},
			"authorName": "Li, Ze",
			"articleRefs": [
				{
					"pageNumber": 674,
					"articleName": "Triangle: Empowering Incident Triage with Multi-Agent",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a674/573300a674.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zehao",
				"surname": "Li"
			},
			"authorName": "Li, Zehao",
			"articleRefs": [
				{
					"pageNumber": 2311,
					"articleName": "Effective Code Membership Inference for Code Completion Models via Adversarial Prompts",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c311/573300c311.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zhenhao",
				"surname": "Li"
			},
			"authorName": "Li, Zhenhao",
			"articleRefs": [
				{
					"pageNumber": 1930,
					"articleName": "Defects4Log: Benchmarking LLMs for Logging Code Defect Detection and Reasoning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b930/573300b930.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zhenhua",
				"surname": "Li"
			},
			"authorName": "Li, Zhenhua",
			"articleRefs": [
				{
					"pageNumber": 393,
					"articleName": "Democratizing the Cryptocurrency Ecosystem by Just-In-Time Transformation of Mining Programs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a393/573300a393.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zhihao",
				"surname": "Li"
			},
			"authorName": "Li, Zhihao",
			"articleRefs": [
				{
					"pageNumber": 3132,
					"articleName": "JSidentify-V2: Leveraging Dynamic Memory Fingerprinting for Mini-Game Plagiarism Detection",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d132/573300d132.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ziyou",
				"surname": "Li"
			},
			"authorName": "Li, Ziyou",
			"articleRefs": [
				{
					"pageNumber": 3345,
					"articleName": "Prompt-With-Me: in-IDE Structured Prompt Management for LLM-Driven Software Engineering",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d345/573300d345.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zongjie",
				"surname": "Li"
			},
			"authorName": "Li, Zongjie",
			"articleRefs": [
				{
					"pageNumber": 3132,
					"articleName": "JSidentify-V2: Leveraging Dynamic Memory Fingerprinting for Mini-Game Plagiarism Detection",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d132/573300d132.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Keke",
				"surname": "Lian"
			},
			"authorName": "Lian, Keke",
			"articleRefs": [
				{
					"pageNumber": 932,
					"articleName": "Exploring Static Taint Analysis in LLMs: A Dynamic Benchmarking Framework for Measurement and Enhancement",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a932/573300a932.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xiaoli",
				"surname": "Lian"
			},
			"authorName": "Lian, Xiaoli",
			"articleRefs": [
				{
					"pageNumber": 2298,
					"articleName": "FastCoder: Accelerating Repository-Level Code Generation via Efficient Retrieval and Verification",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c298/573300c298.pdf"
				},
				{
					"pageNumber": 2618,
					"articleName": "EfficientEdit: Accelerating Code Editing via Edit-Oriented Speculative Decoding",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c618/573300c618.pdf"
				},
				{
					"pageNumber": 3592,
					"articleName": "AutoPLC: Generating Vendor-Aware Structured Text for Programmable Logic Controllers",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d592/573300d592.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jie",
				"surname": "Liang"
			},
			"authorName": "Liang, Jie",
			"articleRefs": [
				{
					"pageNumber": 1806,
					"articleName": "ARG: Testing Query Rewriters via Abstract Rule Guided Fuzzing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b806/573300b806.pdf"
				},
				{
					"pageNumber": 3813,
					"articleName": "LLM-Based Dynamic Differential Testing for Database Connectors with Reinforcement Learning-Guided Prompt Selection",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d813/573300d813.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jingjing",
				"surname": "Liang"
			},
			"authorName": "Liang, Jingjing",
			"articleRefs": [
				{
					"pageNumber": 636,
					"articleName": "Finding Bugs in MLIR Compiler Infrastructure via Lowering Space Exploration",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a636/573300a636.pdf"
				},
				{
					"pageNumber": 2375,
					"articleName": "Interleaved Learning and Exploration: A Self-Adaptive Fuzz Testing Framework for MLIR",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c375/573300c375.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ming",
				"surname": "Liang"
			},
			"authorName": "Liang, Ming",
			"articleRefs": [
				{
					"pageNumber": 1830,
					"articleName": "PEACE: Towards Efficient Project-Level Efficiency Optimization via Hybrid Code Editing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b830/573300b830.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Qi",
				"surname": "Liang"
			},
			"authorName": "Liang, Qi",
			"articleRefs": [
				{
					"pageNumber": 117,
					"articleName": "SateLight: A Satellite Application Update Framework for Satellite Computing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a117/573300a117.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xiao",
				"surname": "Liang"
			},
			"authorName": "Liang, Xiao",
			"articleRefs": [
				{
					"pageNumber": 1207,
					"articleName": "Bridging Natural Language and Formal Specification Automated Translation of Software Requirements to LTL via Hierarchical Semantics Decomposition Using LLMs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b207/573300b207.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zhenkai",
				"surname": "Liang"
			},
			"authorName": "Liang, Zhenkai",
			"articleRefs": [
				{
					"pageNumber": 65,
					"articleName": "Propagation-Based Vulnerability Impact Assessment for Software Supply Chains",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a065/573300a065.pdf"
				},
				{
					"pageNumber": 726,
					"articleName": "Improving LLM-Based Log Parsing by Learning from Errors in Reasoning Traces",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a726/573300a726.pdf"
				},
				{
					"pageNumber": 1094,
					"articleName": "ZendDiff: Differential Testing of PHP Interpreter",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b094/573300b094.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Dianshu",
				"surname": "Liao"
			},
			"authorName": "Liao, Dianshu",
			"articleRefs": [
				{
					"pageNumber": 687,
					"articleName": "Navigating the Labyrinth: Path-Sensitive Unit Test Generation with Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a687/573300a687.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Lizhi",
				"surname": "Liao"
			},
			"authorName": "Liao, Lizhi",
			"articleRefs": [
				{
					"pageNumber": 3057,
					"articleName": "Who's to Blame? Rethinking the Brittleness of Automated Web GUI Testing from a Pragmatic Perspective",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d057/573300d057.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Qing",
				"surname": "Liao"
			},
			"authorName": "Liao, Qing",
			"articleRefs": [
				{
					"pageNumber": 3604,
					"articleName": "IntelliTopo: An IaC Generation Service for Industrial Network Topology Construction",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d604/573300d604.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zeqin",
				"surname": "Liao"
			},
			"authorName": "Liao, Zeqin",
			"articleRefs": [
				{
					"pageNumber": 482,
					"articleName": "VRExplorer: A Model-Based Approach for Semi-Automated Testing of Virtual Reality Scenes",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a482/573300a482.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Cynthia",
				"surname": "Liem"
			},
			"authorName": "Liem, Cynthia",
			"articleRefs": [
				{
					"pageNumber": 66,
					"articleName": "The Last Dependency Crusade: Solving Python Dependency Conflicts with LLMs",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a066/850300a066.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Oscar",
				"surname": "Lilja"
			},
			"authorName": "Lilja, Oscar",
			"articleRefs": [
				{
					"pageNumber": 58,
					"articleName": "Leveraging Large Language Models for Cybersecurity Risk Assessment \u2014 A Case from Forestry Cyber-Physical Systems",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a058/850300a058.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Bruno",
				"surname": "Lima"
			},
			"authorName": "Lima, Bruno",
			"articleRefs": [
				{
					"pageNumber": 3310,
					"articleName": "Streamlining Acceptance Test Generation for Mobile Applications Through Large Language Models: An Industrial Case Study",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d310/573300d310.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ben",
				"surname": "Limpanukorn"
			},
			"authorName": "Limpanukorn, Ben",
			"articleRefs": [
				{
					"pageNumber": 4044,
					"articleName": "Chrysalis: A Lightweight Logging and Replay Framework for Metamorphic Testing in Python",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e044/573300e044.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Bo",
				"surname": "Lin"
			},
			"authorName": "Lin, Bo",
			"articleRefs": [
				{
					"pageNumber": 804,
					"articleName": "Let the Code Speak: Incorporating Program Dynamic State for Better Method-Level Fault Localization",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a804/573300a804.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Dayi",
				"surname": "Lin"
			},
			"authorName": "Lin, Dayi",
			"articleRefs": [
				{
					"pageNumber": 739,
					"articleName": "Watson: A Cognitive Observability Framework for the Reasoning of LLM-Powered Agents",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a739/573300a739.pdf"
				},
				{
					"pageNumber": 2324,
					"articleName": "SPICE\uD83C\uDF36\uFE0F: An Automated SWE-Bench Labeling Pipeline for Issue Clarity, Test Coverage, and Effort Estimation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c324/573300c324.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Feng",
				"surname": "Lin"
			},
			"authorName": "Lin, Feng",
			"articleRefs": [
				{
					"pageNumber": 3718,
					"articleName": "MobileUPReg: Identifying User-Perceived Performance Regressions in Mobile OS Versions",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d718/573300d718.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Hao",
				"surname": "Lin"
			},
			"authorName": "Lin, Hao",
			"articleRefs": [
				{
					"pageNumber": 393,
					"articleName": "Democratizing the Cryptocurrency Ecosystem by Just-In-Time Transformation of Mining Programs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a393/573300a393.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Hong Yi ",
				"surname": "Lin"
			},
			"authorName": "Lin, Hong Yi",
			"articleRefs": [
				{
					"pageNumber": 3759,
					"articleName": "What Types of Code Review Comments Do Developers Most Frequently Resolve?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d759/573300d759.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Huarui",
				"surname": "Lin"
			},
			"authorName": "Lin, Huarui",
			"articleRefs": [
				{
					"pageNumber": 2554,
					"articleName": "ACTaint: Agent-Based Taint Analysis for Access Control Vulnerabilities in Smart Contracts",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c554/573300c554.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Li",
				"surname": "Lin"
			},
			"authorName": "Lin, Li",
			"articleRefs": [
				{
					"pageNumber": 854,
					"articleName": "DLBENCH: A Comprehensive Benchmark for SQL Translation with Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a854/573300a854.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Qingwei",
				"surname": "Lin"
			},
			"authorName": "Lin, Qingwei",
			"articleRefs": [
				{
					"pageNumber": 674,
					"articleName": "Triangle: Empowering Incident Triage with Multi-Agent",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a674/573300a674.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Weibo",
				"surname": "Lin"
			},
			"authorName": "Lin, Weibo",
			"articleRefs": [
				{
					"pageNumber": 228,
					"articleName": "RELIA: Accelerating the Analysis of Cloud Access Control Policies",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a228/573300a228.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Wei-Kai",
				"surname": "Lin"
			},
			"authorName": "Lin, Wei-Kai",
			"articleRefs": [
				{
					"pageNumber": 161,
					"articleName": "MicroViSim: Simulation and Visualization of Kubernetes-Based Microservice Systems",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a161/850300a161.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xingshuang",
				"surname": "Lin"
			},
			"authorName": "Lin, Xingshuang",
			"articleRefs": [
				{
					"pageNumber": 1044,
					"articleName": "PROMFUZZ: Leveraging LLM-Driven and Bug-Oriented Composite Analysis for Detecting Functional Bugs in Smart Contracts",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b044/573300b044.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yuanyi",
				"surname": "Lin"
			},
			"authorName": "Lin, Yuanyi",
			"articleRefs": [
				{
					"pageNumber": 91,
					"articleName": "When AllClose Fails: Round-Off Error Estimation for Deep Learning Programs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a091/573300a091.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yun",
				"surname": "Lin"
			},
			"authorName": "Lin, Yun",
			"articleRefs": [
				{
					"pageNumber": 1376,
					"articleName": "Learning Project-Wise Subsequent Code Edits via Interleaving Neural-Based Induction and Tool-Based Deduction",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b376/573300b376.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zewei",
				"surname": "Lin"
			},
			"authorName": "Lin, Zewei",
			"articleRefs": [
				{
					"pageNumber": 571,
					"articleName": "SSR: Safeguarding Staking Rewards by Defining and Detecting Logical Defects in DeFi Staking",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a571/573300a571.pdf"
				},
				{
					"pageNumber": 1528,
					"articleName": "Finding Insecure State Dependency in DApps via Multi-Source Tracing and Semantic Enrichment",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b528/573300b528.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zhiwei",
				"surname": "Lin"
			},
			"authorName": "Lin, Zhiwei",
			"articleRefs": [
				{
					"pageNumber": 65,
					"articleName": "Propagation-Based Vulnerability Impact Assessment for Software Supply Chains",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a065/573300a065.pdf"
				},
				{
					"pageNumber": 3984,
					"articleName": "A Large-Scale Evolvable Dataset for Model Context Protocol Ecosystem and Security Analysis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d984/573300d984.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zirui",
				"surname": "Lin"
			},
			"authorName": "Lin, Zirui",
			"articleRefs": [
				{
					"pageNumber": 26,
					"articleName": "Vul-R2: A Reasoning LLM for Automated Vulnerability Repair",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a026/573300a026.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Peihong",
				"surname": " Lin"
			},
			"authorName": "Lin, Peihong",
			"articleRefs": [
				{
					"pageNumber": 713,
					"articleName": "When Control Flows Deviate: Directed Grey-box Fuzzing with Probabilistic Reachability Analysis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a713/573300a713.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Martina",
				"surname": "Lindorfer"
			},
			"authorName": "Lindorfer, Martina",
			"articleRefs": [
				{
					"pageNumber": 906,
					"articleName": "Profile Coverage: Using Android Compilation Profiles to Evaluate Dynamic Testing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a906/573300a906.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xiang",
				"surname": "Ling"
			},
			"authorName": "Ling, Xiang",
			"articleRefs": [
				{
					"pageNumber": 3556,
					"articleName": "Shrunk, Yet Complete: Code Shrinking-Resilient Android Third-Party Library Detection",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d556/573300d556.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Marian",
				"surname": "Lingsch-Rosenfeld"
			},
			"authorName": "Lingsch-Rosenfeld, Marian",
			"articleRefs": [
				{
					"pageNumber": 1968,
					"articleName": "Non-Termination Witnesses and Their Validation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b968/573300b968.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Bohan",
				"surname": "Liu"
			},
			"authorName": "Liu, Bohan",
			"articleRefs": [
				{
					"pageNumber": 3706,
					"articleName": "Securing Self-Managed Third-Party Libraries",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d706/573300d706.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Changjian",
				"surname": "Liu"
			},
			"authorName": "Liu, Changjian",
			"articleRefs": [
				{
					"pageNumber": 3156,
					"articleName": "Industry Practice of LLM-Assisted Protocol Fuzzing for Commercial Communication Modules",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d156/573300d156.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Changming",
				"surname": "Liu"
			},
			"authorName": "Liu, Changming",
			"articleRefs": [
				{
					"pageNumber": 2567,
					"articleName": "DRIFT: Debug-Based Trace Inference for Firmware Testing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c567/573300c567.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Chanjuan",
				"surname": "Liu"
			},
			"authorName": "Liu, Chanjuan",
			"articleRefs": [
				{
					"pageNumber": 1272,
					"articleName": "SMTgazer: Learning to Schedule SMT Algorithms via Bayesian Optimization",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b272/573300b272.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Chengwei",
				"surname": "Liu"
			},
			"authorName": "Liu, Chengwei",
			"articleRefs": [
				{
					"pageNumber": 95,
					"articleName": "DroidNative: A Greedy-Constructed Large-Scale Indexing for Android Native Libraries",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a095/850300a095.pdf"
				},
				{
					"pageNumber": 648,
					"articleName": "BinStruct: Binary Structure Recovery Combining Static Analysis and Semantics",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a648/573300a648.pdf"
				},
				{
					"pageNumber": 2969,
					"articleName": "Vulnerability-Affected Versions Identification: How Far Are We?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c969/573300c969.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Chengyue",
				"surname": "Liu"
			},
			"authorName": "Liu, Chengyue",
			"articleRefs": [
				{
					"pageNumber": 648,
					"articleName": "BinStruct: Binary Structure Recovery Combining Static Analysis and Semantics",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a648/573300a648.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Chenyan",
				"surname": "Liu"
			},
			"authorName": "Liu, Chenyan",
			"articleRefs": [
				{
					"pageNumber": 1376,
					"articleName": "Learning Project-Wise Subsequent Code Edits via Interleaving Neural-Based Induction and Tool-Based Deduction",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b376/573300b376.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Chunyan",
				"surname": "Liu"
			},
			"authorName": "Liu, Chunyan",
			"articleRefs": [
				{
					"pageNumber": 406,
					"articleName": "From Sparse to Structured: A Diffusion-Enhanced and Feature-Aligned Framework for Coincidental Correctness Detection",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a406/573300a406.pdf"
				},
				{
					"pageNumber": 1502,
					"articleName": "Sifting Truth from Coincidences: A Two-Stage Positive and Unlabeled Learning Model for Coincidental Correctness Detection",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b502/573300b502.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Fang",
				"surname": "Liu"
			},
			"authorName": "Liu, Fang",
			"articleRefs": [
				{
					"pageNumber": 2007,
					"articleName": "Explainable Fault Localization for Programming Assignments via LLM-Guided Annotation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c007/573300c007.pdf"
				},
				{
					"pageNumber": 2298,
					"articleName": "FastCoder: Accelerating Repository-Level Code Generation via Efficient Retrieval and Verification",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c298/573300c298.pdf"
				},
				{
					"pageNumber": 2618,
					"articleName": "EfficientEdit: Accelerating Code Editing via Edit-Oriented Speculative Decoding",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c618/573300c618.pdf"
				},
				{
					"pageNumber": 3592,
					"articleName": "AutoPLC: Generating Vendor-Aware Structured Text for Programmable Logic Controllers",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d592/573300d592.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Farong",
				"surname": "Liu"
			},
			"authorName": "Liu, Farong",
			"articleRefs": [
				{
					"pageNumber": 3321,
					"articleName": "An Empirical Study on UI Overlap in OpenHarmony Applications",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d321/573300d321.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Gencheng",
				"surname": "Liu"
			},
			"authorName": "Liu, Gencheng",
			"articleRefs": [
				{
					"pageNumber": 2477,
					"articleName": "Evaluating and Improving Framework-Based Parallel Code Completion with Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c477/573300c477.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Han",
				"surname": "Liu"
			},
			"authorName": "Liu, Han",
			"articleRefs": [
				{
					"pageNumber": 945,
					"articleName": "Demystifying OpenZeppelin's Own Vulnerabilities and Analyzing Their Propagation in Smart Contracts",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a945/573300a945.pdf"
				},
				{
					"pageNumber": 1994,
					"articleName": "Have We Solved Access Control Vulnerability Detection in Smart Contracts? A Benchmark Study",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b994/573300b994.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Huai",
				"surname": "Liu"
			},
			"authorName": "Liu, Huai",
			"articleRefs": [
				{
					"pageNumber": 2387,
					"articleName": "FailMapper: Automated Generation of Unit Tests Guided by Failure Scenarios",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c387/573300c387.pdf"
				},
				{
					"pageNumber": 2881,
					"articleName": "DIFFFIX: Incrementally Fixing AST Diffs via Context and Type Information",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c881/573300c881.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Huanyu",
				"surname": "Liu"
			},
			"authorName": "Liu, Huanyu",
			"articleRefs": [
				{
					"pageNumber": 1476,
					"articleName": "Aligning LLMs to Fully Utilize the Cross-File Context in Repository-Level Code Completion",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b476/573300b476.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Hui",
				"surname": "Liu"
			},
			"authorName": "Liu, Hui",
			"articleRefs": [
				{
					"pageNumber": 178,
					"articleName": "Wired for Reuse: Automating Context-Aware Code Adaptation in IDEs via LLM-Based Agent",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a178/573300a178.pdf"
				},
				{
					"pageNumber": 2758,
					"articleName": "LLM-Based Identification of Null Pointer Exception Patches",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c758/573300c758.pdf"
				},
				{
					"pageNumber": 2982,
					"articleName": "LAURA: Enhancing Code Review Generation with Context-Enriched Retrieval-Augmented LLM",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c982/573300c982.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jiachen",
				"surname": "Liu"
			},
			"authorName": "Liu, Jiachen",
			"articleRefs": [
				{
					"pageNumber": 3604,
					"articleName": "IntelliTopo: An IaC Generation Service for Industrial Network Topology Construction",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d604/573300d604.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jiahao",
				"surname": "Liu"
			},
			"authorName": "Liu, Jiahao",
			"articleRefs": [
				{
					"pageNumber": 65,
					"articleName": "Propagation-Based Vulnerability Impact Assessment for Software Supply Chains",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a065/573300a065.pdf"
				},
				{
					"pageNumber": 3984,
					"articleName": "A Large-Scale Evolvable Dataset for Model Context Protocol Ecosystem and Security Analysis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d984/573300d984.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jianhan",
				"surname": "Liu"
			},
			"authorName": "Liu, Jianhan",
			"articleRefs": [
				{
					"pageNumber": 469,
					"articleName": "Comprehend, Imitate, and then Update: Unleashing the Power of LLMs in Test Suite Evolution",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a469/573300a469.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jianzhong",
				"surname": "Liu"
			},
			"authorName": "Liu, Jianzhong",
			"articleRefs": [
				{
					"pageNumber": 3226,
					"articleName": "TRON: Fuzzing Linux Network Stack via Protocol-System Call Payload Synthesis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d226/573300d226.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jiayang",
				"surname": "Liu"
			},
			"authorName": "Liu, Jiayang",
			"articleRefs": [
				{
					"pageNumber": 3179,
					"articleName": "ApkArmor: Low-Cost Lightweight Anti-Decompilation Techniques for Android Apps",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d179/573300d179.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jie",
				"surname": "Liu"
			},
			"authorName": "Liu, Jie",
			"articleRefs": [
				{
					"pageNumber": 2477,
					"articleName": "Evaluating and Improving Framework-Based Parallel Code Completion with Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c477/573300c477.pdf"
				},
				{
					"pageNumber": 2771,
					"articleName": "Root Cause Analysis of RISC-V Build Failures via LLM and MCTS Reasoning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c771/573300c771.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jinyang",
				"surname": "Liu"
			},
			"authorName": "Liu, Jinyang",
			"articleRefs": [
				{
					"pageNumber": 3298,
					"articleName": "LogPilot: Intent-Aware and Scalable Alert Diagnosis for Large-Scale Online Service Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d298/573300d298.pdf"
				},
				{
					"pageNumber": 3425,
					"articleName": "Automated Proactive Logging Quality Improvement for Large-Scale Codebases ",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d425/573300d425.pdf"
				},
				{
					"pageNumber": 3533,
					"articleName": "ErrorPrism: Reconstructing Error Propagation Paths in Cloud Service Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d533/573300d533.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Junhong",
				"surname": "Liu"
			},
			"authorName": "Liu, Junhong",
			"articleRefs": [
				{
					"pageNumber": 3191,
					"articleName": "KAIOps: A Platform Solution of End-to-End Multi-Modal AIOps for AI Training at Scale",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d191/573300d191.pdf"
				},
				{
					"pageNumber": 3753,
					"articleName": "KAIR: A Statistical and Causal Approach to Pinpointing Stragglers in Distributed Model Training",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d753/573300d753.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "ke",
				"surname": "Liu"
			},
			"authorName": "Liu, ke",
			"articleRefs": [
				{
					"pageNumber": 2477,
					"articleName": "Evaluating and Improving Framework-Based Parallel Code Completion with Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c477/573300c477.pdf"
				},
				{
					"pageNumber": 3273,
					"articleName": "Minuku: Detecting Diverse Display Issues in Mobile Apps with Small-Scale Dataset",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d273/573300d273.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Kexin",
				"surname": "Liu"
			},
			"authorName": "Liu, Kexin",
			"articleRefs": [
				{
					"pageNumber": 2221,
					"articleName": "LLM-Powered Multi-Agent Collaboration for Intelligent Industrial On-Call Automation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c221/573300c221.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Kui",
				"surname": "Liu"
			},
			"authorName": "Liu, Kui",
			"articleRefs": [
				{
					"pageNumber": 2605,
					"articleName": "SE-Jury: An LLM-as-Ensemble-Judge Metric for Narrowing the Gap with Human Evaluation in SE",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c605/573300c605.pdf"
				},
				{
					"pageNumber": 2719,
					"articleName": "PALM: Synergizing Program Analysis and LLMs to Enhance Rust Unit Test Coverage",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c719/573300c719.pdf"
				},
				{
					"pageNumber": 3203,
					"articleName": "iCodeReviewer: Improving Secure Code Review with Mixture of Prompts",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d203/573300d203.pdf"
				},
				{
					"pageNumber": 4117,
					"articleName": "evalSmarT: An LLM-Based Framework for Evaluating Smart Contract Generated Comments",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e117/573300e117.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Lei",
				"surname": "Liu"
			},
			"authorName": "Liu, Lei",
			"articleRefs": [
				{
					"pageNumber": 3020,
					"articleName": "RealisticCodeBench: Towards More Realistic Evaluation of Large Language Models for Code Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d020/573300d020.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Long",
				"surname": "Liu"
			},
			"authorName": "Liu, Long",
			"articleRefs": [
				{
					"pageNumber": 1868,
					"articleName": "ORFUZZ: Fuzzing the \"Other Side\" of LLM Safety \u2013 Testing Over-Refusal",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b868/573300b868.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Mingwei",
				"surname": "Liu"
			},
			"authorName": "Liu, Mingwei",
			"articleRefs": [
				{
					"pageNumber": 610,
					"articleName": "RustRepoTrans: Repository-Level Context Code Translation Benchmark Targeting Rust",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a610/573300a610.pdf"
				},
				{
					"pageNumber": 778,
					"articleName": "DrainCode: Stealthy Energy Consumption Attacks on Retrieval-Augmented Code Generation via Context Poisoning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a778/573300a778.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ning",
				"surname": "Liu"
			},
			"authorName": "Liu, Ning",
			"articleRefs": [
				{
					"pageNumber": 1780,
					"articleName": "Detecting Various DeFi Price Manipulations with LLM Reasoning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b780/573300b780.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Peng",
				"surname": "Liu"
			},
			"authorName": "Liu, Peng",
			"articleRefs": [
				{
					"pageNumber": 2157,
					"articleName": "FlakyGuard: Automatically Fixing Flaky Tests at Industry Scale",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c157/573300c157.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Qiange",
				"surname": "Liu"
			},
			"authorName": "Liu, Qiange",
			"articleRefs": [
				{
					"pageNumber": 1094,
					"articleName": "ZendDiff: Differential Testing of PHP Interpreter",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b094/573300b094.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Qifan",
				"surname": "Liu"
			},
			"authorName": "Liu, Qifan",
			"articleRefs": [
				{
					"pageNumber": 1806,
					"articleName": "ARG: Testing Query Rewriters via Abstract Rule Guided Fuzzing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b806/573300b806.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Shuo",
				"surname": "Liu"
			},
			"authorName": "Liu, Shuo",
			"articleRefs": [
				{
					"pageNumber": 1855,
					"articleName": "Can Mamba Be Better? An Experimental Evaluation of Mamba in Code Intelligence",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b855/573300b855.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Tong",
				"surname": "Liu"
			},
			"authorName": "Liu, Tong",
			"articleRefs": [
				{
					"pageNumber": 3238,
					"articleName": "TrioXpert: An Automated Incident Management Framework for Microservice System",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d238/573300d238.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Wei",
				"surname": "Liu"
			},
			"authorName": "Liu, Wei",
			"articleRefs": [
				{
					"pageNumber": 393,
					"articleName": "Democratizing the Cryptocurrency Ecosystem by Just-In-Time Transformation of Mining Programs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a393/573300a393.pdf"
				},
				{
					"pageNumber": 3718,
					"articleName": "MobileUPReg: Identifying User-Perceived Performance Regressions in Mobile OS Versions",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d718/573300d718.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xia",
				"surname": "Liu"
			},
			"authorName": "Liu, Xia",
			"articleRefs": [
				{
					"pageNumber": 3671,
					"articleName": "RepoMasterEval: Evaluating Code Completion via Real-World Repositories",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d671/573300d671.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xiaomo",
				"surname": "Liu"
			},
			"authorName": "Liu, Xiaomo",
			"articleRefs": [
				{
					"pageNumber": 34,
					"articleName": "LLM Agents for Automated Dependency Upgrades",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a034/850300a034.pdf"
				},
				{
					"pageNumber": 288,
					"articleName": "ALMAS: An Autonomous LLM-Based Multi-Agent Software Engineering Framework",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a288/850300a288.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xiaozhou",
				"surname": "Liu"
			},
			"authorName": "Liu, Xiaozhou",
			"articleRefs": [
				{
					"pageNumber": 2221,
					"articleName": "LLM-Powered Multi-Agent Collaboration for Intelligent Industrial On-Call Automation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c221/573300c221.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xilin",
				"surname": "Liu"
			},
			"authorName": "Liu, Xilin",
			"articleRefs": [
				{
					"pageNumber": 778,
					"articleName": "DrainCode: Stealthy Energy Consumption Attacks on Retrieval-Augmented Code Generation via Context Poisoning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a778/573300a778.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xinyang",
				"surname": "Liu"
			},
			"authorName": "Liu, Xinyang",
			"articleRefs": [
				{
					"pageNumber": 4061,
					"articleName": "DSBox: A Data Selection Framework for Efficient Deep Code Learning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e061/573300e061.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xiyuan",
				"surname": "Liu"
			},
			"authorName": "Liu, Xiyuan",
			"articleRefs": [
				{
					"pageNumber": 3649,
					"articleName": "SCOPE: Evaluating and Enhancing Permission Explanation Transparency in Mobile Apps",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d649/573300d649.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xuanming",
				"surname": "Liu"
			},
			"authorName": "Liu, Xuanming",
			"articleRefs": [
				{
					"pageNumber": 2070,
					"articleName": "Why Is My Transaction Risky? Understanding Smart Contract Semantics and Interactions in the NFT Ecosystem",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c070/573300c070.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xuwei",
				"surname": "Liu"
			},
			"authorName": "Liu, Xuwei",
			"articleRefs": [
				{
					"pageNumber": 1220,
					"articleName": "RFCAudit: AI Agent for Auditing Protocol Implementations Against RFC Specifications",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b220/573300b220.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yang",
				"surname": "Liu"
			},
			"authorName": "Liu, Yang",
			"articleRefs": [
				{
					"pageNumber": 52,
					"articleName": "Learning from the Past: Real-World Exploit Migration for Smart Contract PoC Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a052/573300a052.pdf"
				},
				{
					"pageNumber": 95,
					"articleName": "DroidNative: A Greedy-Constructed Large-Scale Indexing for Android Native Libraries",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a095/850300a095.pdf"
				},
				{
					"pageNumber": 104,
					"articleName": "FAULTSEEKER: LLM-Empowered Framework for Blockchain Transaction Fault Localization",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a104/573300a104.pdf"
				},
				{
					"pageNumber": 648,
					"articleName": "BinStruct: Binary Structure Recovery Combining Static Analysis and Semantics",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a648/573300a648.pdf"
				},
				{
					"pageNumber": 945,
					"articleName": "Demystifying OpenZeppelin's Own Vulnerabilities and Analyzing Their Propagation in Smart Contracts",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a945/573300a945.pdf"
				},
				{
					"pageNumber": 1069,
					"articleName": "A Large Scale Study of AI-Based Binary Function Similarity Detection Techniques for Security Researchers and Practitioners",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b069/573300b069.pdf"
				},
				{
					"pageNumber": 1780,
					"articleName": "Detecting Various DeFi Price Manipulations with LLM Reasoning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b780/573300b780.pdf"
				},
				{
					"pageNumber": 1994,
					"articleName": "Have We Solved Access Control Vulnerability Detection in Smart Contracts? A Benchmark Study",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b994/573300b994.pdf"
				},
				{
					"pageNumber": 2133,
					"articleName": "Towards Generalizable Instruction Vulnerability Prediction via LLM-Enhanced Code Representation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c133/573300c133.pdf"
				},
				{
					"pageNumber": 3521,
					"articleName": "Evaluating Large Language Models for Time Series Anomaly Detection in Aerospace Software",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d521/573300d521.pdf"
				},
				{
					"pageNumber": 3875,
					"articleName": "Envisioning Intelligent Requirements Engineering via Knowledge-Guided Multi-Agent Collaboration",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d875/573300d875.pdf"
				},
				{
					"pageNumber": 3931,
					"articleName": "Requirements Development and Formalization for Reliable Code Generation: A Multi-Agent Vision",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d931/573300d931.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ye",
				"surname": "Liu"
			},
			"authorName": "Liu, Ye",
			"articleRefs": [
				{
					"pageNumber": 1780,
					"articleName": "Detecting Various DeFi Price Manipulations with LLM Reasoning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b780/573300b780.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yepang",
				"surname": "Liu"
			},
			"authorName": "Liu, Yepang",
			"articleRefs": [
				{
					"pageNumber": 2208,
					"articleName": "LSPFuzz: Hunting Bugs in Language Servers",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c208/573300c208.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yi",
				"surname": "Liu"
			},
			"authorName": "Liu, Yi",
			"articleRefs": [
				{
					"pageNumber": 1868,
					"articleName": "ORFUZZ: Fuzzing the \"Other Side\" of LLM Safety \u2013 Testing Over-Refusal",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b868/573300b868.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yicong",
				"surname": "Liu"
			},
			"authorName": "Liu, Yicong",
			"articleRefs": [
				{
					"pageNumber": 1717,
					"articleName": "Fixing Broken Graphs: LLM-Powered Automatic Code Optimization for DNN Programs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b717/573300b717.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yifei",
				"surname": "Liu"
			},
			"authorName": "Liu, Yifei",
			"articleRefs": [
				{
					"pageNumber": 1666,
					"articleName": "Leveraging Mixture-of-Experts Framework for Smart Contract Vulnerability Repair with Large Language Model",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b666/573300b666.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yixuan",
				"surname": "Liu"
			},
			"authorName": "Liu, Yixuan",
			"articleRefs": [
				{
					"pageNumber": 4024,
					"articleName": "DeepTx: Real-Time Transaction Risk Analysis via Multi-Modal Features and LLM Reasoning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e024/573300e024.pdf"
				},
				{
					"pageNumber": 4148,
					"articleName": "Secure Transaction Semantics: Analysis, Vulnerability Detection, and Attack Modeling",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e148/573300e148.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yongheng",
				"surname": "Liu"
			},
			"authorName": "Liu, Yongheng",
			"articleRefs": [
				{
					"pageNumber": 932,
					"articleName": "Exploring Static Taint Analysis in LLMs: A Dynamic Benchmarking Framework for Measurement and Enhancement",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a932/573300a932.pdf"
				},
				{
					"pageNumber": 2413,
					"articleName": "DeepExploitor: LLM-Enhanced Automated Exploitation of DeepLink Attack in Hybrid Apps",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c413/573300c413.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yonghui",
				"surname": "Liu"
			},
			"authorName": "Liu, Yonghui",
			"articleRefs": [
				{
					"pageNumber": 3333,
					"articleName": "Multi-Modal Requirements Data-Based Acceptance Criteria Generation Using LLMs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d333/573300d333.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yue",
				"surname": "Liu"
			},
			"authorName": "Liu, Yue",
			"articleRefs": [
				{
					"pageNumber": 191,
					"articleName": "\"My Productivity is Boosted, but \u2026\" Demystifying Users' Perception on AI Coding Assistants",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a191/573300a191.pdf"
				},
				{
					"pageNumber": 3729,
					"articleName": "Thinking Longer, Not Larger: Enhancing Software Engineering Agents via Scaling Test-Time Compute",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d729/573300d729.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yuxuan",
				"surname": "Liu"
			},
			"authorName": "Liu, Yuxuan",
			"articleRefs": [
				{
					"pageNumber": 2944,
					"articleName": "EPSO: A Caching-Based Efficient Superoptimizer for BPF Bytecode",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c944/573300c944.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zhao",
				"surname": "Liu"
			},
			"authorName": "Liu, Zhao",
			"articleRefs": [
				{
					"pageNumber": 3604,
					"articleName": "IntelliTopo: An IaC Generation Service for Industrial Network Topology Construction",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d604/573300d604.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zhe",
				"surname": "Liu"
			},
			"authorName": "Liu, Zhe",
			"articleRefs": [
				{
					"pageNumber": 1602,
					"articleName": "Beyond Static GUI Agent: Evolving LLM-Based GUI Testing via Dynamic Memory",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b602/573300b602.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zheli",
				"surname": "Liu"
			},
			"authorName": "Liu, Zheli",
			"articleRefs": [
				{
					"pageNumber": 2145,
					"articleName": "Don't Mess with Bro's Cheese! An Empirical Study of Resource Conflict in Android Multi-Window",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c145/573300c145.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zhongxin",
				"surname": "Liu"
			},
			"authorName": "Liu, Zhongxin",
			"articleRefs": [
				{
					"pageNumber": 1337,
					"articleName": "FGIT: Fault-Guided Fine-Tuning for Code Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b337/573300b337.pdf"
				},
				{
					"pageNumber": 1830,
					"articleName": "PEACE: Towards Efficient Project-Level Efficiency Optimization via Hybrid Code Editing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b830/573300b830.pdf"
				},
				{
					"pageNumber": 2503,
					"articleName": "Unit Test Update Through LLM-Driven Context Collection and Error-Type-Aware Refinement",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c503/573300c503.pdf"
				},
				{
					"pageNumber": 2857,
					"articleName": "SolContractEval: A Benchmark for Evaluating Contract-Level Solidity Code Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c857/573300c857.pdf"
				},
				{
					"pageNumber": 3033,
					"articleName": "Issue Localization via LLM-Driven Iterative Code Graph Searching",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d033/573300d033.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zichen",
				"surname": "Liu"
			},
			"authorName": "Liu, Zichen",
			"articleRefs": [
				{
					"pageNumber": 880,
					"articleName": "APPBDS: LLM-Powered Description Synthesis for Sensitive Behaviors in Mobile Apps",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a880/573300a880.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ziming",
				"surname": "Liu"
			},
			"authorName": "Liu, Ziming",
			"articleRefs": [
				{
					"pageNumber": 3414,
					"articleName": "Data Dependency-Aware Code Generation from Enhanced UML Sequence Diagrams",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d414/573300d414.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "shangqing",
				"surname": "liu"
			},
			"authorName": "liu, shangqing",
			"articleRefs": [
				{
					"pageNumber": 254,
					"articleName": "Defects4C: Benchmarking Large Language Model Repair Capability with C/C++ Bugs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a254/573300a254.pdf"
				},
				{
					"pageNumber": 2349,
					"articleName": "Incremental Program Analysis in the Wild: An Empirical Study on Real-World Program Changes",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c349/573300c349.pdf"
				},
				{
					"pageNumber": 2944,
					"articleName": "EPSO: A Caching-Based Efficient Superoptimizer for BPF Bytecode",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c944/573300c944.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "David",
				"surname": "Lo"
			},
			"authorName": "Lo, David",
			"articleRefs": [
				{
					"pageNumber": 154,
					"articleName": "CODE-DITING: Automatic Evaluation of Code Generation Without References or Test Cases",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a154/573300a154.pdf"
				},
				{
					"pageNumber": 191,
					"articleName": "\"My Productivity is Boosted, but \u2026\" Demystifying Users' Perception on AI Coding Assistants",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a191/573300a191.pdf"
				},
				{
					"pageNumber": 1181,
					"articleName": "Backdoors in Code Summarizers: How Bad Is It?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b181/573300b181.pdf"
				},
				{
					"pageNumber": 2070,
					"articleName": "Why Is My Transaction Risky? Understanding Smart Contract Semantics and Interactions in the NFT Ecosystem",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c070/573300c070.pdf"
				},
				{
					"pageNumber": 2439,
					"articleName": "Token Sugar: Making Source Code Sweeter for LLMs Through Token-Efficient Shorthand",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c439/573300c439.pdf"
				},
				{
					"pageNumber": 2605,
					"articleName": "SE-Jury: An LLM-as-Ensemble-Judge Metric for Narrowing the Gap with Human Evaluation in SE",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c605/573300c605.pdf"
				},
				{
					"pageNumber": 3333,
					"articleName": "Multi-Modal Requirements Data-Based Acceptance Criteria Generation Using LLMs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d333/573300d333.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jingqi",
				"surname": "Long"
			},
			"authorName": "Long, Jingqi",
			"articleRefs": [
				{
					"pageNumber": 3082,
					"articleName": "Algernon: A Flag-Guided Hybrid Fuzzer for Unlocking Hidden Program Paths",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d082/573300d082.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Qi",
				"surname": "Long"
			},
			"authorName": "Long, Qi",
			"articleRefs": [
				{
					"pageNumber": 3485,
					"articleName": "BitsAI-Fix: LLM-Driven Approach for Automated Lint Error Resolution in Practice",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d485/573300d485.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Andrea",
				"surname": "Lops"
			},
			"authorName": "Lops, Andrea",
			"articleRefs": [
				{
					"pageNumber": 2400,
					"articleName": "LLMs for Automated Unit Test Generation and Assessment in Java: The AgoneTest Framework",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c400/573300c400.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Youssef",
				"surname": "Lotfy"
			},
			"authorName": "Lotfy, Youssef",
			"articleRefs": [
				{
					"pageNumber": 300,
					"articleName": "Bridging the Prototype-Production Gap: A Multi-Agent System for Notebooks Transformation",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a300/850300a300.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Panos",
				"surname": "Louridas"
			},
			"authorName": "Louridas, Panos",
			"articleRefs": [
				{
					"pageNumber": 4069,
					"articleName": "PyTrim: A Practical Tool for Reducing Python Dependency Bloat",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e069/573300e069.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Haochuan ",
				"surname": "Lu"
			},
			"authorName": "Lu, Haochuan",
			"articleRefs": [
				{
					"pageNumber": 3132,
					"articleName": "JSidentify-V2: Leveraging Dynamic Memory Fingerprinting for Mini-Game Plagiarism Detection",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d132/573300d132.pdf"
				},
				{
					"pageNumber": 3144,
					"articleName": "Practical Escape of Exploration Tarpits for Mini-Game Testing in an Industrial Setting",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d144/573300d144.pdf"
				},
				{
					"pageNumber": 3580,
					"articleName": "Element-Aware Fine-Tuning of Vision-Language Models for Cost-Efficient GUI Testing in an Industrial Setting",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d580/573300d580.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jie",
				"surname": "Lu"
			},
			"authorName": "Lu, Jie",
			"articleRefs": [
				{
					"pageNumber": 2681,
					"articleName": "Understanding Resource Injection Vulnerabilities in Kubernetes Ecosystems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c681/573300c681.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Juncheng",
				"surname": "Lu"
			},
			"authorName": "Lu, Juncheng",
			"articleRefs": [
				{
					"pageNumber": 726,
					"articleName": "Improving LLM-Based Log Parsing by Learning from Errors in Reasoning Traces",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a726/573300a726.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Kai",
				"surname": "Lu"
			},
			"authorName": "Lu, Kai",
			"articleRefs": [
				{
					"pageNumber": 713,
					"articleName": "When Control Flows Deviate: Directed Grey-box Fuzzing with Probabilistic Reachability Analysis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a713/573300a713.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Minghai",
				"surname": "Lu"
			},
			"authorName": "Lu, Minghai",
			"articleRefs": [
				{
					"pageNumber": 3107,
					"articleName": "LLM-Assisted Synthesis of High-Assurance C Programs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d107/573300d107.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ruofan",
				"surname": "Lu"
			},
			"authorName": "Lu, Ruofan",
			"articleRefs": [
				{
					"pageNumber": 3855,
					"articleName": "Exploring Autonomous Agents: A Closer Look at Why They Fail When Completing Tasks",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d855/573300d855.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xu",
				"surname": "Lu"
			},
			"authorName": "Lu, Xu",
			"articleRefs": [
				{
					"pageNumber": 3931,
					"articleName": "Requirements Development and Formalization for Reliable Code Generation: A Multi-Agent Vision",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d931/573300d931.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yao",
				"surname": "Lu"
			},
			"authorName": "Lu, Yao",
			"articleRefs": [
				{
					"pageNumber": 1194,
					"articleName": "AdaptEval: A Benchmark for Evaluating Large Language Models on Code Snippet Adaptation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b194/573300b194.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yifei",
				"surname": "Lu"
			},
			"authorName": "Lu, Yifei",
			"articleRefs": [
				{
					"pageNumber": 1389,
					"articleName": "NATE: A Network-Aware Testing Enhancer for Network-Related Fault Detection in Android Apps",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b389/573300b389.pdf"
				},
				{
					"pageNumber": 2820,
					"articleName": "PoliCond: Condition-Aware Ontology-Driven LLMs for Privacy Policy Contradiction Analysis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c820/573300c820.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "You",
				"surname": "Lu"
			},
			"authorName": "Lu, You",
			"articleRefs": [
				{
					"pageNumber": 13,
					"articleName": "Argus: Resilience-Oriented Safety Assurance Framework for End-to-End ADSs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a013/573300a013.pdf"
				},
				{
					"pageNumber": 419,
					"articleName": "ProfMal: Detecting Malicious NPM Packages by the Synergy between Static and Dynamic Analysis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a419/573300a419.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Wenfei",
				"surname": "Luan"
			},
			"authorName": "Luan, Wenfei",
			"articleRefs": [
				{
					"pageNumber": 958,
					"articleName": "iKnow: an Intent-Guided Chatbot for Cloud Operations with Retrieval-Augmented Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a958/573300a958.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zhongzhi",
				"surname": "Luan"
			},
			"authorName": "Luan, Zhongzhi",
			"articleRefs": [
				{
					"pageNumber": 330,
					"articleName": "LogMoE: Lightweight Expert Mixture for Cross-System Log Anomaly Detection",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a330/573300a330.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Kirill",
				"surname": "Lukianov"
			},
			"authorName": "Lukianov, Kirill",
			"articleRefs": [
				{
					"pageNumber": 4032,
					"articleName": "WIBE: Watermarks for generated Images \u2013 Benchmarking & Evaluation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e032/573300e032.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Anton",
				"surname": "Lunov"
			},
			"authorName": "Lunov, Anton",
			"articleRefs": [
				{
					"pageNumber": 3250,
					"articleName": "Metrics Driven Reengineering and Continuous Code Improvement at Meta",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d250/573300d250.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Chuan",
				"surname": "Luo"
			},
			"authorName": "Luo, Chuan",
			"articleRefs": [
				{
					"pageNumber": 1272,
					"articleName": "SMTgazer: Learning to Schedule SMT Algorithms via Bayesian Optimization",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b272/573300b272.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Juntao",
				"surname": "Luo"
			},
			"authorName": "Luo, Juntao",
			"articleRefs": [
				{
					"pageNumber": 3741,
					"articleName": "LogSage: An LLM-Based Framework for CI/CD Failure Detection and Remediation with Industrial Validation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d741/573300d741.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Tianyue",
				"surname": "Luo"
			},
			"authorName": "Luo, Tianyue",
			"articleRefs": [
				{
					"pageNumber": 3556,
					"articleName": "Shrunk, Yet Complete: Code Shrinking-Resilient Android Third-Party Library Detection",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d556/573300d556.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Weiyu",
				"surname": "Luo"
			},
			"authorName": "Luo, Weiyu",
			"articleRefs": [
				{
					"pageNumber": 2528,
					"articleName": "Automated Insertion of Flushes and Fences for Persistency",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c528/573300c528.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xi",
				"surname": "Luo"
			},
			"authorName": "Luo, Xi",
			"articleRefs": [
				{
					"pageNumber": 3238,
					"articleName": "TrioXpert: An Automated Incident Management Framework for Microservice System",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d238/573300d238.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xiang",
				"surname": "Luo"
			},
			"authorName": "Luo, Xiang",
			"articleRefs": [
				{
					"pageNumber": 700,
					"articleName": "LogAction: Consistent Cross-System Anomaly Detection Through Logs via Active Domain Adaptation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a700/573300a700.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xiangyang",
				"surname": "Luo"
			},
			"authorName": "Luo, Xiangyang",
			"articleRefs": [
				{
					"pageNumber": 2145,
					"articleName": "Don't Mess with Bro's Cheese! An Empirical Study of Resource Conflict in Android Multi-Window",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c145/573300c145.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xiapu",
				"surname": "Luo"
			},
			"authorName": "Luo, Xiapu",
			"articleRefs": [
				{
					"pageNumber": 1463,
					"articleName": "ScaleCirc: Scaling the Analysis over Circom Circuits",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b463/573300b463.pdf"
				},
				{
					"pageNumber": 2541,
					"articleName": "Soleker: Uncovering Vulnerabilities in Solana Smart Contracts",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c541/573300c541.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yixing",
				"surname": "Luo"
			},
			"authorName": "Luo, Yixing",
			"articleRefs": [
				{
					"pageNumber": 3521,
					"articleName": "Evaluating Large Language Models for Time Series Anomaly Detection in Aerospace Software",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d521/573300d521.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yu",
				"surname": "Luo"
			},
			"authorName": "Luo, Yu",
			"articleRefs": [
				{
					"pageNumber": 3238,
					"articleName": "TrioXpert: An Automated Incident Management Framework for Microservice System",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d238/573300d238.pdf"
				},
				{
					"pageNumber": 3497,
					"articleName": "Adaptive Performance Regression Detection Using A Semi-Supervised Siamese Network",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d497/573300d497.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yuan",
				"surname": "Luo"
			},
			"authorName": "Luo, Yuan",
			"articleRefs": [
				{
					"pageNumber": 317,
					"articleName": "PrefGen: A Preference-Driven Methodology for Secure Yet Gas-Efficient Smart Contract Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a317/573300a317.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Shichao",
				"surname": "Lv"
			},
			"authorName": "Lv, Shichao",
			"articleRefs": [
				{
					"pageNumber": 2082,
					"articleName": "Breaking the Traffic Barrier: Unveiling Multi-Format of Protocols via Autonomous Program Exploration",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c082/573300c082.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ce",
				"surname": "Lyu"
			},
			"authorName": "Lyu, Ce",
			"articleRefs": [
				{
					"pageNumber": 3813,
					"articleName": "LLM-Based Dynamic Differential Testing for Database Connectors with Reinforcement Learning-Guided Prompt Selection",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d813/573300d813.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Chen",
				"surname": "Lyu"
			},
			"authorName": "Lyu, Chen",
			"articleRefs": [
				{
					"pageNumber": 1918,
					"articleName": "SemGuard: Real-Time Semantic Evaluator for Correcting LLM-Generated Code",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b918/573300b918.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jun",
				"surname": "Lyu"
			},
			"authorName": "Lyu, Jun",
			"articleRefs": [
				{
					"pageNumber": 597,
					"articleName": "Automatic Fixing of Missing Dependency Errors",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a597/573300a597.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Michael R.",
				"surname": "Lyu"
			},
			"authorName": "Lyu, Michael R.",
			"articleRefs": [
				{
					"pageNumber": 241,
					"articleName": "Interaction2Code: Benchmarking MLLM-Based Interactive Webpage Code Generation from Interactive Prototyping",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a241/573300a241.pdf"
				},
				{
					"pageNumber": 958,
					"articleName": "iKnow: an Intent-Guided Chatbot for Cloud Operations with Retrieval-Augmented Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a958/573300a958.pdf"
				},
				{
					"pageNumber": 2905,
					"articleName": "Metamorphic Testing for Audio Content Moderation Software",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c905/573300c905.pdf"
				},
				{
					"pageNumber": 3298,
					"articleName": "LogPilot: Intent-Aware and Scalable Alert Diagnosis for Large-Scale Online Service Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d298/573300d298.pdf"
				},
				{
					"pageNumber": 3425,
					"articleName": "Automated Proactive Logging Quality Improvement for Large-Scale Codebases ",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d425/573300d425.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yunbo",
				"surname": "Lyu"
			},
			"authorName": "Lyu, Yunbo",
			"articleRefs": [
				{
					"pageNumber": 191,
					"articleName": "\"My Productivity is Boosted, but \u2026\" Demystifying Users' Perception on AI Coding Assistants",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a191/573300a191.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Fuchen",
				"surname": "Ma"
			},
			"authorName": "Ma, Fuchen",
			"articleRefs": [
				{
					"pageNumber": 547,
					"articleName": "DNAFuzz: Descriptor-Aware Fuzzing for USB Drivers",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a547/573300a547.pdf"
				},
				{
					"pageNumber": 765,
					"articleName": "DualFuzz: Detecting Vulnerability in Wi-Fi NICs through Dual-Directional Fuzzing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a765/573300a765.pdf"
				},
				{
					"pageNumber": 3156,
					"articleName": "Industry Practice of LLM-Assisted Protocol Fuzzing for Commercial Communication Modules",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d156/573300d156.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Guojun",
				"surname": "Ma"
			},
			"authorName": "Ma, Guojun",
			"articleRefs": [
				{
					"pageNumber": 623,
					"articleName": "Enhancing LLM's Ability to Generate More Repository-Aware Unit Tests Through Precise Context Injection",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a623/573300a623.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Huafeng ",
				"surname": "Ma"
			},
			"authorName": "Ma, Huafeng",
			"articleRefs": [
				{
					"pageNumber": 3132,
					"articleName": "JSidentify-V2: Leveraging Dynamic Memory Fingerprinting for Mini-Game Plagiarism Detection",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d132/573300d132.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jianan",
				"surname": "Ma"
			},
			"authorName": "Ma, Jianan",
			"articleRefs": [
				{
					"pageNumber": 508,
					"articleName": "Provable Fairness Repair for Deep Neural Networks",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a508/573300a508.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jianfeng",
				"surname": "Ma"
			},
			"authorName": "Ma, Jianfeng",
			"articleRefs": [
				{
					"pageNumber": 791,
					"articleName": "Hit The Bullseye On The First Shot: Improving LLMs Using Multi-Sample Self-Reward Feedback for Vulnerability Repair",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a791/573300a791.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Kun",
				"surname": "Ma"
			},
			"authorName": "Ma, Kun",
			"articleRefs": [
				{
					"pageNumber": 1142,
					"articleName": "Hypergraph Neural Network-Based Multi-Granular Root Cause Localization for Microservice Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b142/573300b142.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Minghua",
				"surname": "Ma"
			},
			"authorName": "Ma, Minghua",
			"articleRefs": [
				{
					"pageNumber": 674,
					"articleName": "Triangle: Empowering Incident Triage with Multi-Agent",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a674/573300a674.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Qijun",
				"surname": "Ma"
			},
			"authorName": "Ma, Qijun",
			"articleRefs": [
				{
					"pageNumber": 3741,
					"articleName": "LogSage: An LLM-Based Framework for CI/CD Failure Detection and Remediation with Industrial Validation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d741/573300d741.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Shang-Pin",
				"surname": "Ma"
			},
			"authorName": "Ma, Shang-Pin",
			"articleRefs": [
				{
					"pageNumber": 161,
					"articleName": "MicroViSim: Simulation and Visualization of Kubernetes-Based Microservice Systems",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a161/850300a161.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Tao",
				"surname": "Ma"
			},
			"authorName": "Ma, Tao",
			"articleRefs": [
				{
					"pageNumber": 3545,
					"articleName": "LLM-Assisted Industrial-Scale Differential Testing of Package Incompatibilities in Linux Distributions",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d545/573300d545.pdf"
				},
				{
					"pageNumber": 3615,
					"articleName": "RPG: Linux Kernel Fuzzing Guided by Distribution-Specific Runtime Parameter Interfaces",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d615/573300d615.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Tianyi",
				"surname": "Ma"
			},
			"authorName": "Ma, Tianyi",
			"articleRefs": [
				{
					"pageNumber": 3777,
					"articleName": "SGCR: A Specification-Grounded Framework for Trustworthy LLM Code Review",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d777/573300d777.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xiaolin",
				"surname": "Ma"
			},
			"authorName": "Ma, Xiaolin",
			"articleRefs": [
				{
					"pageNumber": 3683,
					"articleName": "Securing Millions of Decentralized Identities in Alipay Super App with End-to-End Formal Verification",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d683/573300d683.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xiaoxing",
				"surname": "Ma"
			},
			"authorName": "Ma, Xiaoxing",
			"articleRefs": [
				{
					"pageNumber": 469,
					"articleName": "Comprehend, Imitate, and then Update: Unleashing the Power of LLMs in Test Suite Evolution",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a469/573300a469.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yiming",
				"surname": "Ma"
			},
			"authorName": "Ma, Yiming",
			"articleRefs": [
				{
					"pageNumber": 584,
					"articleName": "EditFusion: Resolving Code Merge Conflicts via Edit Selection",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a584/573300a584.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yingwei",
				"surname": "Ma"
			},
			"authorName": "Ma, Yingwei",
			"articleRefs": [
				{
					"pageNumber": 3729,
					"articleName": "Thinking Longer, Not Larger: Enhancing Software Engineering Agents via Scaling Test-Time Compute",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d729/573300d729.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yuchi",
				"surname": "Ma"
			},
			"authorName": "Ma, Yuchi",
			"articleRefs": [
				{
					"pageNumber": 778,
					"articleName": "DrainCode: Stealthy Energy Consumption Attacks on Retrieval-Augmented Code Generation via Context Poisoning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a778/573300a778.pdf"
				},
				{
					"pageNumber": 971,
					"articleName": "AlignCoder: Aligning Retrieval with Target Intent for Repository-Level Code Completion",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a971/573300a971.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zhi",
				"surname": "Ma"
			},
			"authorName": "Ma, Zhi",
			"articleRefs": [
				{
					"pageNumber": 1207,
					"articleName": "Bridging Natural Language and Formal Specification Automated Translation of Software Requirements to LTL via Hierarchical Semantics Decomposition Using LLMs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b207/573300b207.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zhirou",
				"surname": "Ma"
			},
			"authorName": "Ma, Zhirou",
			"articleRefs": [
				{
					"pageNumber": 2771,
					"articleName": "Root Cause Analysis of RISC-V Build Failures via LLM and MCTS Reasoning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c771/573300c771.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zuchao",
				"surname": "Ma"
			},
			"authorName": "Ma, Zuchao",
			"articleRefs": [
				{
					"pageNumber": 2541,
					"articleName": "Soleker: Uncovering Vulnerabilities in Solana Smart Contracts",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c541/573300c541.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Lei",
				"surname": "ma"
			},
			"authorName": "ma, Lei",
			"articleRefs": [
				{
					"pageNumber": 4081,
					"articleName": "TRUSTVIS: A Multi-Dimensional Trustworthiness Evaluation Framework for Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e081/573300e081.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Dor",
				"surname": "Ma'ayan"
			},
			"authorName": "Ma'ayan, Dor",
			"articleRefs": [
				{
					"pageNumber": 266,
					"articleName": "Evolution-Aware Heuristics for GR(1) Realizability Checking",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a266/573300a266.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Alexander",
				"surname": "Maedche"
			},
			"authorName": "Maedche, Alexander",
			"articleRefs": [
				{
					"pageNumber": 4052,
					"articleName": "GUI-ReRank: Enhancing GUI Retrieval with Multi-Modal LLM-Based Reranking",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e052/573300e052.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Cleyton",
				"surname": "Magalhaes"
			},
			"authorName": "Magalhaes, Cleyton",
			"articleRefs": [
				{
					"pageNumber": 3916,
					"articleName": "Tether: A Personalized Support Assistant for Software Engineers with ADHD",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d916/573300d916.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "May",
				"surname": "Mahmoud"
			},
			"authorName": "Mahmoud, May",
			"articleRefs": [
				{
					"pageNumber": 867,
					"articleName": "An Empirical Study of Python Library Migration Using Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a867/573300a867.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Junayed",
				"surname": "Mahmud"
			},
			"authorName": "Mahmud, Junayed",
			"articleRefs": [
				{
					"pageNumber": 2195,
					"articleName": "Generating Failure-Based Oracles to Support Testing of Reported Bugs in Android Apps",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c195/573300c195.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Genting",
				"surname": "Mai"
			},
			"authorName": "Mai, Genting",
			"articleRefs": [
				{
					"pageNumber": 1,
					"articleName": "AlertGuardian: Intelligent Alert Life-Cycle Management for Large-Scale Cloud Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a001/573300a001.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Trong Nhan",
				"surname": "Mai"
			},
			"authorName": "Mai, Trong Nhan",
			"articleRefs": [
				{
					"pageNumber": 3391,
					"articleName": "Unlocking Reproducibility: Automating re-Build Process for Open-Source Software",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d391/573300d391.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Alina",
				"surname": "Mailach"
			},
			"authorName": "Mailach, Alina",
			"articleRefs": [
				{
					"pageNumber": 2515,
					"articleName": "On Automating Configuration Dependency Validation via Retrieval-Augmented Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c515/573300c515.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Rungroj",
				"surname": "Maipradit"
			},
			"authorName": "Maipradit, Rungroj",
			"articleRefs": [
				{
					"pageNumber": 1426,
					"articleName": "Rechecking Recheck Requests in Continuous Integration: An Empirical Study of OpenStack",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b426/573300b426.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Johannes",
				"surname": "M\u00E4kelburg"
			},
			"authorName": "M\u00E4kelburg, Johannes",
			"articleRefs": [
				{
					"pageNumber": 204,
					"articleName": "Explainability in Automated Cross-Domain Model-Driven Brake System Development",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a204/850300a204.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Sanjay",
				"surname": "Malakar"
			},
			"authorName": "Malakar, Sanjay",
			"articleRefs": [
				{
					"pageNumber": 828,
					"articleName": "Repairing Leaks in Resource Wrappers",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a828/573300a828.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ivan",
				"surname": "Malashin"
			},
			"authorName": "Malashin, Ivan",
			"articleRefs": [
				{
					"pageNumber": 229,
					"articleName": "Automated Evolutionary Hyperparameter Tuning for NLP-Based Test Case Generation",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a229/850300a229.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Sam",
				"surname": "Malek"
			},
			"authorName": "Malek, Sam",
			"articleRefs": [
				{
					"pageNumber": 1905,
					"articleName": "Automated Detection of Web Application Navigation Barriers for Screen Reader Users",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b905/573300b905.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Claudia",
				"surname": "Mamede"
			},
			"authorName": "Mamede, Claudia",
			"articleRefs": [
				{
					"pageNumber": 2020,
					"articleName": "Interpretable Vulnerability Detection Reports",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c020/573300c020.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Tural",
				"surname": "Mammadov"
			},
			"authorName": "Mammadov, Tural",
			"articleRefs": [
				{
					"pageNumber": 4048,
					"articleName": "BASHIRI: Learning Failure Oracles from Execution Features",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e048/573300e048.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Claudio",
				"surname": "Mandrioli"
			},
			"authorName": "Mandrioli, Claudio",
			"articleRefs": [
				{
					"pageNumber": 3833,
					"articleName": "Fault Injection for Simulink-Based CPS Models: Insights and Future Directions",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d833/573300d833.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Alessio",
				"surname": "Mansutti"
			},
			"authorName": "Mansutti, Alessio",
			"articleRefs": [
				{
					"pageNumber": 2669,
					"articleName": "How Big is the Automaton? Certified Lower Bounds on the Size of Presburger DFAs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c669/573300c669.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Bing",
				"surname": "Mao"
			},
			"authorName": "Mao, Bing",
			"articleRefs": [
				{
					"pageNumber": 457,
					"articleName": "Uncovering Prompt Elements: Cloning System Prompts from Behavioral Traces",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a457/573300a457.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Bingcheng",
				"surname": "Mao"
			},
			"authorName": "Mao, Bingcheng",
			"articleRefs": [
				{
					"pageNumber": 3777,
					"articleName": "SGCR: A Specification-Grounded Framework for Trustworthy LLM Code Review",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d777/573300d777.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jian",
				"surname": "Mao"
			},
			"authorName": "Mao, Jian",
			"articleRefs": [
				{
					"pageNumber": 1094,
					"articleName": "ZendDiff: Differential Testing of PHP Interpreter",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b094/573300b094.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Tianhao",
				"surname": "Mao"
			},
			"authorName": "Mao, Tianhao",
			"articleRefs": [
				{
					"pageNumber": 893,
					"articleName": "LineBreaker: Finding Token-Inconsistency Bugs with Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a893/573300a893.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Wenxin",
				"surname": "Mao"
			},
			"authorName": "Mao, Wenxin",
			"articleRefs": [
				{
					"pageNumber": 3414,
					"articleName": "Data Dependency-Aware Code Generation from Enhanced UML Sequence Diagrams",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d414/573300d414.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xiaoguang",
				"surname": "Mao"
			},
			"authorName": "Mao, Xiaoguang",
			"articleRefs": [
				{
					"pageNumber": 804,
					"articleName": "Let the Code Speak: Incorporating Program Dynamic State for Better Method-Level Fault Localization",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a804/573300a804.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xinjun",
				"surname": "Mao"
			},
			"authorName": "Mao, Xinjun",
			"articleRefs": [
				{
					"pageNumber": 1194,
					"articleName": "AdaptEval: A Benchmark for Evaluating Large Language Models on Code Snippet Adaptation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b194/573300b194.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zhenyu",
				"surname": "Mao"
			},
			"authorName": "Mao, Zhenyu",
			"articleRefs": [
				{
					"pageNumber": 1855,
					"articleName": "Can Mamba Be Better? An Experimental Evaluation of Mamba in Code Intelligence",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b855/573300b855.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ziyu",
				"surname": "Mao"
			},
			"authorName": "Mao, Ziyu",
			"articleRefs": [
				{
					"pageNumber": 3683,
					"articleName": "Securing Millions of Decentralized Identities in Alipay Super App with End-to-End Formal Verification",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d683/573300d683.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Shahar",
				"surname": "Maoz"
			},
			"authorName": "Maoz, Shahar",
			"articleRefs": [
				{
					"pageNumber": 266,
					"articleName": "Evolution-Aware Heuristics for GR(1) Realizability Checking",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a266/573300a266.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Luciano",
				"surname": "Marchezan"
			},
			"authorName": "Marchezan, Luciano",
			"articleRefs": [
				{
					"pageNumber": 4020,
					"articleName": "PrioTestCI: Efficient Test Case Prioritization in GitHub Workflows for CI Optimization",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e020/573300e020.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Darko",
				"surname": "Marinov"
			},
			"authorName": "Marinov, Darko",
			"articleRefs": [
				{
					"pageNumber": 1082,
					"articleName": "DebCovDiff: Differential Testing of Coverage Measurement Tools on Real-World Projects",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b082/573300b082.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yury",
				"surname": "Markin"
			},
			"authorName": "Markin, Yury",
			"articleRefs": [
				{
					"pageNumber": 4032,
					"articleName": "WIBE: Watermarks for generated Images \u2013 Benchmarking & Evaluation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e032/573300e032.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "David",
				"surname": "Markvica"
			},
			"authorName": "Markvica, David",
			"articleRefs": [
				{
					"pageNumber": 2732,
					"articleName": "TEPHRA: Principled Discovery of Fuzzer Limitations",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c732/573300c732.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jill",
				"surname": "Marley"
			},
			"authorName": "Marley, Jill",
			"articleRefs": [
				{
					"pageNumber": 2794,
					"articleName": "Which Is Better For Reducing Outdated and Vulnerable Dependencies: Pinning or Floating?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c794/573300c794.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Dragos",
				"surname": "Martac "
			},
			"authorName": "Martac, Dragos",
			"articleRefs": [
				{
					"pageNumber": 3250,
					"articleName": "Metrics Driven Reengineering and Continuous Code Improvement at Meta",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d250/573300d250.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Alberto",
				"surname": "Martin-Lopez"
			},
			"authorName": "Martin-Lopez, Alberto",
			"articleRefs": [
				{
					"pageNumber": 278,
					"articleName": "Do LLMs Generate Useful Test Oracles? An Empirical Study with an Unbiased Dataset",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a278/573300a278.pdf"
				},
				{
					"pageNumber": 1363,
					"articleName": "SATORI: Static Test Oracle Generation for REST APIs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b363/573300b363.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Igor",
				"surname": "Masich"
			},
			"authorName": "Masich, Igor",
			"articleRefs": [
				{
					"pageNumber": 229,
					"articleName": "Automated Evolutionary Hyperparameter Tuning for NLP-Based Test Case Generation",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a229/850300a229.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Sogol",
				"surname": "Masoumzadeh"
			},
			"authorName": "Masoumzadeh, Sogol",
			"articleRefs": [
				{
					"pageNumber": 739,
					"articleName": "Watson: A Cognitive Observability Framework for the Reasoning of LLM-Powered Agents",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a739/573300a739.pdf"
				},
				{
					"pageNumber": 4133,
					"articleName": "Detecting Vulnerabilities from Issue Reports for Internet-of-Things",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e133/573300e133.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Kenichi",
				"surname": "Matsumoto"
			},
			"authorName": "Matsumoto, Kenichi",
			"articleRefs": [
				{
					"pageNumber": 261,
					"articleName": "Exploring the SECURITY.md in the Dependency Chain: Preliminary Analysis of the PyPI Ecosystem",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a261/850300a261.pdf"
				},
				{
					"pageNumber": 3996,
					"articleName": "PyGress: Tool for Analyzing the Progression of Code Proficiency in Python OSS Projects",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d996/573300d996.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Maykel",
				"surname": "Mattar"
			},
			"authorName": "Mattar, Maykel",
			"articleRefs": [
				{
					"pageNumber": 291,
					"articleName": "Loupe: End-to-End Learning of Loop Unrolling Heuristics for Abstract Interpretation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a291/573300a291.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Marcello",
				"surname": "Maugeri"
			},
			"authorName": "Maugeri, Marcello",
			"articleRefs": [
				{
					"pageNumber": 4065,
					"articleName": "BenGQL: An Extensible Benchmarking Framework for Automated GraphQL Testing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e065/573300e065.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Bruce",
				"surname": "Maxim"
			},
			"authorName": "Maxim, Bruce",
			"articleRefs": [
				{
					"pageNumber": 1955,
					"articleName": "VRTestSniffer: Test Smell Detector for Virtual Reality (VR) Software Projects",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b955/573300b955.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Fatou Ndiaye",
				"surname": "Mbodji"
			},
			"authorName": "Mbodji, Fatou Ndiaye",
			"articleRefs": [
				{
					"pageNumber": 4117,
					"articleName": "evalSmarT: An LLM-Based Framework for Evaluating Smart Contract Generated Comments",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e117/573300e117.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Stephen",
				"surname": "McCamant"
			},
			"authorName": "McCamant, Stephen",
			"articleRefs": [
				{
					"pageNumber": 153,
					"articleName": "Improving Automated Program Verification for Java Programs with Fuzzing",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a153/850300a153.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Shane",
				"surname": "McIntosh"
			},
			"authorName": "McIntosh, Shane",
			"articleRefs": [
				{
					"pageNumber": 1426,
					"articleName": "Rechecking Recheck Requests in Continuous Integration: An Empirical Study of OpenStack",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b426/573300b426.pdf"
				},
				{
					"pageNumber": 2931,
					"articleName": "The Cost of Downgrading Build Systems A Case Study of Kubernetes",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c931/573300c931.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Samantha",
				"surname": "McLoughlin"
			},
			"authorName": "McLoughlin, Samantha",
			"articleRefs": [
				{
					"pageNumber": 1020,
					"articleName": "Programmers' Visual Attention on Function Call Graphs During Code Summarization",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b020/573300b020.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Collin",
				"surname": "McMillan"
			},
			"authorName": "McMillan, Collin",
			"articleRefs": [
				{
					"pageNumber": 1020,
					"articleName": "Programmers' Visual Attention on Function Call Graphs During Code Summarization",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b020/573300b020.pdf"
				},
				{
					"pageNumber": 4089,
					"articleName": "APIDA-Chat: Structured Synthesis of API Search Dialogues to Bootstrap Conversational Agents",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e089/573300e089.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Sergey",
				"surname": "Mechtaev"
			},
			"authorName": "Mechtaev, Sergey",
			"articleRefs": [
				{
					"pageNumber": 367,
					"articleName": "Automated Repair of Ambiguous Problem Descriptions for LLM-Based Code Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a367/573300a367.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Raveendra Kumar",
				"surname": "Medicherla"
			},
			"authorName": "Medicherla, Raveendra Kumar",
			"articleRefs": [
				{
					"pageNumber": 22,
					"articleName": "Microservices Identification Using LLM",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a022/850300a022.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Neev Nirav",
				"surname": "Mehta"
			},
			"authorName": "Mehta, Neev Nirav",
			"articleRefs": [
				{
					"pageNumber": 2490,
					"articleName": "The Fault in our Stats",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c490/573300c490.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Mashal Afzal",
				"surname": "Memon"
			},
			"authorName": "Memon, Mashal Afzal",
			"articleRefs": [
				{
					"pageNumber": 2451,
					"articleName": "Advancing Automated Ethical Profiling in SE: a Zero-Shot Evaluation of LLM Reasoning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c451/573300c451.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Fanyi",
				"surname": "Meng"
			},
			"authorName": "Meng, Fanyi",
			"articleRefs": [
				{
					"pageNumber": 1893,
					"articleName": "Diplomatist: What Do Cross-Language Dependencies Reflect Software Ecosystem Health?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b893/573300b893.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Linghan",
				"surname": "Meng"
			},
			"authorName": "Meng, Linghan",
			"articleRefs": [
				{
					"pageNumber": 3203,
					"articleName": "iCodeReviewer: Improving Secure Code Review with Mixture of Prompts",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d203/573300d203.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Qiaoyuanhe",
				"surname": "Meng"
			},
			"authorName": "Meng, Qiaoyuanhe",
			"articleRefs": [
				{
					"pageNumber": 2298,
					"articleName": "FastCoder: Accelerating Repository-Level Code Generation via Efficient Retrieval and Verification",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c298/573300c298.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Nandakishore",
				"surname": "Menon"
			},
			"authorName": "Menon, Nandakishore",
			"articleRefs": [
				{
					"pageNumber": 4077,
					"articleName": "Evaluating Program Coverage for Code-Model Training",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e077/573300e077.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Alejandro",
				"surname": "Mera"
			},
			"authorName": "Mera, Alejandro",
			"articleRefs": [
				{
					"pageNumber": 2567,
					"articleName": "DRIFT: Debug-Based Trace Inference for Firmware Testing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c567/573300c567.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ali",
				"surname": "Mesbah"
			},
			"authorName": "Mesbah, Ali",
			"articleRefs": [
				{
					"pageNumber": 1628,
					"articleName": "Characterizing Multi-Hunk Patches: Divergence, Proximity, and LLM Repair Challenges",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b628/573300b628.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Miao",
				"surname": "Miao"
			},
			"authorName": "Miao, Miao",
			"articleRefs": [
				{
					"pageNumber": 181,
					"articleName": "SeedUI: Understanding Initial Seeds in Fuzzing",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a181/850300a181.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Patrizio",
				"surname": "Migliarini"
			},
			"authorName": "Migliarini, Patrizio",
			"articleRefs": [
				{
					"pageNumber": 2451,
					"articleName": "Advancing Automated Ethical Profiling in SE: a Zero-Shot Evaluation of LLM Reasoning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c451/573300c451.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Marc",
				"surname": "Miltenberger"
			},
			"authorName": "Miltenberger, Marc",
			"articleRefs": [
				{
					"pageNumber": 3976,
					"articleName": "VUSC: An Extensible Research Platform for Java-Based Static Analysis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d976/573300d976.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Neil",
				"surname": "Mitchell"
			},
			"authorName": "Mitchell, Neil",
			"articleRefs": [
				{
					"pageNumber": 3250,
					"articleName": "Metrics Driven Reengineering and Continuous Code Improvement at Meta",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d250/573300d250.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Dimitris",
				"surname": "Mitropoulos"
			},
			"authorName": "Mitropoulos, Dimitris",
			"articleRefs": [
				{
					"pageNumber": 4069,
					"articleName": "PyTrim: A Practical Tool for Reducing Python Dependency Bloat",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e069/573300e069.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Masashi",
				"surname": "Mizoguchi"
			},
			"authorName": "Mizoguchi, Masashi",
			"articleRefs": [
				{
					"pageNumber": 3771,
					"articleName": "Acceleration of Automotive Software Development by Retrieval Augmented Integration Test Script Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d771/573300d771.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Mohamed Wiem",
				"surname": "Mkaouer"
			},
			"authorName": "Mkaouer, Mohamed Wiem",
			"articleRefs": [
				{
					"pageNumber": 1955,
					"articleName": "VRTestSniffer: Test Smell Detector for Virtual Reality (VR) Software Projects",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b955/573300b955.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Audris",
				"surname": "Mockus"
			},
			"authorName": "Mockus, Audris",
			"articleRefs": [
				{
					"pageNumber": 3250,
					"articleName": "Metrics Driven Reengineering and Continuous Code Improvement at Meta",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d250/573300d250.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Mazen",
				"surname": "Mohamad"
			},
			"authorName": "Mohamad, Mazen",
			"articleRefs": [
				{
					"pageNumber": 58,
					"articleName": "Leveraging Large Language Models for Cybersecurity Risk Assessment \u2014 A Case from Forestry Cyber-Physical Systems",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a058/850300a058.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Sudharssan",
				"surname": "Mohan"
			},
			"authorName": "Mohan, Sudharssan",
			"articleRefs": [
				{
					"pageNumber": 1590,
					"articleName": "IMUFUZZER: Resilience-Based Discovery of Signal Injection Attacks on Robotic Aerial Vehicles",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b590/573300b590.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Andrada-Mihaela-Nicoleta",
				"surname": "Moldovan"
			},
			"authorName": "Moldovan, Andrada-Mihaela-Nicoleta",
			"articleRefs": [
				{
					"pageNumber": 129,
					"articleName": "Regression Testing Skill Transfer to Industry: A Preliminary Study in Higher Education",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a129/850300a129.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Facundo",
				"surname": "Molina"
			},
			"authorName": "Molina, Facundo",
			"articleRefs": [
				{
					"pageNumber": 2706,
					"articleName": "State Field Coverage: A Metric for Oracle Quality",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c706/573300c706.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Davide",
				"surname": "Molinelli"
			},
			"authorName": "Molinelli, Davide",
			"articleRefs": [
				{
					"pageNumber": 278,
					"articleName": "Do LLMs Generate Useful Test Oracles? An Empirical Study with an Unbiased Dataset",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a278/573300a278.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Verya",
				"surname": "Monjezi"
			},
			"authorName": "Monjezi, Verya",
			"articleRefs": [
				{
					"pageNumber": 1679,
					"articleName": "Uncovering Discrimination Clusters: Quantifying and Explaining Systematic Fairness Violations",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b679/573300b679.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Venus",
				"surname": "Montes"
			},
			"authorName": "Montes, Venus",
			"articleRefs": [
				{
					"pageNumber": 3250,
					"articleName": "Metrics Driven Reengineering and Continuous Code Improvement at Meta",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d250/573300d250.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Kevin",
				"surname": "Moran"
			},
			"authorName": "Moran, Kevin",
			"articleRefs": [
				{
					"pageNumber": 2195,
					"articleName": "Generating Failure-Based Oracles to Support Testing of Reported Bugs in Android Apps",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c195/573300c195.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Akira",
				"surname": "Mori"
			},
			"authorName": "Mori, Akira",
			"articleRefs": [
				{
					"pageNumber": 2337,
					"articleName": "On the Correctness of Software Merge",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c337/573300c337.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Francois",
				"surname": "Morin"
			},
			"authorName": "Morin, Francois",
			"articleRefs": [
				{
					"pageNumber": 3250,
					"articleName": "Metrics Driven Reengineering and Continuous Code Improvement at Meta",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d250/573300d250.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Robbie",
				"surname": "Morris"
			},
			"authorName": "Morris, Robbie",
			"articleRefs": [
				{
					"pageNumber": 367,
					"articleName": "Automated Repair of Ambiguous Problem Descriptions for LLM-Based Code Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a367/573300a367.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Dany",
				"surname": "Moshkovich"
			},
			"authorName": "Moshkovich, Dany",
			"articleRefs": [
				{
					"pageNumber": 3839,
					"articleName": "Taming Uncertainty via Automation: Observing, Analyzing, and Optimizing Agentic AI Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d839/573300d839.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Sali",
				"surname": "Moussa"
			},
			"authorName": "Moussa, Sali",
			"articleRefs": [
				{
					"pageNumber": 4140,
					"articleName": "Testing Autonomous Driving Systems Through Blind-Spot Guided Fuzzing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e140/573300e140.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yanzhou ",
				"surname": "Mu"
			},
			"authorName": "Mu, Yanzhou",
			"articleRefs": [
				{
					"pageNumber": 1168,
					"articleName": "When Autonomous Vehicle Meets V2X Cooperative Perception: How Far Are We?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b168/573300b168.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Prasita",
				"surname": "Mukherjee"
			},
			"authorName": "Mukherjee, Prasita",
			"articleRefs": [
				{
					"pageNumber": 3107,
					"articleName": "LLM-Assisted Synthesis of High-Assurance C Programs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d107/573300d107.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yash",
				"surname": "Mundhra"
			},
			"authorName": "Mundhra, Yash",
			"articleRefs": [
				{
					"pageNumber": 3474,
					"articleName": "Evaluating Large Language Models for Functional and Maintainable Code in Industrial Settings: A Case Study at ASML",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d474/573300d474.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Lekshmi",
				"surname": "Murali Rani"
			},
			"authorName": "Murali Rani, Lekshmi",
			"articleRefs": [
				{
					"pageNumber": 245,
					"articleName": "AI for Requirements Engineering: Industry Adoption and Practitioner Perspectives",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a245/850300a245.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Emerson",
				"surname": "Murphy-Hill"
			},
			"authorName": "Murphy-Hill, Emerson",
			"articleRefs": [
				{
					"pageNumber": 432,
					"articleName": "Why AI Agents Still Need You: Findings from Developer-Agent Collaborations in the Wild",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a432/573300a432.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Sarah",
				"surname": "Nadi"
			},
			"authorName": "Nadi, Sarah",
			"articleRefs": [
				{
					"pageNumber": 867,
					"articleName": "An Empirical Study of Python Library Migration Using Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a867/573300a867.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Nachiappan",
				"surname": "Nagappan"
			},
			"authorName": "Nagappan, Nachiappan",
			"articleRefs": [
				{
					"pageNumber": 3250,
					"articleName": "Metrics Driven Reengineering and Continuous Code Improvement at Meta",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d250/573300d250.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Stefan",
				"surname": "Nagy"
			},
			"authorName": "Nagy, Stefan",
			"articleRefs": [
				{
					"pageNumber": 1131,
					"articleName": "GUIFuzz++: Unleashing Grey-box Fuzzing on Desktop Graphical User Interfacing Applications ",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b131/573300b131.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ravindra",
				"surname": "Naik"
			},
			"authorName": "Naik, Ravindra",
			"articleRefs": [
				{
					"pageNumber": 22,
					"articleName": "Microservices Identification Using LLM",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a022/850300a022.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Keita",
				"surname": "Nakazawa"
			},
			"authorName": "Nakazawa, Keita",
			"articleRefs": [
				{
					"pageNumber": 3771,
					"articleName": "Acceleration of Automotive Software Development by Retrieval Augmented Integration Test Script Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d771/573300d771.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Doha",
				"surname": "Nam"
			},
			"authorName": "Nam, Doha",
			"articleRefs": [
				{
					"pageNumber": 1057,
					"articleName": "LOSVER: Line-Level Modifiability Signal-Guided Vulnerability Detection and Classification",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b057/573300b057.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yuhong",
				"surname": "Nan"
			},
			"authorName": "Nan, Yuhong",
			"articleRefs": [
				{
					"pageNumber": 1528,
					"articleName": "Finding Insecure State Dependency in DApps via Multi-Source Tracing and Semantic Enrichment",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b528/573300b528.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zifan",
				"surname": "Nan"
			},
			"authorName": "Nan, Zifan",
			"articleRefs": [
				{
					"pageNumber": 2719,
					"articleName": "PALM: Synergizing Program Analysis and LLMs to Enhance Rust Unit Test Coverage",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c719/573300c719.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Monil",
				"surname": "Narang"
			},
			"authorName": "Narang, Monil",
			"articleRefs": [
				{
					"pageNumber": 1259,
					"articleName": "What's DAT Smell? Untangling and Weaving the Disjoint Assertion Tangle Test Smell",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b259/573300b259.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Fedelucio",
				"surname": "Narducci"
			},
			"authorName": "Narducci, Fedelucio",
			"articleRefs": [
				{
					"pageNumber": 2400,
					"articleName": "LLMs for Automated Unit Test Generation and Assessment in Java: The AgoneTest Framework",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c400/573300c400.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Fumio",
				"surname": "Narisawa"
			},
			"authorName": "Narisawa, Fumio",
			"articleRefs": [
				{
					"pageNumber": 3771,
					"articleName": "Acceleration of Automotive Software Development by Retrieval Augmented Integration Test Script Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d771/573300d771.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Noor",
				"surname": "Nashid"
			},
			"authorName": "Nashid, Noor",
			"articleRefs": [
				{
					"pageNumber": 1628,
					"articleName": "Characterizing Multi-Hunk Patches: Divergence, Proximity, and LLM Repair Challenges",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b628/573300b628.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Vladimir",
				"surname": "Neluyb"
			},
			"authorName": "Neluyb, Vladimir",
			"articleRefs": [
				{
					"pageNumber": 229,
					"articleName": "Automated Evolutionary Hyperparameter Tuning for NLP-Based Test Case Generation",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a229/850300a229.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ziv",
				"surname": "Nevo"
			},
			"authorName": "Nevo, Ziv",
			"articleRefs": [
				{
					"pageNumber": 7,
					"articleName": "Uncovering Code Insights: Leveraging GitHub Artifacts for Deeper Code Understanding",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a007/850300a007.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Dung Tuan",
				"surname": "Nguyen"
			},
			"authorName": "Nguyen, Dung Tuan",
			"articleRefs": [
				{
					"pageNumber": 1552,
					"articleName": "It's Not Easy Being Green: On the Energy Efficiency of Programming Languages",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b552/573300b552.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Guillaume",
				"surname": "Nguyen"
			},
			"authorName": "Nguyen, Guillaume",
			"articleRefs": [
				{
					"pageNumber": 4028,
					"articleName": "FETT: Fault Injection as an Educational and Training Tool in Cybersecurity",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e028/573300e028.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Minh",
				"surname": "Nguyen"
			},
			"authorName": "Nguyen, Minh",
			"articleRefs": [
				{
					"pageNumber": 365,
					"articleName": "SpareCodeSearch: Searching for Code Context When You Have No Spare GPU",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a365/850300a365.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "ThanhVu",
				"surname": "Nguyen"
			},
			"authorName": "Nguyen, ThanhVu",
			"articleRefs": [
				{
					"pageNumber": 1350,
					"articleName": "Destabilizing Neurons to Generate Challenging Neural Network Verification Benchmarks",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b350/573300b350.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Chao",
				"surname": "Ni"
			},
			"authorName": "Ni, Chao",
			"articleRefs": [
				{
					"pageNumber": 317,
					"articleName": "PrefGen: A Preference-Driven Methodology for Secure Yet Gas-Efficient Smart Contract Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a317/573300a317.pdf"
				},
				{
					"pageNumber": 623,
					"articleName": "Enhancing LLM's Ability to Generate More Repository-Aware Unit Tests Through Precise Context Injection",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a623/573300a623.pdf"
				},
				{
					"pageNumber": 687,
					"articleName": "Navigating the Labyrinth: Path-Sensitive Unit Test Generation with Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a687/573300a687.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xiaohui",
				"surname": "Nie"
			},
			"authorName": "Nie, Xiaohui",
			"articleRefs": [
				{
					"pageNumber": 3238,
					"articleName": "TrioXpert: An Automated Incident Management Framework for Microservice System",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d238/573300d238.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Kaiwen",
				"surname": "Ning"
			},
			"authorName": "Ning, Kaiwen",
			"articleRefs": [
				{
					"pageNumber": 1528,
					"articleName": "Finding Insecure State Dependency in DApps via Multi-Source Tracing and Semantic Enrichment",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b528/573300b528.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yan",
				"surname": "Niu"
			},
			"authorName": "Niu, Yan",
			"articleRefs": [
				{
					"pageNumber": 700,
					"articleName": "LogAction: Consistent Cross-System Anomaly Detection Through Logs via Active Domain Adaptation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a700/573300a700.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yannic",
				"surname": "Noller"
			},
			"authorName": "Noller, Yannic",
			"articleRefs": [
				{
					"pageNumber": 342,
					"articleName": "Risk Estimation in Differential Fuzzing via Extreme Value Theory",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a342/573300a342.pdf"
				},
				{
					"pageNumber": 3895,
					"articleName": "Simulated Interactive Debugging",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d895/573300d895.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Saad Sakib",
				"surname": "Noor"
			},
			"authorName": "Noor, Saad Sakib",
			"articleRefs": [
				{
					"pageNumber": 4109,
					"articleName": "CLARA: A Developer's Companion for Code Comprehension and Analysis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e109/573300e109.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Michael ",
				"surname": "Norris"
			},
			"authorName": "Norris, Michael",
			"articleRefs": [
				{
					"pageNumber": 2893,
					"articleName": "Better Safe than Sorry: Preventing Policy Violations Through Predictive Root-Cause-Analysis for IoT Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c893/573300c893.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Florian",
				"surname": "Oberm\u00FCller"
			},
			"authorName": "Oberm\u00FCller, Florian",
			"articleRefs": [
				{
					"pageNumber": 3988,
					"articleName": "LitterBox+: An Extensible Framework for LLM-Enhanced Scratch Static Code Analysis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d988/573300d988.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Dmitry",
				"surname": "Obydenkov"
			},
			"authorName": "Obydenkov, Dmitry",
			"articleRefs": [
				{
					"pageNumber": 4032,
					"articleName": "WIBE: Watermarks for generated Images \u2013 Benchmarking & Evaluation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e032/573300e032.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Sanghak",
				"surname": "Oh"
			},
			"authorName": "Oh, Sanghak",
			"articleRefs": [
				{
					"pageNumber": 2956,
					"articleName": "When Does Wasm Malware Detection Fail? A Systematic Analysis of Their Robustness to Evasion",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c956/573300c956.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Dan",
				"surname": "O'Keeffe"
			},
			"authorName": "O'Keeffe, Dan",
			"articleRefs": [
				{
					"pageNumber": 3793,
					"articleName": "Measuring Software Resilience Using Socially Aware Truck Factor Estimation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d793/573300d793.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Gustavo A.",
				"surname": "Oliva"
			},
			"authorName": "Oliva, Gustavo A.",
			"articleRefs": [
				{
					"pageNumber": 2324,
					"articleName": "SPICE\uD83C\uDF36\uFE0F: An Automated SWE-Bench Labeling Pipeline for Issue Clarity, Test Coverage, and Effort Estimation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c324/573300c324.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Alejandro",
				"surname": "Olivas"
			},
			"authorName": "Olivas, Alejandro",
			"articleRefs": [
				{
					"pageNumber": 342,
					"articleName": "Risk Estimation in Differential Fuzzing via Extreme Value Theory",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a342/573300a342.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Dillon",
				"surname": "Otto"
			},
			"authorName": "Otto, Dillon",
			"articleRefs": [
				{
					"pageNumber": 1131,
					"articleName": "GUIFuzz++: Unleashing Grey-box Fuzzing on Desktop Graphical User Interfacing Applications ",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b131/573300b131.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Guangshen",
				"surname": "Ou"
			},
			"authorName": "Ou, Guangshen",
			"articleRefs": [
				{
					"pageNumber": 610,
					"articleName": "RustRepoTrans: Repository-Level Context Code Translation Benchmark Targeting Rust",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a610/573300a610.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Wendkuuni A. M. Christian ",
				"surname": "Ouedraogo"
			},
			"authorName": "Ouedraogo, Wendkuuni A. M. Christian",
			"articleRefs": [
				{
					"pageNumber": 4117,
					"articleName": "evalSmarT: An LLM-Based Framework for Evaluating Smart Contract Generated Comments",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e117/573300e117.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jin",
				"surname": "Ouyang"
			},
			"authorName": "Ouyang, Jin",
			"articleRefs": [
				{
					"pageNumber": 3191,
					"articleName": "KAIOps: A Platform Solution of End-to-End Multi-Modal AIOps for AI Training at Scale",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d191/573300d191.pdf"
				},
				{
					"pageNumber": 3753,
					"articleName": "KAIR: A Statistical and Causal Approach to Pinpointing Stragglers in Distributed Model Training",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d753/573300d753.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Sheng",
				"surname": "Ouyang"
			},
			"authorName": "Ouyang, Sheng",
			"articleRefs": [
				{
					"pageNumber": 804,
					"articleName": "Let the Code Speak: Incorporating Program Dynamic State for Better Method-Level Fault Localization",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a804/573300a804.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yavuz Alp Sencer",
				"surname": "\u00D6zt\u00FCrk"
			},
			"authorName": "\u00D6zt\u00FCrk, Yavuz Alp Sencer",
			"articleRefs": [
				{
					"pageNumber": 3094,
					"articleName": "Agents in the Sandbox: End-to-End Crash Bug Reproduction for Minecraft",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d094/573300d094.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Tapti",
				"surname": "Palit"
			},
			"authorName": "Palit, Tapti",
			"articleRefs": [
				{
					"pageNumber": 534,
					"articleName": "RustAssure: Differential Symbolic Testing for LLM-Transpiled C-to-Rust Code",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a534/573300a534.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Haolin",
				"surname": "Pan"
			},
			"authorName": "Pan, Haolin",
			"articleRefs": [
				{
					"pageNumber": 1755,
					"articleName": "HybridSIMD: A Super C++ SIMD Library with Integrated Auto-Tuning Capabilities",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b755/573300b755.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Lingfeng",
				"surname": "Pan"
			},
			"authorName": "Pan, Lingfeng",
			"articleRefs": [
				{
					"pageNumber": 1142,
					"articleName": "Hypergraph Neural Network-Based Multi-Granular Root Cause Localization for Microservice Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b142/573300b142.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Long",
				"surname": "Pan"
			},
			"authorName": "Pan, Long",
			"articleRefs": [
				{
					"pageNumber": 1,
					"articleName": "AlertGuardian: Intelligent Alert Life-Cycle Management for Large-Scale Cloud Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a001/573300a001.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Minxue",
				"surname": "Pan"
			},
			"authorName": "Pan, Minxue",
			"articleRefs": [
				{
					"pageNumber": 1389,
					"articleName": "NATE: A Network-Aware Testing Enhancer for Network-Related Fault Detection in Android Apps",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b389/573300b389.pdf"
				},
				{
					"pageNumber": 2782,
					"articleName": "Understanding Feature Request Practice on GitHub via a Large-Scale Empirical Study",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c782/573300c782.pdf"
				},
				{
					"pageNumber": 2820,
					"articleName": "PoliCond: Condition-Aware Ontology-Driven LLMs for Privacy Policy Contradiction Analysis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c820/573300c820.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ruwei",
				"surname": "Pan"
			},
			"authorName": "Pan, Ruwei",
			"articleRefs": [
				{
					"pageNumber": 4008,
					"articleName": "AgentDroid: A Multi-Agent Tool for Detecting Fraudulent Android Applications",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e008/573300e008.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Shengyi",
				"surname": "Pan"
			},
			"authorName": "Pan, Shengyi",
			"articleRefs": [
				{
					"pageNumber": 2503,
					"articleName": "Unit Test Update Through LLM-Driven Context Collection and Error-Type-Aware Refinement",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c503/573300c503.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Shidong",
				"surname": "Pan"
			},
			"authorName": "Pan, Shidong",
			"articleRefs": [
				{
					"pageNumber": 687,
					"articleName": "Navigating the Labyrinth: Path-Sensitive Unit Test Generation with Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a687/573300a687.pdf"
				},
				{
					"pageNumber": 4004,
					"articleName": "Towards Context-Aware Mobile Privacy Notice: Implementation of A Deployable Contextual Privacy Policies Generator",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e004/573300e004.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Haomin ",
				"surname": "Pang"
			},
			"authorName": "Pang, Haomin",
			"articleRefs": [
				{
					"pageNumber": 1168,
					"articleName": "When Autonomous Vehicle Meets V2X Cooperative Perception: How Far Are We?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b168/573300b168.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Annibale ",
				"surname": "Panichella"
			},
			"authorName": "Panichella, Annibale",
			"articleRefs": [
				{
					"pageNumber": 66,
					"articleName": "The Last Dependency Crusade: Solving Python Dependency Conflicts with LLMs",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a066/850300a066.pdf"
				},
				{
					"pageNumber": 3828,
					"articleName": "The Future of Software Transparency: Bridging Understanding, Measurement, and Practice",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d828/573300d828.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Sebastiano",
				"surname": "Panichella"
			},
			"authorName": "Panichella, Sebastiano",
			"articleRefs": [
				{
					"pageNumber": 3356,
					"articleName": "Bridging Research and Practice in Simulation-Based Testing of Industrial Robot Navigation Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d356/573300d356.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jai",
				"surname": "Parera"
			},
			"authorName": "Parera, Jai",
			"articleRefs": [
				{
					"pageNumber": 4044,
					"articleName": "Chrysalis: A Lightweight Logging and Replay Framework for Metamorphic Testing in Python",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e044/573300e044.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jihun",
				"surname": "Park"
			},
			"authorName": "Park, Jihun",
			"articleRefs": [
				{
					"pageNumber": 3865,
					"articleName": "Unseen Data Detection using Routing Entropy in Mixture-of-Experts for Autonomous Vehicles",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d865/573300d865.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jihyeok",
				"surname": "Park"
			},
			"authorName": "Park, Jihyeok",
			"articleRefs": [
				{
					"pageNumber": 78,
					"articleName": "Debun: Detecting Bundled JavaScript Libraries on Web using Property-Order Graphs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a078/573300a078.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Sungmin",
				"surname": "Park"
			},
			"authorName": "Park, Sungmin",
			"articleRefs": [
				{
					"pageNumber": 78,
					"articleName": "Debun: Detecting Bundled JavaScript Libraries on Web using Property-Order Graphs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a078/573300a078.pdf"
				},
				{
					"pageNumber": 4121,
					"articleName": "Verification and Classification of Exploits for Node.js Vulnerabilities",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e121/573300e121.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Esteban",
				"surname": "Parra"
			},
			"authorName": "Parra, Esteban",
			"articleRefs": [
				{
					"pageNumber": 1439,
					"articleName": "Hierarchical Knowledge Injection for Improving LLM-Based Program Repair",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b439/573300b439.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jo\u00E3o",
				"surname": "Pascoal Faria"
			},
			"authorName": "Pascoal Faria, Jo\u00E3o",
			"articleRefs": [
				{
					"pageNumber": 3310,
					"articleName": "Streamlining Acceptance Test Generation for Mobile Applications Through Large Language Models: An Industrial Case Study",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d310/573300d310.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Fabrizio",
				"surname": "Pastore"
			},
			"authorName": "Pastore, Fabrizio",
			"articleRefs": [
				{
					"pageNumber": 3980,
					"articleName": "DESIGNATOR: a Toolset for Automated GAN-Enhanced Search-Based Testing and Retraining of DNNs in Martian Environments",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d980/573300d980.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jirat",
				"surname": "Pasuksmit"
			},
			"authorName": "Pasuksmit, Jirat",
			"articleRefs": [
				{
					"pageNumber": 3759,
					"articleName": "What Types of Code Review Comments Do Developers Most Frequently Resolve?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d759/573300d759.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ajim",
				"surname": "Pathan"
			},
			"authorName": "Pathan, Ajim",
			"articleRefs": [
				{
					"pageNumber": 14,
					"articleName": "Leveraging LLM for Software Modernization: COBOL Functionality Extraction Case Study",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a014/850300a014.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Manasi",
				"surname": "Patwardhan"
			},
			"authorName": "Patwardhan, Manasi",
			"articleRefs": [
				{
					"pageNumber": 22,
					"articleName": "Microservices Identification Using LLM",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a022/850300a022.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Brandon",
				"surname": "Paulsen"
			},
			"authorName": "Paulsen, Brandon",
			"articleRefs": [
				{
					"pageNumber": 1452,
					"articleName": "VERT: Polyglot Verified Equivalent Rust Transpilation with Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b452/573300b452.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Laurent",
				"surname": "Pautet"
			},
			"authorName": "Pautet, Laurent",
			"articleRefs": [
				{
					"pageNumber": 2183,
					"articleName": "Altered Histories in Version Control System Repositories: Evidence from the Trenches",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c183/573300c183.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Mrigank",
				"surname": "Pawagi"
			},
			"authorName": "Pawagi, Mrigank",
			"articleRefs": [
				{
					"pageNumber": 1233,
					"articleName": "RFCScope: Detecting Logical Ambiguities in Internet Protocol Specifications",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b233/573300b233.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Fatih",
				"surname": "Pehlivan"
			},
			"authorName": "Pehlivan, Fatih",
			"articleRefs": [
				{
					"pageNumber": 3957,
					"articleName": "Are We SOLID Yet? An Empirical Study on Prompting LLMs to Detect Design Principle Violations",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d957/573300d957.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Dan",
				"surname": "Pei"
			},
			"authorName": "Pei, Dan",
			"articleRefs": [
				{
					"pageNumber": 674,
					"articleName": "Triangle: Empowering Incident Triage with Multi-Agent",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a674/573300a674.pdf"
				},
				{
					"pageNumber": 3497,
					"articleName": "Adaptive Performance Regression Detection Using A Semi-Supervised Siamese Network",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d497/573300d497.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Kexin",
				"surname": "Pei"
			},
			"authorName": "Pei, Kexin",
			"articleRefs": [
				{
					"pageNumber": 380,
					"articleName": "Towards More Accurate Static Analysis for Taint-Style Bug Detection in Linux Kernel",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a380/573300a380.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Chao",
				"surname": "Peng"
			},
			"authorName": "Peng, Chao",
			"articleRefs": [
				{
					"pageNumber": 2426,
					"articleName": "An Agent-Based Evaluation Framework for Complex Code Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c426/573300c426.pdf"
				},
				{
					"pageNumber": 3671,
					"articleName": "RepoMasterEval: Evaluating Code Completion via Real-World Repositories",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d671/573300d671.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Fei",
				"surname": "Peng"
			},
			"authorName": "Peng, Fei",
			"articleRefs": [
				{
					"pageNumber": 457,
					"articleName": "Uncovering Prompt Elements: Cloning System Prompts from Behavioral Traces",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a457/573300a457.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xin",
				"surname": "Peng"
			},
			"authorName": "Peng, Xin",
			"articleRefs": [
				{
					"pageNumber": 13,
					"articleName": "Argus: Resilience-Oriented Safety Assurance Framework for End-to-End ADSs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a013/573300a013.pdf"
				},
				{
					"pageNumber": 419,
					"articleName": "ProfMal: Detecting Malicious NPM Packages by the Synergy between Static and Dynamic Analysis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a419/573300a419.pdf"
				},
				{
					"pageNumber": 610,
					"articleName": "RustRepoTrans: Repository-Level Context Code Translation Benchmark Targeting Rust",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a610/573300a610.pdf"
				},
				{
					"pageNumber": 804,
					"articleName": "Let the Code Speak: Incorporating Program Dynamic State for Better Method-Level Fault Localization",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a804/573300a804.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xinyong ",
				"surname": "Peng"
			},
			"authorName": "Peng, Xinyong",
			"articleRefs": [
				{
					"pageNumber": 3132,
					"articleName": "JSidentify-V2: Leveraging Dynamic Memory Fingerprinting for Mini-Game Plagiarism Detection",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d132/573300d132.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yun",
				"surname": "Peng"
			},
			"authorName": "Peng, Yun",
			"articleRefs": [
				{
					"pageNumber": 1830,
					"articleName": "PEACE: Towards Efficient Project-Level Efficiency Optimization via Hybrid Code Editing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b830/573300b830.pdf"
				},
				{
					"pageNumber": 2905,
					"articleName": "Metamorphic Testing for Audio Content Moderation Software",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c905/573300c905.pdf"
				},
				{
					"pageNumber": 3203,
					"articleName": "iCodeReviewer: Improving Secure Code Review with Mixture of Prompts",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d203/573300d203.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zhihao",
				"surname": "Peng"
			},
			"authorName": "Peng, Zhihao",
			"articleRefs": [
				{
					"pageNumber": 1843,
					"articleName": "MCTS-Refined CoT: High-Quality Fine-Tuning Data for LLM-Based Repository Issue Resolution",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b843/573300b843.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zhiyuan",
				"surname": "Peng"
			},
			"authorName": "Peng, Zhiyuan",
			"articleRefs": [
				{
					"pageNumber": 317,
					"articleName": "PrefGen: A Preference-Driven Methodology for Secure Yet Gas-Efficient Smart Contract Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a317/573300a317.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Valentin ",
				"surname": "Perrelle"
			},
			"authorName": "Perrelle, Valentin",
			"articleRefs": [
				{
					"pageNumber": 291,
					"articleName": "Loupe: End-to-End Learning of Loop Unrolling Heuristics for Abstract Interpretation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a291/573300a291.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Justyna",
				"surname": "Petke"
			},
			"authorName": "Petke, Justyna",
			"articleRefs": [
				{
					"pageNumber": 107,
					"articleName": "From Kotlin to Swift and Back: Toward Fully Automated Cross-Language Code Transpilation",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a107/850300a107.pdf"
				},
				{
					"pageNumber": 3901,
					"articleName": "LLM-Guided Genetic Improvement: Envisioning Semantic Aware Automated Software Evolution",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d901/573300d901.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Thomas",
				"surname": "Peyrucain"
			},
			"authorName": "Peyrucain, Thomas",
			"articleRefs": [
				{
					"pageNumber": 3402,
					"articleName": "Out of Distribution Detection in Self-Adaptive Robots with AI-Powered Digital Twins",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d402/573300d402.pdf"
				},
				{
					"pageNumber": 3694,
					"articleName": "Quantum Machine Learning-Based Test Oracle for Autonomous Mobile Robots",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d694/573300d694.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Mauro",
				"surname": "Pezz\u00E8"
			},
			"authorName": "Pezz\u00E8, Mauro",
			"articleRefs": [
				{
					"pageNumber": 278,
					"articleName": "Do LLMs Generate Useful Test Oracles? An Empirical Study with an Unbiased Dataset",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a278/573300a278.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Tri Minh-Triet",
				"surname": "Pham"
			},
			"authorName": "Pham, Tri Minh-Triet",
			"articleRefs": [
				{
					"pageNumber": 1704,
					"articleName": "ADPerf: Investigating and Testing Performance in Autonomous Driving Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b704/573300b704.pdf"
				},
				{
					"pageNumber": 2592,
					"articleName": "On the Robustness Evaluation of 3D Obstacle Detection Against Specifications in Autonomous Driving",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c592/573300c592.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ruzica",
				"surname": "Piskac"
			},
			"authorName": "Piskac, Ruzica",
			"articleRefs": [
				{
					"pageNumber": 1324,
					"articleName": "Efficient and Verifiable Proof Logging for MaxSAT Solving",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b324/573300b324.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Kevin",
				"surname": "Pitstick"
			},
			"authorName": "Pitstick, Kevin",
			"articleRefs": [
				{
					"pageNumber": 3947,
					"articleName": "Vessel: A Taxonomy of Reproducibility Issues for Container Images",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d947/573300d947.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Alice ",
				"surname": "Podolsky"
			},
			"authorName": "Podolsky, Alice",
			"articleRefs": [
				{
					"pageNumber": 30,
					"articleName": "Vintage Code, Modern Judges: Meta-Validation in Low Data Regimes",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a030/850300a030.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Aneta",
				"surname": "Poniszewska-Maranda"
			},
			"authorName": "Poniszewska-Maranda, Aneta",
			"articleRefs": [
				{
					"pageNumber": 304,
					"articleName": "Multi-agent systems for improved information retrieval \u2013 leveraging autonomous agents and LLM models",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a304/850300a304.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Simone Paolo",
				"surname": "Ponzetto"
			},
			"authorName": "Ponzetto, Simone Paolo",
			"articleRefs": [
				{
					"pageNumber": 4052,
					"articleName": "GUI-ReRank: Enhancing GUI Retrieval with Multi-Modal LLM-Based Reranking",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e052/573300e052.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Pablo",
				"surname": "Ponzio"
			},
			"authorName": "Ponzio, Pablo",
			"articleRefs": [
				{
					"pageNumber": 2918,
					"articleName": "Automated Combinatorial Test Generation for Alloy",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c918/573300c918.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Christopher M.",
				"surname": "Poskitt"
			},
			"authorName": "Poskitt, Christopher M.",
			"articleRefs": [
				{
					"pageNumber": 3895,
					"articleName": "Simulated Interactive Debugging",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d895/573300d895.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Michael",
				"surname": "Pradel"
			},
			"authorName": "Pradel, Michael",
			"articleRefs": [
				{
					"pageNumber": 816,
					"articleName": "Execution-Aware Program Reduction for WebAssembly via Record and Replay",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a816/573300a816.pdf"
				},
				{
					"pageNumber": 2845,
					"articleName": "Understanding Software Engineering Agents: A Study of Thought-Action-Result Trajectories",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c845/573300c845.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Diany",
				"surname": "Pressato"
			},
			"authorName": "Pressato, Diany",
			"articleRefs": [
				{
					"pageNumber": 983,
					"articleName": "Coverage-Based Harmfulness Testing for LLM Code Transformation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a983/573300a983.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Alexander",
				"surname": "Pretschner"
			},
			"authorName": "Pretschner, Alexander",
			"articleRefs": [
				{
					"pageNumber": 3215,
					"articleName": "Should We Evaluate LLM Based Security Analysis Approaches on Open Source Systems?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d215/573300d215.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Foivos Timotheos",
				"surname": "Proestakis"
			},
			"authorName": "Proestakis, Foivos Timotheos",
			"articleRefs": [
				{
					"pageNumber": 4069,
					"articleName": "PyTrim: A Practical Tool for Reducing Python Dependency Bloat",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e069/573300e069.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Geguang",
				"surname": "Pu"
			},
			"authorName": "Pu, Geguang",
			"articleRefs": [
				{
					"pageNumber": 129,
					"articleName": "Diagnosing Performance Differences in Model Checkers via Runtime-Guided Problem Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a129/573300a129.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Junsong ",
				"surname": "Pu"
			},
			"authorName": "Pu, Junsong",
			"articleRefs": [
				{
					"pageNumber": 3425,
					"articleName": "Automated Proactive Logging Quality Improvement for Large-Scale Codebases ",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d425/573300d425.pdf"
				},
				{
					"pageNumber": 3533,
					"articleName": "ErrorPrism: Reconstructing Error Propagation Paths in Cloud Service Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d533/573300d533.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ilham",
				"surname": "Qasse"
			},
			"authorName": "Qasse, Ilham",
			"articleRefs": [
				{
					"pageNumber": 4113,
					"articleName": "PROXiFY: A Bytecode Analysis Tool for Detecting and Classifying Proxy Contracts in Ethereum Smart Contracts",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e113/573300e113.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Binhang",
				"surname": "Qi"
			},
			"authorName": "Qi, Binhang",
			"articleRefs": [
				{
					"pageNumber": 1376,
					"articleName": "Learning Project-Wise Subsequent Code Edits via Interleaving Neural-Based Induction and Tool-Based Deduction",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b376/573300b376.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jiaxing",
				"surname": "Qi"
			},
			"authorName": "Qi, Jiaxing",
			"articleRefs": [
				{
					"pageNumber": 330,
					"articleName": "LogMoE: Lightweight Expert Mixture for Cross-System Log Anomaly Detection",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a330/573300a330.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Keyu",
				"surname": "Qi"
			},
			"authorName": "Qi, Keyu",
			"articleRefs": [
				{
					"pageNumber": 1069,
					"articleName": "A Large Scale Study of AI-Based Binary Function Similarity Detection Techniques for Security Researchers and Practitioners",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b069/573300b069.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Depei",
				"surname": "Qian"
			},
			"authorName": "Qian, Depei",
			"articleRefs": [
				{
					"pageNumber": 330,
					"articleName": "LogMoE: Lightweight Expert Mixture for Cross-System Log Anomaly Detection",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a330/573300a330.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Feng",
				"surname": "Qian"
			},
			"authorName": "Qian, Feng",
			"articleRefs": [
				{
					"pageNumber": 393,
					"articleName": "Democratizing the Cryptocurrency Ecosystem by Just-In-Time Transformation of Mining Programs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a393/573300a393.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yi",
				"surname": "Qian"
			},
			"authorName": "Qian, Yi",
			"articleRefs": [
				{
					"pageNumber": 457,
					"articleName": "Uncovering Prompt Elements: Cloning System Prompts from Behavioral Traces",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a457/573300a457.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yichun",
				"surname": "Qian"
			},
			"authorName": "Qian, Yichun",
			"articleRefs": [
				{
					"pageNumber": 141,
					"articleName": "LongCodeZip: Compress Long Context for Code Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a141/573300a141.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zhiyun",
				"surname": "Qian"
			},
			"authorName": "Qian, Zhiyun",
			"articleRefs": [
				{
					"pageNumber": 380,
					"articleName": "Towards More Accurate Static Analysis for Taint-Style Bug Detection in Linux Kernel",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a380/573300a380.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yaqiong",
				"surname": "Qiao"
			},
			"authorName": "Qiao, Yaqiong",
			"articleRefs": [
				{
					"pageNumber": 2145,
					"articleName": "Don't Mess with Bro's Cheese! An Empirical Study of Resource Conflict in Android Multi-Window",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c145/573300c145.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Haoran",
				"surname": "Qin"
			},
			"authorName": "Qin, Haoran",
			"articleRefs": [
				{
					"pageNumber": 1463,
					"articleName": "ScaleCirc: Scaling the Analysis over Circom Circuits",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b463/573300b463.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Shengchao",
				"surname": "Qin"
			},
			"authorName": "Qin, Shengchao",
			"articleRefs": [
				{
					"pageNumber": 1207,
					"articleName": "Bridging Natural Language and Formal Specification Automated Translation of Software Requirements to LTL via Hierarchical Semantics Decomposition Using LLMs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b207/573300b207.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xiaokang",
				"surname": "Qin"
			},
			"authorName": "Qin, Xiaokang",
			"articleRefs": [
				{
					"pageNumber": 393,
					"articleName": "Democratizing the Cryptocurrency Ecosystem by Just-In-Time Transformation of Mining Programs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a393/573300a393.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xue",
				"surname": "Qin"
			},
			"authorName": "Qin, Xue",
			"articleRefs": [
				{
					"pageNumber": 332,
					"articleName": "NavAI: A Generalizable LLM Framework for Navigation Tasks in Virtual Reality Environments",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a332/850300a332.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yihao",
				"surname": "Qin"
			},
			"authorName": "Qin, Yihao",
			"articleRefs": [
				{
					"pageNumber": 804,
					"articleName": "Let the Code Speak: Incorporating Program Dynamic State for Better Method-Level Fault Localization",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a804/573300a804.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Sihao",
				"surname": "Qiu"
			},
			"authorName": "Qiu, Sihao",
			"articleRefs": [
				{
					"pageNumber": 1069,
					"articleName": "A Large Scale Study of AI-Based Binary Function Similarity Detection Techniques for Security Researchers and Practitioners",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b069/573300b069.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yibo",
				"surname": "Qu"
			},
			"authorName": "Qu, Yibo",
			"articleRefs": [
				{
					"pageNumber": 2082,
					"articleName": "Breaking the Traffic Barrier: Unveiling Multi-Format of Protocols via Autonomous Program Exploration",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c082/573300c082.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Lili",
				"surname": "Quan"
			},
			"authorName": "Quan, Lili",
			"articleRefs": [
				{
					"pageNumber": 2095,
					"articleName": "SPEC2CODE: Mapping Protocol Specification to Function-Level Code Implementation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c095/573300c095.pdf"
				},
				{
					"pageNumber": 4061,
					"articleName": "DSBox: A Data Selection Framework for Efficient Deep Code Learning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e061/573300e061.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Cl\u00E9ment",
				"surname": "Quinton"
			},
			"authorName": "Quinton, Cl\u00E9ment",
			"articleRefs": [
				{
					"pageNumber": 1654,
					"articleName": "When Faster Isn't Greener: The Hidden Costs of LLM-Based Code Optimization",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b654/573300b654.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Tomasz ",
				"surname": "Radzik"
			},
			"authorName": "Radzik, Tomasz",
			"articleRefs": [
				{
					"pageNumber": 4016,
					"articleName": "ReFuzzer: Feedback-Driven Approach to Enhance Validity of LLM-Generated Test Programs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e016/573300e016.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Bassel",
				"surname": "Rafie"
			},
			"authorName": "Rafie, Bassel",
			"articleRefs": [
				{
					"pageNumber": 165,
					"articleName": "VeriODD: From YAML to SMT-LIB \u2013 Automating Verification of Operational Design Domains",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a165/850300a165.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Chaiyong",
				"surname": "Ragkhitwetsagul"
			},
			"authorName": "Ragkhitwetsagul, Chaiyong",
			"articleRefs": [
				{
					"pageNumber": 261,
					"articleName": "Exploring the SECURITY.md in the Dependency Chain: Preliminary Analysis of the PyPI Ecosystem",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a261/850300a261.pdf"
				},
				{
					"pageNumber": 3996,
					"articleName": "PyGress: Tool for Analyzing the Progression of Code Proficiency in Python OSS Projects",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d996/573300d996.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Azzurra",
				"surname": "Ragone"
			},
			"authorName": "Ragone, Azzurra",
			"articleRefs": [
				{
					"pageNumber": 2400,
					"articleName": "LLMs for Automated Unit Test Generation and Assessment in Java: The AgoneTest Framework",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c400/573300c400.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Imranur",
				"surname": "Rahman"
			},
			"authorName": "Rahman, Imranur",
			"articleRefs": [
				{
					"pageNumber": 380,
					"articleName": "Relative Positioning Based Code Chunking Method For Rich Context Retrieval In Repository Level Code Completion Task With Code Language Model",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a380/850300a380.pdf"
				},
				{
					"pageNumber": 2794,
					"articleName": "Which Is Better For Reducing Outdated and Vulnerable Dependencies: Pinning or Floating?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c794/573300c794.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Md Rayhanur",
				"surname": "Rahman"
			},
			"authorName": "Rahman, Md Rayhanur",
			"articleRefs": [
				{
					"pageNumber": 380,
					"articleName": "Relative Positioning Based Code Chunking Method For Rich Context Retrieval In Repository Level Code Completion Task With Code Language Model",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a380/850300a380.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Mushfiqur",
				"surname": "Rahman"
			},
			"authorName": "Rahman, Mushfiqur",
			"articleRefs": [
				{
					"pageNumber": 4109,
					"articleName": "CLARA: A Developer's Companion for Code Comprehension and Analysis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e109/573300e109.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Anita",
				"surname": "Raja"
			},
			"authorName": "Raja, Anita",
			"articleRefs": [
				{
					"pageNumber": 752,
					"articleName": "Speculative Automated Refactoring of Imperative Deep Learning Programs to Graph Execution",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a752/573300a752.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Gopi Krishnan",
				"surname": "Rajbahadur"
			},
			"authorName": "Rajbahadur, Gopi Krishnan",
			"articleRefs": [
				{
					"pageNumber": 2324,
					"articleName": "SPICE\uD83C\uDF36\uFE0F: An Automated SWE-Bench Labeling Pipeline for Issue Clarity, Test Coverage, and Effort Estimation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c324/573300c324.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "ASHA",
				"surname": "RAJBHOJ"
			},
			"authorName": "RAJBHOJ, ASHA",
			"articleRefs": [
				{
					"pageNumber": 14,
					"articleName": "Leveraging LLM for Software Modernization: COBOL Functionality Extraction Case Study",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a014/850300a014.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Saravan",
				"surname": "Rajmohan"
			},
			"authorName": "Rajmohan, Saravan",
			"articleRefs": [
				{
					"pageNumber": 674,
					"articleName": "Triangle: Empowering Incident Triage with Multi-Agent",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a674/573300a674.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Keshav",
				"surname": "Ramani"
			},
			"authorName": "Ramani, Keshav",
			"articleRefs": [
				{
					"pageNumber": 39,
					"articleName": "Bridging LLM Planning Agents and Formal Methods: A Case Study in Plan Verification",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a039/850300a039.pdf"
				},
				{
					"pageNumber": 288,
					"articleName": "ALMAS: An Autonomous LLM-Based Multi-Agent Software Engineering Framework",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a288/850300a288.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Dezhi",
				"surname": "Ran"
			},
			"authorName": "Ran, Dezhi",
			"articleRefs": [
				{
					"pageNumber": 3144,
					"articleName": "Practical Escape of Exploration Tarpits for Mini-Game Testing in an Industrial Setting",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d144/573300d144.pdf"
				},
				{
					"pageNumber": 3580,
					"articleName": "Element-Aware Fine-Tuning of Vision-Language Models for Cost-Efficient GUI Testing in an Industrial Setting",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d580/573300d580.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Gareema",
				"surname": "Ranjan"
			},
			"authorName": "Ranjan, Gareema",
			"articleRefs": [
				{
					"pageNumber": 2931,
					"articleName": "The Cost of Downgrading Build Systems A Case Study of Kubernetes",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c931/573300c931.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Solal",
				"surname": "Rapaport"
			},
			"authorName": "Rapaport, Solal",
			"articleRefs": [
				{
					"pageNumber": 2183,
					"articleName": "Altered Histories in Version Control System Repositories: Evidence from the Trenches",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c183/573300c183.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Andreas",
				"surname": "Rausch"
			},
			"authorName": "Rausch, Andreas",
			"articleRefs": [
				{
					"pageNumber": 165,
					"articleName": "VeriODD: From YAML to SMT-LIB \u2013 Automating Verification of Operational Design Domains",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a165/850300a165.pdf"
				},
				{
					"pageNumber": 169,
					"articleName": "LLM-Assisted Tool for Joint Generation of Formulas and Functions in Rule-Based Verification of Map Transformations",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a169/850300a169.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Joshua",
				"surname": "Rauvola"
			},
			"authorName": "Rauvola, Joshua",
			"articleRefs": [
				{
					"pageNumber": 253,
					"articleName": "Fair Developer Score: Build-Adjusted Measurement of Effort and Impact",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a253/850300a253.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Orna",
				"surname": "Raz"
			},
			"authorName": "Raz, Orna",
			"articleRefs": [
				{
					"pageNumber": 7,
					"articleName": "Uncovering Code Insights: Leveraging GitHub Artifacts for Deeper Code Understanding",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a007/850300a007.pdf"
				},
				{
					"pageNumber": 30,
					"articleName": "Vintage Code, Modern Judges: Meta-Validation in Low Data Regimes",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a030/850300a030.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Germ\u00E1n",
				"surname": "Regis"
			},
			"authorName": "Regis, Germ\u00E1n",
			"articleRefs": [
				{
					"pageNumber": 2918,
					"articleName": "Automated Combinatorial Test Generation for Alloy",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c918/573300c918.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xin",
				"surname": " Ren"
			},
			"authorName": "Ren, Xin",
			"articleRefs": [
				{
					"pageNumber": 713,
					"articleName": "When Control Flows Deviate: Directed Grey-box Fuzzing with Probabilistic Reachability Analysis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a713/573300a713.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Daixu",
				"surname": "Ren"
			},
			"authorName": "Ren, Daixu",
			"articleRefs": [
				{
					"pageNumber": 4085,
					"articleName": "Metamorphic Testing of Deep Reinforcement Learning Agents with MDPMORPH",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e085/573300e085.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jikai",
				"surname": "Ren"
			},
			"authorName": "Ren, Jikai",
			"articleRefs": [
				{
					"pageNumber": 1106,
					"articleName": "BCFuzz: Bytecode-Driven Fuzzing for JavaScript Engines",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b106/573300b106.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Rui",
				"surname": "Ren"
			},
			"authorName": "Ren, Rui",
			"articleRefs": [
				{
					"pageNumber": 958,
					"articleName": "iKnow: an Intent-Guided Chatbot for Cloud Operations with Retrieval-Augmented Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a958/573300a958.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xiaoning",
				"surname": "Ren"
			},
			"authorName": "Ren, Xiaoning",
			"articleRefs": [
				{
					"pageNumber": 2045,
					"articleName": "Demystifying the Evolution of Neural Networks with BOM Analysis: Insights from a Large-Scale Study of 55,997 GitHub Repositories",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c045/573300c045.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xiaoxue",
				"surname": "Ren"
			},
			"authorName": "Ren, Xiaoxue",
			"articleRefs": [
				{
					"pageNumber": 1830,
					"articleName": "PEACE: Towards Efficient Project-Level Efficiency Optimization via Hybrid Code Editing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b830/573300b830.pdf"
				},
				{
					"pageNumber": 3033,
					"articleName": "Issue Localization via LLM-Driven Iterative Code Graph Searching",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d033/573300d033.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yimo",
				"surname": "Ren"
			},
			"authorName": "Ren, Yimo",
			"articleRefs": [
				{
					"pageNumber": 919,
					"articleName": "Lares: LLM-Driven Code Slice Semantic Search for Patch Presence Testing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a919/573300a919.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zhiqiang",
				"surname": "Ren"
			},
			"authorName": "Ren, Zhiqiang",
			"articleRefs": [
				{
					"pageNumber": 2221,
					"articleName": "LLM-Powered Multi-Agent Collaboration for Intelligent Industrial On-Call Automation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c221/573300c221.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yuming ",
				"surname": "Ren "
			},
			"authorName": "Ren, Yuming",
			"articleRefs": [
				{
					"pageNumber": 3592,
					"articleName": "AutoPLC: Generating Vendor-Aware Structured Text for Programmable Logic Controllers",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d592/573300d592.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Junghwan",
				"surname": "Rhee"
			},
			"authorName": "Rhee, Junghwan",
			"articleRefs": [
				{
					"pageNumber": 1590,
					"articleName": "IMUFUZZER: Resilience-Based Discovery of Signal Injection Attacks on Robotic Aerial Vehicles",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b590/573300b590.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Peter C",
				"surname": "Rigby"
			},
			"authorName": "Rigby, Peter C",
			"articleRefs": [
				{
					"pageNumber": 3250,
					"articleName": "Metrics Driven Reengineering and Continuous Code Improvement at Meta",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d250/573300d250.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Manuel",
				"surname": "Rigger"
			},
			"authorName": "Rigger, Manuel",
			"articleRefs": [
				{
					"pageNumber": 597,
					"articleName": "Automatic Fixing of Missing Dependency Errors",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a597/573300a597.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jan Oliver",
				"surname": "Ringert"
			},
			"authorName": "Ringert, Jan Oliver",
			"articleRefs": [
				{
					"pageNumber": 266,
					"articleName": "Evolution-Aware Heuristics for GR(1) Realizability Checking",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a266/573300a266.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Aleksandar",
				"surname": "Ristoski"
			},
			"authorName": "Ristoski, Aleksandar",
			"articleRefs": [
				{
					"pageNumber": 277,
					"articleName": "LLMs Choose the Right Stack: From Patterns to Tools",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a277/850300a277.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Maria",
				"surname": "Rivera"
			},
			"authorName": "Rivera, Maria",
			"articleRefs": [
				{
					"pageNumber": 338,
					"articleName": "ARTRIP: Automatic AR Testing with Randomized Interaction Patterns",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a338/850300a338.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Tobias",
				"surname": "Roehm"
			},
			"authorName": "Roehm, Tobias",
			"articleRefs": [
				{
					"pageNumber": 3215,
					"articleName": "Should We Evaluate LLM Based Security Analysis Approaches on Open Source Systems?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d215/573300d215.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jos\u00E9 Miguel",
				"surname": "Rojas"
			},
			"authorName": "Rojas, Jos\u00E9 Miguel",
			"articleRefs": [
				{
					"pageNumber": 326,
					"articleName": "A Test Automation Framework for User Interaction in Extended Reality Applications",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a326/850300a326.pdf"
				},
				{
					"pageNumber": 4012,
					"articleName": "XRINTTEST: An Automated Framework for User Interaction Testing in Extended Reality Applications",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e012/573300e012.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Benjamin",
				"surname": "Rombaut"
			},
			"authorName": "Rombaut, Benjamin",
			"articleRefs": [
				{
					"pageNumber": 739,
					"articleName": "Watson: A Cognitive Observability Framework for the Reasoning of LLM-Powered Agents",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a739/573300a739.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Huanyao",
				"surname": "Rong"
			},
			"authorName": "Rong, Huanyao",
			"articleRefs": [
				{
					"pageNumber": 893,
					"articleName": "LineBreaker: Finding Token-Inconsistency Bugs with Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a893/573300a893.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Siming",
				"surname": "Rong"
			},
			"authorName": "Rong, Siming",
			"articleRefs": [
				{
					"pageNumber": 1142,
					"articleName": "Hypergraph Neural Network-Based Multi-Granular Root Cause Localization for Microservice Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b142/573300b142.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Romain",
				"surname": "Rouvoy"
			},
			"authorName": "Rouvoy, Romain",
			"articleRefs": [
				{
					"pageNumber": 1654,
					"articleName": "When Faster Isn't Greener: The Hidden Costs of LLM-Based Code Optimization",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b654/573300b654.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Tanner",
				"surname": "Rowlett"
			},
			"authorName": "Rowlett, Tanner",
			"articleRefs": [
				{
					"pageNumber": 1131,
					"articleName": "GUIFuzz++: Unleashing Grey-box Fuzzing on Desktop Graphical User Interfacing Applications ",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b131/573300b131.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Subhajit",
				"surname": "Roy"
			},
			"authorName": "Roy, Subhajit",
			"articleRefs": [
				{
					"pageNumber": 3972,
					"articleName": "AndroFL: Evolutionary-Driven Fault Localization for Android Apps",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d972/573300d972.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Rui",
				"surname": "Rua"
			},
			"authorName": "Rua, Rui",
			"articleRefs": [
				{
					"pageNumber": 4040,
					"articleName": "BuilDroid: A Self-Correcting LLM Agent for Automated Android Builds",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e040/573300e040.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Bonan",
				"surname": "Ruan"
			},
			"authorName": "Ruan, Bonan",
			"articleRefs": [
				{
					"pageNumber": 65,
					"articleName": "Propagation-Based Vulnerability Impact Assessment for Software Supply Chains",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a065/573300a065.pdf"
				},
				{
					"pageNumber": 3984,
					"articleName": "A Large-Scale Evolvable Dataset for Model Context Protocol Ecosystem and Security Analysis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d984/573300d984.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Na",
				"surname": "Ruan"
			},
			"authorName": "Ruan, Na",
			"articleRefs": [
				{
					"pageNumber": 1044,
					"articleName": "PROMFUZZ: Leveraging LLM-Driven and Bug-Oriented Composite Analysis for Detecting Functional Bugs in Smart Contracts",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b044/573300b044.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Stefano",
				"surname": "Ruberto"
			},
			"authorName": "Ruberto, Stefano",
			"articleRefs": [
				{
					"pageNumber": 4101,
					"articleName": "LLMORPH: Automated Metamorphic Testing of Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e101/573300e101.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Julia",
				"surname": "Rubin"
			},
			"authorName": "Rubin, Julia",
			"articleRefs": [
				{
					"pageNumber": 79,
					"articleName": "Reliable and Interpretable Android Malware Detection at Scale",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a079/850300a079.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Antonio",
				"surname": "Ruiz-Cort\u00E9s"
			},
			"authorName": "Ruiz-Cort\u00E9s, Antonio",
			"articleRefs": [
				{
					"pageNumber": 1363,
					"articleName": "SATORI: Static Test Oracle Generation for REST APIs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b363/573300b363.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Sukyoung",
				"surname": "Ryu"
			},
			"authorName": "Ryu, Sukyoung",
			"articleRefs": [
				{
					"pageNumber": 816,
					"articleName": "Execution-Aware Program Reduction for WebAssembly via Record and Replay",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a816/573300a816.pdf"
				},
				{
					"pageNumber": 1402,
					"articleName": "WEST: Specification-Based Test Generation for WebAssembly",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b402/573300b402.pdf"
				},
				{
					"pageNumber": 1540,
					"articleName": "Forcrat: Automatic I/O API Translation from C to Rust via Origin and Capability Analysis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b540/573300b540.pdf"
				},
				{
					"pageNumber": 2464,
					"articleName": "Exact Inference for Quantum Circuits: A Testing Oracle for Quantum Software Stacks",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c464/573300c464.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Maher",
				"surname": "Saba"
			},
			"authorName": "Saba, Maher",
			"articleRefs": [
				{
					"pageNumber": 3250,
					"articleName": "Metrics Driven Reengineering and Continuous Code Improvement at Meta",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d250/573300d250.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Mersedeh",
				"surname": "Sadeghi"
			},
			"authorName": "Sadeghi, Mersedeh",
			"articleRefs": [
				{
					"pageNumber": 186,
					"articleName": "From Facts to Foils: Designing and Evaluating Counterfactual Explanations for Smart Environments",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a186/850300a186.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Salah",
				"surname": "Sadou"
			},
			"authorName": "Sadou, Salah",
			"articleRefs": [
				{
					"pageNumber": 291,
					"articleName": "Loupe: End-to-End Learning of Loop Unrolling Heuristics for Abstract Interpretation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a291/573300a291.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Chandan Kumar",
				"surname": "Sah"
			},
			"authorName": "Sah, Chandan Kumar",
			"articleRefs": [
				{
					"pageNumber": 4127,
					"articleName": "Understanding Uncertainty In LLMs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e127/573300e127.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Diptikalyan",
				"surname": "Saha"
			},
			"authorName": "Saha, Diptikalyan",
			"articleRefs": [
				{
					"pageNumber": 4077,
					"articleName": "Evaluating Program Coverage for Code-Model Training",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e077/573300e077.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Rijul",
				"surname": "Saini"
			},
			"authorName": "Saini, Rijul",
			"articleRefs": [
				{
					"pageNumber": 137,
					"articleName": "ForeSPECT: A Model-Driven Framework for Validation and Traceability in Forecasting Systems",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a137/850300a137.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Shin",
				"surname": "Saito"
			},
			"authorName": "Saito, Shin",
			"articleRefs": [
				{
					"pageNumber": 3,
					"articleName": "Grammar- and Coverage-Based Augmentation of Programs for Training LLMs",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a003/850300a003.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Shinobu",
				"surname": "Saito"
			},
			"authorName": "Saito, Shinobu",
			"articleRefs": [
				{
					"pageNumber": 3638,
					"articleName": "M2QCode: A Model-Driven Framework for Generating Multi-Platform Quantum Programs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d638/573300d638.pdf"
				},
				{
					"pageNumber": 3967,
					"articleName": "A Secure Mocking Approach Towards Software Supply Chain Security",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d967/573300d967.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Kazi",
				"surname": "Sakib"
			},
			"authorName": "Sakib, Kazi",
			"articleRefs": [
				{
					"pageNumber": 4109,
					"articleName": "CLARA: A Developer's Companion for Code Comprehension and Analysis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e109/573300e109.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Dishan",
				"surname": "Sambathkumar"
			},
			"authorName": "Sambathkumar, Dishan",
			"articleRefs": [
				{
					"pageNumber": 3333,
					"articleName": "Multi-Modal Requirements Data-Based Acceptance Criteria Generation Using LLMs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d333/573300d333.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jordan",
				"surname": "Samhi"
			},
			"authorName": "Samhi, Jordan",
			"articleRefs": [
				{
					"pageNumber": 3962,
					"articleName": "RAML: Toward Retrieval-Augmented Localization of Malicious Payloads in Android Apps",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d962/573300d962.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Beatriz",
				"surname": "Sanguino"
			},
			"authorName": "Sanguino, Beatriz",
			"articleRefs": [
				{
					"pageNumber": 3402,
					"articleName": "Out of Distribution Detection in Self-Adaptive Robots with AI-Powered Digital Twins",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d402/573300d402.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Tanay",
				"surname": "Sant"
			},
			"authorName": "Sant, Tanay",
			"articleRefs": [
				{
					"pageNumber": 14,
					"articleName": "Leveraging LLM for Software Modernization: COBOL Functionality Extraction Case Study",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a014/850300a014.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Vasil",
				"surname": "Sarafov"
			},
			"authorName": "Sarafov, Vasil",
			"articleRefs": [
				{
					"pageNumber": 2732,
					"articleName": "TEPHRA: Principled Discovery of Fuzzer Limitations",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c732/573300c732.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Federica ",
				"surname": "Sarro"
			},
			"authorName": "Sarro, Federica",
			"articleRefs": [
				{
					"pageNumber": 367,
					"articleName": "Automated Repair of Ambiguous Problem Descriptions for LLM-Based Code Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a367/573300a367.pdf"
				},
				{
					"pageNumber": 3901,
					"articleName": "LLM-Guided Genetic Improvement: Envisioning Semantic Aware Automated Software Evolution",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d901/573300d901.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Hassan",
				"surname": "Sartaj"
			},
			"authorName": "Sartaj, Hassan",
			"articleRefs": [
				{
					"pageNumber": 3402,
					"articleName": "Out of Distribution Detection in Self-Adaptive Robots with AI-Powered Digital Twins",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d402/573300d402.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yasuomi",
				"surname": "Sato"
			},
			"authorName": "Sato, Yasuomi",
			"articleRefs": [
				{
					"pageNumber": 3771,
					"articleName": "Acceleration of Automotive Software Development by Retrieval Augmented Integration Test Script Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d771/573300d771.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Fumiko",
				"surname": "Satoh"
			},
			"authorName": "Satoh, Fumiko",
			"articleRefs": [
				{
					"pageNumber": 26,
					"articleName": "Multilingual Code Explanation for Mainframe Languages",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a026/850300a026.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Vsevolod",
				"surname": "Savinskiy"
			},
			"authorName": "Savinskiy, Vsevolod",
			"articleRefs": [
				{
					"pageNumber": 369,
					"articleName": "On the Importance of Context Filtering in Retrieval-Augmented Code Completion",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a369/850300a369.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Christian",
				"surname": "Schindler"
			},
			"authorName": "Schindler, Christian",
			"articleRefs": [
				{
					"pageNumber": 165,
					"articleName": "VeriODD: From YAML to SMT-LIB \u2013 Automating Verification of Operational Design Domains",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a165/850300a165.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Benjamin",
				"surname": "Schmitz"
			},
			"authorName": "Schmitz, Benjamin",
			"articleRefs": [
				{
					"pageNumber": 4130,
					"articleName": "Dynamic Testing of GUI Exercises in Headless Environments",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e130/573300e130.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Niklas",
				"surname": "Schneider"
			},
			"authorName": "Schneider, Niklas",
			"articleRefs": [
				{
					"pageNumber": 166,
					"articleName": "An Empirical Study of Knowledge Transfer in AI Pair Programming",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a166/573300a166.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Maike",
				"surname": "Schwammberger"
			},
			"authorName": "Schwammberger, Maike",
			"articleRefs": [
				{
					"pageNumber": 204,
					"articleName": "Explainability in Automated Cross-Domain Model-Driven Brake System Development",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a204/850300a204.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Vincenzo",
				"surname": "Scotti"
			},
			"authorName": "Scotti, Vincenzo",
			"articleRefs": [
				{
					"pageNumber": 204,
					"articleName": "Explainability in Automated Cross-Domain Model-Driven Brake System Development",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a204/850300a204.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Sergey",
				"surname": "Sedov"
			},
			"authorName": "Sedov, Sergey",
			"articleRefs": [
				{
					"pageNumber": 369,
					"articleName": "On the Importance of Context Filtering in Retrieval-Augmented Code Completion",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a369/850300a369.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Sergio",
				"surname": "Segura"
			},
			"authorName": "Segura, Sergio",
			"articleRefs": [
				{
					"pageNumber": 1363,
					"articleName": "SATORI: Static Test Oracle Generation for REST APIs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b363/573300b363.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Benjamin",
				"surname": "Selwyn Smith"
			},
			"authorName": "Selwyn Smith, Benjamin",
			"articleRefs": [
				{
					"pageNumber": 3391,
					"articleName": "Unlocking Reproducibility: Automating re-Build Process for Open-Source Software",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d391/573300d391.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Souhaila",
				"surname": "Serbout"
			},
			"authorName": "Serbout, Souhaila",
			"articleRefs": [
				{
					"pageNumber": 4020,
					"articleName": "PrioTestCI: Efficient Test Case Prioritization in GitHub Workflows for CI Optimization",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e020/573300e020.pdf"
				},
				{
					"pageNumber": 4093,
					"articleName": "Quirx: A Mutation-Based Framework for Evaluating Prompt Robustness in LLM-Based Software",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e093/573300e093.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Agnia",
				"surname": "Sergeyuk"
			},
			"authorName": "Sergeyuk, Agnia",
			"articleRefs": [
				{
					"pageNumber": 3345,
					"articleName": "Prompt-With-Me: in-IDE Structured Prompt Management for LLM-Driven Software Engineering",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d345/573300d345.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Irina",
				"surname": "Serzhenko"
			},
			"authorName": "Serzhenko, Irina",
			"articleRefs": [
				{
					"pageNumber": 4032,
					"articleName": "WIBE: Watermarks for generated Images \u2013 Benchmarking & Evaluation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e032/573300e032.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Padmanabha V.",
				"surname": "Seshadri"
			},
			"authorName": "Seshadri, Padmanabha V.",
			"articleRefs": [
				{
					"pageNumber": 4097,
					"articleName": "Training-Control-as-Code: Towards a Declarative Solution to Control Training",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e097/573300e097.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Aarsh",
				"surname": "Shah"
			},
			"authorName": "Shah, Aarsh",
			"articleRefs": [
				{
					"pageNumber": 3916,
					"articleName": "Tether: A Personalized Support Assistant for Software Engineers with ADHD",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d916/573300d916.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Bhavain",
				"surname": "Shah"
			},
			"authorName": "Shah, Bhavain",
			"articleRefs": [
				{
					"pageNumber": 2362,
					"articleName": "Polyglot: An Extensible Framework to Benchmark Code Translation with LLMs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c362/573300c362.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Kaveh",
				"surname": "Shahedi"
			},
			"authorName": "Shahedi, Kaveh",
			"articleRefs": [
				{
					"pageNumber": 3461,
					"articleName": "From Technical Excellence to Practical Adoption: Lessons Learned Building an ML-Enhanced Trace Analysis Tool",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d461/573300d461.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Weiyi",
				"surname": "Shang"
			},
			"authorName": "Shang, Weiyi",
			"articleRefs": [
				{
					"pageNumber": 1704,
					"articleName": "ADPerf: Investigating and Testing Performance in Autonomous Driving Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b704/573300b704.pdf"
				},
				{
					"pageNumber": 3057,
					"articleName": "Who's to Blame? Rethinking the Brittleness of Automated Web GUI Testing from a Pragmatic Perspective",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d057/573300d057.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xiuwei",
				"surname": "Shang"
			},
			"authorName": "Shang, Xiuwei",
			"articleRefs": [
				{
					"pageNumber": 841,
					"articleName": "PseudoFix: Refactoring Distorted Structures in Decompiled C Pseudocode",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a841/573300a841.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Rohith Kumar",
				"surname": "Shanmuganathan"
			},
			"authorName": "Shanmuganathan, Rohith Kumar",
			"articleRefs": [
				{
					"pageNumber": 194,
					"articleName": "Explaining Software Vulnerabilities with Large Language Models",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a194/850300a194.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Lize",
				"surname": "Shao"
			},
			"authorName": "Shao, Lize",
			"articleRefs": [
				{
					"pageNumber": 1233,
					"articleName": "RFCScope: Detecting Logical Ambiguities in Internet Protocol Specifications",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b233/573300b233.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Mingyu",
				"surname": "Shao"
			},
			"authorName": "Shao, Mingyu",
			"articleRefs": [
				{
					"pageNumber": 3604,
					"articleName": "IntelliTopo: An IaC Generation Service for Industrial Network Topology Construction",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d604/573300d604.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zhenzhe",
				"surname": "Shao"
			},
			"authorName": "Shao, Zhenzhe",
			"articleRefs": [
				{
					"pageNumber": 2857,
					"articleName": "SolContractEval: A Benchmark for Evaluating Contract-Level Solidity Code Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c857/573300c857.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Dipesh",
				"surname": "Sharma"
			},
			"authorName": "Sharma, Dipesh",
			"articleRefs": [
				{
					"pageNumber": 22,
					"articleName": "Microservices Identification Using LLM",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a022/850300a022.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Beijun",
				"surname": "Shen"
			},
			"authorName": "Shen, Beijun",
			"articleRefs": [
				{
					"pageNumber": 141,
					"articleName": "LongCodeZip: Compress Long Context for Code Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a141/573300a141.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Bo",
				"surname": "Shen"
			},
			"authorName": "Shen, Bo",
			"articleRefs": [
				{
					"pageNumber": 2618,
					"articleName": "EfficientEdit: Accelerating Code Editing via Edit-Oriented Speculative Decoding",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c618/573300c618.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Han",
				"surname": "Shen"
			},
			"authorName": "Shen, Han",
			"articleRefs": [
				{
					"pageNumber": 2234,
					"articleName": "Enhancing LLM to Decompile Optimized PTX to Readable CUDA for Tensor Programs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c234/573300c234.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yuheng",
				"surname": "Shen"
			},
			"authorName": "Shen, Yuheng",
			"articleRefs": [
				{
					"pageNumber": 3226,
					"articleName": "TRON: Fuzzing Linux Network Stack via Protocol-System Call Payload Synthesis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d226/573300d226.pdf"
				},
				{
					"pageNumber": 3545,
					"articleName": "LLM-Assisted Industrial-Scale Differential Testing of Package Incompatibilities in Linux Distributions",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d545/573300d545.pdf"
				},
				{
					"pageNumber": 3615,
					"articleName": "RPG: Linux Kernel Fuzzing Guided by Distribution-Specific Runtime Parameter Interfaces",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d615/573300d615.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yulong",
				"surname": "Shen"
			},
			"authorName": "Shen, Yulong",
			"articleRefs": [
				{
					"pageNumber": 495,
					"articleName": "RSFuzz: A Robustness-Guided Swarm Fuzzing Framework Based on Behavioral Constraints",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a495/573300a495.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zhuoxiang",
				"surname": "Shen"
			},
			"authorName": "Shen, Zhuoxiang",
			"articleRefs": [
				{
					"pageNumber": 559,
					"articleName": "Security Debt in LLM Agent Applications: A Measurement Study of Vulnerabilities and Mitigation Trade-Offs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a559/573300a559.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "August ",
				"surname": "Shi"
			},
			"authorName": "Shi, August",
			"articleRefs": [
				{
					"pageNumber": 2157,
					"articleName": "FlakyGuard: Automatically Fixing Flaky Tests at Industry Scale",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c157/573300c157.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Changqing",
				"surname": "Shi"
			},
			"authorName": "Shi, Changqing",
			"articleRefs": [
				{
					"pageNumber": 1717,
					"articleName": "Fixing Broken Graphs: LLM-Powered Automatic Code Optimization for DNN Programs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b717/573300b717.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ensheng",
				"surname": "Shi"
			},
			"authorName": "Shi, Ensheng",
			"articleRefs": [
				{
					"pageNumber": 778,
					"articleName": "DrainCode: Stealthy Energy Consumption Attacks on Retrieval-Augmented Code Generation via Context Poisoning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a778/573300a778.pdf"
				},
				{
					"pageNumber": 971,
					"articleName": "AlignCoder: Aligning Retrieval with Target Intent for Repository-Level Code Completion",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a971/573300a971.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Hange",
				"surname": "Shi"
			},
			"authorName": "Shi, Hange",
			"articleRefs": [
				{
					"pageNumber": 2719,
					"articleName": "PALM: Synergizing Program Analysis and LLMs to Enhance Rust Unit Test Coverage",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c719/573300c719.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Heyuan",
				"surname": "Shi"
			},
			"authorName": "Shi, Heyuan",
			"articleRefs": [
				{
					"pageNumber": 3156,
					"articleName": "Industry Practice of LLM-Assisted Protocol Fuzzing for Commercial Communication Modules",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d156/573300d156.pdf"
				},
				{
					"pageNumber": 3226,
					"articleName": "TRON: Fuzzing Linux Network Stack via Protocol-System Call Payload Synthesis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d226/573300d226.pdf"
				},
				{
					"pageNumber": 3545,
					"articleName": "LLM-Assisted Industrial-Scale Differential Testing of Package Incompatibilities in Linux Distributions",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d545/573300d545.pdf"
				},
				{
					"pageNumber": 3615,
					"articleName": "RPG: Linux Kernel Fuzzing Guided by Distribution-Specific Runtime Parameter Interfaces",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d615/573300d615.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jieke",
				"surname": "Shi"
			},
			"authorName": "Shi, Jieke",
			"articleRefs": [
				{
					"pageNumber": 191,
					"articleName": "\"My Productivity is Boosted, but \u2026\" Demystifying Users' Perception on AI Coding Assistants",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a191/573300a191.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jingyi",
				"surname": "Shi"
			},
			"authorName": "Shi, Jingyi",
			"articleRefs": [
				{
					"pageNumber": 1069,
					"articleName": "A Large Scale Study of AI-Based Binary Function Similarity Detection Techniques for Security Researchers and Practitioners",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b069/573300b069.pdf"
				},
				{
					"pageNumber": 2969,
					"articleName": "Vulnerability-Affected Versions Identification: How Far Are We?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c969/573300c969.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Lin",
				"surname": "Shi"
			},
			"authorName": "Shi, Lin",
			"articleRefs": [
				{
					"pageNumber": 2298,
					"articleName": "FastCoder: Accelerating Repository-Level Code Generation via Efficient Retrieval and Verification",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c298/573300c298.pdf"
				},
				{
					"pageNumber": 2618,
					"articleName": "EfficientEdit: Accelerating Code Editing via Edit-Oriented Speculative Decoding",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c618/573300c618.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Qingkai",
				"surname": "Shi"
			},
			"authorName": "Shi, Qingkai",
			"articleRefs": [
				{
					"pageNumber": 1246,
					"articleName": "Protecting Source Code Privacy When Hunting Memory Bugs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b246/573300b246.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ronghua",
				"surname": "Shi"
			},
			"authorName": "Shi, Ronghua",
			"articleRefs": [
				{
					"pageNumber": 3156,
					"articleName": "Industry Practice of LLM-Assisted Protocol Fuzzing for Commercial Communication Modules",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d156/573300d156.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Rui",
				"surname": "Shi"
			},
			"authorName": "Shi, Rui",
			"articleRefs": [
				{
					"pageNumber": 3298,
					"articleName": "LogPilot: Intent-Aware and Scalable Alert Diagnosis for Large-Scale Online Service Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d298/573300d298.pdf"
				},
				{
					"pageNumber": 3425,
					"articleName": "Automated Proactive Logging Quality Improvement for Large-Scale Codebases ",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d425/573300d425.pdf"
				},
				{
					"pageNumber": 3533,
					"articleName": "ErrorPrism: Reconstructing Error Propagation Paths in Cloud Service Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d533/573300d533.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xianjie",
				"surname": "Shi"
			},
			"authorName": "Shi, Xianjie",
			"articleRefs": [
				{
					"pageNumber": 1476,
					"articleName": "Aligning LLMs to Fully Utilize the Cross-File Context in Repository-Level Code Completion",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b476/573300b476.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xiaohai",
				"surname": "Shi"
			},
			"authorName": "Shi, Xiaohai",
			"articleRefs": [
				{
					"pageNumber": 3545,
					"articleName": "LLM-Assisted Industrial-Scale Differential Testing of Package Incompatibilities in Linux Distributions",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d545/573300d545.pdf"
				},
				{
					"pageNumber": 3615,
					"articleName": "RPG: Linux Kernel Fuzzing Guided by Distribution-Specific Runtime Parameter Interfaces",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d615/573300d615.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xiaoxue",
				"surname": "Shi"
			},
			"authorName": "Shi, Xiaoxue",
			"articleRefs": [
				{
					"pageNumber": 3741,
					"articleName": "LogSage: An LLM-Based Framework for CI/CD Failure Detection and Remediation with Industrial Validation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d741/573300d741.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yitong",
				"surname": "Shi"
			},
			"authorName": "Shi, Yitong",
			"articleRefs": [
				{
					"pageNumber": 237,
					"articleName": "Towards MPC-Driven Software Adaptation: A Dual-Layer Approach Combining ICNN-Based Modeling and Delta-Based Tuning",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a237/850300a237.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yuling",
				"surname": "Shi"
			},
			"authorName": "Shi, Yuling",
			"articleRefs": [
				{
					"pageNumber": 141,
					"articleName": "LongCodeZip: Compress Long Context for Code Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a141/573300a141.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zhiqiang",
				"surname": "Shi"
			},
			"authorName": "Shi, Zhiqiang",
			"articleRefs": [
				{
					"pageNumber": 2082,
					"articleName": "Breaking the Traffic Barrier: Unveiling Multi-Format of Protocols via Autonomous Program Exploration",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c082/573300c082.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Donghwan",
				"surname": "Shin"
			},
			"authorName": "Shin, Donghwan",
			"articleRefs": [
				{
					"pageNumber": 3865,
					"articleName": "Unseen Data Detection using Routing Entropy in Mixture-of-Experts for Autonomous Vehicles",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d865/573300d865.pdf"
				},
				{
					"pageNumber": 4012,
					"articleName": "XRINTTEST: An Automated Framework for User Interaction Testing in Extended Reality Applications",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e012/573300e012.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Hyunseo",
				"surname": "Shin"
			},
			"authorName": "Shin, Hyunseo",
			"articleRefs": [
				{
					"pageNumber": 176,
					"articleName": "K-SNAC: Robust Neuron Coverage for OOD Generalization and Test Adequacy",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a176/850300a176.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Wonho",
				"surname": "Shin"
			},
			"authorName": "Shin, Wonho",
			"articleRefs": [
				{
					"pageNumber": 1402,
					"articleName": "WEST: Specification-Based Test Generation for WebAssembly",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b402/573300b402.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Kaoru",
				"surname": "Shinkawa"
			},
			"authorName": "Shinkawa, Kaoru",
			"articleRefs": [
				{
					"pageNumber": 26,
					"articleName": "Multilingual Code Explanation for Mainframe Languages",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a026/850300a026.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Iti",
				"surname": "Shree"
			},
			"authorName": "Shree, Iti",
			"articleRefs": [
				{
					"pageNumber": 4016,
					"articleName": "ReFuzzer: Feedback-Driven Approach to Enhance Validity of LLM-Generated Test Programs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e016/573300e016.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Weipeng",
				"surname": "Shuai "
			},
			"authorName": "Shuai, Weipeng",
			"articleRefs": [
				{
					"pageNumber": 2771,
					"articleName": "Root Cause Analysis of RISC-V Build Failures via LLM and MCTS Reasoning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c771/573300c771.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Bing",
				"surname": "Shui"
			},
			"authorName": "Shui, Bing",
			"articleRefs": [
				{
					"pageNumber": 1246,
					"articleName": "Protecting Source Code Privacy When Hunting Memory Bugs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b246/573300b246.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Shuaizong",
				"surname": "Si"
			},
			"authorName": "Si, Shuaizong",
			"articleRefs": [
				{
					"pageNumber": 2082,
					"articleName": "Breaking the Traffic Barrier: Unveiling Multi-Format of Protocols via Autonomous Program Exploration",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c082/573300c082.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Norbert",
				"surname": "Siegmund"
			},
			"authorName": "Siegmund, Norbert",
			"articleRefs": [
				{
					"pageNumber": 2515,
					"articleName": "On Automating Configuration Dependency Validation via Retrieval-Augmented Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c515/573300c515.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Michael",
				"surname": "Siers"
			},
			"authorName": "Siers, Michael",
			"articleRefs": [
				{
					"pageNumber": 3759,
					"articleName": "What Types of Code Review Comments Do Developers Most Frequently Resolve?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d759/573300d759.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Sebastian",
				"surname": "Simon"
			},
			"authorName": "Simon, Sebastian",
			"articleRefs": [
				{
					"pageNumber": 2515,
					"articleName": "On Automating Configuration Dependency Validation via Retrieval-Augmented Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c515/573300c515.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Vishal",
				"surname": "Singh"
			},
			"authorName": "Singh, Vishal",
			"articleRefs": [
				{
					"pageNumber": 3972,
					"articleName": "AndroFL: Evolutionary-Driven Fault Localization for Android Apps",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d972/573300d972.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Marius",
				"surname": "Smytzek"
			},
			"authorName": "Smytzek, Marius",
			"articleRefs": [
				{
					"pageNumber": 4048,
					"articleName": "BASHIRI: Learning Failure Oracles from Execution Features",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e048/573300e048.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Gustavo",
				"surname": "Soares"
			},
			"authorName": "Soares, Gustavo",
			"articleRefs": [
				{
					"pageNumber": 432,
					"articleName": "Why AI Agents Still Need You: Findings from Developer-Agent Collaborations in the Wild",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a432/573300a432.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Dominik",
				"surname": "Sobania"
			},
			"authorName": "Sobania, Dominik",
			"articleRefs": [
				{
					"pageNumber": 3901,
					"articleName": "LLM-Guided Genetic Improvement: Envisioning Semantic Aware Automated Software Evolution",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d901/573300d901.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Constantinos",
				"surname": "Sofianos"
			},
			"authorName": "Sofianos, Constantinos",
			"articleRefs": [
				{
					"pageNumber": 376,
					"articleName": "Exploration of Structural Code Relationship Space for Context Collection",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a376/850300a376.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Akanksha",
				"surname": "Somase"
			},
			"authorName": "Somase, Akanksha",
			"articleRefs": [
				{
					"pageNumber": 14,
					"articleName": "Leveraging LLM for Software Modernization: COBOL Functionality Extraction Case Study",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a014/850300a014.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Da",
				"surname": "Song"
			},
			"authorName": "Song, Da",
			"articleRefs": [
				{
					"pageNumber": 4081,
					"articleName": "TRUSTVIS: A Multi-Dimensional Trustworthiness Evaluation Framework for Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e081/573300e081.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jianping",
				"surname": "Song"
			},
			"authorName": "Song, Jianping",
			"articleRefs": [
				{
					"pageNumber": 1272,
					"articleName": "SMTgazer: Learning to Schedule SMT Algorithms via Bayesian Optimization",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b272/573300b272.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jiayang",
				"surname": "Song"
			},
			"authorName": "Song, Jiayang",
			"articleRefs": [
				{
					"pageNumber": 4081,
					"articleName": "TRUSTVIS: A Multi-Dimensional Trustworthiness Evaluation Framework for Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e081/573300e081.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yewei",
				"surname": "Song"
			},
			"authorName": "Song, Yewei",
			"articleRefs": [
				{
					"pageNumber": 3921,
					"articleName": "Measuring LLM Code Generation Stability via Structural Entropy",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d921/573300d921.pdf"
				},
				{
					"pageNumber": 3962,
					"articleName": "RAML: Toward Retrieval-Augmented Localization of Malicious Payloads in Android Apps",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d962/573300d962.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yi",
				"surname": "Song"
			},
			"authorName": "Song, Yi",
			"articleRefs": [
				{
					"pageNumber": 996,
					"articleName": "Not Every Patch is an Island: LLM-Enhanced Identification of Multiple Vulnerability Patches",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a996/573300a996.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Chengru",
				"surname": "Song "
			},
			"authorName": "Song, Chengru",
			"articleRefs": [
				{
					"pageNumber": 2234,
					"articleName": "Enhancing LLM to Decompile Optimized PTX to Readable CUDA for Tensor Programs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c234/573300c234.pdf"
				},
				{
					"pageNumber": 3191,
					"articleName": "KAIOps: A Platform Solution of End-to-End Multi-Modal AIOps for AI Training at Scale",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d191/573300d191.pdf"
				},
				{
					"pageNumber": 3753,
					"articleName": "KAIR: A Statistical and Causal Approach to Pinpointing Stragglers in Distributed Model Training",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d753/573300d753.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Priyal",
				"surname": "Soni"
			},
			"authorName": "Soni, Priyal",
			"articleRefs": [
				{
					"pageNumber": 4073,
					"articleName": "OSSPREY: AI-Driven Forecasting and Intervention for OSS Project Sustainability",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e073/573300e073.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Mame Marieme C.",
				"surname": "Sougoufara"
			},
			"authorName": "Sougoufara, Mame Marieme C.",
			"articleRefs": [
				{
					"pageNumber": 4117,
					"articleName": "evalSmarT: An LLM-Based Framework for Evaluating Smart Contract Generated Comments",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e117/573300e117.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Francesco",
				"surname": "Sovrano"
			},
			"authorName": "Sovrano, Francesco",
			"articleRefs": [
				{
					"pageNumber": 1311,
					"articleName": "Detecting Semantic Clones of Unseen Functionality",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b311/573300b311.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Vijay Aravynthan",
				"surname": "S.R."
			},
			"authorName": "S.R., Vijay Aravynthan",
			"articleRefs": [
				{
					"pageNumber": 349,
					"articleName": "A Conformance Checking System for Interaction Testing in Virtual Reality",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a349/850300a349.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Manu",
				"surname": "Sridharan"
			},
			"authorName": "Sridharan, Manu",
			"articleRefs": [
				{
					"pageNumber": 828,
					"articleName": "Repairing Leaks in Resource Wrappers",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a828/573300a828.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ethan",
				"surname": "Stanley"
			},
			"authorName": "Stanley, Ethan",
			"articleRefs": [
				{
					"pageNumber": 204,
					"articleName": "Finding Bugs in WebAssembly Interface Type Binding Generators",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a204/573300a204.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Matt",
				"surname": "Steiner"
			},
			"authorName": "Steiner, Matt",
			"articleRefs": [
				{
					"pageNumber": 3250,
					"articleName": "Metrics Driven Reengineering and Continuous Code Improvement at Meta",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d250/573300d250.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Andrea",
				"surname": "Stocco"
			},
			"authorName": "Stocco, Andrea",
			"articleRefs": [
				{
					"pageNumber": 2807,
					"articleName": "A Multi-Modality Evaluation of the Reality Gap in Autonomous Driving Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c807/573300c807.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jan",
				"surname": "Strej\u010Dek"
			},
			"authorName": "Strej\u010Dek, Jan",
			"articleRefs": [
				{
					"pageNumber": 1968,
					"articleName": "Non-Termination Witnesses and Their Validation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b968/573300b968.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Hongyi",
				"surname": "Su"
			},
			"authorName": "Su, Hongyi",
			"articleRefs": [
				{
					"pageNumber": 3008,
					"articleName": "Mockingbird: Efficient Excessive Data Exposures Detection via Dynamic Code Instrumentation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d008/573300d008.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ting",
				"surname": "Su"
			},
			"authorName": "Su, Ting",
			"articleRefs": [
				{
					"pageNumber": 636,
					"articleName": "Finding Bugs in MLIR Compiler Infrastructure via Lowering Space Exploration",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a636/573300a636.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xiaohong",
				"surname": "Su"
			},
			"authorName": "Su, Xiaohong",
			"articleRefs": [
				{
					"pageNumber": 2311,
					"articleName": "Effective Code Membership Inference for Code Completion Models via Adversarial Prompts",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c311/573300c311.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yucheng",
				"surname": "Su"
			},
			"authorName": "Su, Yucheng",
			"articleRefs": [
				{
					"pageNumber": 521,
					"articleName": "GlassWing: A Tailored Static Analysis Approach for Flutter Android Apps",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a521/573300a521.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zhexin",
				"surname": "Su"
			},
			"authorName": "Su, Zhexin",
			"articleRefs": [
				{
					"pageNumber": 1207,
					"articleName": "Bridging Natural Language and Formal Specification Automated Translation of Software Requirements to LTL via Hierarchical Semantics Decomposition Using LLMs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b207/573300b207.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Kaixin",
				"surname": "Sui"
			},
			"authorName": "Sui, Kaixin",
			"articleRefs": [
				{
					"pageNumber": 3741,
					"articleName": "LogSage: An LLM-Based Framework for CI/CD Failure Detection and Remediation with Industrial Validation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d741/573300d741.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yicheng",
				"surname": "Sui"
			},
			"authorName": "Sui, Yicheng",
			"articleRefs": [
				{
					"pageNumber": 1717,
					"articleName": "Fixing Broken Graphs: LLM-Powered Automatic Code Optimization for DNN Programs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b717/573300b717.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Thitirat",
				"surname": "Sukijprasert"
			},
			"authorName": "Sukijprasert, Thitirat",
			"articleRefs": [
				{
					"pageNumber": 3996,
					"articleName": "PyGress: Tool for Analyzing the Progression of Code Proficiency in Python OSS Projects",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d996/573300d996.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Tyler",
				"surname": "Summers"
			},
			"authorName": "Summers, Tyler",
			"articleRefs": [
				{
					"pageNumber": 1590,
					"articleName": "IMUFUZZER: Resilience-Based Discovery of Signal Injection Attacks on Robotic Aerial Vehicles",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b590/573300b590.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Chang-ai",
				"surname": "Sun"
			},
			"authorName": "Sun, Chang-ai",
			"articleRefs": [
				{
					"pageNumber": 2881,
					"articleName": "DIFFFIX: Incrementally Fixing AST Diffs via Context and Type Information",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c881/573300c881.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Chengnian",
				"surname": "Sun"
			},
			"authorName": "Sun, Chengnian",
			"articleRefs": [
				{
					"pageNumber": 2273,
					"articleName": "Latra: A Template-Based Language-Agnostic Transformation Framework for Effective Program Reduction",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c273/573300c273.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Fute",
				"surname": "Sun"
			},
			"authorName": "Sun, Fute",
			"articleRefs": [
				{
					"pageNumber": 932,
					"articleName": "Exploring Static Taint Analysis in LLMs: A Dynamic Benchmarking Framework for Measurement and Enhancement",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a932/573300a932.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Gengyi",
				"surname": "Sun"
			},
			"authorName": "Sun, Gengyi",
			"articleRefs": [
				{
					"pageNumber": 2931,
					"articleName": "The Cost of Downgrading Build Systems A Case Study of Kubernetes",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c931/573300c931.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jiaxuan",
				"surname": "Sun"
			},
			"authorName": "Sun, Jiaxuan",
			"articleRefs": [
				{
					"pageNumber": 355,
					"articleName": "Enhancing LLMs with Staged Grouping and Dehallucination for Header File Decomposition",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a355/573300a355.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jiazheng",
				"surname": "Sun"
			},
			"authorName": "Sun, Jiazheng",
			"articleRefs": [
				{
					"pageNumber": 3008,
					"articleName": "Mockingbird: Efficient Excessive Data Exposures Detection via Dynamic Code Instrumentation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d008/573300d008.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jinan",
				"surname": "Sun"
			},
			"authorName": "Sun, Jinan",
			"articleRefs": [
				{
					"pageNumber": 217,
					"articleName": "R3-Bench: Reproducible Real-World Reverse Engineering Dataset for Symbol Recovery",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a217/573300a217.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jing",
				"surname": "Sun"
			},
			"authorName": "Sun, Jing",
			"articleRefs": [
				{
					"pageNumber": 2121,
					"articleName": "PAT-Agent: Autoformalization for Model Checking",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c121/573300c121.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jun",
				"surname": "Sun"
			},
			"authorName": "Sun, Jun",
			"articleRefs": [
				{
					"pageNumber": 495,
					"articleName": "RSFuzz: A Robustness-Guided Swarm Fuzzing Framework Based on Behavioral Constraints",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a495/573300a495.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Kairan",
				"surname": "Sun"
			},
			"authorName": "Sun, Kairan",
			"articleRefs": [
				{
					"pageNumber": 52,
					"articleName": "Learning from the Past: Real-World Exploit Migration for Smart Contract PoC Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a052/573300a052.pdf"
				},
				{
					"pageNumber": 104,
					"articleName": "FAULTSEEKER: LLM-Empowered Framework for Blockchain Transaction Fault Localization",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a104/573300a104.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Limin",
				"surname": "Sun"
			},
			"authorName": "Sun, Limin",
			"articleRefs": [
				{
					"pageNumber": 304,
					"articleName": "Advancing Binary Code Similarity Detection via Context-Content Fusion and LLM Verification",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a304/573300a304.pdf"
				},
				{
					"pageNumber": 919,
					"articleName": "Lares: LLM-Driven Code Slice Semantic Search for Patch Presence Testing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a919/573300a919.pdf"
				},
				{
					"pageNumber": 2082,
					"articleName": "Breaking the Traffic Barrier: Unveiling Multi-Format of Protocols via Autonomous Program Exploration",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c082/573300c082.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ruoyu",
				"surname": "Sun"
			},
			"authorName": "Sun, Ruoyu",
			"articleRefs": [
				{
					"pageNumber": 4081,
					"articleName": "TRUSTVIS: A Multi-Dimensional Trustworthiness Evaluation Framework for Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e081/573300e081.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Tianqi",
				"surname": "Sun"
			},
			"authorName": "Sun, Tianqi",
			"articleRefs": [
				{
					"pageNumber": 2969,
					"articleName": "Vulnerability-Affected Versions Identification: How Far Are We?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c969/573300c969.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Tiezhu",
				"surname": "Sun"
			},
			"authorName": "Sun, Tiezhu",
			"articleRefs": [
				{
					"pageNumber": 3921,
					"articleName": "Measuring LLM Code Generation Stability via Structural Entropy",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d921/573300d921.pdf"
				},
				{
					"pageNumber": 3962,
					"articleName": "RAML: Toward Retrieval-Augmented Localization of Malicious Payloads in Android Apps",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d962/573300d962.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Weichao",
				"surname": "Sun"
			},
			"authorName": "Sun, Weichao",
			"articleRefs": [
				{
					"pageNumber": 3683,
					"articleName": "Securing Millions of Decentralized Identities in Alipay Super App with End-to-End Formal Verification",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d683/573300d683.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Weisong",
				"surname": "Sun"
			},
			"authorName": "Sun, Weisong",
			"articleRefs": [
				{
					"pageNumber": 648,
					"articleName": "BinStruct: Binary Structure Recovery Combining Static Analysis and Semantics",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a648/573300a648.pdf"
				},
				{
					"pageNumber": 3875,
					"articleName": "Envisioning Intelligent Requirements Engineering via Knowledge-Guided Multi-Agent Collaboration",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d875/573300d875.pdf"
				},
				{
					"pageNumber": 3931,
					"articleName": "Requirements Development and Formalization for Reliable Code Generation: A Multi-Agent Vision",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d931/573300d931.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xiaoyang",
				"surname": "Sun"
			},
			"authorName": "Sun, Xiaoyang",
			"articleRefs": [
				{
					"pageNumber": 3191,
					"articleName": "KAIOps: A Platform Solution of End-to-End Multi-Modal AIOps for AI Training at Scale",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d191/573300d191.pdf"
				},
				{
					"pageNumber": 3753,
					"articleName": "KAIR: A Statistical and Causal Approach to Pinpointing Stragglers in Distributed Model Training",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d753/573300d753.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xiaoyu",
				"surname": "Sun"
			},
			"authorName": "Sun, Xiaoyu",
			"articleRefs": [
				{
					"pageNumber": 687,
					"articleName": "Navigating the Labyrinth: Path-Sensitive Unit Test Generation with Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a687/573300a687.pdf"
				},
				{
					"pageNumber": 4004,
					"articleName": "Towards Context-Aware Mobile Privacy Notice: Implementation of A Deployable Contextual Privacy Policies Generator",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e004/573300e004.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xinyu",
				"surname": "Sun"
			},
			"authorName": "Sun, Xinyu",
			"articleRefs": [
				{
					"pageNumber": 2234,
					"articleName": "Enhancing LLM to Decompile Optimized PTX to Readable CUDA for Tensor Programs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c234/573300c234.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yicheng",
				"surname": "Sun"
			},
			"authorName": "Sun, Yicheng",
			"articleRefs": [
				{
					"pageNumber": 1855,
					"articleName": "Can Mamba Be Better? An Experimental Evaluation of Mamba in Code Intelligence",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b855/573300b855.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yixin",
				"surname": "Sun"
			},
			"authorName": "Sun, Yixin",
			"articleRefs": [
				{
					"pageNumber": 1233,
					"articleName": "RFCScope: Detecting Logical Ambiguities in Internet Protocol Specifications",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b233/573300b233.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yongqian",
				"surname": "Sun"
			},
			"authorName": "Sun, Yongqian",
			"articleRefs": [
				{
					"pageNumber": 2221,
					"articleName": "LLM-Powered Multi-Agent Collaboration for Intelligent Industrial On-Call Automation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c221/573300c221.pdf"
				},
				{
					"pageNumber": 3238,
					"articleName": "TrioXpert: An Automated Incident Management Framework for Microservice System",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d238/573300d238.pdf"
				},
				{
					"pageNumber": 3497,
					"articleName": "Adaptive Performance Regression Detection Using A Semi-Supervised Siamese Network",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d497/573300d497.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yufei",
				"surname": "Sun"
			},
			"authorName": "Sun, Yufei",
			"articleRefs": [
				{
					"pageNumber": 1717,
					"articleName": "Fixing Broken Graphs: LLM-Powered Automatic Code Optimization for DNN Programs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b717/573300b717.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yuqiang",
				"surname": "Sun"
			},
			"authorName": "Sun, Yuqiang",
			"articleRefs": [
				{
					"pageNumber": 104,
					"articleName": "FAULTSEEKER: LLM-Empowered Framework for Blockchain Transaction Fault Localization",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a104/573300a104.pdf"
				},
				{
					"pageNumber": 648,
					"articleName": "BinStruct: Binary Structure Recovery Combining Static Analysis and Semantics",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a648/573300a648.pdf"
				},
				{
					"pageNumber": 945,
					"articleName": "Demystifying OpenZeppelin's Own Vulnerabilities and Analyzing Their Propagation in Smart Contracts",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a945/573300a945.pdf"
				},
				{
					"pageNumber": 1994,
					"articleName": "Have We Solved Access Control Vulnerability Detection in Smart Contracts? A Benchmark Study",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b994/573300b994.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zeyu",
				"surname": "Sun"
			},
			"authorName": "Sun, Zeyu",
			"articleRefs": [
				{
					"pageNumber": 2375,
					"articleName": "Interleaved Learning and Exploration: A Self-Adaptive Fuzz Testing Framework for MLIR",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c375/573300c375.pdf"
				},
				{
					"pageNumber": 2982,
					"articleName": "LAURA: Enhancing Code Review Generation with Context-Enriched Retrieval-Augmented LLM",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c982/573300c982.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zhensu",
				"surname": "Sun"
			},
			"authorName": "Sun, Zhensu",
			"articleRefs": [
				{
					"pageNumber": 2439,
					"articleName": "Token Sugar: Making Source Code Sweeter for LLMs Through Token-Efficient Shorthand",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c439/573300c439.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zhihong",
				"surname": "Sun"
			},
			"authorName": "Sun, Zhihong",
			"articleRefs": [
				{
					"pageNumber": 1918,
					"articleName": "SemGuard: Real-Time Semantic Evaluator for Correcting LLM-Generated Code",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b918/573300b918.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zian",
				"surname": "Sun"
			},
			"authorName": "Sun, Zian",
			"articleRefs": [
				{
					"pageNumber": 2007,
					"articleName": "Explainable Fault Localization for Programming Assignments via LLM-Guided Annotation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c007/573300c007.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Thanwadee",
				"surname": "Sunetnanta"
			},
			"authorName": "Sunetnanta, Thanwadee",
			"articleRefs": [
				{
					"pageNumber": 261,
					"articleName": "Exploring the SECURITY.md in the Dependency Chain: Preliminary Analysis of the PyPI Ecosystem",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a261/850300a261.pdf"
				},
				{
					"pageNumber": 3996,
					"articleName": "PyGress: Tool for Analyzing the Progression of Code Proficiency in Python OSS Projects",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d996/573300d996.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Chenyao",
				"surname": "Suo"
			},
			"authorName": "Suo, Chenyao",
			"articleRefs": [
				{
					"pageNumber": 2375,
					"articleName": "Interleaved Learning and Exploration: A Self-Adaptive Fuzz Testing Framework for MLIR",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c375/573300c375.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Fanny Febriani",
				"surname": "Susilo"
			},
			"authorName": "Susilo, Fanny Febriani",
			"articleRefs": [
				{
					"pageNumber": 4136,
					"articleName": "Human-Centered Evaluation of REST API Fuzzing Tools: Bridging Academia and Industry",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e136/573300e136.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Aman",
				"surname": "Swaraj"
			},
			"authorName": "Swaraj, Aman",
			"articleRefs": [
				{
					"pageNumber": 4105,
					"articleName": "StackPlagger: A System for Identifying AI-Code Plagiarism on Stack Overflow",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e105/573300e105.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Kengo",
				"surname": "Tajiri"
			},
			"authorName": "Tajiri, Kengo",
			"articleRefs": [
				{
					"pageNumber": 3860,
					"articleName": "LLM-Powered Fully Automated Chaos Engineering: Towards Enabling Anyone to Build Resilient Software Systems at Low Cost",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d860/573300d860.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yoshiki",
				"surname": "Takashima"
			},
			"authorName": "Takashima, Yoshiki",
			"articleRefs": [
				{
					"pageNumber": 1452,
					"articleName": "VERT: Polyglot Verified Equivalent Rust Transpilation with Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b452/573300b452.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Evangelos",
				"surname": "Talos"
			},
			"authorName": "Talos, Evangelos",
			"articleRefs": [
				{
					"pageNumber": 4069,
					"articleName": "PyTrim: A Practical Tool for Reducing Python Dependency Bloat",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e069/573300e069.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Mahzabin",
				"surname": "Tamanna"
			},
			"authorName": "Tamanna, Mahzabin",
			"articleRefs": [
				{
					"pageNumber": 2995,
					"articleName": "Your Build Scripts Stink: The State of Code Smells in Build Scripts",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c995/573300c995.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Srikanth G.",
				"surname": "Tamilselvam"
			},
			"authorName": "Tamilselvam, Srikanth G.",
			"articleRefs": [
				{
					"pageNumber": 3926,
					"articleName": "Multiple Schema-Conformant Declarative Code Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d926/573300d926.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Gang",
				"surname": "Tan"
			},
			"authorName": "Tan, Gang",
			"articleRefs": [
				{
					"pageNumber": 1679,
					"articleName": "Uncovering Discrimination Clusters: Quantifying and Explaining Systematic Fairness Violations",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b679/573300b679.pdf"
				},
				{
					"pageNumber": 2893,
					"articleName": "Better Safe than Sorry: Preventing Policy Violations Through Predictive Root-Cause-Analysis for IoT Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c893/573300c893.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Honghao",
				"surname": "Tan"
			},
			"authorName": "Tan, Honghao",
			"articleRefs": [
				{
					"pageNumber": 983,
					"articleName": "Coverage-Based Harmfulness Testing for LLM Code Transformation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a983/573300a983.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Liwei",
				"surname": "Tan"
			},
			"authorName": "Tan, Liwei",
			"articleRefs": [
				{
					"pageNumber": 104,
					"articleName": "FAULTSEEKER: LLM-Empowered Framework for Blockchain Transaction Fault Localization",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a104/573300a104.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Shin Hwei",
				"surname": "Tan"
			},
			"authorName": "Tan, Shin Hwei",
			"articleRefs": [
				{
					"pageNumber": 983,
					"articleName": "Coverage-Based Harmfulness Testing for LLM Code Transformation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a983/573300a983.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yu-an",
				"surname": "Tan"
			},
			"authorName": "Tan, Yu-an",
			"articleRefs": [
				{
					"pageNumber": 3008,
					"articleName": "Mockingbird: Efficient Excessive Data Exposures Detection via Dynamic Code Instrumentation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d008/573300d008.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Enyi ",
				"surname": "Tang"
			},
			"authorName": "Tang, Enyi",
			"articleRefs": [
				{
					"pageNumber": 1168,
					"articleName": "When Autonomous Vehicle Meets V2X Cooperative Perception: How Far Are We?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b168/573300b168.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Hongshan",
				"surname": "Tang"
			},
			"authorName": "Tang, Hongshan",
			"articleRefs": [
				{
					"pageNumber": 3706,
					"articleName": "Securing Self-Managed Third-Party Libraries",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d706/573300d706.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jiayue ",
				"surname": "Tang"
			},
			"authorName": "Tang, Jiayue",
			"articleRefs": [
				{
					"pageNumber": 1666,
					"articleName": "Leveraging Mixture-of-Experts Framework for Smart Contract Vulnerability Repair with Large Language Model",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b666/573300b666.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jing",
				"surname": "Tang"
			},
			"authorName": "Tang, Jing",
			"articleRefs": [
				{
					"pageNumber": 3741,
					"articleName": "LogSage: An LLM-Based Framework for CI/CD Failure Detection and Remediation with Industrial Validation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d741/573300d741.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jinhe",
				"surname": "Tang"
			},
			"authorName": "Tang, Jinhe",
			"articleRefs": [
				{
					"pageNumber": 3671,
					"articleName": "RepoMasterEval: Evaluating Code Completion via Real-World Repositories",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d671/573300d671.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Linlong",
				"surname": "Tang"
			},
			"authorName": "Tang, Linlong",
			"articleRefs": [
				{
					"pageNumber": 854,
					"articleName": "DLBENCH: A Comprehensive Benchmark for SQL Translation with Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a854/573300a854.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Wei",
				"surname": "Tang"
			},
			"authorName": "Tang, Wei",
			"articleRefs": [
				{
					"pageNumber": 1767,
					"articleName": "Demystifying Cross-Language C/C++ Binaries: A Robust Software Component Analysis Approach",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b767/573300b767.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xunzhu",
				"surname": "Tang"
			},
			"authorName": "Tang, Xunzhu",
			"articleRefs": [
				{
					"pageNumber": 3921,
					"articleName": "Measuring LLM Code Generation Stability via Structural Entropy",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d921/573300d921.pdf"
				},
				{
					"pageNumber": 3962,
					"articleName": "RAML: Toward Retrieval-Augmented Localization of Malicious Payloads in Android Apps",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d962/573300d962.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yongjian",
				"surname": "Tang"
			},
			"authorName": "Tang, Yongjian",
			"articleRefs": [
				{
					"pageNumber": 300,
					"articleName": "Bridging the Prototype-Production Gap: A Multi-Agent System for Notebooks Transformation",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a300/850300a300.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Fugen ",
				"surname": "Tang "
			},
			"authorName": "Tang, Fugen",
			"articleRefs": [
				{
					"pageNumber": 2234,
					"articleName": "Enhancing LLM to Decompile Optimized PTX to Readable CUDA for Tensor Programs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c234/573300c234.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Chakkrit",
				"surname": "Tantithamthavorn"
			},
			"authorName": "Tantithamthavorn, Chakkrit",
			"articleRefs": [
				{
					"pageNumber": 3333,
					"articleName": "Multi-Modal Requirements Data-Based Acceptance Criteria Generation Using LLMs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d333/573300d333.pdf"
				},
				{
					"pageNumber": 3380,
					"articleName": "AdaptiveGuard: Towards Adaptive Runtime Safety for LLM-Powered Software",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d380/573300d380.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Kla",
				"surname": "Tantithamthavorn"
			},
			"authorName": "Tantithamthavorn, Kla",
			"articleRefs": [
				{
					"pageNumber": 3759,
					"articleName": "What Types of Code Review Comments Do Developers Most Frequently Resolve?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d759/573300d759.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Lei",
				"surname": "Tao"
			},
			"authorName": "Tao, Lei",
			"articleRefs": [
				{
					"pageNumber": 3497,
					"articleName": "Adaptive Performance Regression Detection Using A Semi-Supervised Siamese Network",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d497/573300d497.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zhen",
				"surname": "Tao"
			},
			"authorName": "Tao, Zhen",
			"articleRefs": [
				{
					"pageNumber": 4004,
					"articleName": "Towards Context-Aware Mobile Privacy Notice: Implementation of A Deployable Contextual Privacy Policies Generator",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e004/573300e004.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Samuel",
				"surname": "Tardieu"
			},
			"authorName": "Tardieu, Samuel",
			"articleRefs": [
				{
					"pageNumber": 2183,
					"articleName": "Altered Histories in Version Control System Repositories: Evidence from the Trenches",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c183/573300c183.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Takaaki",
				"surname": "Tateishi"
			},
			"authorName": "Tateishi, Takaaki",
			"articleRefs": [
				{
					"pageNumber": 3,
					"articleName": "Grammar- and Coverage-Based Augmentation of Programs for Training LLMs",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a003/850300a003.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Bernhard ",
				"surname": "Taufner"
			},
			"authorName": "Taufner, Bernhard",
			"articleRefs": [
				{
					"pageNumber": 2694,
					"articleName": "From Characters to Structure: Rethinking Real-Time Collaborative Programming Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c694/573300c694.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Sasan",
				"surname": "Tavakkol"
			},
			"authorName": "Tavakkol, Sasan",
			"articleRefs": [
				{
					"pageNumber": 2108,
					"articleName": "Using Fourier Analysis and Mutant Clustering to Accelerate DNN Mutation Testing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c108/573300c108.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Vali",
				"surname": "Tawosi"
			},
			"authorName": "Tawosi, Vali",
			"articleRefs": [
				{
					"pageNumber": 34,
					"articleName": "LLM Agents for Automated Dependency Upgrades",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a034/850300a034.pdf"
				},
				{
					"pageNumber": 39,
					"articleName": "Bridging LLM Planning Agents and Formal Methods: A Case Study in Plan Verification",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a039/850300a039.pdf"
				},
				{
					"pageNumber": 288,
					"articleName": "ALMAS: An Autonomous LLM-Based Multi-Agent Software Engineering Framework",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a288/850300a288.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Earl",
				"surname": "T. Barr"
			},
			"authorName": "T. Barr, Earl",
			"articleRefs": [
				{
					"pageNumber": 1311,
					"articleName": "Detecting Semantic Clones of Unseen Functionality",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b311/573300b311.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Michael",
				"surname": "Tegegn"
			},
			"authorName": "Tegegn, Michael",
			"articleRefs": [
				{
					"pageNumber": 79,
					"articleName": "Reliable and Interpretable Android Malware Detection at Scale",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a079/850300a079.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Kenji",
				"surname": "Tei"
			},
			"authorName": "Tei, Kenji",
			"articleRefs": [
				{
					"pageNumber": 237,
					"articleName": "Towards MPC-Driven Software Adaptation: A Dual-Layer Approach Combining ICNN-Based Modeling and Delta-Based Tuning",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a237/850300a237.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Tachio",
				"surname": "Terauchi"
			},
			"authorName": "Terauchi, Tachio",
			"articleRefs": [
				{
					"pageNumber": 3967,
					"articleName": "A Secure Mocking Approach Towards Software Supply Chain Security",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d967/573300d967.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Chayanid",
				"surname": "Termphaiboon"
			},
			"authorName": "Termphaiboon, Chayanid",
			"articleRefs": [
				{
					"pageNumber": 261,
					"articleName": "Exploring the SECURITY.md in the Dependency Chain: Preliminary Analysis of the PyPI Ecosystem",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a261/850300a261.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Valerio",
				"surname": "Terragni"
			},
			"authorName": "Terragni, Valerio",
			"articleRefs": [
				{
					"pageNumber": 2208,
					"articleName": "LSPFuzz: Hunting Bugs in Language Servers",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c208/573300c208.pdf"
				},
				{
					"pageNumber": 4085,
					"articleName": "Metamorphic Testing of Deep Reinforcement Learning Agents with MDPMORPH",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e085/573300e085.pdf"
				},
				{
					"pageNumber": 4101,
					"articleName": "LLMORPH: Automated Metamorphic Testing of Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e101/573300e101.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Kishanthan",
				"surname": "Thangarajah"
			},
			"authorName": "Thangarajah, Kishanthan",
			"articleRefs": [
				{
					"pageNumber": 3286,
					"articleName": "Context-Aware CodeLLM Eviction for AI-Assisted Coding",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d286/573300d286.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Patanamon",
				"surname": "Thongtanunam"
			},
			"authorName": "Thongtanunam, Patanamon",
			"articleRefs": [
				{
					"pageNumber": 3759,
					"articleName": "What Types of Code Review Comments Do Developers Most Frequently Resolve?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d759/573300d759.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Cong ",
				"surname": "Tian"
			},
			"authorName": "Tian, Cong",
			"articleRefs": [
				{
					"pageNumber": 1207,
					"articleName": "Bridging Natural Language and Formal Specification Automated Translation of Software Requirements to LTL via Hierarchical Semantics Decomposition Using LLMs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b207/573300b207.pdf"
				},
				{
					"pageNumber": 3931,
					"articleName": "Requirements Development and Formalization for Reliable Code Generation: A Multi-Agent Vision",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d931/573300d931.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Haoxiang ",
				"surname": "Tian"
			},
			"authorName": "Tian, Haoxiang",
			"articleRefs": [
				{
					"pageNumber": 1168,
					"articleName": "When Autonomous Vehicle Meets V2X Cooperative Perception: How Far Are We?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b168/573300b168.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yifan",
				"surname": "Tian"
			},
			"authorName": "Tian, Yifan",
			"articleRefs": [
				{
					"pageNumber": 13,
					"articleName": "Argus: Resilience-Oriented Safety Assurance Framework for End-to-End ADSs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a013/573300a013.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yongqiang",
				"surname": "Tian"
			},
			"authorName": "Tian, Yongqiang",
			"articleRefs": [
				{
					"pageNumber": 2273,
					"articleName": "Latra: A Template-Based Language-Agnostic Transformation Framework for Effective Program Reduction",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c273/573300c273.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yuan",
				"surname": "Tian"
			},
			"authorName": "Tian, Yuan",
			"articleRefs": [
				{
					"pageNumber": 1044,
					"articleName": "PROMFUZZ: Leveraging LLM-Driven and Bug-Oriented Composite Analysis for Detecting Functional Bugs in Smart Contracts",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b044/573300b044.pdf"
				},
				{
					"pageNumber": 2260,
					"articleName": "Automated Repair of OpenID Connect Programs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c260/573300c260.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yunpeng",
				"surname": "Tian"
			},
			"authorName": "Tian, Yunpeng",
			"articleRefs": [
				{
					"pageNumber": 2541,
					"articleName": "Soleker: Uncovering Vulnerabilities in Solana Smart Contracts",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c541/573300c541.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jiaji ",
				"surname": "Tian "
			},
			"authorName": "Tian, Jiaji",
			"articleRefs": [
				{
					"pageNumber": 3592,
					"articleName": "AutoPLC: Generating Vendor-Aware Structured Text for Programmable Logic Controllers",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d592/573300d592.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Olga",
				"surname": "Tikhonova"
			},
			"authorName": "Tikhonova, Olga",
			"articleRefs": [
				{
					"pageNumber": 113,
					"articleName": "Pre-Filtering Code Suggestions using Developer Behavioral Telemetry to Optimize LLM-Assisted Programming",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a113/850300a113.pdf"
				},
				{
					"pageNumber": 214,
					"articleName": "Optimizing LLM Code Suggestions: Feedback-Driven Timing with Lightweight State Bounds",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a214/850300a214.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Christopher S.",
				"surname": "Timperley"
			},
			"authorName": "Timperley, Christopher S.",
			"articleRefs": [
				{
					"pageNumber": 3911,
					"articleName": "Human-In-The-Loop Oracle Learning for Simulation-Based Testing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d911/573300d911.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Christof",
				"surname": "Tinnes"
			},
			"authorName": "Tinnes, Christof",
			"articleRefs": [
				{
					"pageNumber": 166,
					"articleName": "An Empirical Study of Knowledge Transfer in AI Pair Programming",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a166/573300a166.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ben L.",
				"surname": "Titzer"
			},
			"authorName": "Titzer, Ben L.",
			"articleRefs": [
				{
					"pageNumber": 816,
					"articleName": "Execution-Aware Program Reduction for WebAssembly via Record and Replay",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a816/573300a816.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Saeid",
				"surname": "Tizpaz-Niari"
			},
			"authorName": "Tizpaz-Niari, Saeid",
			"articleRefs": [
				{
					"pageNumber": 342,
					"articleName": "Risk Estimation in Differential Fuzzing via Extreme Value Theory",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a342/573300a342.pdf"
				},
				{
					"pageNumber": 1679,
					"articleName": "Uncovering Discrimination Clusters: Quantifying and Explaining Systematic Fairness Violations",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b679/573300b679.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Paolo",
				"surname": "Tonella"
			},
			"authorName": "Tonella, Paolo",
			"articleRefs": [
				{
					"pageNumber": 3356,
					"articleName": "Bridging Research and Practice in Simulation-Based Testing of Industrial Robot Navigation Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d356/573300d356.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Greg",
				"surname": "Trafton"
			},
			"authorName": "Trafton, Greg",
			"articleRefs": [
				{
					"pageNumber": 3870,
					"articleName": "CodeACT-R: A Cognitive Simulation Framework for Human Attention in Code Reading",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d870/573300d870.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Anna",
				"surname": "Trapp"
			},
			"authorName": "Trapp, Anna",
			"articleRefs": [
				{
					"pageNumber": 186,
					"articleName": "From Facts to Foils: Designing and Evaluating Counterfactual Explanations for Smart Environments",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a186/850300a186.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Christoph",
				"surname": "Treude"
			},
			"authorName": "Treude, Christoph",
			"articleRefs": [
				{
					"pageNumber": 2311,
					"articleName": "Effective Code Membership Inference for Code Completion Models via Adversarial Prompts",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c311/573300c311.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ashutosh",
				"surname": "Trivedi"
			},
			"authorName": "Trivedi, Ashutosh",
			"articleRefs": [
				{
					"pageNumber": 1679,
					"articleName": "Uncovering Discrimination Clusters: Quantifying and Explaining Systematic Fairness Violations",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b679/573300b679.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Michelantonio",
				"surname": "Trizio"
			},
			"authorName": "Trizio, Michelantonio",
			"articleRefs": [
				{
					"pageNumber": 2400,
					"articleName": "LLMs for Automated Unit Test Generation and Assessment in Java: The AgoneTest Framework",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c400/573300c400.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Matthew",
				"surname": "Truscott"
			},
			"authorName": "Truscott, Matthew",
			"articleRefs": [
				{
					"pageNumber": 3568,
					"articleName": "Tuning LLM-Based Code Optimization via Meta-Prompting: An Industrial Perspective",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d568/573300d568.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Alexi",
				"surname": "Turcotte"
			},
			"authorName": "Turcotte, Alexi",
			"articleRefs": [
				{
					"pageNumber": 2490,
					"articleName": "The Fault in our Stats",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c490/573300c490.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Eray",
				"surname": "T\u00FCz\u00FCn"
			},
			"authorName": "T\u00FCz\u00FCn, Eray",
			"articleRefs": [
				{
					"pageNumber": 1008,
					"articleName": "Automated Inline Comment Smell Detection and Repair with Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b008/573300b008.pdf"
				},
				{
					"pageNumber": 3094,
					"articleName": "Agents in the Sandbox: End-to-End Crash Bug Reproduction for Minecraft",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d094/573300d094.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Vadim",
				"surname": "Tynchenko"
			},
			"authorName": "Tynchenko, Vadim",
			"articleRefs": [
				{
					"pageNumber": 229,
					"articleName": "Automated Evolutionary Hyperparameter Tuning for NLP-Based Test Case Generation",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a229/850300a229.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Tahir",
				"surname": "Ullah"
			},
			"authorName": "Ullah, Tahir",
			"articleRefs": [
				{
					"pageNumber": 2758,
					"articleName": "LLM-Based Identification of Null Pointer Exception Patches",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c758/573300c758.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Francesco P.",
				"surname": "Urbano"
			},
			"authorName": "Urbano, Francesco P.",
			"articleRefs": [
				{
					"pageNumber": 204,
					"articleName": "Explainability in Automated Cross-Domain Model-Driven Brake System Development",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a204/850300a204.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Dmitry",
				"surname": "Ustalov"
			},
			"authorName": "Ustalov, Dmitry",
			"articleRefs": [
				{
					"pageNumber": 358,
					"articleName": "Challenge on Optimization of Context Collection for Code Completion",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a358/850300a358.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Max",
				"surname": "Valk"
			},
			"authorName": "Valk, Max",
			"articleRefs": [
				{
					"pageNumber": 3474,
					"articleName": "Evaluating Large Language Models for Functional and Maintainable Code in Industrial Settings: A Case Study at ASML",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d474/573300d474.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Andrea",
				"surname": "Valori"
			},
			"authorName": "Valori, Andrea",
			"articleRefs": [
				{
					"pageNumber": 3250,
					"articleName": "Metrics Driven Reengineering and Continuous Code Improvement at Meta",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d250/573300d250.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Arie",
				"surname": "van Deursen"
			},
			"authorName": "van Deursen, Arie",
			"articleRefs": [
				{
					"pageNumber": 3509,
					"articleName": "TreeRanker: Fast and Model-Agnostic Ranking System for Code Suggestions in IDEs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d509/573300d509.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Raoul",
				"surname": "van Doren"
			},
			"authorName": "van Doren, Raoul",
			"articleRefs": [
				{
					"pageNumber": 1324,
					"articleName": "Efficient and Verifiable Proof Logging for MaxSAT Solving",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b324/573300b324.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Julien",
				"surname": "Vanegue"
			},
			"authorName": "Vanegue, Julien",
			"articleRefs": [
				{
					"pageNumber": 1298,
					"articleName": "AMPLE: Fine-Grained File Access Policies for Server Applications",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b298/573300b298.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Nicolas",
				"surname": "van Kempen"
			},
			"authorName": "van Kempen, Nicolas",
			"articleRefs": [
				{
					"pageNumber": 1552,
					"articleName": "It's Not Easy Being Green: On the Energy Efficiency of Programming Languages",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b552/573300b552.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Kirill",
				"surname": "Vasilevski"
			},
			"authorName": "Vasilevski, Kirill",
			"articleRefs": [
				{
					"pageNumber": 739,
					"articleName": "Watson: A Cognitive Observability Framework for the Reasoning of LLM-Powered Agents",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a739/573300a739.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Shubham ",
				"surname": "Vasudeo Desai"
			},
			"authorName": "Vasudeo Desai, Shubham",
			"articleRefs": [
				{
					"pageNumber": 4020,
					"articleName": "PrioTestCI: Efficient Test Case Prioritization in GitHub Workflows for CI Optimization",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e020/573300e020.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Tatiana Castro",
				"surname": "V\u00E9lez"
			},
			"authorName": "V\u00E9lez, Tatiana Castro",
			"articleRefs": [
				{
					"pageNumber": 752,
					"articleName": "Speculative Automated Refactoring of Imperative Deep Learning Programs to Graph Execution",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a752/573300a752.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Manuela",
				"surname": "Veloso"
			},
			"authorName": "Veloso, Manuela",
			"articleRefs": [
				{
					"pageNumber": 34,
					"articleName": "LLM Agents for Automated Dependency Upgrades",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a034/850300a034.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Andreea",
				"surname": "Vescan"
			},
			"authorName": "Vescan, Andreea",
			"articleRefs": [
				{
					"pageNumber": 129,
					"articleName": "Regression Testing Skill Transfer to Industry: A Preliminary Study in Higher Education",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a129/850300a129.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Marco",
				"surname": "Vieira"
			},
			"authorName": "Vieira, Marco",
			"articleRefs": [
				{
					"pageNumber": 2362,
					"articleName": "Polyglot: An Extensible Framework to Benchmark Code Translation with LLMs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c362/573300c362.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Tiago",
				"surname": "Vieira"
			},
			"authorName": "Vieira, Tiago",
			"articleRefs": [
				{
					"pageNumber": 51,
					"articleName": "A 3-Layer Agentic Model for Nonfunctional Requirements in Software Engineering",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a051/850300a051.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Francisco Eli",
				"surname": "Vi\u00F1a Barrientos"
			},
			"authorName": "Vi\u00F1a Barrientos, Francisco Eli",
			"articleRefs": [
				{
					"pageNumber": 3356,
					"articleName": "Bridging Research and Practice in Simulation-Based Testing of Industrial Robot Navigation Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d356/573300d356.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Corrado Aaron",
				"surname": "Visaggio"
			},
			"authorName": "Visaggio, Corrado Aaron",
			"articleRefs": [
				{
					"pageNumber": 3828,
					"articleName": "The Future of Software Transparency: Bridging Understanding, Measurement, and Practice",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d828/573300d828.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Andreas",
				"surname": "Vogelsang"
			},
			"authorName": "Vogelsang, Andreas",
			"articleRefs": [
				{
					"pageNumber": 186,
					"articleName": "From Facts to Foils: Designing and Evaluating Counterfactual Explanations for Smart Environments",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a186/850300a186.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Thomas Alexander",
				"surname": "V\u00F6lk"
			},
			"authorName": "V\u00F6lk, Thomas Alexander",
			"articleRefs": [
				{
					"pageNumber": 204,
					"articleName": "Explainability in Automated Cross-Domain Model-Driven Brake System Development",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a204/850300a204.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Vardan",
				"surname": "Voskanyan"
			},
			"authorName": "Voskanyan, Vardan",
			"articleRefs": [
				{
					"pageNumber": 3568,
					"articleName": "Tuning LLM-Based Code Optimization via Meta-Prompting: An Industrial Perspective",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d568/573300d568.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Stefan",
				"surname": "Wagner"
			},
			"authorName": "Wagner, Stefan",
			"articleRefs": [
				{
					"pageNumber": 222,
					"articleName": "Leveraging Large Language Models for Use Case Model Generation from Software Requirements",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a222/850300a222.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jaskaran Singh",
				"surname": "Walia"
			},
			"authorName": "Walia, Jaskaran Singh",
			"articleRefs": [
				{
					"pageNumber": 674,
					"articleName": "Triangle: Empowering Incident Triage with Multi-Agent",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a674/573300a674.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Robert",
				"surname": "Wallace"
			},
			"authorName": "Wallace, Robert",
			"articleRefs": [
				{
					"pageNumber": 1020,
					"articleName": "Programmers' Visual Attention on Function Call Graphs During Code Summarization",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b020/573300b020.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Stefan",
				"surname": "Wallentowitz"
			},
			"authorName": "Wallentowitz, Stefan",
			"articleRefs": [
				{
					"pageNumber": 145,
					"articleName": "BMuzz: Combining Bounded Model Checking and Fuzzing to Enhance Code Coverage",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a145/850300a145.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jun",
				"surname": "Wan"
			},
			"authorName": "Wan, Jun",
			"articleRefs": [
				{
					"pageNumber": 1830,
					"articleName": "PEACE: Towards Efficient Project-Level Efficiency Optimization via Hybrid Code Editing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b830/573300b830.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yuxuan",
				"surname": "Wan"
			},
			"authorName": "Wan, Yuxuan",
			"articleRefs": [
				{
					"pageNumber": 241,
					"articleName": "Interaction2Code: Benchmarking MLLM-Based Interactive Webpage Code Generation from Interactive Prototyping",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a241/573300a241.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zhiyuan",
				"surname": "Wan"
			},
			"authorName": "Wan, Zhiyuan",
			"articleRefs": [
				{
					"pageNumber": 2070,
					"articleName": "Why Is My Transaction Risky? Understanding Smart Contract Semantics and Interactions in the NFT Ecosystem",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c070/573300c070.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Aibin",
				"surname": "Wang"
			},
			"authorName": "Wang, Aibin",
			"articleRefs": [
				{
					"pageNumber": 330,
					"articleName": "LogMoE: Lightweight Expert Mixture for Cross-System Log Anomaly Detection",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a330/573300a330.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Changxin",
				"surname": "Wang"
			},
			"authorName": "Wang, Changxin",
			"articleRefs": [
				{
					"pageNumber": 584,
					"articleName": "EditFusion: Resolving Code Merge Conflicts via Edit Selection",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a584/573300a584.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Chaozheng ",
				"surname": "Wang"
			},
			"authorName": "Wang, Chaozheng",
			"articleRefs": [
				{
					"pageNumber": 3132,
					"articleName": "JSidentify-V2: Leveraging Dynamic Memory Fingerprinting for Mini-Game Plagiarism Detection",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d132/573300d132.pdf"
				},
				{
					"pageNumber": 3449,
					"articleName": "Automated Prompt Generation for Code Intelligence: An Empirical Study and Experience in WeChat",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d449/573300d449.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Chengpeng",
				"surname": "Wang"
			},
			"authorName": "Wang, Chengpeng",
			"articleRefs": [
				{
					"pageNumber": 1220,
					"articleName": "RFCAudit: AI Agent for Auditing Protocol Implementations Against RFC Specifications",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b220/573300b220.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Chenyu",
				"surname": "Wang"
			},
			"authorName": "Wang, Chenyu",
			"articleRefs": [
				{
					"pageNumber": 1181,
					"articleName": "Backdoors in Code Summarizers: How Bad Is It?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b181/573300b181.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Chong",
				"surname": "Wang"
			},
			"authorName": "Wang, Chong",
			"articleRefs": [
				{
					"pageNumber": 778,
					"articleName": "DrainCode: Stealthy Energy Consumption Attacks on Retrieval-Augmented Code Generation via Context Poisoning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a778/573300a778.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Dan",
				"surname": "Wang"
			},
			"authorName": "Wang, Dan",
			"articleRefs": [
				{
					"pageNumber": 228,
					"articleName": "RELIA: Accelerating the Analysis of Cloud Access Control Policies",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a228/573300a228.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Dingji",
				"surname": "Wang"
			},
			"authorName": "Wang, Dingji",
			"articleRefs": [
				{
					"pageNumber": 13,
					"articleName": "Argus: Resilience-Oriented Safety Assurance Framework for End-to-End ADSs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a013/573300a013.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Dong",
				"surname": "Wang"
			},
			"authorName": "Wang, Dong",
			"articleRefs": [
				{
					"pageNumber": 3045,
					"articleName": "Clarifying Semantics of In-Context Examples for Unit Test Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d045/573300d045.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Dongxia",
				"surname": "Wang"
			},
			"authorName": "Wang, Dongxia",
			"articleRefs": [
				{
					"pageNumber": 1868,
					"articleName": "ORFUZZ: Fuzzing the \"Other Side\" of LLM Safety \u2013 Testing Over-Refusal",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b868/573300b868.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Fanyu",
				"surname": "Wang"
			},
			"authorName": "Wang, Fanyu",
			"articleRefs": [
				{
					"pageNumber": 3333,
					"articleName": "Multi-Modal Requirements Data-Based Acceptance Criteria Generation Using LLMs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d333/573300d333.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Feng",
				"surname": "Wang"
			},
			"authorName": "Wang, Feng",
			"articleRefs": [
				{
					"pageNumber": 2221,
					"articleName": "LLM-Powered Multi-Agent Collaboration for Intelligent Industrial On-Call Automation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c221/573300c221.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Haibo",
				"surname": "Wang"
			},
			"authorName": "Wang, Haibo",
			"articleRefs": [
				{
					"pageNumber": 983,
					"articleName": "Coverage-Based Harmfulness Testing for LLM Code Transformation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a983/573300a983.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Haotian",
				"surname": "Wang"
			},
			"authorName": "Wang, Haotian",
			"articleRefs": [
				{
					"pageNumber": 1717,
					"articleName": "Fixing Broken Graphs: LLM-Powered Automatic Code Optimization for DNN Programs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b717/573300b717.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Haoye",
				"surname": "Wang"
			},
			"authorName": "Wang, Haoye",
			"articleRefs": [
				{
					"pageNumber": 1337,
					"articleName": "FGIT: Fault-Guided Fine-Tuning for Code Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b337/573300b337.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Haoyu",
				"surname": "Wang"
			},
			"authorName": "Wang, Haoyu",
			"articleRefs": [
				{
					"pageNumber": 445,
					"articleName": "TensorGuard: Gradient-Based Model Fingerprinting for LLM Similarity Detection and Family Classification",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a445/573300a445.pdf"
				},
				{
					"pageNumber": 1692,
					"articleName": "Demystifying Cookie Sharing Risks in WebView-Based Mobile App-in-app Ecosystems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b692/573300b692.pdf"
				},
				{
					"pageNumber": 1818,
					"articleName": "On the (In)Security of Non-Resettable Device Identifiers in Custom Android Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b818/573300b818.pdf"
				},
				{
					"pageNumber": 3167,
					"articleName": "HarmoBridge: Bridging ArkTS and C/C++ for Cross-Language Static Analysis on HarmonyOS",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d167/573300d167.pdf"
				},
				{
					"pageNumber": 3179,
					"articleName": "ApkArmor: Low-Cost Lightweight Anti-Decompilation Techniques for Android Apps",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d179/573300d179.pdf"
				},
				{
					"pageNumber": 3368,
					"articleName": "A Characterization Study of Bugs in LLM Agent Workflow Orchestration Frameworks",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d368/573300d368.pdf"
				},
				{
					"pageNumber": 3649,
					"articleName": "SCOPE: Evaluating and Enhancing Permission Explanation Transparency in Mobile Apps",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d649/573300d649.pdf"
				},
				{
					"pageNumber": 3660,
					"articleName": "The Gold Digger in the Dark Forest: Industrial-Scale MEV Analysis in Ethereum",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d660/573300d660.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Hongshu",
				"surname": "Wang"
			},
			"authorName": "Wang, Hongshu",
			"articleRefs": [
				{
					"pageNumber": 2121,
					"articleName": "PAT-Agent: Autoformalization for Model Checking",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c121/573300c121.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jialai",
				"surname": "Wang"
			},
			"authorName": "Wang, Jialai",
			"articleRefs": [
				{
					"pageNumber": 726,
					"articleName": "Improving LLM-Based Log Parsing by Learning from Errors in Reasoning Traces",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a726/573300a726.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jian",
				"surname": "Wang"
			},
			"authorName": "Wang, Jian",
			"articleRefs": [
				{
					"pageNumber": 254,
					"articleName": "Defects4C: Benchmarking Large Language Model Repair Capability with C/C++ Bugs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a254/573300a254.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jianing",
				"surname": "Wang"
			},
			"authorName": "Wang, Jianing",
			"articleRefs": [
				{
					"pageNumber": 1094,
					"articleName": "ZendDiff: Differential Testing of PHP Interpreter",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b094/573300b094.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jiashui",
				"surname": "Wang"
			},
			"authorName": "Wang, Jiashui",
			"articleRefs": [
				{
					"pageNumber": 1868,
					"articleName": "ORFUZZ: Fuzzing the \"Other Side\" of LLM Safety \u2013 Testing Over-Refusal",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b868/573300b868.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jiexin",
				"surname": "Wang"
			},
			"authorName": "Wang, Jiexin",
			"articleRefs": [
				{
					"pageNumber": 2247,
					"articleName": "Mixture-of-Experts Low-Rank Adaptation for Multilingual Code Summarization",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c247/573300c247.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jiming",
				"surname": "Wang"
			},
			"authorName": "Wang, Jiming",
			"articleRefs": [
				{
					"pageNumber": 1106,
					"articleName": "BCFuzz: Bytecode-Driven Fuzzing for JavaScript Engines",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b106/573300b106.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jinchen",
				"surname": "Wang"
			},
			"authorName": "Wang, Jinchen",
			"articleRefs": [
				{
					"pageNumber": 2681,
					"articleName": "Understanding Resource Injection Vulnerabilities in Kubernetes Ecosystems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c681/573300c681.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jingyi",
				"surname": "Wang"
			},
			"authorName": "Wang, Jingyi",
			"articleRefs": [
				{
					"pageNumber": 508,
					"articleName": "Provable Fairness Repair for Deep Neural Networks",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a508/573300a508.pdf"
				},
				{
					"pageNumber": 3683,
					"articleName": "Securing Millions of Decentralized Identities in Alipay Super App with End-to-End Formal Verification",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d683/573300d683.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Junjie",
				"surname": "Wang"
			},
			"authorName": "Wang, Junjie",
			"articleRefs": [
				{
					"pageNumber": 726,
					"articleName": "Improving LLM-Based Log Parsing by Learning from Errors in Reasoning Traces",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a726/573300a726.pdf"
				},
				{
					"pageNumber": 1602,
					"articleName": "Beyond Static GUI Agent: Evolving LLM-Based GUI Testing via Dynamic Memory",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b602/573300b602.pdf"
				},
				{
					"pageNumber": 2095,
					"articleName": "SPEC2CODE: Mapping Protocol Specification to Function-Level Code Implementation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c095/573300c095.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Kai",
				"surname": "Wang"
			},
			"authorName": "Wang, Kai",
			"articleRefs": [
				{
					"pageNumber": 3777,
					"articleName": "SGCR: A Specification-Grounded Framework for Trustworthy LLM Code Review",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d777/573300d777.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Kangjin",
				"surname": "Wang"
			},
			"authorName": "Wang, Kangjin",
			"articleRefs": [
				{
					"pageNumber": 3783,
					"articleName": "Walk the Talk: Is Your Log-Based Software Reliability Maintenance System Really Reliable?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d783/573300d783.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Liu",
				"surname": "Wang"
			},
			"authorName": "Wang, Liu",
			"articleRefs": [
				{
					"pageNumber": 1818,
					"articleName": "On the (In)Security of Non-Resettable Device Identifiers in Custom Android Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b818/573300b818.pdf"
				},
				{
					"pageNumber": 3649,
					"articleName": "SCOPE: Evaluating and Enhancing Permission Explanation Transparency in Mobile Apps",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d649/573300d649.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Long",
				"surname": "Wang"
			},
			"authorName": "Wang, Long",
			"articleRefs": [
				{
					"pageNumber": 3414,
					"articleName": "Data Dependency-Aware Code Generation from Enhanced UML Sequence Diagrams",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d414/573300d414.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Lu",
				"surname": "Wang"
			},
			"authorName": "Wang, Lu",
			"articleRefs": [
				{
					"pageNumber": 1142,
					"articleName": "Hypergraph Neural Network-Based Multi-Granular Root Cause Localization for Microservice Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b142/573300b142.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Minggu",
				"surname": "Wang"
			},
			"authorName": "Wang, Minggu",
			"articleRefs": [
				{
					"pageNumber": 2656,
					"articleName": "QuanBench: Benchmarking Quantum Code Generation with Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c656/573300c656.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Nan",
				"surname": "Wang"
			},
			"authorName": "Wang, Nan",
			"articleRefs": [
				{
					"pageNumber": 2869,
					"articleName": "LLMPort: Cross-File Patch Porting via Task Decomposition and Self-Correction",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c869/573300c869.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Peiding",
				"surname": "Wang"
			},
			"authorName": "Wang, Peiding",
			"articleRefs": [
				{
					"pageNumber": 2618,
					"articleName": "EfficientEdit: Accelerating Code Editing via Edit-Oriented Speculative Decoding",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c618/573300c618.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Pengfei",
				"surname": "Wang"
			},
			"authorName": "Wang, Pengfei",
			"articleRefs": [
				{
					"pageNumber": 713,
					"articleName": "When Control Flows Deviate: Directed Grey-box Fuzzing with Probabilistic Reachability Analysis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a713/573300a713.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Qing",
				"surname": "Wang"
			},
			"authorName": "Wang, Qing",
			"articleRefs": [
				{
					"pageNumber": 1602,
					"articleName": "Beyond Static GUI Agent: Evolving LLM-Based GUI Testing via Dynamic Memory",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b602/573300b602.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Qinglin",
				"surname": "Wang"
			},
			"authorName": "Wang, Qinglin",
			"articleRefs": [
				{
					"pageNumber": 1918,
					"articleName": "SemGuard: Real-Time Semantic Evaluator for Correcting LLM-Generated Code",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b918/573300b918.pdf"
				},
				{
					"pageNumber": 2477,
					"articleName": "Evaluating and Improving Framework-Based Parallel Code Completion with Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c477/573300c477.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Rui",
				"surname": "Wang"
			},
			"authorName": "Wang, Rui",
			"articleRefs": [
				{
					"pageNumber": 1,
					"articleName": "AlertGuardian: Intelligent Alert Life-Cycle Management for Large-Scale Cloud Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a001/573300a001.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Rujia",
				"surname": "Wang"
			},
			"authorName": "Wang, Rujia",
			"articleRefs": [
				{
					"pageNumber": 674,
					"articleName": "Triangle: Empowering Incident Triage with Multi-Agent",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a674/573300a674.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Rundong",
				"surname": "Wang"
			},
			"authorName": "Wang, Rundong",
			"articleRefs": [
				{
					"pageNumber": 584,
					"articleName": "EditFusion: Resolving Code Merge Conflicts via Edit Selection",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a584/573300a584.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Runzhe",
				"surname": "Wang"
			},
			"authorName": "Wang, Runzhe",
			"articleRefs": [
				{
					"pageNumber": 3545,
					"articleName": "LLM-Assisted Industrial-Scale Differential Testing of Package Incompatibilities in Linux Distributions",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d545/573300d545.pdf"
				},
				{
					"pageNumber": 3615,
					"articleName": "RPG: Linux Kernel Fuzzing Guided by Distribution-Specific Runtime Parameter Interfaces",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d615/573300d615.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ruyun",
				"surname": "Wang"
			},
			"authorName": "Wang, Ruyun",
			"articleRefs": [
				{
					"pageNumber": 1918,
					"articleName": "SemGuard: Real-Time Semantic Evaluator for Correcting LLM-Generated Code",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b918/573300b918.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Shangguang",
				"surname": "Wang"
			},
			"authorName": "Wang, Shangguang",
			"articleRefs": [
				{
					"pageNumber": 117,
					"articleName": "SateLight: A Satellite Application Update Framework for Satellite Computing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a117/573300a117.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Shangwen",
				"surname": "Wang"
			},
			"authorName": "Wang, Shangwen",
			"articleRefs": [
				{
					"pageNumber": 804,
					"articleName": "Let the Code Speak: Incorporating Program Dynamic State for Better Method-Level Fault Localization",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a804/573300a804.pdf"
				},
				{
					"pageNumber": 1194,
					"articleName": "AdaptEval: A Benchmark for Evaluating Large Language Models on Code Snippet Adaptation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b194/573300b194.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Shaohua",
				"surname": "Wang"
			},
			"authorName": "Wang, Shaohua",
			"articleRefs": [
				{
					"pageNumber": 2387,
					"articleName": "FailMapper: Automated Generation of Unit Tests Guided by Failure Scenarios",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c387/573300c387.pdf"
				},
				{
					"pageNumber": 2579,
					"articleName": "WINGMUZZ: Blackbox Testing of IoT Protocols via Two-Dimensional Fuzzing Schedule",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c579/573300c579.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Shenao",
				"surname": "Wang"
			},
			"authorName": "Wang, Shenao",
			"articleRefs": [
				{
					"pageNumber": 1692,
					"articleName": "Demystifying Cookie Sharing Risks in WebView-Based Mobile App-in-app Ecosystems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b692/573300b692.pdf"
				},
				{
					"pageNumber": 3368,
					"articleName": "A Characterization Study of Bugs in LLM Agent Workflow Orchestration Frameworks",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d368/573300d368.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Shengran",
				"surname": "Wang"
			},
			"authorName": "Wang, Shengran",
			"articleRefs": [
				{
					"pageNumber": 3937,
					"articleName": "IDBFuzz: Web Storage DataBase Fuzzing with Controllable Semantics",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d937/573300d937.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Shuai",
				"surname": "Wang"
			},
			"authorName": "Wang, Shuai",
			"articleRefs": [
				{
					"pageNumber": 945,
					"articleName": "Demystifying OpenZeppelin's Own Vulnerabilities and Analyzing Their Propagation in Smart Contracts",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a945/573300a945.pdf"
				},
				{
					"pageNumber": 1994,
					"articleName": "Have We Solved Access Control Vulnerability Detection in Smart Contracts? A Benchmark Study",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b994/573300b994.pdf"
				},
				{
					"pageNumber": 2771,
					"articleName": "Root Cause Analysis of RISC-V Build Failures via LLM and MCTS Reasoning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c771/573300c771.pdf"
				},
				{
					"pageNumber": 2905,
					"articleName": "Metamorphic Testing for Audio Content Moderation Software",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c905/573300c905.pdf"
				},
				{
					"pageNumber": 3132,
					"articleName": "JSidentify-V2: Leveraging Dynamic Memory Fingerprinting for Mini-Game Plagiarism Detection",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d132/573300d132.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Taiming",
				"surname": "Wang"
			},
			"authorName": "Wang, Taiming",
			"articleRefs": [
				{
					"pageNumber": 178,
					"articleName": "Wired for Reuse: Automating Context-Aware Code Adaptation in IDEs via LLM-Based Agent",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a178/573300a178.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Tianhong",
				"surname": "Wang"
			},
			"authorName": "Wang, Tianhong",
			"articleRefs": [
				{
					"pageNumber": 2145,
					"articleName": "Don't Mess with Bro's Cheese! An Empirical Study of Resource Conflict in Android Multi-Window",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c145/573300c145.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Tiantian",
				"surname": "Wang"
			},
			"authorName": "Wang, Tiantian",
			"articleRefs": [
				{
					"pageNumber": 2311,
					"articleName": "Effective Code Membership Inference for Code Completion Models via Adversarial Prompts",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c311/573300c311.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Tianze",
				"surname": "Wang"
			},
			"authorName": "Wang, Tianze",
			"articleRefs": [
				{
					"pageNumber": 2007,
					"articleName": "Explainable Fault Localization for Programming Assignments via LLM-Guided Annotation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c007/573300c007.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Tongtong",
				"surname": "Wang"
			},
			"authorName": "Wang, Tongtong",
			"articleRefs": [
				{
					"pageNumber": 3402,
					"articleName": "Out of Distribution Detection in Self-Adaptive Robots with AI-Powered Digital Twins",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d402/573300d402.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Wei",
				"surname": "Wang"
			},
			"authorName": "Wang, Wei",
			"articleRefs": [
				{
					"pageNumber": 2771,
					"articleName": "Root Cause Analysis of RISC-V Build Failures via LLM and MCTS Reasoning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c771/573300c771.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Weihang",
				"surname": "Wang"
			},
			"authorName": "Wang, Weihang",
			"articleRefs": [
				{
					"pageNumber": 2956,
					"articleName": "When Does Wasm Malware Detection Fail? A Systematic Analysis of Their Robustness to Evasion",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c956/573300c956.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Wei-Ji",
				"surname": "Wang"
			},
			"authorName": "Wang, Wei-Ji",
			"articleRefs": [
				{
					"pageNumber": 3788,
					"articleName": "From Modules to Marketplaces: A Vision for Composable Capability Sharing Across Organizations",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d788/573300d788.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Weijie",
				"surname": "Wang"
			},
			"authorName": "Wang, Weijie",
			"articleRefs": [
				{
					"pageNumber": 919,
					"articleName": "Lares: LLM-Driven Code Slice Semantic Search for Patch Presence Testing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a919/573300a919.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Weiyi",
				"surname": "Wang"
			},
			"authorName": "Wang, Weiyi",
			"articleRefs": [
				{
					"pageNumber": 2375,
					"articleName": "Interleaved Learning and Exploration: A Self-Adaptive Fuzz Testing Framework for MLIR",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c375/573300c375.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Wenhai",
				"surname": "Wang"
			},
			"authorName": "Wang, Wenhai",
			"articleRefs": [
				{
					"pageNumber": 1868,
					"articleName": "ORFUZZ: Fuzzing the \"Other Side\" of LLM Safety \u2013 Testing Over-Refusal",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b868/573300b868.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Wenxi",
				"surname": "Wang"
			},
			"authorName": "Wang, Wenxi",
			"articleRefs": [
				{
					"pageNumber": 1233,
					"articleName": "RFCScope: Detecting Logical Ambiguities in Internet Protocol Specifications",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b233/573300b233.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Wenxuan",
				"surname": "Wang"
			},
			"authorName": "Wang, Wenxuan",
			"articleRefs": [
				{
					"pageNumber": 241,
					"articleName": "Interaction2Code: Benchmarking MLLM-Based Interactive Webpage Code Generation from Interactive Prototyping",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a241/573300a241.pdf"
				},
				{
					"pageNumber": 2905,
					"articleName": "Metamorphic Testing for Audio Content Moderation Software",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c905/573300c905.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "XiaoFeng",
				"surname": "Wang"
			},
			"authorName": "Wang, XiaoFeng",
			"articleRefs": [
				{
					"pageNumber": 893,
					"articleName": "LineBreaker: Finding Token-Inconsistency Bugs with Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a893/573300a893.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xiaoyin",
				"surname": "Wang"
			},
			"authorName": "Wang, Xiaoyin",
			"articleRefs": [
				{
					"pageNumber": 338,
					"articleName": "ARTRIP: Automatic AR Testing with Randomized Interaction Patterns",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a338/850300a338.pdf"
				},
				{
					"pageNumber": 3808,
					"articleName": "How Does ChatGPT Make Assumptions When Creating Erroneous Programs?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d808/573300d808.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xin",
				"surname": "Wang"
			},
			"authorName": "Wang, Xin",
			"articleRefs": [
				{
					"pageNumber": 1930,
					"articleName": "Defects4Log: Benchmarking LLMs for Logging Code Defect Detection and Reasoning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b930/573300b930.pdf"
				},
				{
					"pageNumber": 3273,
					"articleName": "Minuku: Detecting Diverse Display Issues in Mobile Apps with Small-Scale Dataset",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d273/573300d273.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xinchen",
				"surname": "Wang"
			},
			"authorName": "Wang, Xinchen",
			"articleRefs": [
				{
					"pageNumber": 2426,
					"articleName": "An Agent-Based Evaluation Framework for Complex Code Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c426/573300c426.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xinyi",
				"surname": "Wang"
			},
			"authorName": "Wang, Xinyi",
			"articleRefs": [
				{
					"pageNumber": 3694,
					"articleName": "Quantum Machine Learning-Based Test Oracle for Autonomous Mobile Robots",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d694/573300d694.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xinzhou",
				"surname": "Wang"
			},
			"authorName": "Wang, Xinzhou",
			"articleRefs": [
				{
					"pageNumber": 253,
					"articleName": "Fair Developer Score: Build-Adjusted Measurement of Effort and Impact",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a253/850300a253.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xizao",
				"surname": "Wang"
			},
			"authorName": "Wang, Xizao",
			"articleRefs": [
				{
					"pageNumber": 2349,
					"articleName": "Incremental Program Analysis in the Wild: An Empirical Study on Real-World Program Changes",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c349/573300c349.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xu",
				"surname": "Wang"
			},
			"authorName": "Wang, Xu",
			"articleRefs": [
				{
					"pageNumber": 3191,
					"articleName": "KAIOps: A Platform Solution of End-to-End Multi-Modal AIOps for AI Training at Scale",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d191/573300d191.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xuan",
				"surname": "Wang"
			},
			"authorName": "Wang, Xuan",
			"articleRefs": [
				{
					"pageNumber": 3437,
					"articleName": "From Redundancy to Efficiency: Exploiting Shared UI Interactions Towards Efficient LLM-Based Testing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d437/573300d437.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yanhao",
				"surname": "Wang"
			},
			"authorName": "Wang, Yanhao",
			"articleRefs": [
				{
					"pageNumber": 3813,
					"articleName": "LLM-Based Dynamic Differential Testing for Database Connectors with Reinforcement Learning-Guided Prompt Selection",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d813/573300d813.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yanli",
				"surname": "Wang"
			},
			"authorName": "Wang, Yanli",
			"articleRefs": [
				{
					"pageNumber": 971,
					"articleName": "AlignCoder: Aligning Retrieval with Target Intent for Repository-Level Code Completion",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a971/573300a971.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yanlin",
				"surname": "Wang"
			},
			"authorName": "Wang, Yanlin",
			"articleRefs": [
				{
					"pageNumber": 610,
					"articleName": "RustRepoTrans: Repository-Level Context Code Translation Benchmark Targeting Rust",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a610/573300a610.pdf"
				},
				{
					"pageNumber": 778,
					"articleName": "DrainCode: Stealthy Energy Consumption Attacks on Retrieval-Augmented Code Generation via Context Poisoning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a778/573300a778.pdf"
				},
				{
					"pageNumber": 971,
					"articleName": "AlignCoder: Aligning Retrieval with Target Intent for Repository-Level Code Completion",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a971/573300a971.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yi",
				"surname": "Wang"
			},
			"authorName": "Wang, Yi",
			"articleRefs": [
				{
					"pageNumber": 3649,
					"articleName": "SCOPE: Evaluating and Enhancing Permission Explanation Transparency in Mobile Apps",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d649/573300d649.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yibo",
				"surname": "Wang"
			},
			"authorName": "Wang, Yibo",
			"articleRefs": [
				{
					"pageNumber": 1843,
					"articleName": "MCTS-Refined CoT: High-Quality Fine-Tuning Data for LLM-Based Repository Issue Resolution",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b843/573300b843.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ying",
				"surname": "Wang"
			},
			"authorName": "Wang, Ying",
			"articleRefs": [
				{
					"pageNumber": 1743,
					"articleName": "CROSS2OH: Enabling Seamless Porting of C/C++ Software Libraries to OpenHarmony",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b743/573300b743.pdf"
				},
				{
					"pageNumber": 1767,
					"articleName": "Demystifying Cross-Language C/C++ Binaries: A Robust Software Component Analysis Approach",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b767/573300b767.pdf"
				},
				{
					"pageNumber": 1843,
					"articleName": "MCTS-Refined CoT: High-Quality Fine-Tuning Data for LLM-Based Repository Issue Resolution",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b843/573300b843.pdf"
				},
				{
					"pageNumber": 1893,
					"articleName": "Diplomatist: What Do Cross-Language Dependencies Reflect Software Ecosystem Health?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b893/573300b893.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yingchuan",
				"surname": "Wang"
			},
			"authorName": "Wang, Yingchuan",
			"articleRefs": [
				{
					"pageNumber": 3437,
					"articleName": "From Redundancy to Efficiency: Exploiting Shared UI Interactions Towards Efficient LLM-Based Testing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d437/573300d437.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yiran",
				"surname": "Wang"
			},
			"authorName": "Wang, Yiran",
			"articleRefs": [
				{
					"pageNumber": 2273,
					"articleName": "Latra: A Template-Based Language-Agnostic Transformation Framework for Effective Program Reduction",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c273/573300c273.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yongtao",
				"surname": "Wang"
			},
			"authorName": "Wang, Yongtao",
			"articleRefs": [
				{
					"pageNumber": 3683,
					"articleName": "Securing Millions of Decentralized Identities in Alipay Super App with End-to-End Formal Verification",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d683/573300d683.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yuchen",
				"surname": "Wang"
			},
			"authorName": "Wang, Yuchen",
			"articleRefs": [
				{
					"pageNumber": 330,
					"articleName": "LogMoE: Lightweight Expert Mixture for Cross-System Log Anomaly Detection",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a330/573300a330.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yue",
				"surname": "Wang"
			},
			"authorName": "Wang, Yue",
			"articleRefs": [
				{
					"pageNumber": 355,
					"articleName": "Enhancing LLMs with Staged Grouping and Dehallucination for Header File Decomposition",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a355/573300a355.pdf"
				},
				{
					"pageNumber": 1793,
					"articleName": "Multi-Dimensional Assessment of Crowdsourced Testing Reports via LLMs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b793/573300b793.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yuekun",
				"surname": "Wang"
			},
			"authorName": "Wang, Yuekun",
			"articleRefs": [
				{
					"pageNumber": 2095,
					"articleName": "SPEC2CODE: Mapping Protocol Specification to Function-Level Code Implementation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c095/573300c095.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yuhang",
				"surname": "Wang"
			},
			"authorName": "Wang, Yuhang",
			"articleRefs": [
				{
					"pageNumber": 241,
					"articleName": "Interaction2Code: Benchmarking MLLM-Based Interactive Webpage Code Generation from Interactive Prototyping",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a241/573300a241.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zexu",
				"surname": "Wang"
			},
			"authorName": "Wang, Zexu",
			"articleRefs": [
				{
					"pageNumber": 571,
					"articleName": "SSR: Safeguarding Staking Rewards by Defining and Detecting Logical Defects in DeFi Staking",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a571/573300a571.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zeying",
				"surname": "Wang"
			},
			"authorName": "Wang, Zeying",
			"articleRefs": [
				{
					"pageNumber": 3191,
					"articleName": "KAIOps: A Platform Solution of End-to-End Multi-Modal AIOps for AI Training at Scale",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d191/573300d191.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zhe",
				"surname": "Wang"
			},
			"authorName": "Wang, Zhe",
			"articleRefs": [
				{
					"pageNumber": 1106,
					"articleName": "BCFuzz: Bytecode-Driven Fuzzing for JavaScript Engines",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b106/573300b106.pdf"
				},
				{
					"pageNumber": 3545,
					"articleName": "LLM-Assisted Industrial-Scale Differential Testing of Package Incompatibilities in Linux Distributions",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d545/573300d545.pdf"
				},
				{
					"pageNumber": 3759,
					"articleName": "What Types of Code Review Comments Do Developers Most Frequently Resolve?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d759/573300d759.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zhen",
				"surname": "Wang"
			},
			"authorName": "Wang, Zhen",
			"articleRefs": [
				{
					"pageNumber": 508,
					"articleName": "Provable Fairness Repair for Deep Neural Networks",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a508/573300a508.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zheng",
				"surname": "Wang"
			},
			"authorName": "Wang, Zheng",
			"articleRefs": [
				{
					"pageNumber": 3568,
					"articleName": "Tuning LLM-Based Code Optimization via Meta-Prompting: An Industrial Perspective",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d568/573300d568.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zhengshu",
				"surname": "Wang"
			},
			"authorName": "Wang, Zhengshu",
			"articleRefs": [
				{
					"pageNumber": 547,
					"articleName": "DNAFuzz: Descriptor-Aware Fuzzing for USB Drivers",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a547/573300a547.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zhitao",
				"surname": "Wang"
			},
			"authorName": "Wang, Zhitao",
			"articleRefs": [
				{
					"pageNumber": 3414,
					"articleName": "Data Dependency-Aware Code Generation from Enhanced UML Sequence Diagrams",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d414/573300d414.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zhonghan",
				"surname": "Wang"
			},
			"authorName": "Wang, Zhonghan",
			"articleRefs": [
				{
					"pageNumber": 1515,
					"articleName": "Improving NLSAT for Nonlinear Real Arithmetic",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b515/573300b515.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ziqi",
				"surname": "Wang"
			},
			"authorName": "Wang, Ziqi",
			"articleRefs": [
				{
					"pageNumber": 2833,
					"articleName": "Reflective Unit Test Generation for Precise Type Error Detection with Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c833/573300c833.pdf"
				},
				{
					"pageNumber": 3045,
					"articleName": "Clarifying Semantics of In-Context Examples for Unit Test Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d045/573300d045.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zixin",
				"surname": "Wang"
			},
			"authorName": "Wang, Zixin",
			"articleRefs": [
				{
					"pageNumber": 241,
					"articleName": "Interaction2Code: Benchmarking MLLM-Based Interactive Webpage Code Generation from Interactive Prototyping",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a241/573300a241.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zuobin",
				"surname": "Wang"
			},
			"authorName": "Wang, Zuobin",
			"articleRefs": [
				{
					"pageNumber": 2070,
					"articleName": "Why Is My Transaction Risky? Understanding Smart Contract Semantics and Interactions in the NFT Ecosystem",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c070/573300c070.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jinping",
				"surname": "Wang "
			},
			"authorName": "Wang, Jinping",
			"articleRefs": [
				{
					"pageNumber": 406,
					"articleName": "From Sparse to Structured: A Diffusion-Enhanced and Feature-Aligned Framework for Coincidental Correctness Detection",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a406/573300a406.pdf"
				},
				{
					"pageNumber": 1502,
					"articleName": "Sifting Truth from Coincidences: A Two-Stage Positive and Unlabeled Learning Model for Coincidental Correctness Detection",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b502/573300b502.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Shanchao",
				"surname": "Wang "
			},
			"authorName": "Wang, Shanchao",
			"articleRefs": [
				{
					"pageNumber": 3250,
					"articleName": "Metrics Driven Reengineering and Continuous Code Improvement at Meta",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d250/573300d250.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zehua",
				"surname": "Wang "
			},
			"authorName": "Wang, Zehua",
			"articleRefs": [
				{
					"pageNumber": 2771,
					"articleName": "Root Cause Analysis of RISC-V Build Failures via LLM and MCTS Reasoning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c771/573300c771.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Thomas",
				"surname": "Weber"
			},
			"authorName": "Weber, Thomas",
			"articleRefs": [
				{
					"pageNumber": 204,
					"articleName": "Explainability in Automated Cross-Domain Model-Driven Brake System Development",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a204/850300a204.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Chenfeng",
				"surname": "Wei"
			},
			"authorName": "Wei, Chenfeng",
			"articleRefs": [
				{
					"pageNumber": 1414,
					"articleName": "VeriExploit: Automatic Bug Reproduction in Smart Contracts via LLMs and Formal Methods",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b414/573300b414.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Lili",
				"surname": "Wei"
			},
			"authorName": "Wei, Lili",
			"articleRefs": [
				{
					"pageNumber": 39,
					"articleName": "MIMIC: Integrating Diverse Personality Traits for Better Game Testing Using Large Language Model",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a039/573300a039.pdf"
				},
				{
					"pageNumber": 2208,
					"articleName": "LSPFuzz: Hunting Bugs in Language Servers",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c208/573300c208.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Mingqiang",
				"surname": "Wei"
			},
			"authorName": "Wei, Mingqiang",
			"articleRefs": [
				{
					"pageNumber": 1880,
					"articleName": "Coding-Fuse: Efficient Fusion of Code Pre-Trained Models for Classification Tasks",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b880/573300b880.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Shiyi",
				"surname": "Wei"
			},
			"authorName": "Wei, Shiyi",
			"articleRefs": [
				{
					"pageNumber": 181,
					"articleName": "SeedUI: Understanding Initial Seeds in Fuzzing",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a181/850300a181.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xiaojie",
				"surname": "Wei"
			},
			"authorName": "Wei, Xiaojie",
			"articleRefs": [
				{
					"pageNumber": 1106,
					"articleName": "BCFuzz: Bytecode-Driven Fuzzing for JavaScript Engines",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b106/573300b106.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zhao",
				"surname": "Wei"
			},
			"authorName": "Wei, Zhao",
			"articleRefs": [
				{
					"pageNumber": 1843,
					"articleName": "MCTS-Refined CoT: High-Quality Fine-Tuning Data for LLM-Based Repository Issue Resolution",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b843/573300b843.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Kallistos",
				"surname": "Weis"
			},
			"authorName": "Weis, Kallistos",
			"articleRefs": [
				{
					"pageNumber": 166,
					"articleName": "An Empirical Study of Knowledge Transfer in AI Pair Programming",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a166/573300a166.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Alisa",
				"surname": "Welter"
			},
			"authorName": "Welter, Alisa",
			"articleRefs": [
				{
					"pageNumber": 166,
					"articleName": "An Empirical Study of Knowledge Transfer in AI Pair Programming",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a166/573300a166.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Baiyang",
				"surname": "Wen"
			},
			"authorName": "Wen, Baiyang",
			"articleRefs": [
				{
					"pageNumber": 1142,
					"articleName": "Hypergraph Neural Network-Based Multi-Granular Root Cause Localization for Microservice Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b142/573300b142.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Bao",
				"surname": "Wen"
			},
			"authorName": "Wen, Bao",
			"articleRefs": [
				{
					"pageNumber": 2133,
					"articleName": "Towards Generalizable Instruction Vulnerability Prediction via LLM-Enhanced Code Representation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c133/573300c133.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Cheng",
				"surname": "Wen"
			},
			"authorName": "Wen, Cheng",
			"articleRefs": [
				{
					"pageNumber": 1207,
					"articleName": "Bridging Natural Language and Formal Specification Automated Translation of Software Requirements to LTL via Hierarchical Semantics Decomposition Using LLMs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b207/573300b207.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ge",
				"surname": "Wen"
			},
			"authorName": "Wen, Ge",
			"articleRefs": [
				{
					"pageNumber": 1641,
					"articleName": "Fact-Aligned and Template-Constrained Static Analyzer Rule Enhancement with LLMs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b641/573300b641.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jinfeng",
				"surname": "Wen"
			},
			"authorName": "Wen, Jinfeng",
			"articleRefs": [
				{
					"pageNumber": 117,
					"articleName": "SateLight: A Satellite Application Update Framework for Satellite Computing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a117/573300a117.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ming",
				"surname": "Wen"
			},
			"authorName": "Wen, Ming",
			"articleRefs": [
				{
					"pageNumber": 1641,
					"articleName": "Fact-Aligned and Template-Constrained Static Analyzer Rule Enhancement with LLMs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b641/573300b641.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Sheng",
				"surname": "Wen"
			},
			"authorName": "Wen, Sheng",
			"articleRefs": [
				{
					"pageNumber": 2387,
					"articleName": "FailMapper: Automated Generation of Unit Tests Guided by Failure Scenarios",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c387/573300c387.pdf"
				},
				{
					"pageNumber": 2579,
					"articleName": "WINGMUZZ: Blackbox Testing of IoT Protocols via Two-Dimensional Fuzzing Schedule",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c579/573300c579.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Wu ",
				"surname": "Wen"
			},
			"authorName": "Wen, Wu",
			"articleRefs": [
				{
					"pageNumber": 1168,
					"articleName": "When Autonomous Vehicle Meets V2X Cooperative Perception: How Far Are We?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b168/573300b168.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xidao",
				"surname": "Wen"
			},
			"authorName": "Wen, Xidao",
			"articleRefs": [
				{
					"pageNumber": 3238,
					"articleName": "TrioXpert: An Automated Incident Management Framework for Microservice System",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d238/573300d238.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xin-Cheng",
				"surname": "Wen"
			},
			"authorName": "Wen, Xin-Cheng",
			"articleRefs": [
				{
					"pageNumber": 26,
					"articleName": "Vul-R2: A Reasoning LLM for Automated Vulnerability Repair",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a026/573300a026.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Dominik ",
				"surname": "Wermke"
			},
			"authorName": "Wermke, Dominik",
			"articleRefs": [
				{
					"pageNumber": 2995,
					"articleName": "Your Build Scripts Stink: The State of Code Smells in Build Scripts",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c995/573300c995.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Martin",
				"surname": "Weyssow"
			},
			"authorName": "Weyssow, Martin",
			"articleRefs": [
				{
					"pageNumber": 2605,
					"articleName": "SE-Jury: An LLM-as-Ensemble-Judge Metric for Narrowing the Gap with Human Evaluation in SE",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c605/573300c605.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Laurie",
				"surname": "Williams"
			},
			"authorName": "Williams, Laurie",
			"articleRefs": [
				{
					"pageNumber": 2794,
					"articleName": "Which Is Better For Reducing Outdated and Vulnerable Dependencies: Pinning or Floating?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c794/573300c794.pdf"
				},
				{
					"pageNumber": 2995,
					"articleName": "Your Build Scripts Stink: The State of Code Smells in Build Scripts",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c995/573300c995.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Tianyu",
				"surname": "Wo"
			},
			"authorName": "Wo, Tianyu",
			"articleRefs": [
				{
					"pageNumber": 3191,
					"articleName": "KAIOps: A Platform Solution of End-to-End Multi-Modal AIOps for AI Training at Scale",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d191/573300d191.pdf"
				},
				{
					"pageNumber": 3753,
					"articleName": "KAIR: A Statistical and Causal Approach to Pinpointing Stragglers in Distributed Model Training",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d753/573300d753.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Rebekka",
				"surname": "Wohlrab"
			},
			"authorName": "Wohlrab, Rebekka",
			"articleRefs": [
				{
					"pageNumber": 58,
					"articleName": "Leveraging Large Language Models for Cybersecurity Risk Assessment \u2014 A Case from Forestry Cyber-Physical Systems",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a058/850300a058.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Seunghoon",
				"surname": "Woo"
			},
			"authorName": "Woo, Seunghoon",
			"articleRefs": [
				{
					"pageNumber": 1577,
					"articleName": "CRYPTBARA: Dependency-Guided Detection of Python Cryptographic API Misuses",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b577/573300b577.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Seungwon",
				"surname": "Woo"
			},
			"authorName": "Woo, Seungwon",
			"articleRefs": [
				{
					"pageNumber": 176,
					"articleName": "K-SNAC: Robust Neuron Coverage for OOD Generalization and Test Adequacy",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a176/850300a176.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Brandon",
				"surname": "Wroblewski"
			},
			"authorName": "Wroblewski, Brandon",
			"articleRefs": [
				{
					"pageNumber": 2995,
					"articleName": "Your Build Scripts Stink: The State of Code Smells in Build Scripts",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c995/573300c995.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Aolang",
				"surname": "Wu"
			},
			"authorName": "Wu, Aolang",
			"articleRefs": [
				{
					"pageNumber": 3592,
					"articleName": "AutoPLC: Generating Vendor-Aware Structured Text for Programmable Logic Controllers",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d592/573300d592.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Boyu",
				"surname": "Wu"
			},
			"authorName": "Wu, Boyu",
			"articleRefs": [
				{
					"pageNumber": 1602,
					"articleName": "Beyond Static GUI Agent: Evolving LLM-Based GUI Testing via Dynamic Memory",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b602/573300b602.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Chenggang",
				"surname": "Wu"
			},
			"authorName": "Wu, Chenggang",
			"articleRefs": [
				{
					"pageNumber": 1106,
					"articleName": "BCFuzz: Bytecode-Driven Fuzzing for JavaScript Engines",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b106/573300b106.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Daoyuan",
				"surname": "Wu"
			},
			"authorName": "Wu, Daoyuan",
			"articleRefs": [
				{
					"pageNumber": 52,
					"articleName": "Learning from the Past: Real-World Exploit Migration for Smart Contract PoC Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a052/573300a052.pdf"
				},
				{
					"pageNumber": 945,
					"articleName": "Demystifying OpenZeppelin's Own Vulnerabilities and Analyzing Their Propagation in Smart Contracts",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a945/573300a945.pdf"
				},
				{
					"pageNumber": 1780,
					"articleName": "Detecting Various DeFi Price Manipulations with LLM Reasoning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b780/573300b780.pdf"
				},
				{
					"pageNumber": 1994,
					"articleName": "Have We Solved Access Control Vulnerability Detection in Smart Contracts? A Benchmark Study",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b994/573300b994.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Fan",
				"surname": "Wu"
			},
			"authorName": "Wu, Fan",
			"articleRefs": [
				{
					"pageNumber": 3568,
					"articleName": "Tuning LLM-Based Code Optimization via Meta-Prompting: An Industrial Perspective",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d568/573300d568.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Hao",
				"surname": "Wu"
			},
			"authorName": "Wu, Hao",
			"articleRefs": [
				{
					"pageNumber": 457,
					"articleName": "Uncovering Prompt Elements: Cloning System Prompts from Behavioral Traces",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a457/573300a457.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jiadong",
				"surname": "Wu"
			},
			"authorName": "Wu, Jiadong",
			"articleRefs": [
				{
					"pageNumber": 778,
					"articleName": "DrainCode: Stealthy Energy Consumption Attacks on Retrieval-Augmented Code Generation via Context Poisoning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a778/573300a778.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jiale",
				"surname": "Wu"
			},
			"authorName": "Wu, Jiale",
			"articleRefs": [
				{
					"pageNumber": 3167,
					"articleName": "HarmoBridge: Bridging ArkTS and C/C++ for Cross-Language Static Analysis on HarmonyOS",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d167/573300d167.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jiarong",
				"surname": "Wu"
			},
			"authorName": "Wu, Jiarong",
			"articleRefs": [
				{
					"pageNumber": 2208,
					"articleName": "LSPFuzz: Hunting Bugs in Language Servers",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c208/573300c208.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jielun",
				"surname": "Wu"
			},
			"authorName": "Wu, Jielun",
			"articleRefs": [
				{
					"pageNumber": 1246,
					"articleName": "Protecting Source Code Privacy When Hunting Memory Bugs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b246/573300b246.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jingzheng",
				"surname": "Wu"
			},
			"authorName": "Wu, Jingzheng",
			"articleRefs": [
				{
					"pageNumber": 3556,
					"articleName": "Shrunk, Yet Complete: Code Shrinking-Resilient Android Third-Party Library Detection",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d556/573300d556.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Libin",
				"surname": "Wu"
			},
			"authorName": "Wu, Libin",
			"articleRefs": [
				{
					"pageNumber": 1602,
					"articleName": "Beyond Static GUI Agent: Evolving LLM-Based GUI Testing via Dynamic Memory",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b602/573300b602.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Menghan",
				"surname": "Wu"
			},
			"authorName": "Wu, Menghan",
			"articleRefs": [
				{
					"pageNumber": 2745,
					"articleName": "HFuzzer: Testing Large Language Models for Package Hallucinations via Phrase-Based Fuzzing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c745/573300c745.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Mengzhou",
				"surname": "Wu"
			},
			"authorName": "Wu, Mengzhou",
			"articleRefs": [
				{
					"pageNumber": 3580,
					"articleName": "Element-Aware Fine-Tuning of Vision-Language Models for Cost-Efficient GUI Testing in an Industrial Setting",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d580/573300d580.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ming",
				"surname": "Wu"
			},
			"authorName": "Wu, Ming",
			"articleRefs": [
				{
					"pageNumber": 3759,
					"articleName": "What Types of Code Review Comments Do Developers Most Frequently Resolve?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d759/573300d759.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Qinyun",
				"surname": "Wu"
			},
			"authorName": "Wu, Qinyun",
			"articleRefs": [
				{
					"pageNumber": 3671,
					"articleName": "RepoMasterEval: Evaluating Code Completion via Real-World Repositories",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d671/573300d671.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Rongxin",
				"surname": "Wu"
			},
			"authorName": "Wu, Rongxin",
			"articleRefs": [
				{
					"pageNumber": 854,
					"articleName": "DLBENCH: A Comprehensive Benchmark for SQL Translation with Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a854/573300a854.pdf"
				},
				{
					"pageNumber": 1246,
					"articleName": "Protecting Source Code Privacy When Hunting Memory Bugs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b246/573300b246.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Shengxin",
				"surname": "Wu"
			},
			"authorName": "Wu, Shengxin",
			"articleRefs": [
				{
					"pageNumber": 1246,
					"articleName": "Protecting Source Code Privacy When Hunting Memory Bugs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b246/573300b246.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Susheng",
				"surname": "Wu"
			},
			"authorName": "Wu, Susheng",
			"articleRefs": [
				{
					"pageNumber": 419,
					"articleName": "ProfMal: Detecting Malicious NPM Packages by the Synergy between Static and Dynamic Analysis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a419/573300a419.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Tong",
				"surname": "Wu"
			},
			"authorName": "Wu, Tong",
			"articleRefs": [
				{
					"pageNumber": 1414,
					"articleName": "VeriExploit: Automatic Bug Reproduction in Smart Contracts via LLMs and Formal Methods",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b414/573300b414.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Wei",
				"surname": "Wu"
			},
			"authorName": "Wu, Wei",
			"articleRefs": [
				{
					"pageNumber": 1272,
					"articleName": "SMTgazer: Learning to Schedule SMT Algorithms via Bayesian Optimization",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b272/573300b272.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xin",
				"surname": "Wu"
			},
			"authorName": "Wu, Xin",
			"articleRefs": [
				{
					"pageNumber": 2221,
					"articleName": "LLM-Powered Multi-Agent Collaboration for Intelligent Industrial On-Call Automation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c221/573300c221.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xiongfei",
				"surname": "Wu"
			},
			"authorName": "Wu, Xiongfei",
			"articleRefs": [
				{
					"pageNumber": 2045,
					"articleName": "Demystifying the Evolution of Neural Networks with BOM Analysis: Insights from a Large-Scale Study of 55,997 GitHub Repositories",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c045/573300c045.pdf"
				},
				{
					"pageNumber": 3823,
					"articleName": "Is Measurement Enough? Rethinking Output Validation in Quantum Program Testing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d823/573300d823.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yanjun",
				"surname": "Wu"
			},
			"authorName": "Wu, Yanjun",
			"articleRefs": [
				{
					"pageNumber": 1755,
					"articleName": "HybridSIMD: A Super C++ SIMD Library with Integrated Auto-Tuning Capabilities",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b755/573300b755.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yifan",
				"surname": "Wu"
			},
			"authorName": "Wu, Yifan",
			"articleRefs": [
				{
					"pageNumber": 661,
					"articleName": "United We Stand: Towards End-to-End Log-Based Fault Diagnosis via Interactive Multi-Task Learning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a661/573300a661.pdf"
				},
				{
					"pageNumber": 700,
					"articleName": "LogAction: Consistent Cross-System Anomaly Detection Through Logs via Active Domain Adaptation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a700/573300a700.pdf"
				},
				{
					"pageNumber": 1118,
					"articleName": "CoorLog: Efficient-Generalizable Log Anomaly Detection via Adaptive Coordinator in Software Evolution",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b118/573300b118.pdf"
				},
				{
					"pageNumber": 3783,
					"articleName": "Walk the Talk: Is Your Log-Based Software Reliability Maintenance System Really Reliable?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d783/573300d783.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yiqian",
				"surname": "Wu"
			},
			"authorName": "Wu, Yiqian",
			"articleRefs": [
				{
					"pageNumber": 1565,
					"articleName": "Belief Propagation with Local Structure and Its Applications in Program Analysis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b565/573300b565.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yongjiang",
				"surname": "Wu"
			},
			"authorName": "Wu, Yongjiang",
			"articleRefs": [
				{
					"pageNumber": 2905,
					"articleName": "Metamorphic Testing for Audio Content Moderation Software",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c905/573300c905.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yueming",
				"surname": "Wu"
			},
			"authorName": "Wu, Yueming",
			"articleRefs": [
				{
					"pageNumber": 2045,
					"articleName": "Demystifying the Evolution of Neural Networks with BOM Analysis: Insights from a Large-Scale Study of 55,997 GitHub Repositories",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c045/573300c045.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yufei",
				"surname": "Wu"
			},
			"authorName": "Wu, Yufei",
			"articleRefs": [
				{
					"pageNumber": 3906,
					"articleName": "ConfuseTaint: Exploiting Vulnerabilities to Bypass Dynamic Taint Analysis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d906/573300d906.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zehao",
				"surname": "Wu"
			},
			"authorName": "Wu, Zehao",
			"articleRefs": [
				{
					"pageNumber": 445,
					"articleName": "TensorGuard: Gradient-Based Model Fingerprinting for LLM Similarity Detection and Family Classification",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a445/573300a445.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zhenyu",
				"surname": "Wu"
			},
			"authorName": "Wu, Zhenyu",
			"articleRefs": [
				{
					"pageNumber": 406,
					"articleName": "From Sparse to Structured: A Diffusion-Enhanced and Feature-Aligned Framework for Coincidental Correctness Detection",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a406/573300a406.pdf"
				},
				{
					"pageNumber": 1502,
					"articleName": "Sifting Truth from Coincidences: A Two-Stage Positive and Unlabeled Learning Model for Coincidental Correctness Detection",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b502/573300b502.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zhiyong",
				"surname": "Wu"
			},
			"authorName": "Wu, Zhiyong",
			"articleRefs": [
				{
					"pageNumber": 1806,
					"articleName": "ARG: Testing Query Rewriters via Abstract Rule Guided Fuzzing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b806/573300b806.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zhiyu",
				"surname": "Wu"
			},
			"authorName": "Wu, Zhiyu",
			"articleRefs": [
				{
					"pageNumber": 932,
					"articleName": "Exploring Static Taint Analysis in LLMs: A Dynamic Benchmarking Framework for Measurement and Enhancement",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a932/573300a932.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Maximilian",
				"surname": "Wulf"
			},
			"authorName": "Wulf, Maximilian",
			"articleRefs": [
				{
					"pageNumber": 3356,
					"articleName": "Bridging Research and Practice in Simulation-Based Testing of Industrial Robot Navigation Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d356/573300d356.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Marvin",
				"surname": "Wyrich"
			},
			"authorName": "Wyrich, Marvin",
			"articleRefs": [
				{
					"pageNumber": 166,
					"articleName": "An Empirical Study of Knowledge Transfer in AI Pair Programming",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a166/573300a166.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Chenxiao",
				"surname": "Xia"
			},
			"authorName": "Xia, Chenxiao",
			"articleRefs": [
				{
					"pageNumber": 3008,
					"articleName": "Mockingbird: Efficient Excessive Data Exposures Detection via Dynamic Code Instrumentation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d008/573300d008.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Kun",
				"surname": "Xia"
			},
			"authorName": "Xia, Kun",
			"articleRefs": [
				{
					"pageNumber": 3120,
					"articleName": "How Can Infrastructure as Code Accelerate Data Center Bring-ups? A Case Study at ByteDance",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d120/573300d120.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Pengcheng",
				"surname": "Xia"
			},
			"authorName": "Xia, Pengcheng",
			"articleRefs": [
				{
					"pageNumber": 3179,
					"articleName": "ApkArmor: Low-Cost Lightweight Anti-Decompilation Techniques for Android Apps",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d179/573300d179.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Qun ",
				"surname": "Xia"
			},
			"authorName": "Xia, Qun",
			"articleRefs": [
				{
					"pageNumber": 3132,
					"articleName": "JSidentify-V2: Leveraging Dynamic Memory Fingerprinting for Mini-Game Plagiarism Detection",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d132/573300d132.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Shangzhou",
				"surname": "Xia"
			},
			"authorName": "Xia, Shangzhou",
			"articleRefs": [
				{
					"pageNumber": 3823,
					"articleName": "Is Measurement Enough? Rethinking Output Validation in Quantum Program Testing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d823/573300d823.pdf"
				},
				{
					"pageNumber": 3880,
					"articleName": "NovaQ: Improving Quantum Program Testing through Diversity-Guided Test Case Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d880/573300d880.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xin",
				"surname": "Xia"
			},
			"authorName": "Xia, Xin",
			"articleRefs": [
				{
					"pageNumber": 91,
					"articleName": "When AllClose Fails: Round-Off Error Estimation for Deep Learning Programs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a091/573300a091.pdf"
				},
				{
					"pageNumber": 1337,
					"articleName": "FGIT: Fault-Guided Fine-Tuning for Code Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b337/573300b337.pdf"
				},
				{
					"pageNumber": 2579,
					"articleName": "WINGMUZZ: Blackbox Testing of IoT Protocols via Two-Dimensional Fuzzing Schedule",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c579/573300c579.pdf"
				},
				{
					"pageNumber": 2605,
					"articleName": "SE-Jury: An LLM-as-Ensemble-Judge Metric for Narrowing the Gap with Human Evaluation in SE",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c605/573300c605.pdf"
				},
				{
					"pageNumber": 2745,
					"articleName": "HFuzzer: Testing Large Language Models for Package Hallucinations via Phrase-Based Fuzzing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c745/573300c745.pdf"
				},
				{
					"pageNumber": 3020,
					"articleName": "RealisticCodeBench: Towards More Realistic Evaluation of Large Language Models for Code Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d020/573300d020.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yang",
				"surname": "Xiang"
			},
			"authorName": "Xiang, Yang",
			"articleRefs": [
				{
					"pageNumber": 2387,
					"articleName": "FailMapper: Automated Generation of Unit Tests Guided by Failure Scenarios",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c387/573300c387.pdf"
				},
				{
					"pageNumber": 2579,
					"articleName": "WINGMUZZ: Blackbox Testing of IoT Protocols via Two-Dimensional Fuzzing Schedule",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c579/573300c579.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Bo",
				"surname": "Xiao"
			},
			"authorName": "Xiao, Bo",
			"articleRefs": [
				{
					"pageNumber": 393,
					"articleName": "Democratizing the Cryptocurrency Ecosystem by Just-In-Time Transformation of Mining Programs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a393/573300a393.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jingyu",
				"surname": "Xiao"
			},
			"authorName": "Xiao, Jingyu",
			"articleRefs": [
				{
					"pageNumber": 241,
					"articleName": "Interaction2Code: Benchmarking MLLM-Based Interactive Webpage Code Generation from Interactive Prototyping",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a241/573300a241.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Pei",
				"surname": "Xiao"
			},
			"authorName": "Xiao, Pei",
			"articleRefs": [
				{
					"pageNumber": 661,
					"articleName": "United We Stand: Towards End-to-End Log-Based Fault Diagnosis via Interactive Multi-Task Learning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a661/573300a661.pdf"
				},
				{
					"pageNumber": 700,
					"articleName": "LogAction: Consistent Cross-System Anomaly Detection Through Logs via Active Domain Adaptation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a700/573300a700.pdf"
				},
				{
					"pageNumber": 1118,
					"articleName": "CoorLog: Efficient-Generalizable Log Anomaly Detection via Adaptive Coordinator in Software Evolution",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b118/573300b118.pdf"
				},
				{
					"pageNumber": 3783,
					"articleName": "Walk the Talk: Is Your Log-Based Software Reliability Maintenance System Really Reliable?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d783/573300d783.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xusheng",
				"surname": "Xiao"
			},
			"authorName": "Xiao, Xusheng",
			"articleRefs": [
				{
					"pageNumber": 880,
					"articleName": "APPBDS: LLM-Powered Description Synthesis for Sensitive Behaviors in Mobile Apps",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a880/573300a880.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yang",
				"surname": "Xiao"
			},
			"authorName": "Xiao, Yang",
			"articleRefs": [
				{
					"pageNumber": 304,
					"articleName": "Advancing Binary Code Similarity Detection via Context-Content Fusion and LLM Verification",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a304/573300a304.pdf"
				},
				{
					"pageNumber": 1069,
					"articleName": "A Large Scale Study of AI-Based Binary Function Similarity Detection Techniques for Security Researchers and Practitioners",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b069/573300b069.pdf"
				},
				{
					"pageNumber": 2969,
					"articleName": "Vulnerability-Affected Versions Identification: How Far Are We?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c969/573300c969.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "xiaofei",
				"surname": "xie"
			},
			"authorName": "xie, xiaofei",
			"articleRefs": [
				{
					"pageNumber": 254,
					"articleName": "Defects4C: Benchmarking Large Language Model Repair Capability with C/C++ Bugs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a254/573300a254.pdf"
				},
				{
					"pageNumber": 1155,
					"articleName": "Seeing is Fixing: Cross-Modal Reasoning with Multimodal LLMs for Visual Software Issue Repair",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b155/573300b155.pdf"
				},
				{
					"pageNumber": 2095,
					"articleName": "SPEC2CODE: Mapping Protocol Specification to Function-Level Code Implementation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c095/573300c095.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Bing",
				"surname": "Xie"
			},
			"authorName": "Xie, Bing",
			"articleRefs": [
				{
					"pageNumber": 355,
					"articleName": "Enhancing LLMs with Staged Grouping and Dehallucination for Header File Decomposition",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a355/573300a355.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Difan",
				"surname": "Xie"
			},
			"authorName": "Xie, Difan",
			"articleRefs": [
				{
					"pageNumber": 2070,
					"articleName": "Why Is My Transaction Risky? Understanding Smart Contract Semantics and Interactions in the NFT Ecosystem",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c070/573300c070.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Dongchen",
				"surname": "Xie"
			},
			"authorName": "Xie, Dongchen",
			"articleRefs": [
				{
					"pageNumber": 996,
					"articleName": "Not Every Patch is an Island: LLM-Enhanced Identification of Multiple Vulnerability Patches",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a996/573300a996.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Huan",
				"surname": "Xie"
			},
			"authorName": "Xie, Huan",
			"articleRefs": [
				{
					"pageNumber": 406,
					"articleName": "From Sparse to Structured: A Diffusion-Enhanced and Feature-Aligned Framework for Coincidental Correctness Detection",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a406/573300a406.pdf"
				},
				{
					"pageNumber": 1502,
					"articleName": "Sifting Truth from Coincidences: A Two-Stage Positive and Unlabeled Learning Model for Coincidental Correctness Detection",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b502/573300b502.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Lintao",
				"surname": "Xie"
			},
			"authorName": "Xie, Lintao",
			"articleRefs": [
				{
					"pageNumber": 3485,
					"articleName": "BitsAI-Fix: LLM-Driven Approach for Automated Lint Error Resolution in Practice",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d485/573300d485.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Maoyi",
				"surname": "Xie"
			},
			"authorName": "Xie, Maoyi",
			"articleRefs": [
				{
					"pageNumber": 1780,
					"articleName": "Detecting Various DeFi Price Manipulations with LLM Reasoning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b780/573300b780.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Mengyao",
				"surname": "Xie"
			},
			"authorName": "Xie, Mengyao",
			"articleRefs": [
				{
					"pageNumber": 1106,
					"articleName": "BCFuzz: Bytecode-Driven Fuzzing for JavaScript Engines",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b106/573300b106.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Qinge",
				"surname": "Xie"
			},
			"authorName": "Xie, Qinge",
			"articleRefs": [
				{
					"pageNumber": 1044,
					"articleName": "PROMFUZZ: Leveraging LLM-Driven and Bug-Oriented Composite Analysis for Detecting Functional Bugs in Smart Contracts",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b044/573300b044.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Tao",
				"surname": "Xie"
			},
			"authorName": "Xie, Tao",
			"articleRefs": [
				{
					"pageNumber": 3144,
					"articleName": "Practical Escape of Exploration Tarpits for Mini-Game Testing in an Industrial Setting",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d144/573300d144.pdf"
				},
				{
					"pageNumber": 3580,
					"articleName": "Element-Aware Fine-Tuning of Vision-Language Models for Cost-Efficient GUI Testing in an Industrial Setting",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d580/573300d580.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Wei",
				"surname": "Xie"
			},
			"authorName": "Xie, Wei",
			"articleRefs": [
				{
					"pageNumber": 713,
					"articleName": "When Control Flows Deviate: Directed Grey-box Fuzzing with Probabilistic Reachability Analysis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a713/573300a713.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xiaoyuan",
				"surname": "Xie"
			},
			"authorName": "Xie, Xiaoyuan",
			"articleRefs": [
				{
					"pageNumber": 996,
					"articleName": "Not Every Patch is an Island: LLM-Enhanced Identification of Multiple Vulnerability Patches",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a996/573300a996.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yudong",
				"surname": "Xie"
			},
			"authorName": "Xie, Yudong",
			"articleRefs": [
				{
					"pageNumber": 1717,
					"articleName": "Fixing Broken Graphs: LLM-Powered Automatic Code Optimization for DNN Programs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b717/573300b717.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Luyi",
				"surname": "Xing"
			},
			"authorName": "Xing, Luyi",
			"articleRefs": [
				{
					"pageNumber": 893,
					"articleName": "LineBreaker: Finding Token-Inconsistency Bugs with Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a893/573300a893.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Mingjie",
				"surname": "Xing"
			},
			"authorName": "Xing, Mingjie",
			"articleRefs": [
				{
					"pageNumber": 1755,
					"articleName": "HybridSIMD: A Super C++ SIMD Library with Integrated Auto-Tuning Capabilities",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b755/573300b755.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yujie",
				"surname": "Xing"
			},
			"authorName": "Xing, Yujie",
			"articleRefs": [
				{
					"pageNumber": 2057,
					"articleName": "FirmProj: Detecting Firmware Leakage in IoT Update Processes via Companion App Analysis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c057/573300c057.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yuning",
				"surname": "Xing"
			},
			"authorName": "Xing, Yuning",
			"articleRefs": [
				{
					"pageNumber": 4085,
					"articleName": "Metamorphic Testing of Deep Reinforcement Learning Agents with MDPMORPH",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e085/573300e085.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zhenchang",
				"surname": "Xing"
			},
			"authorName": "Xing, Zhenchang",
			"articleRefs": [
				{
					"pageNumber": 687,
					"articleName": "Navigating the Labyrinth: Path-Sensitive Unit Test Generation with Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a687/573300a687.pdf"
				},
				{
					"pageNumber": 4004,
					"articleName": "Towards Context-Aware Mobile Privacy Notice: Implementation of A Deployable Contextual Privacy Policies Generator",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e004/573300e004.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Gangda",
				"surname": "Xiong"
			},
			"authorName": "Xiong, Gangda",
			"articleRefs": [
				{
					"pageNumber": 1489,
					"articleName": "CoTune: Co-Evolutionary Configuration Tuning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b489/573300b489.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ting ",
				"surname": "Xiong"
			},
			"authorName": "Xiong, Ting",
			"articleRefs": [
				{
					"pageNumber": 3132,
					"articleName": "JSidentify-V2: Leveraging Dynamic Memory Fingerprinting for Mini-Game Plagiarism Detection",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d132/573300d132.pdf"
				},
				{
					"pageNumber": 3144,
					"articleName": "Practical Escape of Exploration Tarpits for Mini-Game Testing in an Industrial Setting",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d144/573300d144.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xiao",
				"surname": "Xiong"
			},
			"authorName": "Xiong, Xiao",
			"articleRefs": [
				{
					"pageNumber": 3497,
					"articleName": "Adaptive Performance Regression Detection Using A Semi-Supervised Siamese Network",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d497/573300d497.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yingfei ",
				"surname": "Xiong"
			},
			"authorName": "Xiong, Yingfei",
			"articleRefs": [
				{
					"pageNumber": 1565,
					"articleName": "Belief Propagation with Local Structure and Its Applications in Program Analysis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b565/573300b565.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Baowen",
				"surname": "Xu"
			},
			"authorName": "Xu, Baowen",
			"articleRefs": [
				{
					"pageNumber": 1246,
					"articleName": "Protecting Source Code Privacy When Hunting Memory Bugs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b246/573300b246.pdf"
				},
				{
					"pageNumber": 2719,
					"articleName": "PALM: Synergizing Program Analysis and LLMs to Enhance Rust Unit Test Coverage",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c719/573300c719.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Dehai",
				"surname": "Xu"
			},
			"authorName": "Xu, Dehai",
			"articleRefs": [
				{
					"pageNumber": 495,
					"articleName": "RSFuzz: A Robustness-Guided Swarm Fuzzing Framework Based on Behavioral Constraints",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a495/573300a495.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Fanjiang",
				"surname": "Xu"
			},
			"authorName": "Xu, Fanjiang",
			"articleRefs": [
				{
					"pageNumber": 2375,
					"articleName": "Interleaved Learning and Exploration: A Self-Adaptive Fuzz Testing Framework for MLIR",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c375/573300c375.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Feng",
				"surname": "Xu"
			},
			"authorName": "Xu, Feng",
			"articleRefs": [
				{
					"pageNumber": 469,
					"articleName": "Comprehend, Imitate, and then Update: Unleashing the Power of LLMs in Test Suite Evolution",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a469/573300a469.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Guoai",
				"surname": "Xu"
			},
			"authorName": "Xu, Guoai",
			"articleRefs": [
				{
					"pageNumber": 1818,
					"articleName": "On the (In)Security of Non-Resettable Device Identifiers in Custom Android Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b818/573300b818.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Haoyu",
				"surname": "Xu"
			},
			"authorName": "Xu, Haoyu",
			"articleRefs": [
				{
					"pageNumber": 2869,
					"articleName": "LLMPort: Cross-File Patch Porting via Task Decomposition and Self-Correction",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c869/573300c869.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jian",
				"surname": "Xu"
			},
			"authorName": "Xu, Jian",
			"articleRefs": [
				{
					"pageNumber": 3485,
					"articleName": "BitsAI-Fix: LLM-Driven Approach for Automated Lint Error Resolution in Practice",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d485/573300d485.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jie",
				"surname": "Xu"
			},
			"authorName": "Xu, Jie",
			"articleRefs": [
				{
					"pageNumber": 3568,
					"articleName": "Tuning LLM-Based Code Optimization via Meta-Prompting: An Industrial Perspective",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d568/573300d568.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jing",
				"surname": "Xu"
			},
			"authorName": "Xu, Jing",
			"articleRefs": [
				{
					"pageNumber": 1118,
					"articleName": "CoorLog: Efficient-Generalizable Log Anomaly Detection via Adaptive Coordinator in Software Evolution",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b118/573300b118.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jinwei",
				"surname": "Xu"
			},
			"authorName": "Xu, Jinwei",
			"articleRefs": [
				{
					"pageNumber": 3706,
					"articleName": "Securing Self-Managed Third-Party Libraries",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d706/573300d706.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Lei",
				"surname": "Xu"
			},
			"authorName": "Xu, Lei",
			"articleRefs": [
				{
					"pageNumber": 584,
					"articleName": "EditFusion: Resolving Code Merge Conflicts via Edit Selection",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a584/573300a584.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Lin",
				"surname": "Xu"
			},
			"authorName": "Xu, Lin",
			"articleRefs": [
				{
					"pageNumber": 996,
					"articleName": "Not Every Patch is an Island: LLM-Enhanced Identification of Multiple Vulnerability Patches",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a996/573300a996.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Lingyun",
				"surname": "Xu"
			},
			"authorName": "Xu, Lingyun",
			"articleRefs": [
				{
					"pageNumber": 3261,
					"articleName": "Context-Sensitive Pointer Analysis for ArkTS",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d261/573300d261.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Meiqiu",
				"surname": "Xu"
			},
			"authorName": "Xu, Meiqiu",
			"articleRefs": [
				{
					"pageNumber": 1767,
					"articleName": "Demystifying Cross-Language C/C++ Binaries: A Robust Software Component Analysis Approach",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b767/573300b767.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Meng",
				"surname": "Xu"
			},
			"authorName": "Xu, Meng",
			"articleRefs": [
				{
					"pageNumber": 1285,
					"articleName": "Agentic Specification Generator for Move Programs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b285/573300b285.pdf"
				},
				{
					"pageNumber": 2567,
					"articleName": "DRIFT: Debug-Based Trace Inference for Firmware Testing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c567/573300c567.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Qinghua",
				"surname": "Xu"
			},
			"authorName": "Xu, Qinghua",
			"articleRefs": [
				{
					"pageNumber": 3694,
					"articleName": "Quantum Machine Learning-Based Test Oracle for Autonomous Mobile Robots",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d694/573300d694.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ruijie",
				"surname": "Xu"
			},
			"authorName": "Xu, Ruijie",
			"articleRefs": [
				{
					"pageNumber": 1,
					"articleName": "AlertGuardian: Intelligent Alert Life-Cycle Management for Large-Scale Cloud Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a001/573300a001.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Tangzhi",
				"surname": "Xu"
			},
			"authorName": "Xu, Tangzhi",
			"articleRefs": [
				{
					"pageNumber": 469,
					"articleName": "Comprehend, Imitate, and then Update: Unleashing the Power of LLMs in Test Suite Evolution",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a469/573300a469.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Tianyin",
				"surname": "Xu"
			},
			"authorName": "Xu, Tianyin",
			"articleRefs": [
				{
					"pageNumber": 393,
					"articleName": "Democratizing the Cryptocurrency Ecosystem by Just-In-Time Transformation of Mining Programs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a393/573300a393.pdf"
				},
				{
					"pageNumber": 1082,
					"articleName": "DebCovDiff: Differential Testing of Coverage Measurement Tools on Real-World Projects",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b082/573300b082.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Tongtong",
				"surname": "Xu"
			},
			"authorName": "Xu, Tongtong",
			"articleRefs": [
				{
					"pageNumber": 91,
					"articleName": "When AllClose Fails: Round-Off Error Estimation for Deep Learning Programs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a091/573300a091.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Wang",
				"surname": "Xu"
			},
			"authorName": "Xu, Wang",
			"articleRefs": [
				{
					"pageNumber": 2618,
					"articleName": "EfficientEdit: Accelerating Code Editing via Edit-Oriented Speculative Decoding",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c618/573300c618.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Weiyuan",
				"surname": "Xu"
			},
			"authorName": "Xu, Weiyuan",
			"articleRefs": [
				{
					"pageNumber": 3741,
					"articleName": "LogSage: An LLM-Based Framework for CI/CD Failure Detection and Remediation with Industrial Validation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d741/573300d741.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xinyi",
				"surname": "Xu"
			},
			"authorName": "Xu, Xinyi",
			"articleRefs": [
				{
					"pageNumber": 241,
					"articleName": "Interaction2Code: Benchmarking MLLM-Based Interactive Webpage Code Generation from Interactive Prototyping",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a241/573300a241.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yanbo",
				"surname": "Xu"
			},
			"authorName": "Xu, Yanbo",
			"articleRefs": [
				{
					"pageNumber": 2057,
					"articleName": "FirmProj: Detecting Firmware Leakage in IoT Update Processes via Companion App Analysis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c057/573300c057.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yicong",
				"surname": "Xu"
			},
			"authorName": "Xu, Yicong",
			"articleRefs": [
				{
					"pageNumber": 129,
					"articleName": "Diagnosing Performance Differences in Model Checkers via Runtime-Guided Problem Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a129/573300a129.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yisen",
				"surname": "Xu"
			},
			"authorName": "Xu, Yisen",
			"articleRefs": [
				{
					"pageNumber": 983,
					"articleName": "Coverage-Based Harmfulness Testing for LLM Code Transformation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a983/573300a983.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zhengzi ",
				"surname": "Xu"
			},
			"authorName": "Xu, Zhengzi",
			"articleRefs": [
				{
					"pageNumber": 52,
					"articleName": "Learning from the Past: Real-World Exploit Migration for Smart Contract PoC Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a052/573300a052.pdf"
				},
				{
					"pageNumber": 104,
					"articleName": "FAULTSEEKER: LLM-Empowered Framework for Blockchain Transaction Fault Localization",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a104/573300a104.pdf"
				},
				{
					"pageNumber": 648,
					"articleName": "BinStruct: Binary Structure Recovery Combining Static Analysis and Semantics",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a648/573300a648.pdf"
				},
				{
					"pageNumber": 1069,
					"articleName": "A Large Scale Study of AI-Based Binary Function Similarity Detection Techniques for Security Researchers and Practitioners",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b069/573300b069.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zhenyang",
				"surname": "Xu"
			},
			"authorName": "Xu, Zhenyang",
			"articleRefs": [
				{
					"pageNumber": 2273,
					"articleName": "Latra: A Template-Based Language-Agnostic Transformation Framework for Effective Program Reduction",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c273/573300c273.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zhiyao",
				"surname": "Xu"
			},
			"authorName": "Xu, Zhiyao",
			"articleRefs": [
				{
					"pageNumber": 241,
					"articleName": "Interaction2Code: Benchmarking MLLM-Based Interactive Webpage Code Generation from Interactive Prototyping",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a241/573300a241.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jiadong ",
				"surname": "Xu "
			},
			"authorName": "Xu, Jiadong",
			"articleRefs": [
				{
					"pageNumber": 1666,
					"articleName": "Leveraging Mixture-of-Experts Framework for Smart Contract Vulnerability Repair with Large Language Model",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b666/573300b666.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Qi",
				"surname": "Xuan"
			},
			"authorName": "Xuan, Qi",
			"articleRefs": [
				{
					"pageNumber": 508,
					"articleName": "Provable Fairness Repair for Deep Neural Networks",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a508/573300a508.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Dingzhao",
				"surname": "Xue"
			},
			"authorName": "Xue, Dingzhao",
			"articleRefs": [
				{
					"pageNumber": 2082,
					"articleName": "Breaking the Traffic Barrier: Unveiling Multi-Format of Protocols via Autonomous Program Exploration",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c082/573300c082.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jingling",
				"surname": "Xue"
			},
			"authorName": "Xue, Jingling",
			"articleRefs": [
				{
					"pageNumber": 3683,
					"articleName": "Securing Millions of Decentralized Identities in Alipay Super App with End-to-End Formal Verification",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d683/573300d683.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yangguang",
				"surname": "Xue"
			},
			"authorName": "Xue, Yangguang",
			"articleRefs": [
				{
					"pageNumber": 1602,
					"articleName": "Beyond Static GUI Agent: Evolving LLM-Based GUI Testing via Dynamic Memory",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b602/573300b602.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yinxing",
				"surname": "Xue"
			},
			"authorName": "Xue, Yinxing",
			"articleRefs": [
				{
					"pageNumber": 1730,
					"articleName": "Function Clustering-Based Fuzzing Termination: Toward Smarter Early Stopping",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b730/573300b730.pdf"
				},
				{
					"pageNumber": 2045,
					"articleName": "Demystifying the Evolution of Neural Networks with BOM Analysis: Insights from a Large-Scale Study of 55,997 GitHub Repositories",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c045/573300c045.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ziluo",
				"surname": "Xue"
			},
			"authorName": "Xue, Ziluo",
			"articleRefs": [
				{
					"pageNumber": 3368,
					"articleName": "A Characterization Study of Bugs in LLM Agent Workflow Orchestration Frameworks",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d368/573300d368.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Raghu Reddy",
				"surname": "Y."
			},
			"authorName": "Y., Raghu Reddy",
			"articleRefs": [
				{
					"pageNumber": 349,
					"articleName": "A Conformance Checking System for Interaction Testing in Virtual Reality",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a349/850300a349.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Drishti",
				"surname": "Yadav"
			},
			"authorName": "Yadav, Drishti",
			"articleRefs": [
				{
					"pageNumber": 3833,
					"articleName": "Fault Injection for Simulink-Based CPS Models: Insights and Future Directions",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d833/573300d833.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Aleksey",
				"surname": "Yakushev"
			},
			"authorName": "Yakushev, Aleksey",
			"articleRefs": [
				{
					"pageNumber": 4032,
					"articleName": "WIBE: Watermarks for generated Images \u2013 Benchmarking & Evaluation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e032/573300e032.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Daisuke",
				"surname": "Yamaguchi"
			},
			"authorName": "Yamaguchi, Daisuke",
			"articleRefs": [
				{
					"pageNumber": 3967,
					"articleName": "A Secure Mocking Approach Towards Software Supply Chain Security",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d967/573300d967.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Chunpeng",
				"surname": "Yan"
			},
			"authorName": "Yan, Chunpeng",
			"articleRefs": [
				{
					"pageNumber": 919,
					"articleName": "Lares: LLM-Driven Code Slice Semantic Search for Patch Presence Testing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a919/573300a919.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Meng",
				"surname": "Yan"
			},
			"authorName": "Yan, Meng",
			"articleRefs": [
				{
					"pageNumber": 3033,
					"articleName": "Issue Localization via LLM-Driven Iterative Code Graph Searching",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d033/573300d033.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Minzhi",
				"surname": "Yan"
			},
			"authorName": "Yan, Minzhi",
			"articleRefs": [
				{
					"pageNumber": 958,
					"articleName": "iKnow: an Intent-Guided Chatbot for Cloud Operations with Retrieval-Augmented Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a958/573300a958.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Aidan Z.H.",
				"surname": "Yang"
			},
			"authorName": "Yang, Aidan Z.H.",
			"articleRefs": [
				{
					"pageNumber": 1452,
					"articleName": "VERT: Polyglot Verified Equivalent Rust Transpilation with Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b452/573300b452.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Bo",
				"surname": "Yang"
			},
			"authorName": "Yang, Bo",
			"articleRefs": [
				{
					"pageNumber": 2592,
					"articleName": "On the Robustness Evaluation of 3D Obstacle Detection Against Specifications in Autonomous Driving",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c592/573300c592.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Chen",
				"surname": "Yang"
			},
			"authorName": "Yang, Chen",
			"articleRefs": [
				{
					"pageNumber": 2833,
					"articleName": "Reflective Unit Test Generation for Precise Type Error Detection with Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c833/573300c833.pdf"
				},
				{
					"pageNumber": 3045,
					"articleName": "Clarifying Semantics of In-Context Examples for Unit Test Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d045/573300d045.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Chengran",
				"surname": "Yang"
			},
			"authorName": "Yang, Chengran",
			"articleRefs": [
				{
					"pageNumber": 2439,
					"articleName": "Token Sugar: Making Source Code Sweeter for LLMs Through Token-Efficient Shorthand",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c439/573300c439.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Donghao",
				"surname": "Yang"
			},
			"authorName": "Yang, Donghao",
			"articleRefs": [
				{
					"pageNumber": 3592,
					"articleName": "AutoPLC: Generating Vendor-Aware Structured Text for Programmable Logic Controllers",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d592/573300d592.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Guang",
				"surname": "Yang"
			},
			"authorName": "Yang, Guang",
			"articleRefs": [
				{
					"pageNumber": 154,
					"articleName": "CODE-DITING: Automatic Evaluation of Code Generation Without References or Test Cases",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a154/573300a154.pdf"
				},
				{
					"pageNumber": 2477,
					"articleName": "Evaluating and Improving Framework-Based Parallel Code Completion with Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c477/573300c477.pdf"
				},
				{
					"pageNumber": 2605,
					"articleName": "SE-Jury: An LLM-as-Ensemble-Judge Metric for Narrowing the Gap with Human Evaluation in SE",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c605/573300c605.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Hailong",
				"surname": "Yang"
			},
			"authorName": "Yang, Hailong",
			"articleRefs": [
				{
					"pageNumber": 330,
					"articleName": "LogMoE: Lightweight Expert Mixture for Cross-System Log Anomaly Detection",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a330/573300a330.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Huan",
				"surname": "Yang"
			},
			"authorName": "Yang, Huan",
			"articleRefs": [
				{
					"pageNumber": 3683,
					"articleName": "Securing Millions of Decentralized Identities in Alipay Super App with End-to-End Formal Verification",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d683/573300d683.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jie",
				"surname": "Yang"
			},
			"authorName": "Yang, Jie",
			"articleRefs": [
				{
					"pageNumber": 726,
					"articleName": "Improving LLM-Based Log Parsing by Learning from Errors in Reasoning Traces",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a726/573300a726.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jinqiu",
				"surname": "Yang"
			},
			"authorName": "Yang, Jinqiu",
			"articleRefs": [
				{
					"pageNumber": 1704,
					"articleName": "ADPerf: Investigating and Testing Performance in Autonomous Driving Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b704/573300b704.pdf"
				},
				{
					"pageNumber": 2592,
					"articleName": "On the Robustness Evaluation of 3D Obstacle Detection Against Specifications in Autonomous Driving",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c592/573300c592.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Kang",
				"surname": "Yang"
			},
			"authorName": "Yang, Kang",
			"articleRefs": [
				{
					"pageNumber": 1194,
					"articleName": "AdaptEval: A Benchmark for Evaluating Large Language Models on Code Snippet Adaptation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b194/573300b194.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Kyeongseok",
				"surname": "Yang"
			},
			"authorName": "Yang, Kyeongseok",
			"articleRefs": [
				{
					"pageNumber": 1590,
					"articleName": "IMUFUZZER: Resilience-Based Discovery of Signal Injection Attacks on Robotic Aerial Vehicles",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b590/573300b590.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Lanxin",
				"surname": "Yang"
			},
			"authorName": "Yang, Lanxin",
			"articleRefs": [
				{
					"pageNumber": 597,
					"articleName": "Automatic Fixing of Missing Dependency Errors",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a597/573300a597.pdf"
				},
				{
					"pageNumber": 3706,
					"articleName": "Securing Self-Managed Third-Party Libraries",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d706/573300d706.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Li",
				"surname": "Yang"
			},
			"authorName": "Yang, Li",
			"articleRefs": [
				{
					"pageNumber": 1666,
					"articleName": "Leveraging Mixture-of-Experts Framework for Smart Contract Vulnerability Repair with Large Language Model",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b666/573300b666.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Lin",
				"surname": "Yang"
			},
			"authorName": "Yang, Lin",
			"articleRefs": [
				{
					"pageNumber": 2833,
					"articleName": "Reflective Unit Test Generation for Precise Type Error Detection with Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c833/573300c833.pdf"
				},
				{
					"pageNumber": 3045,
					"articleName": "Clarifying Semantics of In-Context Examples for Unit Test Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d045/573300d045.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Mengfei",
				"surname": "Yang"
			},
			"authorName": "Yang, Mengfei",
			"articleRefs": [
				{
					"pageNumber": 1207,
					"articleName": "Bridging Natural Language and Formal Specification Automated Translation of Software Requirements to LTL via Hierarchical Semantics Decomposition Using LLMs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b207/573300b207.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Min",
				"surname": "Yang"
			},
			"authorName": "Yang, Min",
			"articleRefs": [
				{
					"pageNumber": 559,
					"articleName": "Security Debt in LLM Agent Applications: A Measurement Study of Vulnerabilities and Mitigation Trade-Offs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a559/573300a559.pdf"
				},
				{
					"pageNumber": 932,
					"articleName": "Exploring Static Taint Analysis in LLMs: A Dynamic Benchmarking Framework for Measurement and Enhancement",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a932/573300a932.pdf"
				},
				{
					"pageNumber": 2413,
					"articleName": "DeepExploitor: LLM-Enhanced Automated Exploitation of DeepLink Attack in Hybrid Apps",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c413/573300c413.pdf"
				},
				{
					"pageNumber": 2869,
					"articleName": "LLMPort: Cross-File Patch Porting via Task Decomposition and Self-Correction",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c869/573300c869.pdf"
				},
				{
					"pageNumber": 3082,
					"articleName": "Algernon: A Flag-Guided Hybrid Fuzzer for Unlocking Hidden Program Paths",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d082/573300d082.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Mutian",
				"surname": "Yang"
			},
			"authorName": "Yang, Mutian",
			"articleRefs": [
				{
					"pageNumber": 3556,
					"articleName": "Shrunk, Yet Complete: Code Shrinking-Resilient Android Third-Party Library Detection",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d556/573300d556.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ping",
				"surname": "Yang"
			},
			"authorName": "Yang, Ping",
			"articleRefs": [
				{
					"pageNumber": 3671,
					"articleName": "RepoMasterEval: Evaluating Code Completion via Real-World Repositories",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d671/573300d671.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Renyu",
				"surname": "Yang"
			},
			"authorName": "Yang, Renyu",
			"articleRefs": [
				{
					"pageNumber": 3191,
					"articleName": "KAIOps: A Platform Solution of End-to-End Multi-Modal AIOps for AI Training at Scale",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d191/573300d191.pdf"
				},
				{
					"pageNumber": 3753,
					"articleName": "KAIR: A Statistical and Causal Approach to Pinpointing Stragglers in Distributed Model Training",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d753/573300d753.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Rui ",
				"surname": "Yang"
			},
			"authorName": "Yang, Rui",
			"articleRefs": [
				{
					"pageNumber": 3380,
					"articleName": "AdaptiveGuard: Towards Adaptive Runtime Safety for LLM-Powered Software",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d380/573300d380.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Shishuai",
				"surname": "Yang"
			},
			"authorName": "Yang, Shishuai",
			"articleRefs": [
				{
					"pageNumber": 2057,
					"articleName": "FirmProj: Detecting Firmware Leakage in IoT Update Processes via Companion App Analysis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c057/573300c057.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Shouguo",
				"surname": "Yang"
			},
			"authorName": "Yang, Shouguo",
			"articleRefs": [
				{
					"pageNumber": 304,
					"articleName": "Advancing Binary Code Similarity Detection via Context-Content Fusion and LLM Verification",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a304/573300a304.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Tianyu",
				"surname": "Yang"
			},
			"authorName": "Yang, Tianyu",
			"articleRefs": [
				{
					"pageNumber": 958,
					"articleName": "iKnow: an Intent-Guided Chatbot for Cloud Operations with Retrieval-Augmented Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a958/573300a958.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Wei",
				"surname": "Yang"
			},
			"authorName": "Yang, Wei",
			"articleRefs": [
				{
					"pageNumber": 3580,
					"articleName": "Element-Aware Fine-Tuning of Vision-Language Models for Cost-Efficient GUI Testing in an Industrial Setting",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d580/573300d580.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Wenhua",
				"surname": "Yang"
			},
			"authorName": "Yang, Wenhua",
			"articleRefs": [
				{
					"pageNumber": 2782,
					"articleName": "Understanding Feature Request Practice on GitHub via a Large-Scale Empirical Study",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c782/573300c782.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Wenzhang",
				"surname": "Yang"
			},
			"authorName": "Yang, Wenzhang",
			"articleRefs": [
				{
					"pageNumber": 1730,
					"articleName": "Function Clustering-Based Fuzzing Termination: Toward Smarter Early Stopping",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b730/573300b730.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xiaohu",
				"surname": "Yang"
			},
			"authorName": "Yang, Xiaohu",
			"articleRefs": [
				{
					"pageNumber": 623,
					"articleName": "Enhancing LLM's Ability to Generate More Repository-Aware Unit Tests Through Precise Context Injection",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a623/573300a623.pdf"
				},
				{
					"pageNumber": 2070,
					"articleName": "Why Is My Transaction Risky? Understanding Smart Contract Semantics and Interactions in the NFT Ecosystem",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c070/573300c070.pdf"
				},
				{
					"pageNumber": 2554,
					"articleName": "ACTaint: Agent-Based Taint Analysis for Access Control Vulnerabilities in Smart Contracts",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c554/573300c554.pdf"
				},
				{
					"pageNumber": 2857,
					"articleName": "SolContractEval: A Benchmark for Evaluating Contract-Level Solidity Code Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c857/573300c857.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yanjing",
				"surname": "Yang"
			},
			"authorName": "Yang, Yanjing",
			"articleRefs": [
				{
					"pageNumber": 3706,
					"articleName": "Securing Self-Managed Third-Party Libraries",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d706/573300d706.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yijun",
				"surname": "Yang"
			},
			"authorName": "Yang, Yijun",
			"articleRefs": [
				{
					"pageNumber": 26,
					"articleName": "Vul-R2: A Reasoning LLM for Automated Vulnerability Repair",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a026/573300a026.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yitang",
				"surname": "Yang"
			},
			"authorName": "Yang, Yitang",
			"articleRefs": [
				{
					"pageNumber": 3753,
					"articleName": "KAIR: A Statistical and Causal Approach to Pinpointing Stragglers in Distributed Model Training",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d753/573300d753.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yizhuo",
				"surname": "Yang"
			},
			"authorName": "Yang, Yizhuo",
			"articleRefs": [
				{
					"pageNumber": 3261,
					"articleName": "Context-Sensitive Pointer Analysis for ArkTS",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d261/573300d261.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yuhao",
				"surname": "Yang"
			},
			"authorName": "Yang, Yuhao",
			"articleRefs": [
				{
					"pageNumber": 3545,
					"articleName": "LLM-Assisted Industrial-Scale Differential Testing of Package Incompatibilities in Linux Distributions",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d545/573300d545.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zezhou",
				"surname": "Yang"
			},
			"authorName": "Yang, Zezhou",
			"articleRefs": [
				{
					"pageNumber": 3449,
					"articleName": "Automated Prompt Generation for Code Intelligence: An Empirical Study and Experience in WeChat",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d449/573300d449.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zhemin",
				"surname": "Yang"
			},
			"authorName": "Yang, Zhemin",
			"articleRefs": [
				{
					"pageNumber": 2413,
					"articleName": "DeepExploitor: LLM-Enhanced Automated Exploitation of DeepLink Attack in Hybrid Apps",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c413/573300c413.pdf"
				},
				{
					"pageNumber": 3082,
					"articleName": "Algernon: A Flag-Guided Hybrid Fuzzer for Unlocking Hidden Program Paths",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d082/573300d082.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zhen",
				"surname": "Yang"
			},
			"authorName": "Yang, Zhen",
			"articleRefs": [
				{
					"pageNumber": 1855,
					"articleName": "Can Mamba Be Better? An Experimental Evaluation of Mamba in Code Intelligence",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b855/573300b855.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zheyu",
				"surname": "Yang"
			},
			"authorName": "Yang, Zheyu",
			"articleRefs": [
				{
					"pageNumber": 2007,
					"articleName": "Explainable Fault Localization for Programming Assignments via LLM-Guided Annotation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c007/573300c007.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zhiquan",
				"surname": "Yang"
			},
			"authorName": "Yang, Zhiquan",
			"articleRefs": [
				{
					"pageNumber": 2503,
					"articleName": "Unit Test Update Through LLM-Driven Context Collection and Error-Type-Aware Refinement",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c503/573300c503.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zhou",
				"surname": "Yang"
			},
			"authorName": "Yang, Zhou",
			"articleRefs": [
				{
					"pageNumber": 191,
					"articleName": "\"My Productivity is Boosted, but \u2026\" Demystifying Users' Perception on AI Coding Assistants",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a191/573300a191.pdf"
				},
				{
					"pageNumber": 1181,
					"articleName": "Backdoors in Code Summarizers: How Bad Is It?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b181/573300b181.pdf"
				},
				{
					"pageNumber": 2439,
					"articleName": "Token Sugar: Making Source Code Sweeter for LLMs Through Token-Efficient Shorthand",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c439/573300c439.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Kundi",
				"surname": "Yao"
			},
			"authorName": "Yao, Kundi",
			"articleRefs": [
				{
					"pageNumber": 3057,
					"articleName": "Who's to Blame? Rethinking the Brittleness of Automated Web GUI Testing from a Pragmatic Perspective",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d057/573300d057.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Liangchao",
				"surname": "Yao"
			},
			"authorName": "Yao, Liangchao",
			"articleRefs": [
				{
					"pageNumber": 3580,
					"articleName": "Element-Aware Fine-Tuning of Vision-Language Models for Cost-Efficient GUI Testing in an Industrial Setting",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d580/573300d580.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yuan",
				"surname": "Yao"
			},
			"authorName": "Yao, Yuan",
			"articleRefs": [
				{
					"pageNumber": 469,
					"articleName": "Comprehend, Imitate, and then Update: Unleashing the Power of LLMs in Test Suite Evolution",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a469/573300a469.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zhiyuan",
				"surname": "Yao"
			},
			"authorName": "Yao, Zhiyuan",
			"articleRefs": [
				{
					"pageNumber": 3485,
					"articleName": "BitsAI-Fix: LLM-Driven Approach for Automated Lint Error Resolution in Practice",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d485/573300d485.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zitong",
				"surname": "Yao"
			},
			"authorName": "Yao, Zitong",
			"articleRefs": [
				{
					"pageNumber": 1528,
					"articleName": "Finding Insecure State Dependency in DApps via Multi-Source Tracing and Semantic Enrichment",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b528/573300b528.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Roland H. C.",
				"surname": "Yap"
			},
			"authorName": "Yap, Roland H. C.",
			"articleRefs": [
				{
					"pageNumber": 1094,
					"articleName": "ZendDiff: Differential Testing of PHP Interpreter",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b094/573300b094.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Eray",
				"surname": "Yapa\u011Fc\u0131"
			},
			"authorName": "Yapa\u011Fc\u0131, Eray",
			"articleRefs": [
				{
					"pageNumber": 3094,
					"articleName": "Agents in the Sandbox: End-to-End Crash Bug Reproduction for Minecraft",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d094/573300d094.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Dan",
				"surname": "Ye"
			},
			"authorName": "Ye, Dan",
			"articleRefs": [
				{
					"pageNumber": 2771,
					"articleName": "Root Cause Analysis of RISC-V Build Failures via LLM and MCTS Reasoning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c771/573300c771.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Deheng ",
				"surname": "Ye"
			},
			"authorName": "Ye, Deheng",
			"articleRefs": [
				{
					"pageNumber": 26,
					"articleName": "Vul-R2: A Reasoning LLM for Automated Vulnerability Repair",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a026/573300a026.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "He",
				"surname": "Ye"
			},
			"authorName": "Ye, He",
			"articleRefs": [
				{
					"pageNumber": 367,
					"articleName": "Automated Repair of Ambiguous Problem Descriptions for LLM-Based Code Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a367/573300a367.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jiaming",
				"surname": "Ye"
			},
			"authorName": "Ye, Jiaming",
			"articleRefs": [
				{
					"pageNumber": 3823,
					"articleName": "Is Measurement Enough? Rethinking Output Validation in Quantum Program Testing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d823/573300d823.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Wei",
				"surname": "Ye"
			},
			"authorName": "Ye, Wei",
			"articleRefs": [
				{
					"pageNumber": 217,
					"articleName": "R3-Bench: Reproducible Real-World Reverse Engineering Dataset for Symbol Recovery",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a217/573300a217.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yuhang",
				"surname": "Ye"
			},
			"authorName": "Ye, Yuhang",
			"articleRefs": [
				{
					"pageNumber": 2045,
					"articleName": "Demystifying the Evolution of Neural Networks with BOM Analysis: Insights from a Large-Scale Study of 55,997 GitHub Repositories",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c045/573300c045.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zhifan",
				"surname": "Ye"
			},
			"authorName": "Ye, Zhifan",
			"articleRefs": [
				{
					"pageNumber": 2857,
					"articleName": "SolContractEval: A Benchmark for Evaluating Contract-Level Solidity Code Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c857/573300c857.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Sahand Moslemi",
				"surname": "Yengejeh"
			},
			"authorName": "Yengejeh, Sahand Moslemi",
			"articleRefs": [
				{
					"pageNumber": 3957,
					"articleName": "Are We SOLID Yet? An Empirical Study on Prompting LLMs to Detect Design Principle Violations",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d957/573300d957.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Juan Diego",
				"surname": "Yepes-Parra"
			},
			"authorName": "Yepes-Parra, Juan Diego",
			"articleRefs": [
				{
					"pageNumber": 3952,
					"articleName": "Autonomous Agents for Accessibility: Simulating Visual Impairments in Web Interfaces",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d952/573300d952.pdf"
				},
				{
					"pageNumber": 4056,
					"articleName": "EyeNav: Accessible Webpage Interaction and Testing Using Eye-Tracking and NLP",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e056/573300e056.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Enes",
				"surname": "Yigitbas"
			},
			"authorName": "Yigitbas, Enes",
			"articleRefs": [
				{
					"pageNumber": 343,
					"articleName": "Toward Static Analysis of Immersive Attacks",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a343/850300a343.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Guoyu",
				"surname": "Yin"
			},
			"authorName": "Yin, Guoyu",
			"articleRefs": [
				{
					"pageNumber": 3615,
					"articleName": "RPG: Linux Kernel Fuzzing Guided by Distribution-Specific Runtime Parameter Interfaces",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d615/573300d615.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jianwei",
				"surname": "Yin"
			},
			"authorName": "Yin, Jianwei",
			"articleRefs": [
				{
					"pageNumber": 2630,
					"articleName": "AutoFid: Adaptive and Noise-Aware Fidelity Measurement for Quantum Programs via Circuit Graph Analysis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c630/573300c630.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xin",
				"surname": "Yin"
			},
			"authorName": "Yin, Xin",
			"articleRefs": [
				{
					"pageNumber": 317,
					"articleName": "PrefGen: A Preference-Driven Methodology for Secure Yet Gas-Efficient Smart Contract Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a317/573300a317.pdf"
				},
				{
					"pageNumber": 623,
					"articleName": "Enhancing LLM's Ability to Generate More Repository-Aware Unit Tests Through Precise Context Injection",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a623/573300a623.pdf"
				},
				{
					"pageNumber": 687,
					"articleName": "Navigating the Labyrinth: Path-Sensitive Unit Test Generation with Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a687/573300a687.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Chenhao",
				"surname": "Ying"
			},
			"authorName": "Ying, Chenhao",
			"articleRefs": [
				{
					"pageNumber": 317,
					"articleName": "PrefGen: A Preference-Driven Methodology for Secure Yet Gas-Efficient Smart Contract Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a317/573300a317.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xinlei",
				"surname": "Ying"
			},
			"authorName": "Ying, Xinlei",
			"articleRefs": [
				{
					"pageNumber": 1868,
					"articleName": "ORFUZZ: Fuzzing the \"Other Side\" of LLM Safety \u2013 Testing Over-Refusal",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b868/573300b868.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Karen",
				"surname": "Yorav"
			},
			"authorName": "Yorav, Karen",
			"articleRefs": [
				{
					"pageNumber": 7,
					"articleName": "Uncovering Code Insights: Leveraging GitHub Artifacts for Deeper Code Understanding",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a007/850300a007.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Kentaro",
				"surname": "Yoshimura"
			},
			"authorName": "Yoshimura, Kentaro",
			"articleRefs": [
				{
					"pageNumber": 3771,
					"articleName": "Acceleration of Automotive Software Development by Retrieval Augmented Integration Test Script Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d771/573300d771.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Dongjun",
				"surname": "Youn"
			},
			"authorName": "Youn, Dongjun",
			"articleRefs": [
				{
					"pageNumber": 1402,
					"articleName": "WEST: Specification-Based Test Generation for WebAssembly",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b402/573300b402.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Chendong",
				"surname": "Yu"
			},
			"authorName": "Yu, Chendong",
			"articleRefs": [
				{
					"pageNumber": 2681,
					"articleName": "Understanding Resource Injection Vulnerabilities in Kubernetes Ecosystems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c681/573300c681.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Erkai",
				"surname": "Yu"
			},
			"authorName": "Yu, Erkai",
			"articleRefs": [
				{
					"pageNumber": 1082,
					"articleName": "DebCovDiff: Differential Testing of Coverage Measurement Tools on Real-World Projects",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b082/573300b082.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Guangba",
				"surname": "Yu"
			},
			"authorName": "Yu, Guangba",
			"articleRefs": [
				{
					"pageNumber": 1,
					"articleName": "AlertGuardian: Intelligent Alert Life-Cycle Management for Large-Scale Cloud Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a001/573300a001.pdf"
				},
				{
					"pageNumber": 958,
					"articleName": "iKnow: an Intent-Guided Chatbot for Cloud Operations with Retrieval-Augmented Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a958/573300a958.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Hai",
				"surname": "Yu"
			},
			"authorName": "Yu, Hai",
			"articleRefs": [
				{
					"pageNumber": 1767,
					"articleName": "Demystifying Cross-Language C/C++ Binaries: A Robust Software Component Analysis Approach",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b767/573300b767.pdf"
				},
				{
					"pageNumber": 1843,
					"articleName": "MCTS-Refined CoT: High-Quality Fine-Tuning Data for LLM-Based Repository Issue Resolution",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b843/573300b843.pdf"
				},
				{
					"pageNumber": 1893,
					"articleName": "Diplomatist: What Do Cross-Language Dependencies Reflect Software Ecosystem Health?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b893/573300b893.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jiongchi ",
				"surname": "Yu"
			},
			"authorName": "Yu, Jiongchi",
			"articleRefs": [
				{
					"pageNumber": 254,
					"articleName": "Defects4C: Benchmarking Large Language Model Repair Capability with C/C++ Bugs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a254/573300a254.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Lei",
				"surname": "Yu"
			},
			"authorName": "Yu, Lei",
			"articleRefs": [
				{
					"pageNumber": 1666,
					"articleName": "Leveraging Mixture-of-Experts Framework for Smart Contract Vulnerability Repair with Large Language Model",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b666/573300b666.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Muzhi",
				"surname": "Yu"
			},
			"authorName": "Yu, Muzhi",
			"articleRefs": [
				{
					"pageNumber": 217,
					"articleName": "R3-Bench: Reproducible Real-World Reverse Engineering Dataset for Symbol Recovery",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a217/573300a217.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "NengHai",
				"surname": "Yu"
			},
			"authorName": "Yu, NengHai",
			"articleRefs": [
				{
					"pageNumber": 841,
					"articleName": "PseudoFix: Refactoring Distorted Structures in Decompiled C Pseudocode",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a841/573300a841.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Pengfei",
				"surname": "Yu"
			},
			"authorName": "Yu, Pengfei",
			"articleRefs": [
				{
					"pageNumber": 2133,
					"articleName": "Towards Generalizable Instruction Vulnerability Prediction via LLM-Enhanced Code Representation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c133/573300c133.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Seungeun",
				"surname": "Yu"
			},
			"authorName": "Yu, Seungeun",
			"articleRefs": [
				{
					"pageNumber": 1577,
					"articleName": "CRYPTBARA: Dependency-Guided Detection of Python Cryptographic API Misuses",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b577/573300b577.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Shengcheng",
				"surname": "Yu"
			},
			"authorName": "Yu, Shengcheng",
			"articleRefs": [
				{
					"pageNumber": 1793,
					"articleName": "Multi-Dimensional Assessment of Crowdsourced Testing Reports via LLMs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b793/573300b793.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Siyu",
				"surname": "Yu"
			},
			"authorName": "Yu, Siyu",
			"articleRefs": [
				{
					"pageNumber": 661,
					"articleName": "United We Stand: Towards End-to-End Log-Based Fault Diagnosis via Interactive Multi-Task Learning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a661/573300a661.pdf"
				},
				{
					"pageNumber": 700,
					"articleName": "LogAction: Consistent Cross-System Anomaly Detection Through Logs via Active Domain Adaptation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a700/573300a700.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Tianchen",
				"surname": "Yu"
			},
			"authorName": "Yu, Tianchen",
			"articleRefs": [
				{
					"pageNumber": 2247,
					"articleName": "Mixture-of-Experts Low-Rank Adaptation for Multilingual Code Summarization",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c247/573300c247.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xiao",
				"surname": "Yu"
			},
			"authorName": "Yu, Xiao",
			"articleRefs": [
				{
					"pageNumber": 3020,
					"articleName": "RealisticCodeBench: Towards More Realistic Evaluation of Large Language Models for Code Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d020/573300d020.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yue",
				"surname": "Yu"
			},
			"authorName": "Yu, Yue",
			"articleRefs": [
				{
					"pageNumber": 1194,
					"articleName": "AdaptEval: A Benchmark for Evaluating Large Language Models on Code Snippet Adaptation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b194/573300b194.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zhaoyang",
				"surname": "Yu"
			},
			"authorName": "Yu, Zhaoyang",
			"articleRefs": [
				{
					"pageNumber": 674,
					"articleName": "Triangle: Empowering Incident Triage with Multi-Agent",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a674/573300a674.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Hang",
				"surname": "Yuan"
			},
			"authorName": "Yuan, Hang",
			"articleRefs": [
				{
					"pageNumber": 1666,
					"articleName": "Leveraging Mixture-of-Experts Framework for Smart Contract Vulnerability Repair with Large Language Model",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b666/573300b666.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Juxing",
				"surname": "Yuan"
			},
			"authorName": "Yuan, Juxing",
			"articleRefs": [
				{
					"pageNumber": 3273,
					"articleName": "Minuku: Detecting Diverse Display Issues in Mobile Apps with Small-Scale Dataset",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d273/573300d273.pdf"
				},
				{
					"pageNumber": 3437,
					"articleName": "From Redundancy to Efficiency: Exploiting Shared UI Interactions Towards Efficient LLM-Based Testing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d437/573300d437.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Li",
				"surname": "Yuan"
			},
			"authorName": "Yuan, Li",
			"articleRefs": [
				{
					"pageNumber": 2247,
					"articleName": "Mixture-of-Experts Low-Rank Adaptation for Multilingual Code Summarization",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c247/573300c247.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yuan",
				"surname": "Yuan"
			},
			"authorName": "Yuan, Yuan",
			"articleRefs": [
				{
					"pageNumber": 3238,
					"articleName": "TrioXpert: An Automated Incident Management Framework for Microservice System",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d238/573300d238.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Uswat",
				"surname": "Yusuf"
			},
			"authorName": "Yusuf, Uswat",
			"articleRefs": [
				{
					"pageNumber": 372,
					"articleName": "Beyond More Context: How Granularity and Order Drive Code Completion Quality",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a372/850300a372.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ehsan",
				"surname": "Zabardast"
			},
			"authorName": "Zabardast, Ehsan",
			"articleRefs": [
				{
					"pageNumber": 51,
					"articleName": "A 3-Layer Agentic Model for Nonfunctional Requirements in Software Engineering",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a051/850300a051.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jonas",
				"surname": "Zabel"
			},
			"authorName": "Zabel, Jonas",
			"articleRefs": [
				{
					"pageNumber": 1615,
					"articleName": "Terminator: Enabling Efficient Fuzzing of Closed-Source GUI Programs by Automatic Coverage-Guided Termination",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b615/573300b615.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Stefano",
				"surname": "Zacchiroli"
			},
			"authorName": "Zacchiroli, Stefano",
			"articleRefs": [
				{
					"pageNumber": 2183,
					"articleName": "Altered Histories in Version Control System Repositories: Evidence from the Trenches",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c183/573300c183.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Fiorella ",
				"surname": "Zampetti"
			},
			"authorName": "Zampetti, Fiorella",
			"articleRefs": [
				{
					"pageNumber": 3992,
					"articleName": "CodeGenLink: A Tool to Find the Likely Origin and License of Automatically Generated Code",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d992/573300d992.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Boris",
				"surname": "Zarubin"
			},
			"authorName": "Zarubin, Boris",
			"articleRefs": [
				{
					"pageNumber": 292,
					"articleName": "GRACG: Graph Retrieval Augmented Code Generation",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a292/850300a292.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Andreas",
				"surname": "Zeller"
			},
			"authorName": "Zeller, Andreas",
			"articleRefs": [
				{
					"pageNumber": 4048,
					"articleName": "BASHIRI: Learning Failure Oracles from Execution Features",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e048/573300e048.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Sergey",
				"surname": "Zeltyn"
			},
			"authorName": "Zeltyn, Sergey",
			"articleRefs": [
				{
					"pageNumber": 3839,
					"articleName": "Taming Uncertainty via Automation: Observing, Analyzing, and Optimizing Agentic AI Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d839/573300d839.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Guofeng ",
				"surname": "Zeng"
			},
			"authorName": "Zeng, Guofeng",
			"articleRefs": [
				{
					"pageNumber": 2881,
					"articleName": "DIFFFIX: Incrementally Fixing AST Diffs via Context and Type Information",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c881/573300c881.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xia",
				"surname": "Zeng"
			},
			"authorName": "Zeng, Xia",
			"articleRefs": [
				{
					"pageNumber": 3580,
					"articleName": "Element-Aware Fine-Tuning of Vision-Language Models for Cost-Efficient GUI Testing in an Industrial Setting",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d580/573300d580.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zhengran",
				"surname": "Zeng"
			},
			"authorName": "Zeng, Zhengran",
			"articleRefs": [
				{
					"pageNumber": 217,
					"articleName": "R3-Bench: Reproducible Real-World Reverse Engineering Dataset for Symbol Recovery",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a217/573300a217.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Lihan",
				"surname": "Zhan"
			},
			"authorName": "Zhan, Lihan",
			"articleRefs": [
				{
					"pageNumber": 3947,
					"articleName": "Vessel: A Taxonomy of Reproducibility Issues for Container Images",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d947/573300d947.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Qi",
				"surname": "Zhan"
			},
			"authorName": "Zhan, Qi",
			"articleRefs": [
				{
					"pageNumber": 91,
					"articleName": "When AllClose Fails: Round-Off Error Estimation for Deep Learning Programs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a091/573300a091.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xian",
				"surname": "Zhan"
			},
			"authorName": "Zhan, Xian",
			"articleRefs": [
				{
					"pageNumber": 1767,
					"articleName": "Demystifying Cross-Language C/C++ Binaries: A Robust Software Component Analysis Approach",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b767/573300b767.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Chao",
				"surname": "Zhang"
			},
			"authorName": "Zhang, Chao",
			"articleRefs": [
				{
					"pageNumber": 726,
					"articleName": "Improving LLM-Based Log Parsing by Learning from Errors in Reasoning Traces",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a726/573300a726.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Chaoyun",
				"surname": "Zhang"
			},
			"authorName": "Zhang, Chaoyun",
			"articleRefs": [
				{
					"pageNumber": 674,
					"articleName": "Triangle: Empowering Incident Triage with Multi-Agent",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a674/573300a674.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Chengyu",
				"surname": "Zhang"
			},
			"authorName": "Zhang, Chengyu",
			"articleRefs": [
				{
					"pageNumber": 129,
					"articleName": "Diagnosing Performance Differences in Model Checkers via Runtime-Guided Problem Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a129/573300a129.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Chenxi",
				"surname": "Zhang"
			},
			"authorName": "Zhang, Chenxi",
			"articleRefs": [
				{
					"pageNumber": 1142,
					"articleName": "Hypergraph Neural Network-Based Multi-Granular Root Cause Localization for Microservice Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b142/573300b142.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Chi",
				"surname": "Zhang"
			},
			"authorName": "Zhang, Chi",
			"articleRefs": [
				{
					"pageNumber": 1069,
					"articleName": "A Large Scale Study of AI-Based Binary Function Similarity Detection Techniques for Security Researchers and Practitioners",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b069/573300b069.pdf"
				},
				{
					"pageNumber": 1806,
					"articleName": "ARG: Testing Query Rewriters via Abstract Rule Guided Fuzzing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b806/573300b806.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Chuqi",
				"surname": "Zhang"
			},
			"authorName": "Zhang, Chuqi",
			"articleRefs": [
				{
					"pageNumber": 65,
					"articleName": "Propagation-Based Vulnerability Impact Assessment for Software Supply Chains",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a065/573300a065.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Fengjun",
				"surname": "Zhang"
			},
			"authorName": "Zhang, Fengjun",
			"articleRefs": [
				{
					"pageNumber": 1666,
					"articleName": "Leveraging Mixture-of-Experts Framework for Smart Contract Vulnerability Repair with Large Language Model",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b666/573300b666.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Fuyuan",
				"surname": "Zhang"
			},
			"authorName": "Zhang, Fuyuan",
			"articleRefs": [
				{
					"pageNumber": 3823,
					"articleName": "Is Measurement Enough? Rethinking Output Validation in Quantum Program Testing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d823/573300d823.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Hang",
				"surname": "Zhang"
			},
			"authorName": "Zhang, Hang",
			"articleRefs": [
				{
					"pageNumber": 380,
					"articleName": "Towards More Accurate Static Analysis for Taint-Style Bug Detection in Linux Kernel",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a380/573300a380.pdf"
				},
				{
					"pageNumber": 893,
					"articleName": "LineBreaker: Finding Token-Inconsistency Bugs with Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a893/573300a893.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Haonan",
				"surname": "Zhang"
			},
			"authorName": "Zhang, Haonan",
			"articleRefs": [
				{
					"pageNumber": 1868,
					"articleName": "ORFUZZ: Fuzzing the \"Other Side\" of LLM Safety \u2013 Testing Over-Refusal",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b868/573300b868.pdf"
				},
				{
					"pageNumber": 3057,
					"articleName": "Who's to Blame? Rethinking the Brittleness of Automated Web GUI Testing from a Pragmatic Perspective",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d057/573300d057.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Haoxiang",
				"surname": "Zhang"
			},
			"authorName": "Zhang, Haoxiang",
			"articleRefs": [
				{
					"pageNumber": 2324,
					"articleName": "SPICE\uD83C\uDF36\uFE0F: An Automated SWE-Bench Labeling Pipeline for Issue Clarity, Test Coverage, and Effort Estimation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c324/573300c324.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "He ",
				"surname": "Zhang"
			},
			"authorName": "Zhang, He",
			"articleRefs": [
				{
					"pageNumber": 597,
					"articleName": "Automatic Fixing of Missing Dependency Errors",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a597/573300a597.pdf"
				},
				{
					"pageNumber": 996,
					"articleName": "Not Every Patch is an Island: LLM-Enhanced Identification of Multiple Vulnerability Patches",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a996/573300a996.pdf"
				},
				{
					"pageNumber": 3706,
					"articleName": "Securing Self-Managed Third-Party Libraries",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d706/573300d706.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Hengyu",
				"surname": "Zhang"
			},
			"authorName": "Zhang, Hengyu",
			"articleRefs": [
				{
					"pageNumber": 3580,
					"articleName": "Element-Aware Fine-Tuning of Vision-Language Models for Cost-Efficient GUI Testing in an Industrial Setting",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d580/573300d580.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Hongyu",
				"surname": "Zhang"
			},
			"authorName": "Zhang, Hongyu",
			"articleRefs": [
				{
					"pageNumber": 141,
					"articleName": "LongCodeZip: Compress Long Context for Code Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a141/573300a141.pdf"
				},
				{
					"pageNumber": 330,
					"articleName": "LogMoE: Lightweight Expert Mixture for Cross-System Log Anomaly Detection",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a330/573300a330.pdf"
				},
				{
					"pageNumber": 4008,
					"articleName": "AgentDroid: A Multi-Agent Tool for Detecting Fraudulent Android Applications",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e008/573300e008.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Houxiang",
				"surname": "Zhang"
			},
			"authorName": "Zhang, Houxiang",
			"articleRefs": [
				{
					"pageNumber": 3402,
					"articleName": "Out of Distribution Detection in Self-Adaptive Robots with AI-Powered Digital Twins",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d402/573300d402.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jian",
				"surname": "Zhang"
			},
			"authorName": "Zhang, Jian",
			"articleRefs": [
				{
					"pageNumber": 1155,
					"articleName": "Seeing is Fixing: Cross-Modal Reasoning with Multimodal LLMs for Visual Software Issue Repair",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b155/573300b155.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jin",
				"surname": "Zhang"
			},
			"authorName": "Zhang, Jin",
			"articleRefs": [
				{
					"pageNumber": 1194,
					"articleName": "AdaptEval: A Benchmark for Evaluating Large Language Models on Code Snippet Adaptation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b194/573300b194.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jingkun",
				"surname": "Zhang"
			},
			"authorName": "Zhang, Jingkun",
			"articleRefs": [
				{
					"pageNumber": 3556,
					"articleName": "Shrunk, Yet Complete: Code Shrinking-Resilient Android Third-Party Library Detection",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d556/573300d556.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jingwen",
				"surname": "Zhang"
			},
			"authorName": "Zhang, Jingwen",
			"articleRefs": [
				{
					"pageNumber": 571,
					"articleName": "SSR: Safeguarding Staking Rewards by Defining and Detecting Logical Defects in DeFi Staking",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a571/573300a571.pdf"
				},
				{
					"pageNumber": 1528,
					"articleName": "Finding Insecure State Dependency in DApps via Multi-Source Tracing and Semantic Enrichment",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b528/573300b528.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jingxuan",
				"surname": "Zhang"
			},
			"authorName": "Zhang, Jingxuan",
			"articleRefs": [
				{
					"pageNumber": 2133,
					"articleName": "Towards Generalizable Instruction Vulnerability Prediction via LLM-Enhanced Code Representation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c133/573300c133.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Junqi",
				"surname": "Zhang"
			},
			"authorName": "Zhang, Junqi",
			"articleRefs": [
				{
					"pageNumber": 841,
					"articleName": "PseudoFix: Refactoring Distorted Structures in Decompiled C Pseudocode",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a841/573300a841.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Junyuan",
				"surname": "Zhang"
			},
			"authorName": "Zhang, Junyuan",
			"articleRefs": [
				{
					"pageNumber": 2905,
					"articleName": "Metamorphic Testing for Audio Content Moderation Software",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c905/573300c905.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Kechi",
				"surname": "Zhang"
			},
			"authorName": "Zhang, Kechi",
			"articleRefs": [
				{
					"pageNumber": 1476,
					"articleName": "Aligning LLMs to Fully Utilize the Cross-File Context in Repository-Level Code Completion",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b476/573300b476.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Lei",
				"surname": "Zhang"
			},
			"authorName": "Zhang, Lei",
			"articleRefs": [
				{
					"pageNumber": 932,
					"articleName": "Exploring Static Taint Analysis in LLMs: A Dynamic Benchmarking Framework for Measurement and Enhancement",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a932/573300a932.pdf"
				},
				{
					"pageNumber": 2413,
					"articleName": "DeepExploitor: LLM-Enhanced Automated Exploitation of DeepLink Attack in Hybrid Apps",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c413/573300c413.pdf"
				},
				{
					"pageNumber": 2869,
					"articleName": "LLMPort: Cross-File Patch Porting via Task Decomposition and Self-Correction",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c869/573300c869.pdf"
				},
				{
					"pageNumber": 3082,
					"articleName": "Algernon: A Flag-Guided Hybrid Fuzzer for Unlocking Hidden Program Paths",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d082/573300d082.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Li",
				"surname": "Zhang"
			},
			"authorName": "Zhang, Li",
			"articleRefs": [
				{
					"pageNumber": 2007,
					"articleName": "Explainable Fault Localization for Programming Assignments via LLM-Guided Annotation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c007/573300c007.pdf"
				},
				{
					"pageNumber": 2298,
					"articleName": "FastCoder: Accelerating Repository-Level Code Generation via Efficient Retrieval and Verification",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c298/573300c298.pdf"
				},
				{
					"pageNumber": 2618,
					"articleName": "EfficientEdit: Accelerating Code Editing via Edit-Oriented Speculative Decoding",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c618/573300c618.pdf"
				},
				{
					"pageNumber": 3592,
					"articleName": "AutoPLC: Generating Vendor-Aware Structured Text for Programmable Logic Controllers",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d592/573300d592.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Lingzhe",
				"surname": "Zhang"
			},
			"authorName": "Zhang, Lingzhe",
			"articleRefs": [
				{
					"pageNumber": 661,
					"articleName": "United We Stand: Towards End-to-End Log-Based Fault Diagnosis via Interactive Multi-Task Learning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a661/573300a661.pdf"
				},
				{
					"pageNumber": 700,
					"articleName": "LogAction: Consistent Cross-System Anomaly Detection Through Logs via Active Domain Adaptation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a700/573300a700.pdf"
				},
				{
					"pageNumber": 1118,
					"articleName": "CoorLog: Efficient-Generalizable Log Anomaly Detection via Adaptive Coordinator in Software Evolution",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b118/573300b118.pdf"
				},
				{
					"pageNumber": 3783,
					"articleName": "Walk the Talk: Is Your Log-Based Software Reliability Maintenance System Really Reliable?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d783/573300d783.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Lyuye",
				"surname": "Zhang"
			},
			"authorName": "Zhang, Lyuye",
			"articleRefs": [
				{
					"pageNumber": 52,
					"articleName": "Learning from the Past: Real-World Exploit Migration for Smart Contract PoC Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a052/573300a052.pdf"
				},
				{
					"pageNumber": 95,
					"articleName": "DroidNative: A Greedy-Constructed Large-Scale Indexing for Android Native Libraries",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a095/850300a095.pdf"
				},
				{
					"pageNumber": 104,
					"articleName": "FAULTSEEKER: LLM-Empowered Framework for Blockchain Transaction Fault Localization",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a104/573300a104.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Meng",
				"surname": "Zhang"
			},
			"authorName": "Zhang, Meng",
			"articleRefs": [
				{
					"pageNumber": 169,
					"articleName": "LLM-Assisted Tool for Joint Generation of Formulas and Functions in Rule-Based Verification of Map Transformations",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a169/850300a169.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Mengxiao",
				"surname": "Zhang"
			},
			"authorName": "Zhang, Mengxiao",
			"articleRefs": [
				{
					"pageNumber": 2273,
					"articleName": "Latra: A Template-Based Language-Agnostic Transformation Framework for Effective Program Reduction",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c273/573300c273.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Miao",
				"surname": "Zhang"
			},
			"authorName": "Zhang, Miao",
			"articleRefs": [
				{
					"pageNumber": 1692,
					"articleName": "Demystifying Cookie Sharing Risks in WebView-Based Mobile App-in-app Ecosystems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b692/573300b692.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Mingyue",
				"surname": "Zhang"
			},
			"authorName": "Zhang, Mingyue",
			"articleRefs": [
				{
					"pageNumber": 237,
					"articleName": "Towards MPC-Driven Software Adaptation: A Dual-Layer Approach Combining ICNN-Based Modeling and Delta-Based Tuning",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a237/850300a237.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Peng",
				"surname": "Zhang"
			},
			"authorName": "Zhang, Peng",
			"articleRefs": [
				{
					"pageNumber": 228,
					"articleName": "RELIA: Accelerating the Analysis of Cloud Access Control Policies",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a228/573300a228.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Penghao",
				"surname": "Zhang"
			},
			"authorName": "Zhang, Penghao",
			"articleRefs": [
				{
					"pageNumber": 3191,
					"articleName": "KAIOps: A Platform Solution of End-to-End Multi-Modal AIOps for AI Training at Scale",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d191/573300d191.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Qian",
				"surname": "Zhang"
			},
			"authorName": "Zhang, Qian",
			"articleRefs": [
				{
					"pageNumber": 1743,
					"articleName": "CROSS2OH: Enabling Seamless Porting of C/C++ Software Libraries to OpenHarmony",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b743/573300b743.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Qiang",
				"surname": "Zhang"
			},
			"authorName": "Zhang, Qiang",
			"articleRefs": [
				{
					"pageNumber": 3226,
					"articleName": "TRON: Fuzzing Linux Network Stack via Protocol-System Call Payload Synthesis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d226/573300d226.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Qiming",
				"surname": "Zhang"
			},
			"authorName": "Zhang, Qiming",
			"articleRefs": [
				{
					"pageNumber": 3414,
					"articleName": "Data Dependency-Aware Code Generation from Enhanced UML Sequence Diagrams",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d414/573300d414.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ray",
				"surname": "Zhang"
			},
			"authorName": "Zhang, Ray",
			"articleRefs": [
				{
					"pageNumber": 3759,
					"articleName": "What Types of Code Review Comments Do Developers Most Frequently Resolve?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d759/573300d759.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Shenglin",
				"surname": "Zhang"
			},
			"authorName": "Zhang, Shenglin",
			"articleRefs": [
				{
					"pageNumber": 674,
					"articleName": "Triangle: Empowering Incident Triage with Multi-Agent",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a674/573300a674.pdf"
				},
				{
					"pageNumber": 2221,
					"articleName": "LLM-Powered Multi-Agent Collaboration for Intelligent Industrial On-Call Automation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c221/573300c221.pdf"
				},
				{
					"pageNumber": 3238,
					"articleName": "TrioXpert: An Automated Incident Management Framework for Microservice System",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d238/573300d238.pdf"
				},
				{
					"pageNumber": 3497,
					"articleName": "Adaptive Performance Regression Detection Using A Semi-Supervised Siamese Network",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d497/573300d497.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Shikun",
				"surname": "Zhang"
			},
			"authorName": "Zhang, Shikun",
			"articleRefs": [
				{
					"pageNumber": 217,
					"articleName": "R3-Bench: Reproducible Real-World Reverse Engineering Dataset for Symbol Recovery",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a217/573300a217.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Shiyang",
				"surname": "Zhang"
			},
			"authorName": "Zhang, Shiyang",
			"articleRefs": [
				{
					"pageNumber": 95,
					"articleName": "DroidNative: A Greedy-Constructed Large-Scale Indexing for Android Native Libraries",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a095/850300a095.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Shuoxiao ",
				"surname": "Zhang"
			},
			"authorName": "Zhang, Shuoxiao",
			"articleRefs": [
				{
					"pageNumber": 1168,
					"articleName": "When Autonomous Vehicle Meets V2X Cooperative Perception: How Far Are We?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b168/573300b168.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Tanghaoran",
				"surname": "Zhang"
			},
			"authorName": "Zhang, Tanghaoran",
			"articleRefs": [
				{
					"pageNumber": 1194,
					"articleName": "AdaptEval: A Benchmark for Evaluating Large Language Models on Code Snippet Adaptation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b194/573300b194.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Tianyi",
				"surname": "Zhang"
			},
			"authorName": "Zhang, Tianyi",
			"articleRefs": [
				{
					"pageNumber": 3592,
					"articleName": "AutoPLC: Generating Vendor-Aware Structured Text for Programmable Logic Controllers",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d592/573300d592.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Tieying",
				"surname": "Zhang"
			},
			"authorName": "Zhang, Tieying",
			"articleRefs": [
				{
					"pageNumber": 3298,
					"articleName": "LogPilot: Intent-Aware and Scalable Alert Diagnosis for Large-Scale Online Service Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d298/573300d298.pdf"
				},
				{
					"pageNumber": 3425,
					"articleName": "Automated Proactive Logging Quality Improvement for Large-Scale Codebases ",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d425/573300d425.pdf"
				},
				{
					"pageNumber": 3533,
					"articleName": "ErrorPrism: Reconstructing Error Propagation Paths in Cloud Service Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d533/573300d533.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ting",
				"surname": "Zhang"
			},
			"authorName": "Zhang, Ting",
			"articleRefs": [
				{
					"pageNumber": 2605,
					"articleName": "SE-Jury: An LLM-as-Ensemble-Judge Metric for Narrowing the Gap with Human Evaluation in SE",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c605/573300c605.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Weibo",
				"surname": "Zhang"
			},
			"authorName": "Zhang, Weibo",
			"articleRefs": [
				{
					"pageNumber": 3545,
					"articleName": "LLM-Assisted Industrial-Scale Differential Testing of Package Incompatibilities in Linux Distributions",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d545/573300d545.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Weifeng",
				"surname": "Zhang"
			},
			"authorName": "Zhang, Weifeng",
			"articleRefs": [
				{
					"pageNumber": 584,
					"articleName": "EditFusion: Resolving Code Merge Conflicts via Edit Selection",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a584/573300a584.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Weiming",
				"surname": "Zhang"
			},
			"authorName": "Zhang, Weiming",
			"articleRefs": [
				{
					"pageNumber": 841,
					"articleName": "PseudoFix: Refactoring Distorted Structures in Decompiled C Pseudocode",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a841/573300a841.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Weizhe",
				"surname": "Zhang"
			},
			"authorName": "Zhang, Weizhe",
			"articleRefs": [
				{
					"pageNumber": 571,
					"articleName": "SSR: Safeguarding Staking Rewards by Defining and Detecting Logical Defects in DeFi Staking",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a571/573300a571.pdf"
				},
				{
					"pageNumber": 1528,
					"articleName": "Finding Insecure State Dependency in DApps via Multi-Source Tracing and Semantic Enrichment",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b528/573300b528.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Wentao",
				"surname": "Zhang"
			},
			"authorName": "Zhang, Wentao",
			"articleRefs": [
				{
					"pageNumber": 1082,
					"articleName": "DebCovDiff: Differential Testing of Coverage Measurement Tools on Real-World Projects",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b082/573300b082.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Wu",
				"surname": "Zhang"
			},
			"authorName": "Zhang, Wu",
			"articleRefs": [
				{
					"pageNumber": 3683,
					"articleName": "Securing Millions of Decentralized Identities in Alipay Super App with End-to-End Formal Verification",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d683/573300d683.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xiangyu",
				"surname": "Zhang"
			},
			"authorName": "Zhang, Xiangyu",
			"articleRefs": [
				{
					"pageNumber": 521,
					"articleName": "GlassWing: A Tailored Static Analysis Approach for Flutter Android Apps",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a521/573300a521.pdf"
				},
				{
					"pageNumber": 1220,
					"articleName": "RFCAudit: AI Agent for Auditing Protocol Implementations Against RFC Specifications",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b220/573300b220.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xiaodong",
				"surname": "Zhang"
			},
			"authorName": "Zhang, Xiaodong",
			"articleRefs": [
				{
					"pageNumber": 495,
					"articleName": "RSFuzz: A Robustness-Guided Swarm Fuzzing Framework Based on Behavioral Constraints",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a495/573300a495.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xiaomin",
				"surname": "Zhang"
			},
			"authorName": "Zhang, Xiaomin",
			"articleRefs": [
				{
					"pageNumber": 117,
					"articleName": "SateLight: A Satellite Application Update Framework for Satellite Computing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a117/573300a117.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xiaoyu",
				"surname": "Zhang"
			},
			"authorName": "Zhang, Xiaoyu",
			"articleRefs": [
				{
					"pageNumber": 129,
					"articleName": "Diagnosing Performance Differences in Model Checkers via Runtime-Guided Problem Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a129/573300a129.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xin",
				"surname": "Zhang"
			},
			"authorName": "Zhang, Xin",
			"articleRefs": [
				{
					"pageNumber": 700,
					"articleName": "LogAction: Consistent Cross-System Anomaly Detection Through Logs via Active Domain Adaptation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a700/573300a700.pdf"
				},
				{
					"pageNumber": 1565,
					"articleName": "Belief Propagation with Local Structure and Its Applications in Program Analysis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b565/573300b565.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xindi",
				"surname": "Zhang"
			},
			"authorName": "Zhang, Xindi",
			"articleRefs": [
				{
					"pageNumber": 1272,
					"articleName": "SMTgazer: Learning to Schedule SMT Algorithms via Bayesian Optimization",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b272/573300b272.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xuchao ",
				"surname": "Zhang"
			},
			"authorName": "Zhang, Xuchao",
			"articleRefs": [
				{
					"pageNumber": 674,
					"articleName": "Triangle: Empowering Incident Triage with Multi-Agent",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a674/573300a674.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yang",
				"surname": "Zhang"
			},
			"authorName": "Zhang, Yang",
			"articleRefs": [
				{
					"pageNumber": 2221,
					"articleName": "LLM-Powered Multi-Agent Collaboration for Intelligent Industrial On-Call Automation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c221/573300c221.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yifan",
				"surname": "Zhang"
			},
			"authorName": "Zhang, Yifan",
			"articleRefs": [
				{
					"pageNumber": 893,
					"articleName": "LineBreaker: Finding Token-Inconsistency Bugs with Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a893/573300a893.pdf"
				},
				{
					"pageNumber": 2121,
					"articleName": "PAT-Agent: Autoformalization for Model Checking",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c121/573300c121.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yiran",
				"surname": "Zhang"
			},
			"authorName": "Zhang, Yiran",
			"articleRefs": [
				{
					"pageNumber": 648,
					"articleName": "BinStruct: Binary Structure Recovery Combining Static Analysis and Semantics",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a648/573300a648.pdf"
				},
				{
					"pageNumber": 3931,
					"articleName": "Requirements Development and Formalization for Reliable Code Generation: A Multi-Agent Vision",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d931/573300d931.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yu",
				"surname": "Zhang"
			},
			"authorName": "Zhang, Yu",
			"articleRefs": [
				{
					"pageNumber": 169,
					"articleName": "LLM-Assisted Tool for Joint Generation of Formulas and Functions in Rule-Based Verification of Map Transformations",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a169/850300a169.pdf"
				},
				{
					"pageNumber": 2221,
					"articleName": "LLM-Powered Multi-Agent Collaboration for Intelligent Industrial On-Call Automation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c221/573300c221.pdf"
				},
				{
					"pageNumber": 2234,
					"articleName": "Enhancing LLM to Decompile Optimized PTX to Readable CUDA for Tensor Programs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c234/573300c234.pdf"
				},
				{
					"pageNumber": 3437,
					"articleName": "From Redundancy to Efficiency: Exploiting Shared UI Interactions Towards Efficient LLM-Based Testing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d437/573300d437.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yuan",
				"surname": "Zhang"
			},
			"authorName": "Zhang, Yuan",
			"articleRefs": [
				{
					"pageNumber": 559,
					"articleName": "Security Debt in LLM Agent Applications: A Measurement Study of Vulnerabilities and Mitigation Trade-Offs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a559/573300a559.pdf"
				},
				{
					"pageNumber": 932,
					"articleName": "Exploring Static Taint Analysis in LLMs: A Dynamic Benchmarking Framework for Measurement and Enhancement",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a932/573300a932.pdf"
				},
				{
					"pageNumber": 2413,
					"articleName": "DeepExploitor: LLM-Enhanced Automated Exploitation of DeepLink Attack in Hybrid Apps",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c413/573300c413.pdf"
				},
				{
					"pageNumber": 2869,
					"articleName": "LLMPort: Cross-File Patch Porting via Task Decomposition and Self-Correction",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c869/573300c869.pdf"
				},
				{
					"pageNumber": 3082,
					"articleName": "Algernon: A Flag-Guided Hybrid Fuzzer for Unlocking Hidden Program Paths",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d082/573300d082.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yuanhe",
				"surname": "Zhang"
			},
			"authorName": "Zhang, Yuanhe",
			"articleRefs": [
				{
					"pageNumber": 2503,
					"articleName": "Unit Test Update Through LLM-Driven Context Collection and Error-Type-Aware Refinement",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c503/573300c503.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yue",
				"surname": "Zhang"
			},
			"authorName": "Zhang, Yue",
			"articleRefs": [
				{
					"pageNumber": 791,
					"articleName": "Hit The Bullseye On The First Shot: Improving LLMs Using Multi-Sample Self-Reward Feedback for Vulnerability Repair",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a791/573300a791.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yueke",
				"surname": "Zhang"
			},
			"authorName": "Zhang, Yueke",
			"articleRefs": [
				{
					"pageNumber": 3870,
					"articleName": "CodeACT-R: A Cognitive Simulation Framework for Human Attention in Code Reading",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d870/573300d870.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yuheng",
				"surname": "Zhang"
			},
			"authorName": "Zhang, Yuheng",
			"articleRefs": [
				{
					"pageNumber": 893,
					"articleName": "LineBreaker: Finding Token-Inconsistency Bugs with Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a893/573300a893.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yuxia",
				"surname": "Zhang"
			},
			"authorName": "Zhang, Yuxia",
			"articleRefs": [
				{
					"pageNumber": 178,
					"articleName": "Wired for Reuse: Automating Context-Aware Code Adaptation in IDEs via LLM-Based Agent",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a178/573300a178.pdf"
				},
				{
					"pageNumber": 2982,
					"articleName": "LAURA: Enhancing Code Review Generation with Context-Enriched Retrieval-Augmented LLM",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c982/573300c982.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yuxin",
				"surname": "Zhang"
			},
			"authorName": "Zhang, Yuxin",
			"articleRefs": [
				{
					"pageNumber": 2982,
					"articleName": "LAURA: Enhancing Code Review Generation with Context-Enriched Retrieval-Augmented LLM",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c982/573300c982.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yuzhi",
				"surname": "Zhang"
			},
			"authorName": "Zhang, Yuzhi",
			"articleRefs": [
				{
					"pageNumber": 1717,
					"articleName": "Fixing Broken Graphs: LLM-Powered Automatic Code Optimization for DNN Programs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b717/573300b717.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zhang",
				"surname": "Zhang"
			},
			"authorName": "Zhang, Zhang",
			"articleRefs": [
				{
					"pageNumber": 1194,
					"articleName": "AdaptEval: A Benchmark for Evaluating Large Language Models on Code Snippet Adaptation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b194/573300b194.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zhangyue",
				"surname": "Zhang"
			},
			"authorName": "Zhang, Zhangyue",
			"articleRefs": [
				{
					"pageNumber": 2413,
					"articleName": "DeepExploitor: LLM-Enhanced Automated Exploitation of DeepLink Attack in Hybrid Apps",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c413/573300c413.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zhibo",
				"surname": "Zhang"
			},
			"authorName": "Zhang, Zhibo",
			"articleRefs": [
				{
					"pageNumber": 2413,
					"articleName": "DeepExploitor: LLM-Enhanced Automated Exploitation of DeepLink Attack in Hybrid Apps",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c413/573300c413.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zhiwei",
				"surname": "Zhang"
			},
			"authorName": "Zhang, Zhiwei",
			"articleRefs": [
				{
					"pageNumber": 495,
					"articleName": "RSFuzz: A Robustness-Guided Swarm Fuzzing Framework Based on Behavioral Constraints",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a495/573300a495.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zixuan",
				"surname": "Zhang"
			},
			"authorName": "Zhang, Zixuan",
			"articleRefs": [
				{
					"pageNumber": 253,
					"articleName": "Fair Developer Score: Build-Adjusted Measurement of Effort and Impact",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a253/850300a253.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Di",
				"surname": "Zhang "
			},
			"authorName": "Zhang, Di",
			"articleRefs": [
				{
					"pageNumber": 2234,
					"articleName": "Enhancing LLM to Decompile Optimized PTX to Readable CUDA for Tensor Programs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c234/573300c234.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Binbin",
				"surname": "Zhao"
			},
			"authorName": "Zhao, Binbin",
			"articleRefs": [
				{
					"pageNumber": 1044,
					"articleName": "PROMFUZZ: Leveraging LLM-Driven and Bug-Oriented Composite Analysis for Detecting Functional Bugs in Smart Contracts",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b044/573300b044.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Haoran",
				"surname": "Zhao"
			},
			"authorName": "Zhao, Haoran",
			"articleRefs": [
				{
					"pageNumber": 932,
					"articleName": "Exploring Static Taint Analysis in LLMs: A Dynamic Benchmarking Framework for Measurement and Enhancement",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a932/573300a932.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Huimin",
				"surname": "Zhao"
			},
			"authorName": "Zhao, Huimin",
			"articleRefs": [
				{
					"pageNumber": 2145,
					"articleName": "Don't Mess with Bro's Cheese! An Empirical Study of Resource Conflict in Android Multi-Window",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c145/573300c145.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jianhua",
				"surname": "Zhao"
			},
			"authorName": "Zhao, Jianhua",
			"articleRefs": [
				{
					"pageNumber": 2349,
					"articleName": "Incremental Program Analysis in the Wild: An Empirical Study on Real-World Program Changes",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c349/573300c349.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jianjun",
				"surname": "Zhao"
			},
			"authorName": "Zhao, Jianjun",
			"articleRefs": [
				{
					"pageNumber": 2656,
					"articleName": "QuanBench: Benchmarking Quantum Code Generation with Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c656/573300c656.pdf"
				},
				{
					"pageNumber": 3638,
					"articleName": "M2QCode: A Model-Driven Framework for Generating Multi-Platform Quantum Programs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d638/573300d638.pdf"
				},
				{
					"pageNumber": 3823,
					"articleName": "Is Measurement Enough? Rethinking Output Validation in Quantum Program Testing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d823/573300d823.pdf"
				},
				{
					"pageNumber": 3880,
					"articleName": "NovaQ: Improving Quantum Program Testing through Diversity-Guided Test Case Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d880/573300d880.pdf"
				},
				{
					"pageNumber": 3885,
					"articleName": "When Abstraction Breaks Physics: Rethinking Modular Design in Quantum Software",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d885/573300d885.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jianshu",
				"surname": "Zhao"
			},
			"authorName": "Zhao, Jianshu",
			"articleRefs": [
				{
					"pageNumber": 117,
					"articleName": "SateLight: A Satellite Application Update Framework for Satellite Computing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a117/573300a117.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Kunsong",
				"surname": "Zhao"
			},
			"authorName": "Zhao, Kunsong",
			"articleRefs": [
				{
					"pageNumber": 2541,
					"articleName": "Soleker: Uncovering Vulnerabilities in Solana Smart Contracts",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c541/573300c541.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Minghao",
				"surname": "Zhao"
			},
			"authorName": "Zhao, Minghao",
			"articleRefs": [
				{
					"pageNumber": 3813,
					"articleName": "LLM-Based Dynamic Differential Testing for Database Connectors with Reinforcement Learning-Guided Prompt Selection",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d813/573300d813.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Qianhui",
				"surname": "Zhao"
			},
			"authorName": "Zhao, Qianhui",
			"articleRefs": [
				{
					"pageNumber": 2298,
					"articleName": "FastCoder: Accelerating Repository-Level Code Generation via Efficient Retrieval and Verification",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c298/573300c298.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Weibo",
				"surname": "Zhao"
			},
			"authorName": "Zhao, Weibo",
			"articleRefs": [
				{
					"pageNumber": 3984,
					"articleName": "A Large-Scale Evolvable Dataset for Model Context Protocol Ecosystem and Security Analysis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d984/573300d984.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yanchao",
				"surname": "Zhao"
			},
			"authorName": "Zhao, Yanchao",
			"articleRefs": [
				{
					"pageNumber": 2133,
					"articleName": "Towards Generalizable Instruction Vulnerability Prediction via LLM-Enhanced Code Representation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c133/573300c133.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yanjie",
				"surname": "Zhao"
			},
			"authorName": "Zhao, Yanjie",
			"articleRefs": [
				{
					"pageNumber": 445,
					"articleName": "TensorGuard: Gradient-Based Model Fingerprinting for LLM Similarity Detection and Family Classification",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a445/573300a445.pdf"
				},
				{
					"pageNumber": 1692,
					"articleName": "Demystifying Cookie Sharing Risks in WebView-Based Mobile App-in-app Ecosystems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b692/573300b692.pdf"
				},
				{
					"pageNumber": 3167,
					"articleName": "HarmoBridge: Bridging ArkTS and C/C++ for Cross-Language Static Analysis on HarmonyOS",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d167/573300d167.pdf"
				},
				{
					"pageNumber": 3179,
					"articleName": "ApkArmor: Low-Cost Lightweight Anti-Decompilation Techniques for Android Apps",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d179/573300d179.pdf"
				},
				{
					"pageNumber": 3368,
					"articleName": "A Characterization Study of Bugs in LLM Agent Workflow Orchestration Frameworks",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d368/573300d368.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yanyang",
				"surname": "Zhao"
			},
			"authorName": "Zhao, Yanyang",
			"articleRefs": [
				{
					"pageNumber": 765,
					"articleName": "DualFuzz: Detecting Vulnerability in Wi-Fi NICs through Dual-Directional Fuzzing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a765/573300a765.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yu",
				"surname": "Zhao"
			},
			"authorName": "Zhao, Yu",
			"articleRefs": [
				{
					"pageNumber": 1880,
					"articleName": "Coding-Fuse: Efficient Fusion of Code Pre-Trained Models for Classification Tasks",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b880/573300b880.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yuan",
				"surname": "Zhao"
			},
			"authorName": "Zhao, Yuan",
			"articleRefs": [
				{
					"pageNumber": 1793,
					"articleName": "Multi-Dimensional Assessment of Crowdsourced Testing Reports via LLMs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b793/573300b793.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yukai",
				"surname": "Zhao"
			},
			"authorName": "Zhao, Yukai",
			"articleRefs": [
				{
					"pageNumber": 2745,
					"articleName": "HFuzzer: Testing Large Language Models for Package Hallucinations via Phrase-Based Fuzzing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c745/573300c745.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yuxin",
				"surname": "Zhao"
			},
			"authorName": "Zhao, Yuxin",
			"articleRefs": [
				{
					"pageNumber": 1194,
					"articleName": "AdaptEval: A Benchmark for Evaluating Large Language Models on Code Snippet Adaptation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b194/573300b194.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ziming",
				"surname": "Zhao"
			},
			"authorName": "Zhao, Ziming",
			"articleRefs": [
				{
					"pageNumber": 2630,
					"articleName": "AutoFid: Adaptive and Noise-Aware Fidelity Measurement for Quantum Programs via Circuit Graph Analysis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c630/573300c630.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Guilin",
				"surname": "Zheng"
			},
			"authorName": "Zheng, Guilin",
			"articleRefs": [
				{
					"pageNumber": 1692,
					"articleName": "Demystifying Cookie Sharing Risks in WebView-Based Mobile App-in-app Ecosystems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b692/573300b692.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jun",
				"surname": "Zheng"
			},
			"authorName": "Zheng, Jun",
			"articleRefs": [
				{
					"pageNumber": 3008,
					"articleName": "Mockingbird: Efficient Excessive Data Exposures Detection via Dynamic Code Instrumentation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d008/573300d008.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Mingwei",
				"surname": "Zheng"
			},
			"authorName": "Zheng, Mingwei",
			"articleRefs": [
				{
					"pageNumber": 1220,
					"articleName": "RFCAudit: AI Agent for Auditing Protocol Implementations Against RFC Specifications",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b220/573300b220.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Wei",
				"surname": "Zheng"
			},
			"authorName": "Zheng, Wei",
			"articleRefs": [
				{
					"pageNumber": 154,
					"articleName": "CODE-DITING: Automatic Evaluation of Code Generation Without References or Test Cases",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a154/573300a154.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Wen",
				"surname": "Zheng"
			},
			"authorName": "Zheng, Wen",
			"articleRefs": [
				{
					"pageNumber": 419,
					"articleName": "ProfMal: Detecting Malicious NPM Packages by the Synergy between Static and Dynamic Analysis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a419/573300a419.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yannan",
				"surname": "Zheng"
			},
			"authorName": "Zheng, Yannan",
			"articleRefs": [
				{
					"pageNumber": 393,
					"articleName": "Democratizing the Cryptocurrency Ecosystem by Just-In-Time Transformation of Mining Programs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a393/573300a393.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yaowen",
				"surname": "Zheng"
			},
			"authorName": "Zheng, Yaowen",
			"articleRefs": [
				{
					"pageNumber": 919,
					"articleName": "Lares: LLM-Driven Code Slice Semantic Search for Patch Presence Testing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a919/573300a919.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yuteng",
				"surname": "Zheng"
			},
			"authorName": "Zheng, Yuteng",
			"articleRefs": [
				{
					"pageNumber": 2833,
					"articleName": "Reflective Unit Test Generation for Precise Type Error Detection with Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c833/573300c833.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zheng",
				"surname": "Zheng"
			},
			"authorName": "Zheng, Zheng",
			"articleRefs": [
				{
					"pageNumber": 4085,
					"articleName": "Metamorphic Testing of Deep Reinforcement Learning Agents with MDPMORPH",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e085/573300e085.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zibin",
				"surname": "Zheng"
			},
			"authorName": "Zheng, Zibin",
			"articleRefs": [
				{
					"pageNumber": 482,
					"articleName": "VRExplorer: A Model-Based Approach for Semi-Automated Testing of Virtual Reality Scenes",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a482/573300a482.pdf"
				},
				{
					"pageNumber": 571,
					"articleName": "SSR: Safeguarding Staking Rewards by Defining and Detecting Logical Defects in DeFi Staking",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a571/573300a571.pdf"
				},
				{
					"pageNumber": 610,
					"articleName": "RustRepoTrans: Repository-Level Context Code Translation Benchmark Targeting Rust",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a610/573300a610.pdf"
				},
				{
					"pageNumber": 778,
					"articleName": "DrainCode: Stealthy Energy Consumption Attacks on Retrieval-Augmented Code Generation via Context Poisoning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a778/573300a778.pdf"
				},
				{
					"pageNumber": 971,
					"articleName": "AlignCoder: Aligning Retrieval with Target Intent for Repository-Level Code Completion",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a971/573300a971.pdf"
				},
				{
					"pageNumber": 1528,
					"articleName": "Finding Insecure State Dependency in DApps via Multi-Source Tracing and Semantic Enrichment",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b528/573300b528.pdf"
				},
				{
					"pageNumber": 3533,
					"articleName": "ErrorPrism: Reconstructing Error Propagation Paths in Cloud Service Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d533/573300d533.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Chenxing",
				"surname": "Zhong"
			},
			"authorName": "Zhong, Chenxing",
			"articleRefs": [
				{
					"pageNumber": 597,
					"articleName": "Automatic Fixing of Missing Dependency Errors",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a597/573300a597.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Juantao",
				"surname": "Zhong"
			},
			"authorName": "Zhong, Juantao",
			"articleRefs": [
				{
					"pageNumber": 1780,
					"articleName": "Detecting Various DeFi Price Manipulations with LLM Reasoning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b780/573300b780.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yuedong",
				"surname": "Zhong"
			},
			"authorName": "Zhong, Yuedong",
			"articleRefs": [
				{
					"pageNumber": 958,
					"articleName": "iKnow: an Intent-Guided Chatbot for Cloud Operations with Retrieval-Augmented Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a958/573300a958.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zhenyu",
				"surname": "Zhong"
			},
			"authorName": "Zhong, Zhenyu",
			"articleRefs": [
				{
					"pageNumber": 2221,
					"articleName": "LLM-Powered Multi-Agent Collaboration for Intelligent Industrial On-Call Automation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c221/573300c221.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zhewei",
				"surname": "Zhong"
			},
			"authorName": "Zhong, Zhewei",
			"articleRefs": [
				{
					"pageNumber": 700,
					"articleName": "LogAction: Consistent Cross-System Anomaly Detection Through Logs via Active Domain Adaptation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a700/573300a700.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ao",
				"surname": "Zhou"
			},
			"authorName": "Zhou, Ao",
			"articleRefs": [
				{
					"pageNumber": 117,
					"articleName": "SateLight: A Satellite Application Update Framework for Satellite Computing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a117/573300a117.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Bolin",
				"surname": "Zhou"
			},
			"authorName": "Zhou, Bolin",
			"articleRefs": [
				{
					"pageNumber": 3556,
					"articleName": "Shrunk, Yet Complete: Code Shrinking-Resilient Android Third-Party Library Detection",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d556/573300d556.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Chijin",
				"surname": "Zhou"
			},
			"authorName": "Zhou, Chijin",
			"articleRefs": [
				{
					"pageNumber": 3545,
					"articleName": "LLM-Assisted Industrial-Scale Differential Testing of Package Incompatibilities in Linux Distributions",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d545/573300d545.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Chunying",
				"surname": "Zhou"
			},
			"authorName": "Zhou, Chunying",
			"articleRefs": [
				{
					"pageNumber": 996,
					"articleName": "Not Every Patch is an Island: LLM-Enhanced Identification of Multiple Vulnerability Patches",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a996/573300a996.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jianyi",
				"surname": "Zhou"
			},
			"authorName": "Zhou, Jianyi",
			"articleRefs": [
				{
					"pageNumber": 2833,
					"articleName": "Reflective Unit Test Generation for Precise Type Error Detection with Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c833/573300c833.pdf"
				},
				{
					"pageNumber": 3045,
					"articleName": "Clarifying Semantics of In-Context Examples for Unit Test Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d045/573300d045.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jun",
				"surname": "Zhou"
			},
			"authorName": "Zhou, Jun",
			"articleRefs": [
				{
					"pageNumber": 3414,
					"articleName": "Data Dependency-Aware Code Generation from Enhanced UML Sequence Diagrams",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d414/573300d414.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Mingyi",
				"surname": "Zhou"
			},
			"authorName": "Zhou, Mingyi",
			"articleRefs": [
				{
					"pageNumber": 3261,
					"articleName": "Context-Sensitive Pointer Analysis for ArkTS",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d261/573300d261.pdf"
				},
				{
					"pageNumber": 3321,
					"articleName": "An Empirical Study on UI Overlap in OpenHarmony Applications",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d321/573300d321.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ruoyu",
				"surname": "Zhou"
			},
			"authorName": "Zhou, Ruoyu",
			"articleRefs": [
				{
					"pageNumber": 495,
					"articleName": "RSFuzz: A Robustness-Guided Swarm Fuzzing Framework Based on Behavioral Constraints",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a495/573300a495.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Tianshu",
				"surname": "Zhou"
			},
			"authorName": "Zhou, Tianshu",
			"articleRefs": [
				{
					"pageNumber": 3649,
					"articleName": "SCOPE: Evaluating and Enhancing Permission Explanation Transparency in Mobile Apps",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d649/573300d649.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xin",
				"surname": "Zhou"
			},
			"authorName": "Zhou, Xin",
			"articleRefs": [
				{
					"pageNumber": 154,
					"articleName": "CODE-DITING: Automatic Evaluation of Code Generation Without References or Test Cases",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a154/573300a154.pdf"
				},
				{
					"pageNumber": 2605,
					"articleName": "SE-Jury: An LLM-as-Ensemble-Judge Metric for Narrowing the Gap with Human Evaluation in SE",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c605/573300c605.pdf"
				},
				{
					"pageNumber": 3706,
					"articleName": "Securing Self-Managed Third-Party Libraries",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d706/573300d706.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xu",
				"surname": "Zhou"
			},
			"authorName": "Zhou, Xu",
			"articleRefs": [
				{
					"pageNumber": 713,
					"articleName": "When Control Flows Deviate: Directed Grey-box Fuzzing with Probabilistic Reachability Analysis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a713/573300a713.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xulin",
				"surname": "Zhou"
			},
			"authorName": "Zhou, Xulin",
			"articleRefs": [
				{
					"pageNumber": 1755,
					"articleName": "HybridSIMD: A Super C++ SIMD Library with Integrated Auto-Tuning Capabilities",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b755/573300b755.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yangfan",
				"surname": "Zhou"
			},
			"authorName": "Zhou, Yangfan",
			"articleRefs": [
				{
					"pageNumber": 3273,
					"articleName": "Minuku: Detecting Diverse Display Issues in Mobile Apps with Small-Scale Dataset",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d273/573300d273.pdf"
				},
				{
					"pageNumber": 3437,
					"articleName": "From Redundancy to Efficiency: Exploiting Shared UI Interactions Towards Efficient LLM-Based Testing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d437/573300d437.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yu",
				"surname": "Zhou"
			},
			"authorName": "Zhou, Yu",
			"articleRefs": [
				{
					"pageNumber": 154,
					"articleName": "CODE-DITING: Automatic Evaluation of Code Generation Without References or Test Cases",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a154/573300a154.pdf"
				},
				{
					"pageNumber": 2782,
					"articleName": "Understanding Feature Request Practice on GitHub via a Large-Scale Empirical Study",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c782/573300c782.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zetong",
				"surname": "Zhou"
			},
			"authorName": "Zhou, Zetong",
			"articleRefs": [
				{
					"pageNumber": 2298,
					"articleName": "FastCoder: Accelerating Repository-Level Code Generation via Efficient Retrieval and Verification",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c298/573300c298.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zhuotong",
				"surname": "Zhou"
			},
			"authorName": "Zhou, Zhuotong",
			"articleRefs": [
				{
					"pageNumber": 419,
					"articleName": "ProfMal: Detecting Malicious NPM Packages by the Synergy between Static and Dynamic Analysis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a419/573300a419.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zijie",
				"surname": "Zhou"
			},
			"authorName": "Zhou, Zijie",
			"articleRefs": [
				{
					"pageNumber": 317,
					"articleName": "PrefGen: A Preference-Driven Methodology for Secure Yet Gas-Efficient Smart Contract Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a317/573300a317.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Donglai",
				"surname": "Zhu"
			},
			"authorName": "Zhu, Donglai",
			"articleRefs": [
				{
					"pageNumber": 3082,
					"articleName": "Algernon: A Flag-Guided Hybrid Fuzzer for Unlocking Hidden Program Paths",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d082/573300d082.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Hao",
				"surname": "Zhu"
			},
			"authorName": "Zhu, Hao",
			"articleRefs": [
				{
					"pageNumber": 1476,
					"articleName": "Aligning LLMs to Fully Utilize the Cross-File Context in Repository-Level Code Completion",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b476/573300b476.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Hengcheng",
				"surname": "Zhu"
			},
			"authorName": "Zhu, Hengcheng",
			"articleRefs": [
				{
					"pageNumber": 2208,
					"articleName": "LSPFuzz: Hunting Bugs in Language Servers",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c208/573300c208.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Hongsong",
				"surname": "Zhu"
			},
			"authorName": "Zhu, Hongsong",
			"articleRefs": [
				{
					"pageNumber": 919,
					"articleName": "Lares: LLM-Driven Code Slice Semantic Search for Patch Presence Testing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a919/573300a919.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jiancong",
				"surname": "Zhu"
			},
			"authorName": "Zhu, Jiancong",
			"articleRefs": [
				{
					"pageNumber": 253,
					"articleName": "Fair Developer Score: Build-Adjusted Measurement of Effort and Impact",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a253/850300a253.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Jiaxin",
				"surname": "Zhu"
			},
			"authorName": "Zhu, Jiaxin",
			"articleRefs": [
				{
					"pageNumber": 2771,
					"articleName": "Root Cause Analysis of RISC-V Build Failures via LLM and MCTS Reasoning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c771/573300c771.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Qian",
				"surname": "Zhu"
			},
			"authorName": "Zhu, Qian",
			"articleRefs": [
				{
					"pageNumber": 2944,
					"articleName": "EPSO: A Caching-Based Efficient Superoptimizer for BPF Bytecode",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c944/573300c944.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Qinglin",
				"surname": "Zhu"
			},
			"authorName": "Zhu, Qinglin",
			"articleRefs": [
				{
					"pageNumber": 854,
					"articleName": "DLBENCH: A Comprehensive Benchmark for SQL Translation with Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a854/573300a854.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xiaogang",
				"surname": "Zhu"
			},
			"authorName": "Zhu, Xiaogang",
			"articleRefs": [
				{
					"pageNumber": 2387,
					"articleName": "FailMapper: Automated Generation of Unit Tests Guided by Failure Scenarios",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c387/573300c387.pdf"
				},
				{
					"pageNumber": 2579,
					"articleName": "WINGMUZZ: Blackbox Testing of IoT Protocols via Two-Dimensional Fuzzing Schedule",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c579/573300c579.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xu",
				"surname": "Zhu"
			},
			"authorName": "Zhu, Xu",
			"articleRefs": [
				{
					"pageNumber": 841,
					"articleName": "PseudoFix: Refactoring Distorted Structures in Decompiled C Pseudocode",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a841/573300a841.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yinghao",
				"surname": "Zhu"
			},
			"authorName": "Zhu, Yinghao",
			"articleRefs": [
				{
					"pageNumber": 2618,
					"articleName": "EfficientEdit: Accelerating Code Editing via Edit-Oriented Speculative Decoding",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c618/573300c618.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zhengyang",
				"surname": "Zhu"
			},
			"authorName": "Zhu, Zhengyang",
			"articleRefs": [
				{
					"pageNumber": 482,
					"articleName": "VRExplorer: A Model-Based Approach for Semi-Automated Testing of Virtual Reality Scenes",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a482/573300a482.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zhiliang",
				"surname": "Zhu"
			},
			"authorName": "Zhu, Zhiliang",
			"articleRefs": [
				{
					"pageNumber": 1767,
					"articleName": "Demystifying Cross-Language C/C++ Binaries: A Robust Software Component Analysis Approach",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b767/573300b767.pdf"
				},
				{
					"pageNumber": 1843,
					"articleName": "MCTS-Refined CoT: High-Quality Fine-Tuning Data for LLM-Based Repository Issue Resolution",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b843/573300b843.pdf"
				},
				{
					"pageNumber": 1893,
					"articleName": "Diplomatist: What Do Cross-Language Dependencies Reflect Software Ecosystem Health?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b893/573300b893.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Zixi",
				"surname": "Zhu"
			},
			"authorName": "Zhu, Zixi",
			"articleRefs": [
				{
					"pageNumber": 117,
					"articleName": "SateLight: A Satellite Application Update Framework for Satellite Computing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a117/573300a117.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Ziyuan",
				"surname": "Zhu"
			},
			"authorName": "Zhu, Ziyuan",
			"articleRefs": [
				{
					"pageNumber": 2944,
					"articleName": "EPSO: A Caching-Based Efficient Superoptimizer for BPF Bytecode",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c944/573300c944.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Huandong",
				"surname": "Zhuang"
			},
			"authorName": "Zhuang, Huandong",
			"articleRefs": [
				{
					"pageNumber": 3497,
					"articleName": "Adaptive Performance Regression Detection Using A Semi-Supervised Siamese Network",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d497/573300d497.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "He",
				"surname": "Zong"
			},
			"authorName": "Zong, He",
			"articleRefs": [
				{
					"pageNumber": 1476,
					"articleName": "Aligning LLMs to Fully Utilize the Cross-File Context in Repository-Level Code Completion",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b476/573300b476.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Saman",
				"surname": "Zonouz"
			},
			"authorName": "Zonouz, Saman",
			"articleRefs": [
				{
					"pageNumber": 1044,
					"articleName": "PROMFUZZ: Leveraging LLM-Driven and Bug-Oriented Composite Analysis for Detecting Functional Bugs in Smart Contracts",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b044/573300b044.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yanyan",
				"surname": "Zou"
			},
			"authorName": "Zou, Yanyan",
			"articleRefs": [
				{
					"pageNumber": 1069,
					"articleName": "A Large Scale Study of AI-Based Binary Function Similarity Detection Techniques for Security Researchers and Practitioners",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b069/573300b069.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yanzhen",
				"surname": "Zou"
			},
			"authorName": "Zou, Yanzhen",
			"articleRefs": [
				{
					"pageNumber": 355,
					"articleName": "Enhancing LLMs with Staged Grouping and Dehallucination for Header File Decomposition",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a355/573300a355.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Behjat",
				"surname": "Zuhaira"
			},
			"authorName": "Zuhaira, Behjat",
			"articleRefs": [
				{
					"pageNumber": 87,
					"articleName": "A Data-Driven Approach for Automated Quality Concern Extraction from App Reviews",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a087/850300a087.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Chun",
				"surname": "Zuo"
			},
			"authorName": "Zuo, Chun",
			"articleRefs": [
				{
					"pageNumber": 1666,
					"articleName": "Leveraging Mixture-of-Experts Framework for Smart Contract Vulnerability Repair with Large Language Model",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b666/573300b666.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Xinyue",
				"surname": "Zuo"
			},
			"authorName": "Zuo, Xinyue",
			"articleRefs": [
				{
					"pageNumber": 2121,
					"articleName": "PAT-Agent: Autoformalization for Model Checking",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c121/573300c121.pdf"
				}
			]
		},
		{
			"author": {
				"givenName": "Yimin",
				"surname": "Zuo"
			},
			"authorName": "Zuo, Yimin",
			"articleRefs": [
				{
					"pageNumber": 3497,
					"articleName": "Adaptive Performance Regression Detection Using A Semi-Supervised Siamese Network",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d497/573300d497.pdf"
				}
			]
		}
	],
	"affiliations": [
		{
			"affiliation": "Adelaide University, Australia",
			"articleRefs": [
				{
					"pageNumber": 2387,
					"articleName": "FailMapper: Automated Generation of Unit Tests Guided by Failure Scenarios",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c387/573300c387.pdf"
				},
				{
					"pageNumber": 2579,
					"articleName": "WINGMUZZ: Blackbox Testing of IoT Protocols via Two-Dimensional Fuzzing Schedule",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c579/573300c579.pdf"
				}
			]
		},
		{
			"affiliation": "Ain Shams University, Egypt",
			"articleRefs": [
				{
					"pageNumber": 153,
					"articleName": "Improving Automated Program Verification for Java Programs with Fuzzing",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a153/850300a153.pdf"
				}
			]
		},
		{
			"affiliation": "aiXcoder, China",
			"articleRefs": [
				{
					"pageNumber": 1476,
					"articleName": "Aligning LLMs to Fully Utilize the Cross-File Context in Repository-Level Code Completion",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b476/573300b476.pdf"
				}
			]
		},
		{
			"affiliation": "Al Ain University, UAE",
			"articleRefs": [
				{
					"pageNumber": 87,
					"articleName": "A Data-Driven Approach for Automated Quality Concern Extraction from App Reviews",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a087/850300a087.pdf"
				}
			]
		},
		{
			"affiliation": "Alibaba Co., Ltd, China",
			"articleRefs": [
				{
					"pageNumber": 3545,
					"articleName": "LLM-Assisted Industrial-Scale Differential Testing of Package Incompatibilities in Linux Distributions",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d545/573300d545.pdf"
				},
				{
					"pageNumber": 3615,
					"articleName": "RPG: Linux Kernel Fuzzing Guided by Distribution-Specific Runtime Parameter Interfaces",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d615/573300d615.pdf"
				}
			]
		},
		{
			"affiliation": "Alibaba Group",
			"articleRefs": [
				{
					"pageNumber": 217,
					"articleName": "R3-Bench: Reproducible Real-World Reverse Engineering Dataset for Symbol Recovery",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a217/573300a217.pdf"
				}
			]
		},
		{
			"affiliation": "Alibaba Group, China",
			"articleRefs": [
				{
					"pageNumber": 3783,
					"articleName": "Walk the Talk: Is Your Log-Based Software Reliability Maintenance System Really Reliable?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d783/573300d783.pdf"
				}
			]
		},
		{
			"affiliation": "Amazon Web Services",
			"articleRefs": [
				{
					"pageNumber": 1452,
					"articleName": "VERT: Polyglot Verified Equivalent Rust Transpilation with Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b452/573300b452.pdf"
				}
			]
		},
		{
			"affiliation": "AMD, India",
			"articleRefs": [
				{
					"pageNumber": 22,
					"articleName": "Microservices Identification Using LLM",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a022/850300a022.pdf"
				}
			]
		},
		{
			"affiliation": "Ant Group, China",
			"articleRefs": [
				{
					"pageNumber": 393,
					"articleName": "Democratizing the Cryptocurrency Ecosystem by Just-In-Time Transformation of Mining Programs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a393/573300a393.pdf"
				},
				{
					"pageNumber": 1830,
					"articleName": "PEACE: Towards Efficient Project-Level Efficiency Optimization via Hybrid Code Editing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b830/573300b830.pdf"
				},
				{
					"pageNumber": 3033,
					"articleName": "Issue Localization via LLM-Driven Iterative Code Graph Searching",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d033/573300d033.pdf"
				},
				{
					"pageNumber": 3683,
					"articleName": "Securing Millions of Decentralized Identities in Alipay Super App with End-to-End Formal Verification",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d683/573300d683.pdf"
				}
			]
		},
		{
			"affiliation": "ANYbotics AG, Switzerland",
			"articleRefs": [
				{
					"pageNumber": 3356,
					"articleName": "Bridging Research and Practice in Simulation-Based Testing of Industrial Robot Navigation Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d356/573300d356.pdf"
				}
			]
		},
		{
			"affiliation": "Arizona State University, USA",
			"articleRefs": [
				{
					"pageNumber": 880,
					"articleName": "APPBDS: LLM-Powered Description Synthesis for Sensitive Behaviors in Mobile Apps",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a880/573300a880.pdf"
				}
			]
		},
		{
			"affiliation": "ASML, Netherlands",
			"articleRefs": [
				{
					"pageNumber": 3474,
					"articleName": "Evaluating Large Language Models for Functional and Maintainable Code in Industrial Settings: A Case Study at ASML",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d474/573300d474.pdf"
				}
			]
		},
		{
			"affiliation": "Astemo, Ltd., Japan",
			"articleRefs": [
				{
					"pageNumber": 3771,
					"articleName": "Acceleration of Automotive Software Development by Retrieval Augmented Integration Test Script Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d771/573300d771.pdf"
				}
			]
		},
		{
			"affiliation": "Athens University of Economics and Business, Greece",
			"articleRefs": [
				{
					"pageNumber": 4069,
					"articleName": "PyTrim: A Practical Tool for Reducing Python Dependency Bloat",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e069/573300e069.pdf"
				}
			]
		},
		{
			"affiliation": "Atlassian, Australia",
			"articleRefs": [
				{
					"pageNumber": 3759,
					"articleName": "What Types of Code Review Comments Do Developers Most Frequently Resolve?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d759/573300d759.pdf"
				}
			]
		},
		{
			"affiliation": "Atlassian, Australia; Monash University, Australia",
			"articleRefs": [
				{
					"pageNumber": 3759,
					"articleName": "What Types of Code Review Comments Do Developers Most Frequently Resolve?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d759/573300d759.pdf"
				}
			]
		},
		{
			"affiliation": "Atlassian, USA",
			"articleRefs": [
				{
					"pageNumber": 3759,
					"articleName": "What Types of Code Review Comments Do Developers Most Frequently Resolve?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d759/573300d759.pdf"
				}
			]
		},
		{
			"affiliation": "Auburn University, USA",
			"articleRefs": [
				{
					"pageNumber": 2108,
					"articleName": "Using Fourier Analysis and Mutant Clustering to Accelerate DNN Mutation Testing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c108/573300c108.pdf"
				}
			]
		},
		{
			"affiliation": "Australian National University",
			"articleRefs": [
				{
					"pageNumber": 4004,
					"articleName": "Towards Context-Aware Mobile Privacy Notice: Implementation of A Deployable Contextual Privacy Policies Generator",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e004/573300e004.pdf"
				}
			]
		},
		{
			"affiliation": "Australian National University; CSIRO's Data61",
			"articleRefs": [
				{
					"pageNumber": 4004,
					"articleName": "Towards Context-Aware Mobile Privacy Notice: Implementation of A Deployable Contextual Privacy Policies Generator",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e004/573300e004.pdf"
				}
			]
		},
		{
			"affiliation": "Australian National University; CSIRO's Data61, Australia",
			"articleRefs": [
				{
					"pageNumber": 4004,
					"articleName": "Towards Context-Aware Mobile Privacy Notice: Implementation of A Deployable Contextual Privacy Policies Generator",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e004/573300e004.pdf"
				}
			]
		},
		{
			"affiliation": "Babe\u0219-Bolyai University, Romania",
			"articleRefs": [
				{
					"pageNumber": 129,
					"articleName": "Regression Testing Skill Transfer to Industry: A Preliminary Study in Higher Education",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a129/850300a129.pdf"
				}
			]
		},
		{
			"affiliation": "Bangladesh University of Business and Technology (BUBT), Bangladesh",
			"articleRefs": [
				{
					"pageNumber": 4109,
					"articleName": "CLARA: A Developer's Companion for Code Comprehension and Analysis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e109/573300e109.pdf"
				}
			]
		},
		{
			"affiliation": "Bauhaus University Weimar, Germany",
			"articleRefs": [
				{
					"pageNumber": 266,
					"articleName": "Evolution-Aware Heuristics for GR(1) Realizability Checking",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a266/573300a266.pdf"
				}
			]
		},
		{
			"affiliation": "Bauman Moscow State Technical University, Russia",
			"articleRefs": [
				{
					"pageNumber": 229,
					"articleName": "Automated Evolutionary Hyperparameter Tuning for NLP-Based Test Case Generation",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a229/850300a229.pdf"
				}
			]
		},
		{
			"affiliation": "Beihang University",
			"articleRefs": [
				{
					"pageNumber": 2439,
					"articleName": "Token Sugar: Making Source Code Sweeter for LLMs Through Token-Efficient Shorthand",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c439/573300c439.pdf"
				},
				{
					"pageNumber": 3191,
					"articleName": "KAIOps: A Platform Solution of End-to-End Multi-Modal AIOps for AI Training at Scale",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d191/573300d191.pdf"
				}
			]
		},
		{
			"affiliation": "Beihang University, China",
			"articleRefs": [
				{
					"pageNumber": 330,
					"articleName": "LogMoE: Lightweight Expert Mixture for Cross-System Log Anomaly Detection",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a330/573300a330.pdf"
				},
				{
					"pageNumber": 1094,
					"articleName": "ZendDiff: Differential Testing of PHP Interpreter",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b094/573300b094.pdf"
				},
				{
					"pageNumber": 1272,
					"articleName": "SMTgazer: Learning to Schedule SMT Algorithms via Bayesian Optimization",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b272/573300b272.pdf"
				},
				{
					"pageNumber": 1743,
					"articleName": "CROSS2OH: Enabling Seamless Porting of C/C++ Software Libraries to OpenHarmony",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b743/573300b743.pdf"
				},
				{
					"pageNumber": 1806,
					"articleName": "ARG: Testing Query Rewriters via Abstract Rule Guided Fuzzing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b806/573300b806.pdf"
				},
				{
					"pageNumber": 2007,
					"articleName": "Explainable Fault Localization for Programming Assignments via LLM-Guided Annotation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c007/573300c007.pdf"
				},
				{
					"pageNumber": 2298,
					"articleName": "FastCoder: Accelerating Repository-Level Code Generation via Efficient Retrieval and Verification",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c298/573300c298.pdf"
				},
				{
					"pageNumber": 2618,
					"articleName": "EfficientEdit: Accelerating Code Editing via Edit-Oriented Speculative Decoding",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c618/573300c618.pdf"
				},
				{
					"pageNumber": 3167,
					"articleName": "HarmoBridge: Bridging ArkTS and C/C++ for Cross-Language Static Analysis on HarmonyOS",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d167/573300d167.pdf"
				},
				{
					"pageNumber": 3261,
					"articleName": "Context-Sensitive Pointer Analysis for ArkTS",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d261/573300d261.pdf"
				},
				{
					"pageNumber": 3321,
					"articleName": "An Empirical Study on UI Overlap in OpenHarmony Applications",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d321/573300d321.pdf"
				},
				{
					"pageNumber": 3592,
					"articleName": "AutoPLC: Generating Vendor-Aware Structured Text for Programmable Logic Controllers",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d592/573300d592.pdf"
				},
				{
					"pageNumber": 3753,
					"articleName": "KAIR: A Statistical and Causal Approach to Pinpointing Stragglers in Distributed Model Training",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d753/573300d753.pdf"
				},
				{
					"pageNumber": 3813,
					"articleName": "LLM-Based Dynamic Differential Testing for Database Connectors with Reinforcement Learning-Guided Prompt Selection",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d813/573300d813.pdf"
				},
				{
					"pageNumber": 4085,
					"articleName": "Metamorphic Testing of Deep Reinforcement Learning Agents with MDPMORPH",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e085/573300e085.pdf"
				},
				{
					"pageNumber": 4127,
					"articleName": "Understanding Uncertainty In LLMs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e127/573300e127.pdf"
				}
			]
		},
		{
			"affiliation": "Beijing Institute of Control Engineering, China",
			"articleRefs": [
				{
					"pageNumber": 3521,
					"articleName": "Evaluating Large Language Models for Time Series Anomaly Detection in Aerospace Software",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d521/573300d521.pdf"
				}
			]
		},
		{
			"affiliation": "Beijing Institute of Technology, China",
			"articleRefs": [
				{
					"pageNumber": 178,
					"articleName": "Wired for Reuse: Automating Context-Aware Code Adaptation in IDEs via LLM-Based Agent",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a178/573300a178.pdf"
				},
				{
					"pageNumber": 2758,
					"articleName": "LLM-Based Identification of Null Pointer Exception Patches",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c758/573300c758.pdf"
				},
				{
					"pageNumber": 2982,
					"articleName": "LAURA: Enhancing Code Review Generation with Context-Enriched Retrieval-Augmented LLM",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c982/573300c982.pdf"
				}
			]
		},
		{
			"affiliation": "Beijing Institute of Technology, China; COMSATS University Islamabad, Pakistan",
			"articleRefs": [
				{
					"pageNumber": 2758,
					"articleName": "LLM-Based Identification of Null Pointer Exception Patches",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c758/573300c758.pdf"
				}
			]
		},
		{
			"affiliation": "Beijing Institute of Technology, China; Key Laboratory of Intelligent Networking Technology for Social Governance",
			"articleRefs": [
				{
					"pageNumber": 3008,
					"articleName": "Mockingbird: Efficient Excessive Data Exposures Detection via Dynamic Code Instrumentation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d008/573300d008.pdf"
				}
			]
		},
		{
			"affiliation": "Beijing Jiaotong University, China",
			"articleRefs": [
				{
					"pageNumber": 3580,
					"articleName": "Element-Aware Fine-Tuning of Vision-Language Models for Cost-Efficient GUI Testing in an Industrial Setting",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d580/573300d580.pdf"
				}
			]
		},
		{
			"affiliation": "Beijing University of Posts and Telecommunications, China",
			"articleRefs": [
				{
					"pageNumber": 117,
					"articleName": "SateLight: A Satellite Application Update Framework for Satellite Computing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a117/573300a117.pdf"
				},
				{
					"pageNumber": 1692,
					"articleName": "Demystifying Cookie Sharing Risks in WebView-Based Mobile App-in-app Ecosystems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b692/573300b692.pdf"
				},
				{
					"pageNumber": 3649,
					"articleName": "SCOPE: Evaluating and Enhancing Permission Explanation Transparency in Mobile Apps",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d649/573300d649.pdf"
				},
				{
					"pageNumber": 3660,
					"articleName": "The Gold Digger in the Dark Forest: Industrial-Scale MEV Analysis in Ethereum",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d660/573300d660.pdf"
				}
			]
		},
		{
			"affiliation": "Beijing VuLab Technology Co.Ltd, China",
			"articleRefs": [
				{
					"pageNumber": 3556,
					"articleName": "Shrunk, Yet Complete: Code Shrinking-Resilient Android Third-Party Library Detection",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d556/573300d556.pdf"
				}
			]
		},
		{
			"affiliation": "Belmont University, USA",
			"articleRefs": [
				{
					"pageNumber": 1439,
					"articleName": "Hierarchical Knowledge Injection for Improving LLM-Based Program Repair",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b439/573300b439.pdf"
				}
			]
		},
		{
			"affiliation": "Bilkent University, Turkey",
			"articleRefs": [
				{
					"pageNumber": 1008,
					"articleName": "Automated Inline Comment Smell Detection and Repair with Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b008/573300b008.pdf"
				},
				{
					"pageNumber": 3094,
					"articleName": "Agents in the Sandbox: End-to-End Crash Bug Reproduction for Minecraft",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d094/573300d094.pdf"
				},
				{
					"pageNumber": 3957,
					"articleName": "Are We SOLID Yet? An Empirical Study on Prompting LLMs to Detect Design Principle Violations",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d957/573300d957.pdf"
				}
			]
		},
		{
			"affiliation": "Bilkent University, Udemy, Inc, Turkey",
			"articleRefs": [
				{
					"pageNumber": 1008,
					"articleName": "Automated Inline Comment Smell Detection and Repair with Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b008/573300b008.pdf"
				}
			]
		},
		{
			"affiliation": "Birkbeck, University of London, UK",
			"articleRefs": [
				{
					"pageNumber": 154,
					"articleName": "CODE-DITING: Automatic Evaluation of Code Generation Without References or Test Cases",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a154/573300a154.pdf"
				}
			]
		},
		{
			"affiliation": "BizSeer",
			"articleRefs": [
				{
					"pageNumber": 3238,
					"articleName": "TrioXpert: An Automated Incident Management Framework for Microservice System",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d238/573300d238.pdf"
				}
			]
		},
		{
			"affiliation": "Blekinge Institute of Technology and fortiss, Sweden; fortiss GmbH, Germany",
			"articleRefs": [
				{
					"pageNumber": 51,
					"articleName": "A 3-Layer Agentic Model for Nonfunctional Requirements in Software Engineering",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a051/850300a051.pdf"
				}
			]
		},
		{
			"affiliation": "Blekinge Institute of Technology and Gaetir, Sweden",
			"articleRefs": [
				{
					"pageNumber": 51,
					"articleName": "A 3-Layer Agentic Model for Nonfunctional Requirements in Software Engineering",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a051/850300a051.pdf"
				}
			]
		},
		{
			"affiliation": "Bloomberg, United States",
			"articleRefs": [
				{
					"pageNumber": 1298,
					"articleName": "AMPLE: Fine-Grained File Access Policies for Server Applications",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b298/573300b298.pdf"
				}
			]
		},
		{
			"affiliation": "Boston University, U.S.A.",
			"articleRefs": [
				{
					"pageNumber": 3844,
					"articleName": "Detecting and Repairing Incomplete Software Requirements with Multi-LLM Ensembles",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d844/573300d844.pdf"
				}
			]
		},
		{
			"affiliation": "Budapest University of Technology and Economics, Hungary",
			"articleRefs": [
				{
					"pageNumber": 1968,
					"articleName": "Non-Termination Witnesses and Their Validation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b968/573300b968.pdf"
				}
			]
		},
		{
			"affiliation": "ByteDance",
			"articleRefs": [
				{
					"pageNumber": 3298,
					"articleName": "LogPilot: Intent-Aware and Scalable Alert Diagnosis for Large-Scale Online Service Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d298/573300d298.pdf"
				},
				{
					"pageNumber": 3425,
					"articleName": "Automated Proactive Logging Quality Improvement for Large-Scale Codebases ",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d425/573300d425.pdf"
				},
				{
					"pageNumber": 3533,
					"articleName": "ErrorPrism: Reconstructing Error Propagation Paths in Cloud Service Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d533/573300d533.pdf"
				},
				{
					"pageNumber": 3671,
					"articleName": "RepoMasterEval: Evaluating Code Completion via Real-World Repositories",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d671/573300d671.pdf"
				}
			]
		},
		{
			"affiliation": "ByteDance, China",
			"articleRefs": [
				{
					"pageNumber": 623,
					"articleName": "Enhancing LLM's Ability to Generate More Repository-Aware Unit Tests Through Precise Context Injection",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a623/573300a623.pdf"
				},
				{
					"pageNumber": 700,
					"articleName": "LogAction: Consistent Cross-System Anomaly Detection Through Logs via Active Domain Adaptation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a700/573300a700.pdf"
				},
				{
					"pageNumber": 1118,
					"articleName": "CoorLog: Efficient-Generalizable Log Anomaly Detection via Adaptive Coordinator in Software Evolution",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b118/573300b118.pdf"
				},
				{
					"pageNumber": 2426,
					"articleName": "An Agent-Based Evaluation Framework for Complex Code Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c426/573300c426.pdf"
				},
				{
					"pageNumber": 3485,
					"articleName": "BitsAI-Fix: LLM-Driven Approach for Automated Lint Error Resolution in Practice",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d485/573300d485.pdf"
				},
				{
					"pageNumber": 3671,
					"articleName": "RepoMasterEval: Evaluating Code Completion via Real-World Repositories",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d671/573300d671.pdf"
				},
				{
					"pageNumber": 3741,
					"articleName": "LogSage: An LLM-Based Framework for CI/CD Failure Detection and Remediation with Industrial Validation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d741/573300d741.pdf"
				}
			]
		},
		{
			"affiliation": "ByteDance Inc., China",
			"articleRefs": [
				{
					"pageNumber": 2221,
					"articleName": "LLM-Powered Multi-Agent Collaboration for Intelligent Industrial On-Call Automation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c221/573300c221.pdf"
				}
			]
		},
		{
			"affiliation": "ByteDance Ltd.",
			"articleRefs": [
				{
					"pageNumber": 3120,
					"articleName": "How Can Infrastructure as Code Accelerate Data Center Bring-ups? A Case Study at ByteDance",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d120/573300d120.pdf"
				}
			]
		},
		{
			"affiliation": "Bytedance Network Technology, China",
			"articleRefs": [
				{
					"pageNumber": 1376,
					"articleName": "Learning Project-Wise Subsequent Code Edits via Interleaving Neural-Based Induction and Tool-Based Deduction",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b376/573300b376.pdf"
				}
			]
		},
		{
			"affiliation": "Capital Normal University, China",
			"articleRefs": [
				{
					"pageNumber": 3144,
					"articleName": "Practical Escape of Exploration Tarpits for Mini-Game Testing in an Industrial Setting",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d144/573300d144.pdf"
				}
			]
		},
		{
			"affiliation": "Carnegie Mellon Software Engineering Institute, USA",
			"articleRefs": [
				{
					"pageNumber": 3947,
					"articleName": "Vessel: A Taxonomy of Reproducibility Issues for Container Images",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d947/573300d947.pdf"
				}
			]
		},
		{
			"affiliation": "Carnegie Mellon University",
			"articleRefs": [
				{
					"pageNumber": 2020,
					"articleName": "Interpretable Vulnerability Detection Reports",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c020/573300c020.pdf"
				}
			]
		},
		{
			"affiliation": "Carnegie Mellon University; Faculty of Engineering of University of Porto, Portugal",
			"articleRefs": [
				{
					"pageNumber": 2020,
					"articleName": "Interpretable Vulnerability Detection Reports",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c020/573300c020.pdf"
				}
			]
		},
		{
			"affiliation": "Carnegie Mellon University, United States",
			"articleRefs": [
				{
					"pageNumber": 3485,
					"articleName": "BitsAI-Fix: LLM-Driven Approach for Automated Lint Error Resolution in Practice",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d485/573300d485.pdf"
				}
			]
		},
		{
			"affiliation": "Carnegie Mellon University, USA",
			"articleRefs": [
				{
					"pageNumber": 816,
					"articleName": "Execution-Aware Program Reduction for WebAssembly via Record and Replay",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a816/573300a816.pdf"
				},
				{
					"pageNumber": 3911,
					"articleName": "Human-In-The-Loop Oracle Learning for Simulation-Based Testing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d911/573300d911.pdf"
				}
			]
		},
		{
			"affiliation": "CBG Software Engineering Department, Huawei",
			"articleRefs": [
				{
					"pageNumber": 3261,
					"articleName": "Context-Sensitive Pointer Analysis for ArkTS",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d261/573300d261.pdf"
				}
			]
		},
		{
			"affiliation": "Center for Software Excellence, Huawei Canada",
			"articleRefs": [
				{
					"pageNumber": 2324,
					"articleName": "SPICE\uD83C\uDF36\uFE0F: An Automated SWE-Bench Labeling Pipeline for Issue Clarity, Test Coverage, and Effort Estimation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c324/573300c324.pdf"
				}
			]
		},
		{
			"affiliation": "Central South University, China",
			"articleRefs": [
				{
					"pageNumber": 1272,
					"articleName": "SMTgazer: Learning to Schedule SMT Algorithms via Bayesian Optimization",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b272/573300b272.pdf"
				},
				{
					"pageNumber": 3156,
					"articleName": "Industry Practice of LLM-Assisted Protocol Fuzzing for Commercial Communication Modules",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d156/573300d156.pdf"
				},
				{
					"pageNumber": 3226,
					"articleName": "TRON: Fuzzing Linux Network Stack via Protocol-System Call Payload Synthesis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d226/573300d226.pdf"
				},
				{
					"pageNumber": 3545,
					"articleName": "LLM-Assisted Industrial-Scale Differential Testing of Package Incompatibilities in Linux Distributions",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d545/573300d545.pdf"
				},
				{
					"pageNumber": 3615,
					"articleName": "RPG: Linux Kernel Fuzzing Guided by Distribution-Specific Runtime Parameter Interfaces",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d615/573300d615.pdf"
				}
			]
		},
		{
			"affiliation": "Central South University, China; China Mobile IoT Co., Ltd, China",
			"articleRefs": [
				{
					"pageNumber": 3156,
					"articleName": "Industry Practice of LLM-Assisted Protocol Fuzzing for Commercial Communication Modules",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d156/573300d156.pdf"
				}
			]
		},
		{
			"affiliation": "Central University of Finance and Economics, China",
			"articleRefs": [
				{
					"pageNumber": 2387,
					"articleName": "FailMapper: Automated Generation of Unit Tests Guided by Failure Scenarios",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c387/573300c387.pdf"
				},
				{
					"pageNumber": 2579,
					"articleName": "WINGMUZZ: Blackbox Testing of IoT Protocols via Two-Dimensional Fuzzing Schedule",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c579/573300c579.pdf"
				}
			]
		},
		{
			"affiliation": "Central University, Russia",
			"articleRefs": [
				{
					"pageNumber": 292,
					"articleName": "GRACG: Graph Retrieval Augmented Code Generation",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a292/850300a292.pdf"
				}
			]
		},
		{
			"affiliation": "Centre for Software Excellence, Canada",
			"articleRefs": [
				{
					"pageNumber": 3286,
					"articleName": "Context-Aware CodeLLM Eviction for AI-Assisted Coding",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d286/573300d286.pdf"
				}
			]
		},
		{
			"affiliation": "Centre for Software Excellence, Huawei Canada",
			"articleRefs": [
				{
					"pageNumber": 739,
					"articleName": "Watson: A Cognitive Observability Framework for the Reasoning of LLM-Powered Agents",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a739/573300a739.pdf"
				}
			]
		},
		{
			"affiliation": "Centre for Software Excellence, Huawei Canada; McGill University, Canada",
			"articleRefs": [
				{
					"pageNumber": 739,
					"articleName": "Watson: A Cognitive Observability Framework for the Reasoning of LLM-Powered Agents",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a739/573300a739.pdf"
				}
			]
		},
		{
			"affiliation": "Chalmers University of Technology; University of Gothenburg, Sweden",
			"articleRefs": [
				{
					"pageNumber": 245,
					"articleName": "AI for Requirements Engineering: Industry Adoption and Practitioner Perspectives",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a245/850300a245.pdf"
				}
			]
		},
		{
			"affiliation": "Chang'an University, China",
			"articleRefs": [
				{
					"pageNumber": 4140,
					"articleName": "Testing Autonomous Driving Systems Through Blind-Spot Guided Fuzzing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e140/573300e140.pdf"
				}
			]
		},
		{
			"affiliation": "Changsha University of Science and Technology, China",
			"articleRefs": [
				{
					"pageNumber": 1194,
					"articleName": "AdaptEval: A Benchmark for Evaluating Large Language Models on Code Snippet Adaptation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b194/573300b194.pdf"
				}
			]
		},
		{
			"affiliation": "Chapman University, United States",
			"articleRefs": [
				{
					"pageNumber": 194,
					"articleName": "Explaining Software Vulnerabilities with Large Language Models",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a194/850300a194.pdf"
				}
			]
		},
		{
			"affiliation": "Charles University, Czech republic",
			"articleRefs": [
				{
					"pageNumber": 4036,
					"articleName": "ORMorpher: An Interactive Framework for ORM Translation and Optimization",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e036/573300e036.pdf"
				}
			]
		},
		{
			"affiliation": "Chiba Institute of Technology, Japan",
			"articleRefs": [
				{
					"pageNumber": 2337,
					"articleName": "On the Correctness of Software Merge",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c337/573300c337.pdf"
				}
			]
		},
		{
			"affiliation": "China Academy of Space Technology, China",
			"articleRefs": [
				{
					"pageNumber": 1207,
					"articleName": "Bridging Natural Language and Formal Specification Automated Translation of Software Requirements to LTL via Hierarchical Semantics Decomposition Using LLMs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b207/573300b207.pdf"
				}
			]
		},
		{
			"affiliation": "China Mobile IoT Co., Ltd, China",
			"articleRefs": [
				{
					"pageNumber": 3156,
					"articleName": "Industry Practice of LLM-Assisted Protocol Fuzzing for Commercial Communication Modules",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d156/573300d156.pdf"
				}
			]
		},
		{
			"affiliation": "China University of Petroleum, (Beijing)",
			"articleRefs": [
				{
					"pageNumber": 317,
					"articleName": "PrefGen: A Preference-Driven Methodology for Secure Yet Gas-Efficient Smart Contract Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a317/573300a317.pdf"
				}
			]
		},
		{
			"affiliation": "Chinese Academy of Science, China; University of Chinese Academy of Sciences, China",
			"articleRefs": [
				{
					"pageNumber": 1666,
					"articleName": "Leveraging Mixture-of-Experts Framework for Smart Contract Vulnerability Repair with Large Language Model",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b666/573300b666.pdf"
				}
			]
		},
		{
			"affiliation": "Chinese Academy of Sciences",
			"articleRefs": [
				{
					"pageNumber": 3238,
					"articleName": "TrioXpert: An Automated Incident Management Framework for Microservice System",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d238/573300d238.pdf"
				}
			]
		},
		{
			"affiliation": "Chinese Academy of Sciences, Beijing, China; University of Chinese Academy of Sciences, China",
			"articleRefs": [
				{
					"pageNumber": 1602,
					"articleName": "Beyond Static GUI Agent: Evolving LLM-Based GUI Testing via Dynamic Memory",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b602/573300b602.pdf"
				}
			]
		},
		{
			"affiliation": "Chinese Academy of Sciences, Beijing, China; University of Chinese Academy of Sciences, China; State Key Laboratory of Complex System Modeling and Simulation Technology ISCAS, China",
			"articleRefs": [
				{
					"pageNumber": 1602,
					"articleName": "Beyond Static GUI Agent: Evolving LLM-Based GUI Testing via Dynamic Memory",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b602/573300b602.pdf"
				}
			]
		},
		{
			"affiliation": "Chinese Academy of Sciences, China",
			"articleRefs": [
				{
					"pageNumber": 648,
					"articleName": "BinStruct: Binary Structure Recovery Combining Static Analysis and Semantics",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a648/573300a648.pdf"
				},
				{
					"pageNumber": 1272,
					"articleName": "SMTgazer: Learning to Schedule SMT Algorithms via Bayesian Optimization",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b272/573300b272.pdf"
				},
				{
					"pageNumber": 1666,
					"articleName": "Leveraging Mixture-of-Experts Framework for Smart Contract Vulnerability Repair with Large Language Model",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b666/573300b666.pdf"
				},
				{
					"pageNumber": 2375,
					"articleName": "Interleaved Learning and Exploration: A Self-Adaptive Fuzz Testing Framework for MLIR",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c375/573300c375.pdf"
				},
				{
					"pageNumber": 2982,
					"articleName": "LAURA: Enhancing Code Review Generation with Context-Enriched Retrieval-Augmented LLM",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c982/573300c982.pdf"
				},
				{
					"pageNumber": 3556,
					"articleName": "Shrunk, Yet Complete: Code Shrinking-Resilient Android Third-Party Library Detection",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d556/573300d556.pdf"
				}
			]
		},
		{
			"affiliation": "Chinese Academy of Sciences, China; UCAS, China",
			"articleRefs": [
				{
					"pageNumber": 2969,
					"articleName": "Vulnerability-Affected Versions Identification: How Far Are We?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c969/573300c969.pdf"
				}
			]
		},
		{
			"affiliation": "Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China",
			"articleRefs": [
				{
					"pageNumber": 919,
					"articleName": "Lares: LLM-Driven Code Slice Semantic Search for Patch Presence Testing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a919/573300a919.pdf"
				},
				{
					"pageNumber": 3556,
					"articleName": "Shrunk, Yet Complete: Code Shrinking-Resilient Android Third-Party Library Detection",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d556/573300d556.pdf"
				}
			]
		},
		{
			"affiliation": "Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China;",
			"articleRefs": [
				{
					"pageNumber": 1069,
					"articleName": "A Large Scale Study of AI-Based Binary Function Similarity Detection Techniques for Security Researchers and Practitioners",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b069/573300b069.pdf"
				}
			]
		},
		{
			"affiliation": "Chongqing University, China",
			"articleRefs": [
				{
					"pageNumber": 141,
					"articleName": "LongCodeZip: Compress Long Context for Code Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a141/573300a141.pdf"
				},
				{
					"pageNumber": 330,
					"articleName": "LogMoE: Lightweight Expert Mixture for Cross-System Log Anomaly Detection",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a330/573300a330.pdf"
				},
				{
					"pageNumber": 406,
					"articleName": "From Sparse to Structured: A Diffusion-Enhanced and Feature-Aligned Framework for Coincidental Correctness Detection",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a406/573300a406.pdf"
				},
				{
					"pageNumber": 1502,
					"articleName": "Sifting Truth from Coincidences: A Two-Stage Positive and Unlabeled Learning Model for Coincidental Correctness Detection",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b502/573300b502.pdf"
				},
				{
					"pageNumber": 3033,
					"articleName": "Issue Localization via LLM-Driven Iterative Code Graph Searching",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d033/573300d033.pdf"
				},
				{
					"pageNumber": 4008,
					"articleName": "AgentDroid: A Multi-Agent Tool for Detecting Fraudulent Android Applications",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e008/573300e008.pdf"
				}
			]
		},
		{
			"affiliation": "Chongqing University of Posts and Telecommunications, China",
			"articleRefs": [
				{
					"pageNumber": 3875,
					"articleName": "Envisioning Intelligent Requirements Engineering via Knowledge-Guided Multi-Agent Collaboration",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d875/573300d875.pdf"
				}
			]
		},
		{
			"affiliation": "Chungnam National University, South Korea",
			"articleRefs": [
				{
					"pageNumber": 3865,
					"articleName": "Unseen Data Detection using Routing Entropy in Mixture-of-Experts for Autonomous Vehicles",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d865/573300d865.pdf"
				}
			]
		},
		{
			"affiliation": "Chuzhou University, China",
			"articleRefs": [
				{
					"pageNumber": 129,
					"articleName": "Diagnosing Performance Differences in Model Checkers via Runtime-Guided Problem Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a129/573300a129.pdf"
				}
			]
		},
		{
			"affiliation": "CIn-UFPE, Brazil",
			"articleRefs": [
				{
					"pageNumber": 3916,
					"articleName": "Tether: A Personalized Support Assistant for Software Engineers with ADHD",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d916/573300d916.pdf"
				}
			]
		},
		{
			"affiliation": "CISPA Helmholtz Center for Information Security, China",
			"articleRefs": [
				{
					"pageNumber": 4048,
					"articleName": "BASHIRI: Learning Failure Oracles from Execution Features",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e048/573300e048.pdf"
				}
			]
		},
		{
			"affiliation": "CISPA Helmholtz Center for Information Security, Germany",
			"articleRefs": [
				{
					"pageNumber": 2490,
					"articleName": "The Fault in our Stats",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c490/573300c490.pdf"
				},
				{
					"pageNumber": 2845,
					"articleName": "Understanding Software Engineering Agents: A Study of Thought-Action-Result Trajectories",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c845/573300c845.pdf"
				},
				{
					"pageNumber": 4048,
					"articleName": "BASHIRI: Learning Failure Oracles from Execution Features",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e048/573300e048.pdf"
				}
			]
		},
		{
			"affiliation": "CISPA Helmholtz Center for Information Security, Germnay",
			"articleRefs": [
				{
					"pageNumber": 816,
					"articleName": "Execution-Aware Program Reduction for WebAssembly via Record and Replay",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a816/573300a816.pdf"
				}
			]
		},
		{
			"affiliation": "City University of Hong Kong, China",
			"articleRefs": [
				{
					"pageNumber": 26,
					"articleName": "Vul-R2: A Reasoning LLM for Automated Vulnerability Repair",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a026/573300a026.pdf"
				},
				{
					"pageNumber": 1780,
					"articleName": "Detecting Various DeFi Price Manipulations with LLM Reasoning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b780/573300b780.pdf"
				},
				{
					"pageNumber": 1855,
					"articleName": "Can Mamba Be Better? An Experimental Evaluation of Mamba in Code Intelligence",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b855/573300b855.pdf"
				},
				{
					"pageNumber": 2905,
					"articleName": "Metamorphic Testing for Audio Content Moderation Software",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c905/573300c905.pdf"
				},
				{
					"pageNumber": 3020,
					"articleName": "RealisticCodeBench: Towards More Realistic Evaluation of Large Language Models for Code Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d020/573300d020.pdf"
				}
			]
		},
		{
			"affiliation": "City University of New York (CUNY) Hunter College; CUNY Graduate Center",
			"articleRefs": [
				{
					"pageNumber": 752,
					"articleName": "Speculative Automated Refactoring of Imperative Deep Learning Programs to Graph Execution",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a752/573300a752.pdf"
				}
			]
		},
		{
			"affiliation": "Clausthal University of Technology, Germany",
			"articleRefs": [
				{
					"pageNumber": 165,
					"articleName": "VeriODD: From YAML to SMT-LIB \u2013 Automating Verification of Operational Design Domains",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a165/850300a165.pdf"
				},
				{
					"pageNumber": 4052,
					"articleName": "GUI-ReRank: Enhancing GUI Retrieval with Multi-Modal LLM-Based Reranking",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e052/573300e052.pdf"
				}
			]
		},
		{
			"affiliation": "COEP Tech, India",
			"articleRefs": [
				{
					"pageNumber": 22,
					"articleName": "Microservices Identification Using LLM",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a022/850300a022.pdf"
				}
			]
		},
		{
			"affiliation": "Cohere, Canada",
			"articleRefs": [
				{
					"pageNumber": 39,
					"articleName": "MIMIC: Integrating Diverse Personality Traits for Better Game Testing Using Large Language Model",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a039/573300a039.pdf"
				}
			]
		},
		{
			"affiliation": "Concordia University, Canada",
			"articleRefs": [
				{
					"pageNumber": 330,
					"articleName": "LogMoE: Lightweight Expert Mixture for Cross-System Log Anomaly Detection",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a330/573300a330.pdf"
				},
				{
					"pageNumber": 372,
					"articleName": "Beyond More Context: How Granularity and Order Drive Code Completion Quality",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a372/850300a372.pdf"
				},
				{
					"pageNumber": 983,
					"articleName": "Coverage-Based Harmfulness Testing for LLM Code Transformation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a983/573300a983.pdf"
				},
				{
					"pageNumber": 1704,
					"articleName": "ADPerf: Investigating and Testing Performance in Autonomous Driving Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b704/573300b704.pdf"
				},
				{
					"pageNumber": 2592,
					"articleName": "On the Robustness Evaluation of 3D Obstacle Detection Against Specifications in Autonomous Driving",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c592/573300c592.pdf"
				},
				{
					"pageNumber": 3718,
					"articleName": "MobileUPReg: Identifying User-Perceived Performance Regressions in Mobile OS Versions",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d718/573300d718.pdf"
				}
			]
		},
		{
			"affiliation": "Constructor University Bremen",
			"articleRefs": [
				{
					"pageNumber": 369,
					"articleName": "On the Importance of Context Filtering in Retrieval-Augmented Code Completion",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a369/850300a369.pdf"
				}
			]
		},
		{
			"affiliation": "Cornell University, USA",
			"articleRefs": [
				{
					"pageNumber": 2285,
					"articleName": "Faster Runtime Verification During Testing via Feedback-Guided Selective Monitoring",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c285/573300c285.pdf"
				}
			]
		},
		{
			"affiliation": "CQSE GmbH, Germany",
			"articleRefs": [
				{
					"pageNumber": 3215,
					"articleName": "Should We Evaluate LLM Based Security Analysis Approaches on Open Source Systems?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d215/573300d215.pdf"
				}
			]
		},
		{
			"affiliation": "CSIRO\u2019s Data61, Australia",
			"articleRefs": [
				{
					"pageNumber": 687,
					"articleName": "Navigating the Labyrinth: Path-Sensitive Unit Test Generation with Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a687/573300a687.pdf"
				}
			]
		},
		{
			"affiliation": "CUNY Graduate Center",
			"articleRefs": [
				{
					"pageNumber": 752,
					"articleName": "Speculative Automated Refactoring of Imperative Deep Learning Programs to Graph Execution",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a752/573300a752.pdf"
				}
			]
		},
		{
			"affiliation": "Dalian University of Technology, China",
			"articleRefs": [
				{
					"pageNumber": 1272,
					"articleName": "SMTgazer: Learning to Schedule SMT Algorithms via Bayesian Optimization",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b272/573300b272.pdf"
				}
			]
		},
		{
			"affiliation": "Delft University of Technology; JetBrains Research, The Netherlands",
			"articleRefs": [
				{
					"pageNumber": 3345,
					"articleName": "Prompt-With-Me: in-IDE Structured Prompt Management for LLM-Driven Software Engineering",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d345/573300d345.pdf"
				}
			]
		},
		{
			"affiliation": "Delft University of Technology, The Netherlands",
			"articleRefs": [
				{
					"pageNumber": 66,
					"articleName": "The Last Dependency Crusade: Solving Python Dependency Conflicts with LLMs",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a066/850300a066.pdf"
				},
				{
					"pageNumber": 3345,
					"articleName": "Prompt-With-Me: in-IDE Structured Prompt Management for LLM-Driven Software Engineering",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d345/573300d345.pdf"
				},
				{
					"pageNumber": 3474,
					"articleName": "Evaluating Large Language Models for Functional and Maintainable Code in Industrial Settings: A Case Study at ASML",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d474/573300d474.pdf"
				},
				{
					"pageNumber": 3509,
					"articleName": "TreeRanker: Fast and Model-Agnostic Ranking System for Code Suggestions in IDEs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d509/573300d509.pdf"
				},
				{
					"pageNumber": 3828,
					"articleName": "The Future of Software Transparency: Bridging Understanding, Measurement, and Practice",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d828/573300d828.pdf"
				}
			]
		},
		{
			"affiliation": "DGIST",
			"articleRefs": [
				{
					"pageNumber": 1590,
					"articleName": "IMUFUZZER: Resilience-Based Discovery of Signal Injection Attacks on Robotic Aerial Vehicles",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b590/573300b590.pdf"
				}
			]
		},
		{
			"affiliation": "DGIST, Korea",
			"articleRefs": [
				{
					"pageNumber": 3203,
					"articleName": "iCodeReviewer: Improving Secure Code Review with Mixture of Prompts",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d203/573300d203.pdf"
				},
				{
					"pageNumber": 3962,
					"articleName": "RAML: Toward Retrieval-Augmented Localization of Malicious Payloads in Android Apps",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d962/573300d962.pdf"
				}
			]
		},
		{
			"affiliation": "DGIST, Republic of Korea",
			"articleRefs": [
				{
					"pageNumber": 2605,
					"articleName": "SE-Jury: An LLM-as-Ensemble-Judge Metric for Narrowing the Gap with Human Evaluation in SE",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c605/573300c605.pdf"
				}
			]
		},
		{
			"affiliation": "Digital Emissions, USA",
			"articleRefs": [
				{
					"pageNumber": 253,
					"articleName": "Fair Developer Score: Build-Adjusted Measurement of Effort and Impact",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a253/850300a253.pdf"
				}
			]
		},
		{
			"affiliation": "Drexel University, USA",
			"articleRefs": [
				{
					"pageNumber": 1439,
					"articleName": "Hierarchical Knowledge Injection for Improving LLM-Based Program Repair",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b439/573300b439.pdf"
				},
				{
					"pageNumber": 3849,
					"articleName": "Linguistic Theories Coincide with Misformalization in Temporal Logic",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d849/573300d849.pdf"
				}
			]
		},
		{
			"affiliation": "DZ Bank, Germany",
			"articleRefs": [
				{
					"pageNumber": 1615,
					"articleName": "Terminator: Enabling Efficient Fuzzing of Closed-Source GUI Programs by Automatic Coverage-Guided Termination",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b615/573300b615.pdf"
				}
			]
		},
		{
			"affiliation": "East China Normal University, China",
			"articleRefs": [
				{
					"pageNumber": 129,
					"articleName": "Diagnosing Performance Differences in Model Checkers via Runtime-Guided Problem Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a129/573300a129.pdf"
				},
				{
					"pageNumber": 636,
					"articleName": "Finding Bugs in MLIR Compiler Infrastructure via Lowering Space Exploration",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a636/573300a636.pdf"
				},
				{
					"pageNumber": 945,
					"articleName": "Demystifying OpenZeppelin's Own Vulnerabilities and Analyzing Their Propagation in Smart Contracts",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a945/573300a945.pdf"
				},
				{
					"pageNumber": 2375,
					"articleName": "Interleaved Learning and Exploration: A Self-Adaptive Fuzz Testing Framework for MLIR",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c375/573300c375.pdf"
				},
				{
					"pageNumber": 3741,
					"articleName": "LogSage: An LLM-Based Framework for CI/CD Failure Detection and Remediation with Industrial Validation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d741/573300d741.pdf"
				},
				{
					"pageNumber": 3813,
					"articleName": "LLM-Based Dynamic Differential Testing for Database Connectors with Reinforcement Learning-Guided Prompt Selection",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d813/573300d813.pdf"
				}
			]
		},
		{
			"affiliation": "East China Normal University, China; ByteDance, China",
			"articleRefs": [
				{
					"pageNumber": 3741,
					"articleName": "LogSage: An LLM-Based Framework for CI/CD Failure Detection and Remediation with Industrial Validation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d741/573300d741.pdf"
				}
			]
		},
		{
			"affiliation": "East China Normal University, China; Tsinghua University, China",
			"articleRefs": [
				{
					"pageNumber": 3545,
					"articleName": "LLM-Assisted Industrial-Scale Differential Testing of Package Incompatibilities in Linux Distributions",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d545/573300d545.pdf"
				}
			]
		},
		{
			"affiliation": "Electronics and Telecommunications Research Institute, Republic of Korea",
			"articleRefs": [
				{
					"pageNumber": 2956,
					"articleName": "When Does Wasm Malware Detection Fail? A Systematic Analysis of Their Robustness to Evasion",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c956/573300c956.pdf"
				}
			]
		},
		{
			"affiliation": "Ericsson AB, Canada",
			"articleRefs": [
				{
					"pageNumber": 3461,
					"articleName": "From Technical Excellence to Practical Adoption: Lessons Learned Building an ML-Enhanced Trace Analysis Tool",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d461/573300d461.pdf"
				}
			]
		},
		{
			"affiliation": "ETH Zurich, Switzerland",
			"articleRefs": [
				{
					"pageNumber": 469,
					"articleName": "Comprehend, Imitate, and then Update: Unleashing the Power of LLMs in Test Suite Evolution",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a469/573300a469.pdf"
				},
				{
					"pageNumber": 1324,
					"articleName": "Efficient and Verifiable Proof Logging for MaxSAT Solving",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b324/573300b324.pdf"
				}
			]
		},
		{
			"affiliation": "Eureka Robotics, Vietnam",
			"articleRefs": [
				{
					"pageNumber": 1552,
					"articleName": "It's Not Easy Being Green: On the Energy Efficiency of Programming Languages",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b552/573300b552.pdf"
				}
			]
		},
		{
			"affiliation": "Faculty of Engineering of University of Porto, Portugal; INESC-ID, Portugal",
			"articleRefs": [
				{
					"pageNumber": 2020,
					"articleName": "Interpretable Vulnerability Detection Reports",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c020/573300c020.pdf"
				}
			]
		},
		{
			"affiliation": "Faculty of Engineering of University of Porto, Portugal; Universidade de Lisboa, Portugal",
			"articleRefs": [
				{
					"pageNumber": 2020,
					"articleName": "Interpretable Vulnerability Detection Reports",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c020/573300c020.pdf"
				}
			]
		},
		{
			"affiliation": "Florida State University, USA",
			"articleRefs": [
				{
					"pageNumber": 1439,
					"articleName": "Hierarchical Knowledge Injection for Improving LLM-Based Program Repair",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b439/573300b439.pdf"
				}
			]
		},
		{
			"affiliation": "Fraunhofer IEE, Germany",
			"articleRefs": [
				{
					"pageNumber": 277,
					"articleName": "LLMs Choose the Right Stack: From Patterns to Tools",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a277/850300a277.pdf"
				}
			]
		},
		{
			"affiliation": "Fraunhofer IEE, Germany; Fraunhofer IEE, Germany",
			"articleRefs": [
				{
					"pageNumber": 277,
					"articleName": "LLMs Choose the Right Stack: From Patterns to Tools",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a277/850300a277.pdf"
				}
			]
		},
		{
			"affiliation": "Fraunhofer IEM, Germany",
			"articleRefs": [
				{
					"pageNumber": 194,
					"articleName": "Explaining Software Vulnerabilities with Large Language Models",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a194/850300a194.pdf"
				}
			]
		},
		{
			"affiliation": "Fraunhofer SIT \u2014 ATHENE, Germany",
			"articleRefs": [
				{
					"pageNumber": 3976,
					"articleName": "VUSC: An Extensible Research Platform for Java-Based Static Analysis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d976/573300d976.pdf"
				}
			]
		},
		{
			"affiliation": "Fraunhofer SIT, Germany",
			"articleRefs": [
				{
					"pageNumber": 1615,
					"articleName": "Terminator: Enabling Efficient Fuzzing of Closed-Source GUI Programs by Automatic Coverage-Guided Termination",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b615/573300b615.pdf"
				}
			]
		},
		{
			"affiliation": "Freshippo, Alibaba Group, China",
			"articleRefs": [
				{
					"pageNumber": 3649,
					"articleName": "SCOPE: Evaluating and Enhancing Permission Explanation Transparency in Mobile Apps",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d649/573300d649.pdf"
				}
			]
		},
		{
			"affiliation": "Fudan University",
			"articleRefs": [
				{
					"pageNumber": 932,
					"articleName": "Exploring Static Taint Analysis in LLMs: A Dynamic Benchmarking Framework for Measurement and Enhancement",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a932/573300a932.pdf"
				},
				{
					"pageNumber": 2413,
					"articleName": "DeepExploitor: LLM-Enhanced Automated Exploitation of DeepLink Attack in Hybrid Apps",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c413/573300c413.pdf"
				},
				{
					"pageNumber": 2869,
					"articleName": "LLMPort: Cross-File Patch Porting via Task Decomposition and Self-Correction",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c869/573300c869.pdf"
				}
			]
		},
		{
			"affiliation": "Fudan University, China",
			"articleRefs": [
				{
					"pageNumber": 13,
					"articleName": "Argus: Resilience-Oriented Safety Assurance Framework for End-to-End ADSs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a013/573300a013.pdf"
				},
				{
					"pageNumber": 419,
					"articleName": "ProfMal: Detecting Malicious NPM Packages by the Synergy between Static and Dynamic Analysis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a419/573300a419.pdf"
				},
				{
					"pageNumber": 559,
					"articleName": "Security Debt in LLM Agent Applications: A Measurement Study of Vulnerabilities and Mitigation Trade-Offs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a559/573300a559.pdf"
				},
				{
					"pageNumber": 610,
					"articleName": "RustRepoTrans: Repository-Level Context Code Translation Benchmark Targeting Rust",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a610/573300a610.pdf"
				},
				{
					"pageNumber": 3008,
					"articleName": "Mockingbird: Efficient Excessive Data Exposures Detection via Dynamic Code Instrumentation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d008/573300d008.pdf"
				},
				{
					"pageNumber": 3082,
					"articleName": "Algernon: A Flag-Guided Hybrid Fuzzer for Unlocking Hidden Program Paths",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d082/573300d082.pdf"
				},
				{
					"pageNumber": 3273,
					"articleName": "Minuku: Detecting Diverse Display Issues in Mobile Apps with Small-Scale Dataset",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d273/573300d273.pdf"
				},
				{
					"pageNumber": 3437,
					"articleName": "From Redundancy to Efficiency: Exploiting Shared UI Interactions Towards Efficient LLM-Based Testing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d437/573300d437.pdf"
				}
			]
		},
		{
			"affiliation": "Fudan University, China; Shanghai Key Laboratory of Intelligent Information Processing, China",
			"articleRefs": [
				{
					"pageNumber": 3273,
					"articleName": "Minuku: Detecting Diverse Display Issues in Mobile Apps with Small-Scale Dataset",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d273/573300d273.pdf"
				}
			]
		},
		{
			"affiliation": "George Mason University, USA",
			"articleRefs": [
				{
					"pageNumber": 199,
					"articleName": "Explaining Code Risk in OSS: Towards LLM-Generated Fault Prediction Interpretations",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a199/850300a199.pdf"
				},
				{
					"pageNumber": 1350,
					"articleName": "Destabilizing Neurons to Generate Challenging Neural Network Verification Benchmarks",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b350/573300b350.pdf"
				}
			]
		},
		{
			"affiliation": "Georgia Institute of Technology",
			"articleRefs": [
				{
					"pageNumber": 1044,
					"articleName": "PROMFUZZ: Leveraging LLM-Driven and Bug-Oriented Composite Analysis for Detecting Functional Bugs in Smart Contracts",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b044/573300b044.pdf"
				},
				{
					"pageNumber": 1285,
					"articleName": "Agentic Specification Generator for Move Programs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b285/573300b285.pdf"
				}
			]
		},
		{
			"affiliation": "German Aerospace Center, Germany",
			"articleRefs": [
				{
					"pageNumber": 4000,
					"articleName": "FlowStrider: Low-Friction Continuous Threat Modeling",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d000/573300d000.pdf"
				}
			]
		},
		{
			"affiliation": "Google Germany GmbH, Germany",
			"articleRefs": [
				{
					"pageNumber": 816,
					"articleName": "Execution-Aware Program Reduction for WebAssembly via Record and Replay",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a816/573300a816.pdf"
				}
			]
		},
		{
			"affiliation": "Google Research, USA",
			"articleRefs": [
				{
					"pageNumber": 2108,
					"articleName": "Using Fourier Analysis and Mutant Clustering to Accelerate DNN Mutation Testing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c108/573300c108.pdf"
				}
			]
		},
		{
			"affiliation": "Gran Sasso Science Institute, Italy",
			"articleRefs": [
				{
					"pageNumber": 2451,
					"articleName": "Advancing Automated Ethical Profiling in SE: a Zero-Shot Evaluation of LLM Reasoning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c451/573300c451.pdf"
				},
				{
					"pageNumber": 3798,
					"articleName": "Interaction-Aware Patch Assessment for Multi-Fault Automated Program Repair",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d798/573300d798.pdf"
				},
				{
					"pageNumber": 3803,
					"articleName": "Debugging the Undebuggable: Why Multi-Fault Programs Break Debugging and Repair Tools",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d803/573300d803.pdf"
				}
			]
		},
		{
			"affiliation": "Griffith University, Australia",
			"articleRefs": [
				{
					"pageNumber": 2121,
					"articleName": "PAT-Agent: Autoformalization for Model Checking",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c121/573300c121.pdf"
				}
			]
		},
		{
			"affiliation": "Guangzhou Institute of Technology of Xidian University, China",
			"articleRefs": [
				{
					"pageNumber": 1207,
					"articleName": "Bridging Natural Language and Formal Specification Automated Translation of Software Requirements to LTL via Hierarchical Semantics Decomposition Using LLMs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b207/573300b207.pdf"
				}
			]
		},
		{
			"affiliation": "Guangzhou University, China",
			"articleRefs": [
				{
					"pageNumber": 1168,
					"articleName": "When Autonomous Vehicle Meets V2X Cooperative Perception: How Far Are We?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b168/573300b168.pdf"
				}
			]
		},
		{
			"affiliation": "Gyeongsang National University, Republic of Korea",
			"articleRefs": [
				{
					"pageNumber": 269,
					"articleName": "Explainable AI for Issue Classification: A Multi-Class Study with LIME and SHAP",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a269/850300a269.pdf"
				}
			]
		},
		{
			"affiliation": "Hangzhou City University, China",
			"articleRefs": [
				{
					"pageNumber": 1337,
					"articleName": "FGIT: Fault-Guided Fine-Tuning for Code Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b337/573300b337.pdf"
				}
			]
		},
		{
			"affiliation": "Hangzhou Dianzi University, China",
			"articleRefs": [
				{
					"pageNumber": 508,
					"articleName": "Provable Fairness Repair for Deep Neural Networks",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a508/573300a508.pdf"
				}
			]
		},
		{
			"affiliation": "Hangzhou Dianzi University, China; Zhejiang University, China",
			"articleRefs": [
				{
					"pageNumber": 508,
					"articleName": "Provable Fairness Repair for Deep Neural Networks",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a508/573300a508.pdf"
				}
			]
		},
		{
			"affiliation": "Hangzhou High-Tech Zone (Binjiang) Institute of Blockchain and Data Security",
			"articleRefs": [
				{
					"pageNumber": 2070,
					"articleName": "Why Is My Transaction Risky? Understanding Smart Contract Semantics and Interactions in the NFT Ecosystem",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c070/573300c070.pdf"
				}
			]
		},
		{
			"affiliation": "Harbin Institute of Technology, China",
			"articleRefs": [
				{
					"pageNumber": 1818,
					"articleName": "On the (In)Security of Non-Resettable Device Identifiers in Custom Android Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b818/573300b818.pdf"
				},
				{
					"pageNumber": 2311,
					"articleName": "Effective Code Membership Inference for Code Completion Models via Adversarial Prompts",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c311/573300c311.pdf"
				},
				{
					"pageNumber": 2426,
					"articleName": "An Agent-Based Evaluation Framework for Complex Code Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c426/573300c426.pdf"
				},
				{
					"pageNumber": 3604,
					"articleName": "IntelliTopo: An IaC Generation Service for Industrial Network Topology Construction",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d604/573300d604.pdf"
				},
				{
					"pageNumber": 3671,
					"articleName": "RepoMasterEval: Evaluating Code Completion via Real-World Repositories",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d671/573300d671.pdf"
				}
			]
		},
		{
			"affiliation": "Harbin Institute of Technology, China; Pengcheng Laboratory, China",
			"articleRefs": [
				{
					"pageNumber": 3604,
					"articleName": "IntelliTopo: An IaC Generation Service for Industrial Network Topology Construction",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d604/573300d604.pdf"
				}
			]
		},
		{
			"affiliation": "Harbin Institute of Technology; Peng Cheng Laboratory",
			"articleRefs": [
				{
					"pageNumber": 571,
					"articleName": "SSR: Safeguarding Staking Rewards by Defining and Detecting Logical Defects in DeFi Staking",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a571/573300a571.pdf"
				}
			]
		},
		{
			"affiliation": "Harbin Institute of Technology; Peng Cheng Laboratory, China",
			"articleRefs": [
				{
					"pageNumber": 1528,
					"articleName": "Finding Insecure State Dependency in DApps via Multi-Source Tracing and Semantic Enrichment",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b528/573300b528.pdf"
				}
			]
		},
		{
			"affiliation": "Hitachi, Ltd., Japan",
			"articleRefs": [
				{
					"pageNumber": 3771,
					"articleName": "Acceleration of Automotive Software Development by Retrieval Augmented Integration Test Script Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d771/573300d771.pdf"
				}
			]
		},
		{
			"affiliation": "HiThink Research, China",
			"articleRefs": [
				{
					"pageNumber": 3777,
					"articleName": "SGCR: A Specification-Grounded Framework for Trustworthy LLM Code Review",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d777/573300d777.pdf"
				}
			]
		},
		{
			"affiliation": "HiThink Research, China; Zhejiang University, China",
			"articleRefs": [
				{
					"pageNumber": 3777,
					"articleName": "SGCR: A Specification-Grounded Framework for Trustworthy LLM Code Review",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d777/573300d777.pdf"
				}
			]
		},
		{
			"affiliation": "Hochschule Campus Wien, Austria",
			"articleRefs": [
				{
					"pageNumber": 2694,
					"articleName": "From Characters to Structure: Rethinking Real-Time Collaborative Programming Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c694/573300c694.pdf"
				}
			]
		},
		{
			"affiliation": "Hochschule Campus Wien/TU Wien, Austria",
			"articleRefs": [
				{
					"pageNumber": 2694,
					"articleName": "From Characters to Structure: Rethinking Real-Time Collaborative Programming Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c694/573300c694.pdf"
				}
			]
		},
		{
			"affiliation": "Hong Kong Baptist University, China",
			"articleRefs": [
				{
					"pageNumber": 482,
					"articleName": "VRExplorer: A Model-Based Approach for Semi-Automated Testing of Virtual Reality Scenes",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a482/573300a482.pdf"
				}
			]
		},
		{
			"affiliation": "Hong Kong Polytechnic University, China",
			"articleRefs": [
				{
					"pageNumber": 1463,
					"articleName": "ScaleCirc: Scaling the Analysis over Circom Circuits",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b463/573300b463.pdf"
				}
			]
		},
		{
			"affiliation": "Hong Kong University of Science and Technology, China",
			"articleRefs": [
				{
					"pageNumber": 2905,
					"articleName": "Metamorphic Testing for Audio Content Moderation Software",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c905/573300c905.pdf"
				}
			]
		},
		{
			"affiliation": "Hornor Device Co., Ltd. China",
			"articleRefs": [
				{
					"pageNumber": 457,
					"articleName": "Uncovering Prompt Elements: Cloning System Prompts from Behavioral Traces",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a457/573300a457.pdf"
				}
			]
		},
		{
			"affiliation": "Huawei",
			"articleRefs": [
				{
					"pageNumber": 4117,
					"articleName": "evalSmarT: An LLM-Based Framework for Evaluating Smart Contract Generated Comments",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e117/573300e117.pdf"
				}
			]
		},
		{
			"affiliation": "Huawei, China",
			"articleRefs": [
				{
					"pageNumber": 91,
					"articleName": "When AllClose Fails: Round-Off Error Estimation for Deep Learning Programs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a091/573300a091.pdf"
				}
			]
		},
		{
			"affiliation": "Huawei Cloud",
			"articleRefs": [
				{
					"pageNumber": 228,
					"articleName": "RELIA: Accelerating the Analysis of Cloud Access Control Policies",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a228/573300a228.pdf"
				},
				{
					"pageNumber": 3497,
					"articleName": "Adaptive Performance Regression Detection Using A Semi-Supervised Siamese Network",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d497/573300d497.pdf"
				}
			]
		},
		{
			"affiliation": "Huawei Cloud Computing Technologies Co., Ltd., China",
			"articleRefs": [
				{
					"pageNumber": 778,
					"articleName": "DrainCode: Stealthy Energy Consumption Attacks on Retrieval-Augmented Code Generation via Context Poisoning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a778/573300a778.pdf"
				},
				{
					"pageNumber": 971,
					"articleName": "AlignCoder: Aligning Retrieval with Target Intent for Repository-Level Code Completion",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a971/573300a971.pdf"
				},
				{
					"pageNumber": 2618,
					"articleName": "EfficientEdit: Accelerating Code Editing via Edit-Oriented Speculative Decoding",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c618/573300c618.pdf"
				},
				{
					"pageNumber": 2833,
					"articleName": "Reflective Unit Test Generation for Precise Type Error Detection with Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c833/573300c833.pdf"
				},
				{
					"pageNumber": 3045,
					"articleName": "Clarifying Semantics of In-Context Examples for Unit Test Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d045/573300d045.pdf"
				}
			]
		},
		{
			"affiliation": "Huawei Cloud Computing Technologies Co., Ltd, China",
			"articleRefs": [
				{
					"pageNumber": 778,
					"articleName": "DrainCode: Stealthy Energy Consumption Attacks on Retrieval-Augmented Code Generation via Context Poisoning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a778/573300a778.pdf"
				}
			]
		},
		{
			"affiliation": "Huawei Cloud Computing Technology Co., Ltd, China",
			"articleRefs": [
				{
					"pageNumber": 958,
					"articleName": "iKnow: an Intent-Guided Chatbot for Cloud Operations with Retrieval-Augmented Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a958/573300a958.pdf"
				}
			]
		},
		{
			"affiliation": "Huawei Research Center, Russia",
			"articleRefs": [
				{
					"pageNumber": 4032,
					"articleName": "WIBE: Watermarks for generated Images \u2013 Benchmarking & Evaluation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e032/573300e032.pdf"
				}
			]
		},
		{
			"affiliation": "Huawei Software Engineering Application Technology Lab, China",
			"articleRefs": [
				{
					"pageNumber": 2605,
					"articleName": "SE-Jury: An LLM-as-Ensemble-Judge Metric for Narrowing the Gap with Human Evaluation in SE",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c605/573300c605.pdf"
				}
			]
		},
		{
			"affiliation": "Huawei Technologies, China",
			"articleRefs": [
				{
					"pageNumber": 3203,
					"articleName": "iCodeReviewer: Improving Secure Code Review with Mixture of Prompts",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d203/573300d203.pdf"
				}
			]
		},
		{
			"affiliation": "Huawei Technologies Co., Ltd., China",
			"articleRefs": [
				{
					"pageNumber": 1767,
					"articleName": "Demystifying Cross-Language C/C++ Binaries: A Robust Software Component Analysis Approach",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b767/573300b767.pdf"
				}
			]
		},
		{
			"affiliation": "Huazhong University of Science and Technology, China",
			"articleRefs": [
				{
					"pageNumber": 445,
					"articleName": "TensorGuard: Gradient-Based Model Fingerprinting for LLM Similarity Detection and Family Classification",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a445/573300a445.pdf"
				},
				{
					"pageNumber": 1641,
					"articleName": "Fact-Aligned and Template-Constrained Static Analyzer Rule Enhancement with LLMs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b641/573300b641.pdf"
				},
				{
					"pageNumber": 1692,
					"articleName": "Demystifying Cookie Sharing Risks in WebView-Based Mobile App-in-app Ecosystems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b692/573300b692.pdf"
				},
				{
					"pageNumber": 1818,
					"articleName": "On the (In)Security of Non-Resettable Device Identifiers in Custom Android Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b818/573300b818.pdf"
				},
				{
					"pageNumber": 2045,
					"articleName": "Demystifying the Evolution of Neural Networks with BOM Analysis: Insights from a Large-Scale Study of 55,997 GitHub Repositories",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c045/573300c045.pdf"
				},
				{
					"pageNumber": 3167,
					"articleName": "HarmoBridge: Bridging ArkTS and C/C++ for Cross-Language Static Analysis on HarmonyOS",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d167/573300d167.pdf"
				},
				{
					"pageNumber": 3179,
					"articleName": "ApkArmor: Low-Cost Lightweight Anti-Decompilation Techniques for Android Apps",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d179/573300d179.pdf"
				},
				{
					"pageNumber": 3368,
					"articleName": "A Characterization Study of Bugs in LLM Agent Workflow Orchestration Frameworks",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d368/573300d368.pdf"
				},
				{
					"pageNumber": 3649,
					"articleName": "SCOPE: Evaluating and Enhancing Permission Explanation Transparency in Mobile Apps",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d649/573300d649.pdf"
				},
				{
					"pageNumber": 3660,
					"articleName": "The Gold Digger in the Dark Forest: Industrial-Scale MEV Analysis in Ethereum",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d660/573300d660.pdf"
				}
			]
		},
		{
			"affiliation": "Hubei University, China",
			"articleRefs": [
				{
					"pageNumber": 547,
					"articleName": "DNAFuzz: Descriptor-Aware Fuzzing for USB Drivers",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a547/573300a547.pdf"
				}
			]
		},
		{
			"affiliation": "Humboldt-Universit\u00E4t zu Berlin",
			"articleRefs": [
				{
					"pageNumber": 4144,
					"articleName": "Detecting and Mitigating Inconsistencies Between Code, Documentation and Tests",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e144/573300e144.pdf"
				}
			]
		},
		{
			"affiliation": "Humboldt-Universit\u00E4t zu Berlin, Germany",
			"articleRefs": [
				{
					"pageNumber": 1942,
					"articleName": "Efficient Understanding of Machine Learning Model Mispredictions",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b942/573300b942.pdf"
				},
				{
					"pageNumber": 4048,
					"articleName": "BASHIRI: Learning Failure Oracles from Execution Features",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e048/573300e048.pdf"
				}
			]
		},
		{
			"affiliation": "Hunan University, China",
			"articleRefs": [
				{
					"pageNumber": 3226,
					"articleName": "TRON: Fuzzing Linux Network Stack via Protocol-System Call Payload Synthesis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d226/573300d226.pdf"
				}
			]
		},
		{
			"affiliation": "IBM Research ",
			"articleRefs": [
				{
					"pageNumber": 30,
					"articleName": "Vintage Code, Modern Judges: Meta-Validation in Low Data Regimes",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a030/850300a030.pdf"
				}
			]
		},
		{
			"affiliation": "IBM Research, India",
			"articleRefs": [
				{
					"pageNumber": 3926,
					"articleName": "Multiple Schema-Conformant Declarative Code Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d926/573300d926.pdf"
				},
				{
					"pageNumber": 4077,
					"articleName": "Evaluating Program Coverage for Code-Model Training",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e077/573300e077.pdf"
				},
				{
					"pageNumber": 4097,
					"articleName": "Training-Control-as-Code: Towards a Declarative Solution to Control Training",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e097/573300e097.pdf"
				}
			]
		},
		{
			"affiliation": "IBM Research, Israel",
			"articleRefs": [
				{
					"pageNumber": 7,
					"articleName": "Uncovering Code Insights: Leveraging GitHub Artifacts for Deeper Code Understanding",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a007/850300a007.pdf"
				},
				{
					"pageNumber": 30,
					"articleName": "Vintage Code, Modern Judges: Meta-Validation in Low Data Regimes",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a030/850300a030.pdf"
				},
				{
					"pageNumber": 3839,
					"articleName": "Taming Uncertainty via Automation: Observing, Analyzing, and Optimizing Agentic AI Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d839/573300d839.pdf"
				}
			]
		},
		{
			"affiliation": "IBM Research, Japan",
			"articleRefs": [
				{
					"pageNumber": 26,
					"articleName": "Multilingual Code Explanation for Mainframe Languages",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a026/850300a026.pdf"
				}
			]
		},
		{
			"affiliation": "IBM Research - Tokyo",
			"articleRefs": [
				{
					"pageNumber": 3,
					"articleName": "Grammar- and Coverage-Based Augmentation of Programs for Training LLMs",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a003/850300a003.pdf"
				}
			]
		},
		{
			"affiliation": "IBM Research, Tokyo",
			"articleRefs": [
				{
					"pageNumber": 3,
					"articleName": "Grammar- and Coverage-Based Augmentation of Programs for Training LLMs",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a003/850300a003.pdf"
				}
			]
		},
		{
			"affiliation": "IMDEA Software Institute, Spain",
			"articleRefs": [
				{
					"pageNumber": 2669,
					"articleName": "How Big is the Automaton? Certified Lower Bounds on the Size of Presburger DFAs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c669/573300c669.pdf"
				},
				{
					"pageNumber": 2706,
					"articleName": "State Field Coverage: A Metric for Oracle Quality",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c706/573300c706.pdf"
				}
			]
		},
		{
			"affiliation": "Imperial College London, Imperial Global Singapore, Singapore",
			"articleRefs": [
				{
					"pageNumber": 52,
					"articleName": "Learning from the Past: Real-World Exploit Migration for Smart Contract PoC Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a052/573300a052.pdf"
				},
				{
					"pageNumber": 104,
					"articleName": "FAULTSEEKER: LLM-Empowered Framework for Blockchain Transaction Fault Localization",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a104/573300a104.pdf"
				}
			]
		},
		{
			"affiliation": "\u2020Imperial Global Singapore, Imperial College London, Singapore",
			"articleRefs": [
				{
					"pageNumber": 648,
					"articleName": "BinStruct: Binary Structure Recovery Combining Static Analysis and Semantics",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a648/573300a648.pdf"
				}
			]
		},
		{
			"affiliation": "Imperial Global Singapore, Singapore",
			"articleRefs": [
				{
					"pageNumber": 1069,
					"articleName": "A Large Scale Study of AI-Based Binary Function Similarity Detection Techniques for Security Researchers and Practitioners",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b069/573300b069.pdf"
				}
			]
		},
		{
			"affiliation": "Independent Researcher, China",
			"articleRefs": [
				{
					"pageNumber": 971,
					"articleName": "AlignCoder: Aligning Retrieval with Target Intent for Repository-Level Code Completion",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a971/573300a971.pdf"
				}
			]
		},
		{
			"affiliation": "Independent Researcher, Cyprus",
			"articleRefs": [
				{
					"pageNumber": 376,
					"articleName": "Exploration of Structural Code Relationship Space for Context Collection",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a376/850300a376.pdf"
				}
			]
		},
		{
			"affiliation": "Independent Researcher, Ethiopia",
			"articleRefs": [
				{
					"pageNumber": 4065,
					"articleName": "BenGQL: An Extensible Benchmarking Framework for Automated GraphQL Testing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e065/573300e065.pdf"
				}
			]
		},
		{
			"affiliation": "Independent researcher; Samsung Research America",
			"articleRefs": [
				{
					"pageNumber": 893,
					"articleName": "LineBreaker: Finding Token-Inconsistency Bugs with Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a893/573300a893.pdf"
				}
			]
		},
		{
			"affiliation": "Independent Researcher, Sweden",
			"articleRefs": [
				{
					"pageNumber": 51,
					"articleName": "A 3-Layer Agentic Model for Nonfunctional Requirements in Software Engineering",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a051/850300a051.pdf"
				}
			]
		},
		{
			"affiliation": "Indiana University Bloomington, USA",
			"articleRefs": [
				{
					"pageNumber": 380,
					"articleName": "Towards More Accurate Static Analysis for Taint-Style Bug Detection in Linux Kernel",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a380/573300a380.pdf"
				},
				{
					"pageNumber": 893,
					"articleName": "LineBreaker: Finding Token-Inconsistency Bugs with Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a893/573300a893.pdf"
				}
			]
		},
		{
			"affiliation": "Indiana University Bloomington, USA; University of Illinois Urbana-Champaign, USA",
			"articleRefs": [
				{
					"pageNumber": 893,
					"articleName": "LineBreaker: Finding Token-Inconsistency Bugs with Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a893/573300a893.pdf"
				}
			]
		},
		{
			"affiliation": "Indian Institute of Science, India",
			"articleRefs": [
				{
					"pageNumber": 1233,
					"articleName": "RFCScope: Detecting Logical Ambiguities in Internet Protocol Specifications",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b233/573300b233.pdf"
				}
			]
		},
		{
			"affiliation": "Indian Institute of Technology Kanpur, India",
			"articleRefs": [
				{
					"pageNumber": 3972,
					"articleName": "AndroFL: Evolutionary-Driven Fault Localization for Android Apps",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d972/573300d972.pdf"
				}
			]
		},
		{
			"affiliation": "Indian Institute of Technology Roorkee, India",
			"articleRefs": [
				{
					"pageNumber": 4105,
					"articleName": "StackPlagger: A System for Identifying AI-Code Plagiarism on Stack Overflow",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e105/573300e105.pdf"
				}
			]
		},
		{
			"affiliation": "InMobi, India",
			"articleRefs": [
				{
					"pageNumber": 3972,
					"articleName": "AndroFL: Evolutionary-Driven Fault Localization for Android Apps",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d972/573300d972.pdf"
				}
			]
		},
		{
			"affiliation": "Innopolis University, Russia",
			"articleRefs": [
				{
					"pageNumber": 292,
					"articleName": "GRACG: Graph Retrieval Augmented Code Generation",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a292/850300a292.pdf"
				},
				{
					"pageNumber": 4152,
					"articleName": "Improving Quality of LLM Code Generation in Low-Resource Programming Languages via Uncertainty Estimation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e152/573300e152.pdf"
				}
			]
		},
		{
			"affiliation": "Institute of AI for industries, China",
			"articleRefs": [
				{
					"pageNumber": 1730,
					"articleName": "Function Clustering-Based Fuzzing Termination: Toward Smarter Early Stopping",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b730/573300b730.pdf"
				},
				{
					"pageNumber": 2045,
					"articleName": "Demystifying the Evolution of Neural Networks with BOM Analysis: Insights from a Large-Scale Study of 55,997 GitHub Repositories",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c045/573300c045.pdf"
				}
			]
		},
		{
			"affiliation": "Institute of Computing Technology, China",
			"articleRefs": [
				{
					"pageNumber": 1106,
					"articleName": "BCFuzz: Bytecode-Driven Fuzzing for JavaScript Engines",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b106/573300b106.pdf"
				}
			]
		},
		{
			"affiliation": "Institute of Computing Technology, China; University of Chinese Academy of Sciences",
			"articleRefs": [
				{
					"pageNumber": 1106,
					"articleName": "BCFuzz: Bytecode-Driven Fuzzing for JavaScript Engines",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b106/573300b106.pdf"
				}
			]
		},
		{
			"affiliation": "Institute of Information Engineering, China; University of Chinese Academy of Sciences, China",
			"articleRefs": [
				{
					"pageNumber": 304,
					"articleName": "Advancing Binary Code Similarity Detection via Context-Content Fusion and LLM Verification",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a304/573300a304.pdf"
				}
			]
		},
		{
			"affiliation": "Institute of Information Engineering, Chinese Academy of Sciences, China",
			"articleRefs": [
				{
					"pageNumber": 1918,
					"articleName": "SemGuard: Real-Time Semantic Evaluator for Correcting LLM-Generated Code",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b918/573300b918.pdf"
				},
				{
					"pageNumber": 2681,
					"articleName": "Understanding Resource Injection Vulnerabilities in Kubernetes Ecosystems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c681/573300c681.pdf"
				}
			]
		},
		{
			"affiliation": "Institute of Information Engineering, Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China",
			"articleRefs": [
				{
					"pageNumber": 2681,
					"articleName": "Understanding Resource Injection Vulnerabilities in Kubernetes Ecosystems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c681/573300c681.pdf"
				}
			]
		},
		{
			"affiliation": "Institute of Information Engineering of CAS, China; College of Cyberspace Security, Chinese Academy of Sciences, China",
			"articleRefs": [
				{
					"pageNumber": 2082,
					"articleName": "Breaking the Traffic Barrier: Unveiling Multi-Format of Protocols via Autonomous Program Exploration",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c082/573300c082.pdf"
				}
			]
		},
		{
			"affiliation": "Institute of Science Tokyo, Japan",
			"articleRefs": [
				{
					"pageNumber": 237,
					"articleName": "Towards MPC-Driven Software Adaptation: A Dual-Layer Approach Combining ICNN-Based Modeling and Delta-Based Tuning",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a237/850300a237.pdf"
				}
			]
		},
		{
			"affiliation": "Institute of Software at Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China",
			"articleRefs": [
				{
					"pageNumber": 2771,
					"articleName": "Root Cause Analysis of RISC-V Build Failures via LLM and MCTS Reasoning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c771/573300c771.pdf"
				}
			]
		},
		{
			"affiliation": "Institute of Software, Chinese Academy of Sciences, China",
			"articleRefs": [
				{
					"pageNumber": 1755,
					"articleName": "HybridSIMD: A Super C++ SIMD Library with Integrated Auto-Tuning Capabilities",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b755/573300b755.pdf"
				},
				{
					"pageNumber": 2771,
					"articleName": "Root Cause Analysis of RISC-V Build Failures via LLM and MCTS Reasoning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c771/573300c771.pdf"
				}
			]
		},
		{
			"affiliation": "Institute of Software, Chinese Academy of Sciences, China; Hangzhou Institute for Advanced Study at University of Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China",
			"articleRefs": [
				{
					"pageNumber": 1755,
					"articleName": "HybridSIMD: A Super C++ SIMD Library with Integrated Auto-Tuning Capabilities",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b755/573300b755.pdf"
				}
			]
		},
		{
			"affiliation": "Institute of Software, Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China",
			"articleRefs": [
				{
					"pageNumber": 1515,
					"articleName": "Improving NLSAT for Nonlinear Real Arithmetic",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b515/573300b515.pdf"
				},
				{
					"pageNumber": 1755,
					"articleName": "HybridSIMD: A Super C++ SIMD Library with Integrated Auto-Tuning Capabilities",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b755/573300b755.pdf"
				},
				{
					"pageNumber": 2771,
					"articleName": "Root Cause Analysis of RISC-V Build Failures via LLM and MCTS Reasoning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c771/573300c771.pdf"
				}
			]
		},
		{
			"affiliation": "Institute of Software, Chinese Academy of Sciences, ChinaUniversity of Chinese Academy of Sciences, China",
			"articleRefs": [
				{
					"pageNumber": 2771,
					"articleName": "Root Cause Analysis of RISC-V Build Failures via LLM and MCTS Reasoning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c771/573300c771.pdf"
				}
			]
		},
		{
			"affiliation": "Institute of Software, Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China; Laboratory of System Software (Chinese Academy of Sciences), China",
			"articleRefs": [
				{
					"pageNumber": 2771,
					"articleName": "Root Cause Analysis of RISC-V Build Failures via LLM and MCTS Reasoning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c771/573300c771.pdf"
				}
			]
		},
		{
			"affiliation": "Institute of Software Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China; Laboratory of System Software (Chinese Academy of Sciences), China",
			"articleRefs": [
				{
					"pageNumber": 2771,
					"articleName": "Root Cause Analysis of RISC-V Build Failures via LLM and MCTS Reasoning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c771/573300c771.pdf"
				}
			]
		},
		{
			"affiliation": "Instituto Superior T\u00E9cnico, Portugal",
			"articleRefs": [
				{
					"pageNumber": 121,
					"articleName": "On Effectiveness of Formal Model Repair by Large Language Models",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a121/850300a121.pdf"
				}
			]
		},
		{
			"affiliation": "Institut Polytechnique de Paris, France",
			"articleRefs": [
				{
					"pageNumber": 2183,
					"articleName": "Altered Histories in Version Control System Repositories: Evidence from the Trenches",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c183/573300c183.pdf"
				}
			]
		},
		{
			"affiliation": "International Institute of Information Technology, India",
			"articleRefs": [
				{
					"pageNumber": 349,
					"articleName": "A Conformance Checking System for Interaction Testing in Virtual Reality",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a349/850300a349.pdf"
				}
			]
		},
		{
			"affiliation": "ISP RAS Research Center, Russia; MIPT, Russia",
			"articleRefs": [
				{
					"pageNumber": 4032,
					"articleName": "WIBE: Watermarks for generated Images \u2013 Benchmarking & Evaluation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e032/573300e032.pdf"
				}
			]
		},
		{
			"affiliation": "ISP RAS Research Center, Russia; MSU AI Institute, Russia",
			"articleRefs": [
				{
					"pageNumber": 4032,
					"articleName": "WIBE: Watermarks for generated Images \u2013 Benchmarking & Evaluation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e032/573300e032.pdf"
				}
			]
		},
		{
			"affiliation": "ISP RAS, Russia",
			"articleRefs": [
				{
					"pageNumber": 4032,
					"articleName": "WIBE: Watermarks for generated Images \u2013 Benchmarking & Evaluation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e032/573300e032.pdf"
				}
			]
		},
		{
			"affiliation": "ITMO University",
			"articleRefs": [
				{
					"pageNumber": 113,
					"articleName": "Pre-Filtering Code Suggestions using Developer Behavioral Telemetry to Optimize LLM-Assisted Programming",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a113/850300a113.pdf"
				}
			]
		},
		{
			"affiliation": "ITMO University, Russia",
			"articleRefs": [
				{
					"pageNumber": 214,
					"articleName": "Optimizing LLM Code Suggestions: Feedback-Driven Timing with Lightweight State Bounds",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a214/850300a214.pdf"
				},
				{
					"pageNumber": 292,
					"articleName": "GRACG: Graph Retrieval Augmented Code Generation",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a292/850300a292.pdf"
				}
			]
		},
		{
			"affiliation": "Japan Aerospace Exploration Agency, Japan",
			"articleRefs": [
				{
					"pageNumber": 121,
					"articleName": "On Effectiveness of Formal Model Repair by Large Language Models",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a121/850300a121.pdf"
				}
			]
		},
		{
			"affiliation": "JD.com, Inc., China",
			"articleRefs": [
				{
					"pageNumber": 3706,
					"articleName": "Securing Self-Managed Third-Party Libraries",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d706/573300d706.pdf"
				}
			]
		},
		{
			"affiliation": "JetBrains Research, Serbia",
			"articleRefs": [
				{
					"pageNumber": 3345,
					"articleName": "Prompt-With-Me: in-IDE Structured Prompt Management for LLM-Driven Software Engineering",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d345/573300d345.pdf"
				}
			]
		},
		{
			"affiliation": "JetBrains Research, The Netherlands",
			"articleRefs": [
				{
					"pageNumber": 74,
					"articleName": "AgentGuard: Runtime Verification of AI Agents",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a074/850300a074.pdf"
				},
				{
					"pageNumber": 358,
					"articleName": "Challenge on Optimization of Context Collection for Code Completion",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a358/850300a358.pdf"
				},
				{
					"pageNumber": 3509,
					"articleName": "TreeRanker: Fast and Model-Agnostic Ranking System for Code Suggestions in IDEs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d509/573300d509.pdf"
				}
			]
		},
		{
			"affiliation": "JetBrains, Serbia",
			"articleRefs": [
				{
					"pageNumber": 358,
					"articleName": "Challenge on Optimization of Context Collection for Code Completion",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a358/850300a358.pdf"
				}
			]
		},
		{
			"affiliation": "JetBrains, The Netherlands; Delft University of Technology, The Netherlands",
			"articleRefs": [
				{
					"pageNumber": 3509,
					"articleName": "TreeRanker: Fast and Model-Agnostic Ranking System for Code Suggestions in IDEs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d509/573300d509.pdf"
				}
			]
		},
		{
			"affiliation": "Jiangsu University, China",
			"articleRefs": [
				{
					"pageNumber": 3937,
					"articleName": "IDBFuzz: Web Storage DataBase Fuzzing with Controllable Semantics",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d937/573300d937.pdf"
				}
			]
		},
		{
			"affiliation": "Johannes Gutenberg University Mainz, Germany",
			"articleRefs": [
				{
					"pageNumber": 3901,
					"articleName": "LLM-Guided Genetic Improvement: Envisioning Semantic Aware Automated Software Evolution",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d901/573300d901.pdf"
				}
			]
		},
		{
			"affiliation": "J.P. Morgan AI Research, UK",
			"articleRefs": [
				{
					"pageNumber": 34,
					"articleName": "LLM Agents for Automated Dependency Upgrades",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a034/850300a034.pdf"
				},
				{
					"pageNumber": 39,
					"articleName": "Bridging LLM Planning Agents and Formal Methods: A Case Study in Plan Verification",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a039/850300a039.pdf"
				},
				{
					"pageNumber": 288,
					"articleName": "ALMAS: An Autonomous LLM-Based Multi-Agent Software Engineering Framework",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a288/850300a288.pdf"
				}
			]
		},
		{
			"affiliation": "J.P. Morgan AI Research, USA",
			"articleRefs": [
				{
					"pageNumber": 288,
					"articleName": "ALMAS: An Autonomous LLM-Based Multi-Agent Software Engineering Framework",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a288/850300a288.pdf"
				}
			]
		},
		{
			"affiliation": "JRC European Commission, Italy",
			"articleRefs": [
				{
					"pageNumber": 4101,
					"articleName": "LLMORPH: Automated Metamorphic Testing of Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e101/573300e101.pdf"
				}
			]
		},
		{
			"affiliation": "KAIST, South Korea",
			"articleRefs": [
				{
					"pageNumber": 816,
					"articleName": "Execution-Aware Program Reduction for WebAssembly via Record and Replay",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a816/573300a816.pdf"
				},
				{
					"pageNumber": 1057,
					"articleName": "LOSVER: Line-Level Modifiability Signal-Guided Vulnerability Detection and Classification",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b057/573300b057.pdf"
				},
				{
					"pageNumber": 1402,
					"articleName": "WEST: Specification-Based Test Generation for WebAssembly",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b402/573300b402.pdf"
				},
				{
					"pageNumber": 1540,
					"articleName": "Forcrat: Automatic I/O API Translation from C to Rust via Origin and Capability Analysis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b540/573300b540.pdf"
				},
				{
					"pageNumber": 2464,
					"articleName": "Exact Inference for Quantum Circuits: A Testing Oracle for Quantum Software Stacks",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c464/573300c464.pdf"
				}
			]
		},
		{
			"affiliation": "Karlsruhe Institute of Technology, Germany",
			"articleRefs": [
				{
					"pageNumber": 204,
					"articleName": "Explainability in Automated Cross-Domain Model-Driven Brake System Development",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a204/850300a204.pdf"
				},
				{
					"pageNumber": 2643,
					"articleName": "Using Active Learning to Train Predictive Mutation Testing with Minimal Data",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c643/573300c643.pdf"
				},
				{
					"pageNumber": 4052,
					"articleName": "GUI-ReRank: Enhancing GUI Retrieval with Multi-Modal LLM-Based Reranking",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e052/573300e052.pdf"
				}
			]
		},
		{
			"affiliation": "Key Lab of HCST (PKU); SCS, China",
			"articleRefs": [
				{
					"pageNumber": 1918,
					"articleName": "SemGuard: Real-Time Semantic Evaluator for Correcting LLM-Generated Code",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b918/573300b918.pdf"
				}
			]
		},
		{
			"affiliation": "KFUPM, Saudi Arabia; Interdisciplinary Research Center for Finance and Digital Economy, Saudi Arabia",
			"articleRefs": [
				{
					"pageNumber": 99,
					"articleName": "A Domain-Independent Framework for Effective Prioritization and Evaluation of UX Aspects in Mobile Apps",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a099/850300a099.pdf"
				}
			]
		},
		{
			"affiliation": "KFUPM, Saudi Arabia; Interdisciplinary Research Center for Intelligent Secure Systems, Saudi Arabia",
			"articleRefs": [
				{
					"pageNumber": 99,
					"articleName": "A Domain-Independent Framework for Effective Prioritization and Evaluation of UX Aspects in Mobile Apps",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a099/850300a099.pdf"
				}
			]
		},
		{
			"affiliation": "KFUPM, Saudi Arabia; Technical and Vocational Training Corporation, Saudi Arabia",
			"articleRefs": [
				{
					"pageNumber": 99,
					"articleName": "A Domain-Independent Framework for Effective Prioritization and Evaluation of UX Aspects in Mobile Apps",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a099/850300a099.pdf"
				}
			]
		},
		{
			"affiliation": "King's College London, UK",
			"articleRefs": [
				{
					"pageNumber": 3901,
					"articleName": "LLM-Guided Genetic Improvement: Envisioning Semantic Aware Automated Software Evolution",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d901/573300d901.pdf"
				}
			]
		},
		{
			"affiliation": "King's College London, United Kingdom",
			"articleRefs": [
				{
					"pageNumber": 4016,
					"articleName": "ReFuzzer: Feedback-Driven Approach to Enhance Validity of LLM-Generated Test Programs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e016/573300e016.pdf"
				}
			]
		},
		{
			"affiliation": "Korea University",
			"articleRefs": [
				{
					"pageNumber": 1590,
					"articleName": "IMUFUZZER: Resilience-Based Discovery of Signal Injection Attacks on Robotic Aerial Vehicles",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b590/573300b590.pdf"
				},
				{
					"pageNumber": 4121,
					"articleName": "Verification and Classification of Exploits for Node.js Vulnerabilities",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e121/573300e121.pdf"
				}
			]
		},
		{
			"affiliation": "Korea University, Republic of Korea",
			"articleRefs": [
				{
					"pageNumber": 1577,
					"articleName": "CRYPTBARA: Dependency-Guided Detection of Python Cryptographic API Misuses",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b577/573300b577.pdf"
				}
			]
		},
		{
			"affiliation": "Korea University, South Korea",
			"articleRefs": [
				{
					"pageNumber": 78,
					"articleName": "Debun: Detecting Bundled JavaScript Libraries on Web using Property-Order Graphs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a078/573300a078.pdf"
				}
			]
		},
		{
			"affiliation": "Kristiania University of Applied Sciences, Norway",
			"articleRefs": [
				{
					"pageNumber": 4136,
					"articleName": "Human-Centered Evaluation of REST API Fuzzing Tools: Bridging Academia and Industry",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e136/573300e136.pdf"
				}
			]
		},
		{
			"affiliation": "Kuaishou Inc.",
			"articleRefs": [
				{
					"pageNumber": 3191,
					"articleName": "KAIOps: A Platform Solution of End-to-End Multi-Modal AIOps for AI Training at Scale",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d191/573300d191.pdf"
				}
			]
		},
		{
			"affiliation": "Kuaishou Inc., China",
			"articleRefs": [
				{
					"pageNumber": 3753,
					"articleName": "KAIR: A Statistical and Causal Approach to Pinpointing Stragglers in Distributed Model Training",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d753/573300d753.pdf"
				}
			]
		},
		{
			"affiliation": "Kuaishou Technology, China",
			"articleRefs": [
				{
					"pageNumber": 2234,
					"articleName": "Enhancing LLM to Decompile Optimized PTX to Readable CUDA for Tensor Programs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c234/573300c234.pdf"
				}
			]
		},
		{
			"affiliation": "Kyushu University",
			"articleRefs": [
				{
					"pageNumber": 2656,
					"articleName": "QuanBench: Benchmarking Quantum Code Generation with Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c656/573300c656.pdf"
				},
				{
					"pageNumber": 3638,
					"articleName": "M2QCode: A Model-Driven Framework for Generating Multi-Platform Quantum Programs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d638/573300d638.pdf"
				}
			]
		},
		{
			"affiliation": "Kyushu University, Japan",
			"articleRefs": [
				{
					"pageNumber": 3823,
					"articleName": "Is Measurement Enough? Rethinking Output Validation in Quantum Program Testing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d823/573300d823.pdf"
				},
				{
					"pageNumber": 3880,
					"articleName": "NovaQ: Improving Quantum Program Testing through Diversity-Guided Test Case Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d880/573300d880.pdf"
				},
				{
					"pageNumber": 3885,
					"articleName": "When Abstraction Breaks Physics: Rethinking Modular Design in Quantum Software",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d885/573300d885.pdf"
				}
			]
		},
		{
			"affiliation": "Leipzig University, Germany",
			"articleRefs": [
				{
					"pageNumber": 2515,
					"articleName": "On Automating Configuration Dependency Validation via Retrieval-Augmented Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c515/573300c515.pdf"
				}
			]
		},
		{
			"affiliation": "Leipzig University, Germany; ScaDS.AI Dresden/Leipzig, Germany",
			"articleRefs": [
				{
					"pageNumber": 2515,
					"articleName": "On Automating Configuration Dependency Validation via Retrieval-Augmented Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c515/573300c515.pdf"
				}
			]
		},
		{
			"affiliation": "Lenovo (TianJin) Co., Ltd.",
			"articleRefs": [
				{
					"pageNumber": 3238,
					"articleName": "TrioXpert: An Automated Incident Management Framework for Microservice System",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d238/573300d238.pdf"
				}
			]
		},
		{
			"affiliation": "Lingnan University, China",
			"articleRefs": [
				{
					"pageNumber": 945,
					"articleName": "Demystifying OpenZeppelin's Own Vulnerabilities and Analyzing Their Propagation in Smart Contracts",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a945/573300a945.pdf"
				},
				{
					"pageNumber": 1780,
					"articleName": "Detecting Various DeFi Price Manipulations with LLM Reasoning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b780/573300b780.pdf"
				},
				{
					"pageNumber": 1994,
					"articleName": "Have We Solved Access Control Vulnerability Detection in Smart Contracts? A Benchmark Study",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b994/573300b994.pdf"
				}
			]
		},
		{
			"affiliation": "Lingnan University, Hong Kong SAR, China",
			"articleRefs": [
				{
					"pageNumber": 52,
					"articleName": "Learning from the Past: Real-World Exploit Migration for Smart Contract PoC Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a052/573300a052.pdf"
				}
			]
		},
		{
			"affiliation": "LMU Munich, Germany",
			"articleRefs": [
				{
					"pageNumber": 1968,
					"articleName": "Non-Termination Witnesses and Their Validation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b968/573300b968.pdf"
				}
			]
		},
		{
			"affiliation": "Lodz University of Technology, Poland",
			"articleRefs": [
				{
					"pageNumber": 304,
					"articleName": "Multi-agent systems for improved information retrieval \u2013 leveraging autonomous agents and LLM models",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a304/850300a304.pdf"
				}
			]
		},
		{
			"affiliation": "Loughborough University, United Kingdom",
			"articleRefs": [
				{
					"pageNumber": 129,
					"articleName": "Diagnosing Performance Differences in Model Checkers via Runtime-Guided Problem Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a129/573300a129.pdf"
				}
			]
		},
		{
			"affiliation": "Louisiana State University",
			"articleRefs": [
				{
					"pageNumber": 1020,
					"articleName": "Programmers' Visual Attention on Function Call Graphs During Code Summarization",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b020/573300b020.pdf"
				}
			]
		},
		{
			"affiliation": "Luxembourg Institute of Science and Technology (LIST)",
			"articleRefs": [
				{
					"pageNumber": 3765,
					"articleName": "Towards Reliable LLM-Based Exam Generation Lessons Learned and Open Challenges in an Industrial Project",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d765/573300d765.pdf"
				}
			]
		},
		{
			"affiliation": "Luxembourg Institute of Science and Technology, Luxembourg",
			"articleRefs": [
				{
					"pageNumber": 3890,
					"articleName": "Towards Automated Governance: A DSL for Human-Agent Collaboration in Software Projects",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d890/573300d890.pdf"
				}
			]
		},
		{
			"affiliation": "Macau University of Science and Technology, China",
			"articleRefs": [
				{
					"pageNumber": 4081,
					"articleName": "TRUSTVIS: A Multi-Dimensional Trustworthiness Evaluation Framework for Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e081/573300e081.pdf"
				}
			]
		},
		{
			"affiliation": "Mahidol University, Thailand",
			"articleRefs": [
				{
					"pageNumber": 261,
					"articleName": "Exploring the SECURITY.md in the Dependency Chain: Preliminary Analysis of the PyPI Ecosystem",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a261/850300a261.pdf"
				},
				{
					"pageNumber": 3996,
					"articleName": "PyGress: Tool for Analyzing the Progression of Code Proficiency in Python OSS Projects",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d996/573300d996.pdf"
				}
			]
		},
		{
			"affiliation": "Masaryk University, Czech Republic",
			"articleRefs": [
				{
					"pageNumber": 1968,
					"articleName": "Non-Termination Witnesses and Their Validation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b968/573300b968.pdf"
				}
			]
		},
		{
			"affiliation": "McGill University, Canada",
			"articleRefs": [
				{
					"pageNumber": 39,
					"articleName": "MIMIC: Integrating Diverse Personality Traits for Better Game Testing Using Large Language Model",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a039/573300a039.pdf"
				},
				{
					"pageNumber": 2208,
					"articleName": "LSPFuzz: Hunting Bugs in Language Servers",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c208/573300c208.pdf"
				},
				{
					"pageNumber": 4133,
					"articleName": "Detecting Vulnerabilities from Issue Reports for Internet-of-Things",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e133/573300e133.pdf"
				}
			]
		},
		{
			"affiliation": "Meituan, China",
			"articleRefs": [
				{
					"pageNumber": 3273,
					"articleName": "Minuku: Detecting Diverse Display Issues in Mobile Apps with Small-Scale Dataset",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d273/573300d273.pdf"
				},
				{
					"pageNumber": 3437,
					"articleName": "From Redundancy to Efficiency: Exploiting Shared UI Interactions Towards Efficient LLM-Based Testing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d437/573300d437.pdf"
				}
			]
		},
		{
			"affiliation": "Memorial University of Newfoundland",
			"articleRefs": [
				{
					"pageNumber": 3057,
					"articleName": "Who's to Blame? Rethinking the Brittleness of Automated Web GUI Testing from a Pragmatic Perspective",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d057/573300d057.pdf"
				}
			]
		},
		{
			"affiliation": "Meta Platforms, Inc.",
			"articleRefs": [
				{
					"pageNumber": 3250,
					"articleName": "Metrics Driven Reengineering and Continuous Code Improvement at Meta",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d250/573300d250.pdf"
				}
			]
		},
		{
			"affiliation": "Meta Platforms, Inc.; Concordia University, Montreal",
			"articleRefs": [
				{
					"pageNumber": 3250,
					"articleName": "Metrics Driven Reengineering and Continuous Code Improvement at Meta",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d250/573300d250.pdf"
				}
			]
		},
		{
			"affiliation": " Meta Platforms, Inc.; The University of Tennessee, Knoxville",
			"articleRefs": [
				{
					"pageNumber": 3250,
					"articleName": "Metrics Driven Reengineering and Continuous Code Improvement at Meta",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d250/573300d250.pdf"
				}
			]
		},
		{
			"affiliation": "MetaTrust Labs, Singapore",
			"articleRefs": [
				{
					"pageNumber": 104,
					"articleName": "FAULTSEEKER: LLM-Empowered Framework for Blockchain Transaction Fault Localization",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a104/573300a104.pdf"
				}
			]
		},
		{
			"affiliation": "Meta, US",
			"articleRefs": [
				{
					"pageNumber": 2170,
					"articleName": "Spinner: Detecting Locking Violations in the eBPF Runtime",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c170/573300c170.pdf"
				}
			]
		},
		{
			"affiliation": "Microsoft",
			"articleRefs": [
				{
					"pageNumber": 674,
					"articleName": "Triangle: Empowering Incident Triage with Multi-Agent",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a674/573300a674.pdf"
				}
			]
		},
		{
			"affiliation": "Microsoft, Beijing",
			"articleRefs": [
				{
					"pageNumber": 674,
					"articleName": "Triangle: Empowering Incident Triage with Multi-Agent",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a674/573300a674.pdf"
				}
			]
		},
		{
			"affiliation": "Microsoft, India",
			"articleRefs": [
				{
					"pageNumber": 432,
					"articleName": "Why AI Agents Still Need You: Findings from Developer-Agent Collaborations in the Wild",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a432/573300a432.pdf"
				}
			]
		},
		{
			"affiliation": "Microsoft, USA",
			"articleRefs": [
				{
					"pageNumber": 432,
					"articleName": "Why AI Agents Still Need You: Findings from Developer-Agent Collaborations in the Wild",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a432/573300a432.pdf"
				}
			]
		},
		{
			"affiliation": "Mila - Quebec Artificial Intelligence Institute",
			"articleRefs": [
				{
					"pageNumber": 4081,
					"articleName": "TRUSTVIS: A Multi-Dimensional Trustworthiness Evaluation Framework for Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e081/573300e081.pdf"
				}
			]
		},
		{
			"affiliation": "MIPT, Russia",
			"articleRefs": [
				{
					"pageNumber": 4032,
					"articleName": "WIBE: Watermarks for generated Images \u2013 Benchmarking & Evaluation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e032/573300e032.pdf"
				}
			]
		},
		{
			"affiliation": "Monash University",
			"articleRefs": [
				{
					"pageNumber": 2439,
					"articleName": "Token Sugar: Making Source Code Sweeter for LLMs Through Token-Efficient Shorthand",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c439/573300c439.pdf"
				}
			]
		},
		{
			"affiliation": "Monash University, Australia",
			"articleRefs": [
				{
					"pageNumber": 1032,
					"articleName": "An LLM-Based Multi-Agent Framework for Agile Effort Estimation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b032/573300b032.pdf"
				},
				{
					"pageNumber": 2273,
					"articleName": "Latra: A Template-Based Language-Agnostic Transformation Framework for Effective Program Reduction",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c273/573300c273.pdf"
				},
				{
					"pageNumber": 2387,
					"articleName": "FailMapper: Automated Generation of Unit Tests Guided by Failure Scenarios",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c387/573300c387.pdf"
				},
				{
					"pageNumber": 2605,
					"articleName": "SE-Jury: An LLM-as-Ensemble-Judge Metric for Narrowing the Gap with Human Evaluation in SE",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c605/573300c605.pdf"
				},
				{
					"pageNumber": 3333,
					"articleName": "Multi-Modal Requirements Data-Based Acceptance Criteria Generation Using LLMs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d333/573300d333.pdf"
				},
				{
					"pageNumber": 3380,
					"articleName": "AdaptiveGuard: Towards Adaptive Runtime Safety for LLM-Powered Software",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d380/573300d380.pdf"
				}
			]
		},
		{
			"affiliation": "Monash University Malaysia, Malaysia",
			"articleRefs": [
				{
					"pageNumber": 1893,
					"articleName": "Diplomatist: What Do Cross-Language Dependencies Reflect Software Ecosystem Health?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b893/573300b893.pdf"
				}
			]
		},
		{
			"affiliation": "Monash University, Transurban, Australia",
			"articleRefs": [
				{
					"pageNumber": 3380,
					"articleName": "AdaptiveGuard: Towards Adaptive Runtime Safety for LLM-Powered Software",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d380/573300d380.pdf"
				}
			]
		},
		{
			"affiliation": "Mozilla Corporation, UK",
			"articleRefs": [
				{
					"pageNumber": 1981,
					"articleName": "Automated Generation of Issue-Reproducing Tests by Combining LLMs and Search-Based Testing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b981/573300b981.pdf"
				}
			]
		},
		{
			"affiliation": "MSU AI Institute, Russia",
			"articleRefs": [
				{
					"pageNumber": 4032,
					"articleName": "WIBE: Watermarks for generated Images \u2013 Benchmarking & Evaluation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e032/573300e032.pdf"
				}
			]
		},
		{
			"affiliation": "MSU, Russia",
			"articleRefs": [
				{
					"pageNumber": 4032,
					"articleName": "WIBE: Watermarks for generated Images \u2013 Benchmarking & Evaluation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e032/573300e032.pdf"
				}
			]
		},
		{
			"affiliation": "n/a",
			"articleRefs": [
				{
					"pageNumber": 1868,
					"articleName": "ORFUZZ: Fuzzing the \"Other Side\" of LLM Safety \u2013 Testing Over-Refusal",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b868/573300b868.pdf"
				}
			]
		},
		{
			"affiliation": "Nanjing University, China",
			"articleRefs": [
				{
					"pageNumber": 254,
					"articleName": "Defects4C: Benchmarking Large Language Model Repair Capability with C/C++ Bugs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a254/573300a254.pdf"
				},
				{
					"pageNumber": 457,
					"articleName": "Uncovering Prompt Elements: Cloning System Prompts from Behavioral Traces",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a457/573300a457.pdf"
				},
				{
					"pageNumber": 469,
					"articleName": "Comprehend, Imitate, and then Update: Unleashing the Power of LLMs in Test Suite Evolution",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a469/573300a469.pdf"
				},
				{
					"pageNumber": 584,
					"articleName": "EditFusion: Resolving Code Merge Conflicts via Edit Selection",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a584/573300a584.pdf"
				},
				{
					"pageNumber": 597,
					"articleName": "Automatic Fixing of Missing Dependency Errors",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a597/573300a597.pdf"
				},
				{
					"pageNumber": 1168,
					"articleName": "When Autonomous Vehicle Meets V2X Cooperative Perception: How Far Are We?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b168/573300b168.pdf"
				},
				{
					"pageNumber": 1246,
					"articleName": "Protecting Source Code Privacy When Hunting Memory Bugs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b246/573300b246.pdf"
				},
				{
					"pageNumber": 1389,
					"articleName": "NATE: A Network-Aware Testing Enhancer for Network-Related Fault Detection in Android Apps",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b389/573300b389.pdf"
				},
				{
					"pageNumber": 1793,
					"articleName": "Multi-Dimensional Assessment of Crowdsourced Testing Reports via LLMs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b793/573300b793.pdf"
				},
				{
					"pageNumber": 2349,
					"articleName": "Incremental Program Analysis in the Wild: An Empirical Study on Real-World Program Changes",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c349/573300c349.pdf"
				},
				{
					"pageNumber": 2719,
					"articleName": "PALM: Synergizing Program Analysis and LLMs to Enhance Rust Unit Test Coverage",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c719/573300c719.pdf"
				},
				{
					"pageNumber": 2782,
					"articleName": "Understanding Feature Request Practice on GitHub via a Large-Scale Empirical Study",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c782/573300c782.pdf"
				},
				{
					"pageNumber": 2820,
					"articleName": "PoliCond: Condition-Aware Ontology-Driven LLMs for Privacy Policy Contradiction Analysis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c820/573300c820.pdf"
				},
				{
					"pageNumber": 2944,
					"articleName": "EPSO: A Caching-Based Efficient Superoptimizer for BPF Bytecode",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c944/573300c944.pdf"
				},
				{
					"pageNumber": 3706,
					"articleName": "Securing Self-Managed Third-Party Libraries",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d706/573300d706.pdf"
				}
			]
		},
		{
			"affiliation": "Nanjing University of Aeronautics and Astronautics, China",
			"articleRefs": [
				{
					"pageNumber": 154,
					"articleName": "CODE-DITING: Automatic Evaluation of Code Generation Without References or Test Cases",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a154/573300a154.pdf"
				},
				{
					"pageNumber": 2133,
					"articleName": "Towards Generalizable Instruction Vulnerability Prediction via LLM-Enhanced Code Representation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c133/573300c133.pdf"
				},
				{
					"pageNumber": 2477,
					"articleName": "Evaluating and Improving Framework-Based Parallel Code Completion with Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c477/573300c477.pdf"
				},
				{
					"pageNumber": 2605,
					"articleName": "SE-Jury: An LLM-as-Ensemble-Judge Metric for Narrowing the Gap with Human Evaluation in SE",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c605/573300c605.pdf"
				},
				{
					"pageNumber": 2782,
					"articleName": "Understanding Feature Request Practice on GitHub via a Large-Scale Empirical Study",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c782/573300c782.pdf"
				}
			]
		},
		{
			"affiliation": "Nanjing University of Aeronautics and Astronautics, China; Key Laboratory of Brain-Machine Intelligence Technology",
			"articleRefs": [
				{
					"pageNumber": 1880,
					"articleName": "Coding-Fuse: Efficient Fusion of Code Pre-Trained Models for Classification Tasks",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b880/573300b880.pdf"
				}
			]
		},
		{
			"affiliation": "Nanjing University of Aeronautics and Astronautics, China; Ministry of Industry and Information Technology",
			"articleRefs": [
				{
					"pageNumber": 1880,
					"articleName": "Coding-Fuse: Efficient Fusion of Code Pre-Trained Models for Classification Tasks",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b880/573300b880.pdf"
				}
			]
		},
		{
			"affiliation": "Nanjing University of Aeronautics and Astronautics, China; Nanjing University, China",
			"articleRefs": [
				{
					"pageNumber": 2782,
					"articleName": "Understanding Feature Request Practice on GitHub via a Large-Scale Empirical Study",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c782/573300c782.pdf"
				}
			]
		},
		{
			"affiliation": "Nanjing University of Aeronautics and Astronautics, China; Nantong Normal College, China; Nantong University, China",
			"articleRefs": [
				{
					"pageNumber": 154,
					"articleName": "CODE-DITING: Automatic Evaluation of Code Generation Without References or Test Cases",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a154/573300a154.pdf"
				}
			]
		},
		{
			"affiliation": "Nanjing University of Posts and Telecommunications, China",
			"articleRefs": [
				{
					"pageNumber": 584,
					"articleName": "EditFusion: Resolving Code Merge Conflicts via Edit Selection",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a584/573300a584.pdf"
				}
			]
		},
		{
			"affiliation": "Nanjing University of Science and Technology, China",
			"articleRefs": [
				{
					"pageNumber": 597,
					"articleName": "Automatic Fixing of Missing Dependency Errors",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a597/573300a597.pdf"
				}
			]
		},
		{
			"affiliation": "Nankai University",
			"articleRefs": [
				{
					"pageNumber": 674,
					"articleName": "Triangle: Empowering Incident Triage with Multi-Agent",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a674/573300a674.pdf"
				},
				{
					"pageNumber": 3238,
					"articleName": "TrioXpert: An Automated Incident Management Framework for Microservice System",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d238/573300d238.pdf"
				},
				{
					"pageNumber": 3497,
					"articleName": "Adaptive Performance Regression Detection Using A Semi-Supervised Siamese Network",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d497/573300d497.pdf"
				}
			]
		},
		{
			"affiliation": "Nankai University, China",
			"articleRefs": [
				{
					"pageNumber": 95,
					"articleName": "DroidNative: A Greedy-Constructed Large-Scale Indexing for Android Native Libraries",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a095/850300a095.pdf"
				},
				{
					"pageNumber": 521,
					"articleName": "GlassWing: A Tailored Static Analysis Approach for Flutter Android Apps",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a521/573300a521.pdf"
				},
				{
					"pageNumber": 1717,
					"articleName": "Fixing Broken Graphs: LLM-Powered Automatic Code Optimization for DNN Programs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b717/573300b717.pdf"
				},
				{
					"pageNumber": 2145,
					"articleName": "Don't Mess with Bro's Cheese! An Empirical Study of Resource Conflict in Android Multi-Window",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c145/573300c145.pdf"
				},
				{
					"pageNumber": 2221,
					"articleName": "LLM-Powered Multi-Agent Collaboration for Intelligent Industrial On-Call Automation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c221/573300c221.pdf"
				}
			]
		},
		{
			"affiliation": "Nankai University, China; Haihe Lab of ITAI, China",
			"articleRefs": [
				{
					"pageNumber": 2145,
					"articleName": "Don't Mess with Bro's Cheese! An Empirical Study of Resource Conflict in Android Multi-Window",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c145/573300c145.pdf"
				}
			]
		},
		{
			"affiliation": "Nankai University, China; Tianjin Key Laboratory of Software Experience and Human Computer Interaction",
			"articleRefs": [
				{
					"pageNumber": 2221,
					"articleName": "LLM-Powered Multi-Agent Collaboration for Intelligent Industrial On-Call Automation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c221/573300c221.pdf"
				},
				{
					"pageNumber": 3238,
					"articleName": "TrioXpert: An Automated Incident Management Framework for Microservice System",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d238/573300d238.pdf"
				}
			]
		},
		{
			"affiliation": "Nankai University, China; Zhongguancun Academy, China",
			"articleRefs": [
				{
					"pageNumber": 521,
					"articleName": "GlassWing: A Tailored Static Analysis Approach for Flutter Android Apps",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a521/573300a521.pdf"
				}
			]
		},
		{
			"affiliation": "Nankai University; Key Laboratory of Data and Intelligent System Security, Ministry of Education, China",
			"articleRefs": [
				{
					"pageNumber": 3238,
					"articleName": "TrioXpert: An Automated Incident Management Framework for Microservice System",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d238/573300d238.pdf"
				}
			]
		},
		{
			"affiliation": "Nankai University; Ministry of Education, China",
			"articleRefs": [
				{
					"pageNumber": 3497,
					"articleName": "Adaptive Performance Regression Detection Using A Semi-Supervised Siamese Network",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d497/573300d497.pdf"
				}
			]
		},
		{
			"affiliation": "Nankai University; Tianjin Key Laboratory of Software Experience and Human Computer Interaction",
			"articleRefs": [
				{
					"pageNumber": 3497,
					"articleName": "Adaptive Performance Regression Detection Using A Semi-Supervised Siamese Network",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d497/573300d497.pdf"
				}
			]
		},
		{
			"affiliation": "Nantong University, China",
			"articleRefs": [
				{
					"pageNumber": 154,
					"articleName": "CODE-DITING: Automatic Evaluation of Code Generation Without References or Test Cases",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a154/573300a154.pdf"
				},
				{
					"pageNumber": 2477,
					"articleName": "Evaluating and Improving Framework-Based Parallel Code Completion with Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c477/573300c477.pdf"
				},
				{
					"pageNumber": 2554,
					"articleName": "ACTaint: Agent-Based Taint Analysis for Access Control Vulnerabilities in Smart Contracts",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c554/573300c554.pdf"
				}
			]
		},
		{
			"affiliation": "Nanyang Technical University, Singapore",
			"articleRefs": [
				{
					"pageNumber": 4148,
					"articleName": "Secure Transaction Semantics: Analysis, Vulnerability Detection, and Attack Modeling",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e148/573300e148.pdf"
				}
			]
		},
		{
			"affiliation": "Nanyang Technological University",
			"articleRefs": [
				{
					"pageNumber": 1155,
					"articleName": "Seeing is Fixing: Cross-Modal Reasoning with Multimodal LLMs for Visual Software Issue Repair",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b155/573300b155.pdf"
				}
			]
		},
		{
			"affiliation": "Nanyang Technological University, Singapore",
			"articleRefs": [
				{
					"pageNumber": 52,
					"articleName": "Learning from the Past: Real-World Exploit Migration for Smart Contract PoC Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a052/573300a052.pdf"
				},
				{
					"pageNumber": 95,
					"articleName": "DroidNative: A Greedy-Constructed Large-Scale Indexing for Android Native Libraries",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a095/850300a095.pdf"
				},
				{
					"pageNumber": 104,
					"articleName": "FAULTSEEKER: LLM-Empowered Framework for Blockchain Transaction Fault Localization",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a104/573300a104.pdf"
				},
				{
					"pageNumber": 254,
					"articleName": "Defects4C: Benchmarking Large Language Model Repair Capability with C/C++ Bugs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a254/573300a254.pdf"
				},
				{
					"pageNumber": 304,
					"articleName": "Advancing Binary Code Similarity Detection via Context-Content Fusion and LLM Verification",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a304/573300a304.pdf"
				},
				{
					"pageNumber": 648,
					"articleName": "BinStruct: Binary Structure Recovery Combining Static Analysis and Semantics",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a648/573300a648.pdf"
				},
				{
					"pageNumber": 778,
					"articleName": "DrainCode: Stealthy Energy Consumption Attacks on Retrieval-Augmented Code Generation via Context Poisoning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a778/573300a778.pdf"
				},
				{
					"pageNumber": 893,
					"articleName": "LineBreaker: Finding Token-Inconsistency Bugs with Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a893/573300a893.pdf"
				},
				{
					"pageNumber": 945,
					"articleName": "Demystifying OpenZeppelin's Own Vulnerabilities and Analyzing Their Propagation in Smart Contracts",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a945/573300a945.pdf"
				},
				{
					"pageNumber": 1069,
					"articleName": "A Large Scale Study of AI-Based Binary Function Similarity Detection Techniques for Security Researchers and Practitioners",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b069/573300b069.pdf"
				},
				{
					"pageNumber": 1168,
					"articleName": "When Autonomous Vehicle Meets V2X Cooperative Perception: How Far Are We?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b168/573300b168.pdf"
				},
				{
					"pageNumber": 1780,
					"articleName": "Detecting Various DeFi Price Manipulations with LLM Reasoning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b780/573300b780.pdf"
				},
				{
					"pageNumber": 1994,
					"articleName": "Have We Solved Access Control Vulnerability Detection in Smart Contracts? A Benchmark Study",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b994/573300b994.pdf"
				},
				{
					"pageNumber": 2579,
					"articleName": "WINGMUZZ: Blackbox Testing of IoT Protocols via Two-Dimensional Fuzzing Schedule",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c579/573300c579.pdf"
				},
				{
					"pageNumber": 2969,
					"articleName": "Vulnerability-Affected Versions Identification: How Far Are We?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c969/573300c969.pdf"
				},
				{
					"pageNumber": 3875,
					"articleName": "Envisioning Intelligent Requirements Engineering via Knowledge-Guided Multi-Agent Collaboration",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d875/573300d875.pdf"
				},
				{
					"pageNumber": 3931,
					"articleName": "Requirements Development and Formalization for Reliable Code Generation: A Multi-Agent Vision",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d931/573300d931.pdf"
				},
				{
					"pageNumber": 4024,
					"articleName": "DeepTx: Real-Time Transaction Risk Analysis via Multi-Modal Features and LLM Reasoning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e024/573300e024.pdf"
				}
			]
		},
		{
			"affiliation": "Nanyang Technological University, Singapore; China-Singapore International Joint Research Institute, China",
			"articleRefs": [
				{
					"pageNumber": 648,
					"articleName": "BinStruct: Binary Structure Recovery Combining Static Analysis and Semantics",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a648/573300a648.pdf"
				}
			]
		},
		{
			"affiliation": "Nara Institute of Science and Technology, Japan",
			"articleRefs": [
				{
					"pageNumber": 261,
					"articleName": "Exploring the SECURITY.md in the Dependency Chain: Preliminary Analysis of the PyPI Ecosystem",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a261/850300a261.pdf"
				},
				{
					"pageNumber": 3996,
					"articleName": "PyGress: Tool for Analyzing the Progression of Code Proficiency in Python OSS Projects",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d996/573300d996.pdf"
				}
			]
		},
		{
			"affiliation": "National Cheng Kung University, Taiwan",
			"articleRefs": [
				{
					"pageNumber": 161,
					"articleName": "MicroViSim: Simulation and Visualization of Kubernetes-Based Microservice Systems",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a161/850300a161.pdf"
				}
			]
		},
		{
			"affiliation": "National Engineering Research Center for Big Data Technology and System, Services Computing Technology and System Lab; Cluster and Grid Computing Lab, School of Computer Science and Technology, China",
			"articleRefs": [
				{
					"pageNumber": 1641,
					"articleName": "Fact-Aligned and Template-Constrained Static Analyzer Rule Enhancement with LLMs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b641/573300b641.pdf"
				}
			]
		},
		{
			"affiliation": "National Engineering Research Center for Big Data Technology and System, Services Computing Technology and System Lab; Hubei Engineering Research Center on Big Data Security, Hubei Key Laboratory of Distributed System Security; Huazhong University of Science and Technology (HUST), China",
			"articleRefs": [
				{
					"pageNumber": 1641,
					"articleName": "Fact-Aligned and Template-Constrained Static Analyzer Rule Enhancement with LLMs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b641/573300b641.pdf"
				}
			]
		},
		{
			"affiliation": "National Institute of Advanced Industrial Science and Technology, Japan",
			"articleRefs": [
				{
					"pageNumber": 2337,
					"articleName": "On the Correctness of Software Merge",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c337/573300c337.pdf"
				}
			]
		},
		{
			"affiliation": "National Institute of Informatics, Japan",
			"articleRefs": [
				{
					"pageNumber": 121,
					"articleName": "On Effectiveness of Formal Model Repair by Large Language Models",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a121/850300a121.pdf"
				},
				{
					"pageNumber": 3694,
					"articleName": "Quantum Machine Learning-Based Test Oracle for Autonomous Mobile Robots",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d694/573300d694.pdf"
				}
			]
		},
		{
			"affiliation": "National Institute of Technology Warangal, India",
			"articleRefs": [
				{
					"pageNumber": 1414,
					"articleName": "VeriExploit: Automatic Bug Reproduction in Smart Contracts via LLMs and Formal Methods",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b414/573300b414.pdf"
				}
			]
		},
		{
			"affiliation": "National Kaohsiung Normal University, Taiwan",
			"articleRefs": [
				{
					"pageNumber": 161,
					"articleName": "MicroViSim: Simulation and Visualization of Kubernetes-Based Microservice Systems",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a161/850300a161.pdf"
				}
			]
		},
		{
			"affiliation": "National Key Laboratory of Data Space Technology and System, China",
			"articleRefs": [
				{
					"pageNumber": 700,
					"articleName": "LogAction: Consistent Cross-System Anomaly Detection Through Logs via Active Domain Adaptation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a700/573300a700.pdf"
				},
				{
					"pageNumber": 1118,
					"articleName": "CoorLog: Efficient-Generalizable Log Anomaly Detection via Adaptive Coordinator in Software Evolution",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b118/573300b118.pdf"
				}
			]
		},
		{
			"affiliation": "National Taiwan Ocean University, Taiwan",
			"articleRefs": [
				{
					"pageNumber": 161,
					"articleName": "MicroViSim: Simulation and Visualization of Kubernetes-Based Microservice Systems",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a161/850300a161.pdf"
				}
			]
		},
		{
			"affiliation": "National Taiwan University, Taiwan",
			"articleRefs": [
				{
					"pageNumber": 3788,
					"articleName": "From Modules to Marketplaces: A Vision for Composable Capability Sharing Across Organizations",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d788/573300d788.pdf"
				}
			]
		},
		{
			"affiliation": "National University of Computer and Emerging Sciences, Pakistan",
			"articleRefs": [
				{
					"pageNumber": 87,
					"articleName": "A Data-Driven Approach for Automated Quality Concern Extraction from App Reviews",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a087/850300a087.pdf"
				}
			]
		},
		{
			"affiliation": "National University of Defense and Technology, China",
			"articleRefs": [
				{
					"pageNumber": 1194,
					"articleName": "AdaptEval: A Benchmark for Evaluating Large Language Models on Code Snippet Adaptation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b194/573300b194.pdf"
				}
			]
		},
		{
			"affiliation": "National University of Defense and Technology, China; Peng Cheng Laboratory, China",
			"articleRefs": [
				{
					"pageNumber": 1194,
					"articleName": "AdaptEval: A Benchmark for Evaluating Large Language Models on Code Snippet Adaptation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b194/573300b194.pdf"
				}
			]
		},
		{
			"affiliation": "National University of Defense Technology",
			"articleRefs": [
				{
					"pageNumber": 713,
					"articleName": "When Control Flows Deviate: Directed Grey-box Fuzzing with Probabilistic Reachability Analysis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a713/573300a713.pdf"
				},
				{
					"pageNumber": 3238,
					"articleName": "TrioXpert: An Automated Incident Management Framework for Microservice System",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d238/573300d238.pdf"
				}
			]
		},
		{
			"affiliation": "National University of Defense Technology, China",
			"articleRefs": [
				{
					"pageNumber": 804,
					"articleName": "Let the Code Speak: Incorporating Program Dynamic State for Better Method-Level Fault Localization",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a804/573300a804.pdf"
				},
				{
					"pageNumber": 2057,
					"articleName": "FirmProj: Detecting Firmware Leakage in IoT Update Processes via Companion App Analysis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c057/573300c057.pdf"
				},
				{
					"pageNumber": 2477,
					"articleName": "Evaluating and Improving Framework-Based Parallel Code Completion with Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c477/573300c477.pdf"
				},
				{
					"pageNumber": 3156,
					"articleName": "Industry Practice of LLM-Assisted Protocol Fuzzing for Commercial Communication Modules",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d156/573300d156.pdf"
				}
			]
		},
		{
			"affiliation": "National University of Singapore",
			"articleRefs": [
				{
					"pageNumber": 65,
					"articleName": "Propagation-Based Vulnerability Impact Assessment for Software Supply Chains",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a065/573300a065.pdf"
				},
				{
					"pageNumber": 3984,
					"articleName": "A Large-Scale Evolvable Dataset for Model Context Protocol Ecosystem and Security Analysis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d984/573300d984.pdf"
				}
			]
		},
		{
			"affiliation": "National University of Singapore, Singapore",
			"articleRefs": [
				{
					"pageNumber": 129,
					"articleName": "Diagnosing Performance Differences in Model Checkers via Runtime-Guided Problem Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a129/573300a129.pdf"
				},
				{
					"pageNumber": 597,
					"articleName": "Automatic Fixing of Missing Dependency Errors",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a597/573300a597.pdf"
				},
				{
					"pageNumber": 726,
					"articleName": "Improving LLM-Based Log Parsing by Learning from Errors in Reasoning Traces",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a726/573300a726.pdf"
				},
				{
					"pageNumber": 1094,
					"articleName": "ZendDiff: Differential Testing of PHP Interpreter",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b094/573300b094.pdf"
				},
				{
					"pageNumber": 1376,
					"articleName": "Learning Project-Wise Subsequent Code Edits via Interleaving Neural-Based Induction and Tool-Based Deduction",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b376/573300b376.pdf"
				},
				{
					"pageNumber": 2121,
					"articleName": "PAT-Agent: Autoformalization for Model Checking",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c121/573300c121.pdf"
				}
			]
		},
		{
			"affiliation": "National University of Singapore, Singapore; Shandong University, China",
			"articleRefs": [
				{
					"pageNumber": 1094,
					"articleName": "ZendDiff: Differential Testing of PHP Interpreter",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b094/573300b094.pdf"
				}
			]
		},
		{
			"affiliation": "NAV CANADA, Canada",
			"articleRefs": [
				{
					"pageNumber": 137,
					"articleName": "ForeSPECT: A Model-Driven Framework for Validation and Traceability in Forecasting Systems",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a137/850300a137.pdf"
				}
			]
		},
		{
			"affiliation": "Neapolis University Pafos, Cyprus",
			"articleRefs": [
				{
					"pageNumber": 358,
					"articleName": "Challenge on Optimization of Context Collection for Code Completion",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a358/850300a358.pdf"
				}
			]
		},
		{
			"affiliation": "New Jersey Institute of Technology, USA",
			"articleRefs": [
				{
					"pageNumber": 828,
					"articleName": "Repairing Leaks in Resource Wrappers",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a828/573300a828.pdf"
				}
			]
		},
		{
			"affiliation": "New York University",
			"articleRefs": [
				{
					"pageNumber": 369,
					"articleName": "On the Importance of Context Filtering in Retrieval-Augmented Code Completion",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a369/850300a369.pdf"
				}
			]
		},
		{
			"affiliation": "New York University Abu Dhabi, U.A.E.",
			"articleRefs": [
				{
					"pageNumber": 3844,
					"articleName": "Detecting and Repairing Incomplete Software Requirements with Multi-LLM Ensembles",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d844/573300d844.pdf"
				}
			]
		},
		{
			"affiliation": "New York University Abu Dhabi, United Arab Emirates",
			"articleRefs": [
				{
					"pageNumber": 867,
					"articleName": "An Empirical Study of Python Library Migration Using Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a867/573300a867.pdf"
				}
			]
		},
		{
			"affiliation": "North Carolina State University",
			"articleRefs": [
				{
					"pageNumber": 380,
					"articleName": "Relative Positioning Based Code Chunking Method For Rich Context Retrieval In Repository Level Code Completion Task With Code Language Model",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a380/850300a380.pdf"
				},
				{
					"pageNumber": 2794,
					"articleName": "Which Is Better For Reducing Outdated and Vulnerable Dependencies: Pinning or Floating?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c794/573300c794.pdf"
				}
			]
		},
		{
			"affiliation": "North Carolina State University, United States",
			"articleRefs": [
				{
					"pageNumber": 4020,
					"articleName": "PrioTestCI: Efficient Test Case Prioritization in GitHub Workflows for CI Optimization",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e020/573300e020.pdf"
				}
			]
		},
		{
			"affiliation": "North Carolina State University, USA",
			"articleRefs": [
				{
					"pageNumber": 2995,
					"articleName": "Your Build Scripts Stink: The State of Code Smells in Build Scripts",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c995/573300c995.pdf"
				}
			]
		},
		{
			"affiliation": "North Dakota State University, USA",
			"articleRefs": [
				{
					"pageNumber": 867,
					"articleName": "An Empirical Study of Python Library Migration Using Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a867/573300a867.pdf"
				}
			]
		},
		{
			"affiliation": "Northeastern University, Canada",
			"articleRefs": [
				{
					"pageNumber": 867,
					"articleName": "An Empirical Study of Python Library Migration Using Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a867/573300a867.pdf"
				}
			]
		},
		{
			"affiliation": "Northeastern University, China",
			"articleRefs": [
				{
					"pageNumber": 1743,
					"articleName": "CROSS2OH: Enabling Seamless Porting of C/C++ Software Libraries to OpenHarmony",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b743/573300b743.pdf"
				},
				{
					"pageNumber": 1767,
					"articleName": "Demystifying Cross-Language C/C++ Binaries: A Robust Software Component Analysis Approach",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b767/573300b767.pdf"
				},
				{
					"pageNumber": 1843,
					"articleName": "MCTS-Refined CoT: High-Quality Fine-Tuning Data for LLM-Based Repository Issue Resolution",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b843/573300b843.pdf"
				},
				{
					"pageNumber": 1893,
					"articleName": "Diplomatist: What Do Cross-Language Dependencies Reflect Software Ecosystem Health?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b893/573300b893.pdf"
				}
			]
		},
		{
			"affiliation": "Northeastern University, USA",
			"articleRefs": [
				{
					"pageNumber": 2567,
					"articleName": "DRIFT: Debug-Based Trace Inference for Firmware Testing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c567/573300c567.pdf"
				}
			]
		},
		{
			"affiliation": "Northwestern Polytechnical University, China",
			"articleRefs": [
				{
					"pageNumber": 154,
					"articleName": "CODE-DITING: Automatic Evaluation of Code Generation Without References or Test Cases",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a154/573300a154.pdf"
				}
			]
		},
		{
			"affiliation": "Northwestern University, United States",
			"articleRefs": [
				{
					"pageNumber": 253,
					"articleName": "Fair Developer Score: Build-Adjusted Measurement of Effort and Impact",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a253/850300a253.pdf"
				}
			]
		},
		{
			"affiliation": "Norwegian University of Science and Technology, Norway",
			"articleRefs": [
				{
					"pageNumber": 3402,
					"articleName": "Out of Distribution Detection in Self-Adaptive Robots with AI-Powered Digital Twins",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d402/573300d402.pdf"
				}
			]
		},
		{
			"affiliation": "NTT, Inc. Computer & Data Science Laboratories",
			"articleRefs": [
				{
					"pageNumber": 3638,
					"articleName": "M2QCode: A Model-Driven Framework for Generating Multi-Platform Quantum Programs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d638/573300d638.pdf"
				}
			]
		},
		{
			"affiliation": "NTT, Inc., Japan",
			"articleRefs": [
				{
					"pageNumber": 3860,
					"articleName": "LLM-Powered Fully Automated Chaos Engineering: Towards Enabling Anyone to Build Resilient Software Systems at Low Cost",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d860/573300d860.pdf"
				},
				{
					"pageNumber": 3967,
					"articleName": "A Secure Mocking Approach Towards Software Supply Chain Security",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d967/573300d967.pdf"
				}
			]
		},
		{
			"affiliation": "NYU, Abu Dhabi",
			"articleRefs": [
				{
					"pageNumber": 4040,
					"articleName": "BuilDroid: A Self-Correcting LLM Agent for Automated Android Builds",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e040/573300e040.pdf"
				}
			]
		},
		{
			"affiliation": "Oakland University",
			"articleRefs": [
				{
					"pageNumber": 752,
					"articleName": "Speculative Automated Refactoring of Imperative Deep Learning Programs to Graph Execution",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a752/573300a752.pdf"
				}
			]
		},
		{
			"affiliation": "Oakland University, USA",
			"articleRefs": [
				{
					"pageNumber": 316,
					"articleName": "Traceability and Accountability in Role-Specialized Multi-Agent LLM Pipelines",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a316/850300a316.pdf"
				}
			]
		},
		{
			"affiliation": "Oracle Labs, Australia",
			"articleRefs": [
				{
					"pageNumber": 3391,
					"articleName": "Unlocking Reproducibility: Automating re-Build Process for Open-Source Software",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d391/573300d391.pdf"
				}
			]
		},
		{
			"affiliation": "Oracle Labs Australia, Australia",
			"articleRefs": [
				{
					"pageNumber": 3627,
					"articleName": "DALEQ - Explainable Equivalence for Java Bytecode",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d627/573300d627.pdf"
				}
			]
		},
		{
			"affiliation": "Oregon State University, USA",
			"articleRefs": [
				{
					"pageNumber": 2956,
					"articleName": "When Does Wasm Malware Detection Fail? A Systematic Analysis of Their Robustness to Evasion",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c956/573300c956.pdf"
				}
			]
		},
		{
			"affiliation": "Oslo Metropolitan University, Norway",
			"articleRefs": [
				{
					"pageNumber": 3694,
					"articleName": "Quantum Machine Learning-Based Test Oracle for Autonomous Mobile Robots",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d694/573300d694.pdf"
				}
			]
		},
		{
			"affiliation": "Paderborn University and Fraunhofer IEM, Germany",
			"articleRefs": [
				{
					"pageNumber": 194,
					"articleName": "Explaining Software Vulnerabilities with Large Language Models",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a194/850300a194.pdf"
				}
			]
		},
		{
			"affiliation": "Paderborn University Germany",
			"articleRefs": [
				{
					"pageNumber": 181,
					"articleName": "SeedUI: Understanding Initial Seeds in Fuzzing",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a181/850300a181.pdf"
				}
			]
		},
		{
			"affiliation": "Paderborn University, Germany",
			"articleRefs": [
				{
					"pageNumber": 181,
					"articleName": "SeedUI: Understanding Initial Seeds in Fuzzing",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a181/850300a181.pdf"
				},
				{
					"pageNumber": 194,
					"articleName": "Explaining Software Vulnerabilities with Large Language Models",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a194/850300a194.pdf"
				},
				{
					"pageNumber": 343,
					"articleName": "Toward Static Analysis of Immersive Attacks",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a343/850300a343.pdf"
				}
			]
		},
		{
			"affiliation": "PAL Robotics, Spain",
			"articleRefs": [
				{
					"pageNumber": 3402,
					"articleName": "Out of Distribution Detection in Self-Adaptive Robots with AI-Powered Digital Twins",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d402/573300d402.pdf"
				},
				{
					"pageNumber": 3694,
					"articleName": "Quantum Machine Learning-Based Test Oracle for Autonomous Mobile Robots",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d694/573300d694.pdf"
				}
			]
		},
		{
			"affiliation": "Peking University",
			"articleRefs": [
				{
					"pageNumber": 217,
					"articleName": "R3-Bench: Reproducible Real-World Reverse Engineering Dataset for Symbol Recovery",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a217/573300a217.pdf"
				}
			]
		},
		{
			"affiliation": "Peking University; Alibaba Group",
			"articleRefs": [
				{
					"pageNumber": 217,
					"articleName": "R3-Bench: Reproducible Real-World Reverse Engineering Dataset for Symbol Recovery",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a217/573300a217.pdf"
				}
			]
		},
		{
			"affiliation": "Peking University, China",
			"articleRefs": [
				{
					"pageNumber": 355,
					"articleName": "Enhancing LLMs with Staged Grouping and Dehallucination for Header File Decomposition",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a355/573300a355.pdf"
				},
				{
					"pageNumber": 367,
					"articleName": "Automated Repair of Ambiguous Problem Descriptions for LLM-Based Code Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a367/573300a367.pdf"
				},
				{
					"pageNumber": 661,
					"articleName": "United We Stand: Towards End-to-End Log-Based Fault Diagnosis via Interactive Multi-Task Learning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a661/573300a661.pdf"
				},
				{
					"pageNumber": 700,
					"articleName": "LogAction: Consistent Cross-System Anomaly Detection Through Logs via Active Domain Adaptation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a700/573300a700.pdf"
				},
				{
					"pageNumber": 1118,
					"articleName": "CoorLog: Efficient-Generalizable Log Anomaly Detection via Adaptive Coordinator in Software Evolution",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b118/573300b118.pdf"
				},
				{
					"pageNumber": 1142,
					"articleName": "Hypergraph Neural Network-Based Multi-Granular Root Cause Localization for Microservice Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b142/573300b142.pdf"
				},
				{
					"pageNumber": 1476,
					"articleName": "Aligning LLMs to Fully Utilize the Cross-File Context in Repository-Level Code Completion",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b476/573300b476.pdf"
				},
				{
					"pageNumber": 1565,
					"articleName": "Belief Propagation with Local Structure and Its Applications in Program Analysis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b565/573300b565.pdf"
				},
				{
					"pageNumber": 2298,
					"articleName": "FastCoder: Accelerating Repository-Level Code Generation via Efficient Retrieval and Verification",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c298/573300c298.pdf"
				},
				{
					"pageNumber": 3144,
					"articleName": "Practical Escape of Exploration Tarpits for Mini-Game Testing in an Industrial Setting",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d144/573300d144.pdf"
				},
				{
					"pageNumber": 3521,
					"articleName": "Evaluating Large Language Models for Time Series Anomaly Detection in Aerospace Software",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d521/573300d521.pdf"
				},
				{
					"pageNumber": 3580,
					"articleName": "Element-Aware Fine-Tuning of Vision-Language Models for Cost-Efficient GUI Testing in an Industrial Setting",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d580/573300d580.pdf"
				},
				{
					"pageNumber": 3783,
					"articleName": "Walk the Talk: Is Your Log-Based Software Reliability Maintenance System Really Reliable?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d783/573300d783.pdf"
				},
				{
					"pageNumber": 3875,
					"articleName": "Envisioning Intelligent Requirements Engineering via Knowledge-Guided Multi-Agent Collaboration",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d875/573300d875.pdf"
				}
			]
		},
		{
			"affiliation": "Peking University, China;",
			"articleRefs": [
				{
					"pageNumber": 700,
					"articleName": "LogAction: Consistent Cross-System Anomaly Detection Through Logs via Active Domain Adaptation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a700/573300a700.pdf"
				}
			]
		},
		{
			"affiliation": "Peking University, China; National Key Laboratory of Data Space Technology and System, China",
			"articleRefs": [
				{
					"pageNumber": 661,
					"articleName": "United We Stand: Towards End-to-End Log-Based Fault Diagnosis via Interactive Multi-Task Learning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a661/573300a661.pdf"
				},
				{
					"pageNumber": 700,
					"articleName": "LogAction: Consistent Cross-System Anomaly Detection Through Logs via Active Domain Adaptation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a700/573300a700.pdf"
				},
				{
					"pageNumber": 1118,
					"articleName": "CoorLog: Efficient-Generalizable Log Anomaly Detection via Adaptive Coordinator in Software Evolution",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b118/573300b118.pdf"
				},
				{
					"pageNumber": 3783,
					"articleName": "Walk the Talk: Is Your Log-Based Software Reliability Maintenance System Really Reliable?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d783/573300d783.pdf"
				}
			]
		},
		{
			"affiliation": "Peng Cheng Laboratory",
			"articleRefs": [
				{
					"pageNumber": 571,
					"articleName": "SSR: Safeguarding Staking Rewards by Defining and Detecting Logical Defects in DeFi Staking",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a571/573300a571.pdf"
				}
			]
		},
		{
			"affiliation": "Peng Cheng Laboratory, China",
			"articleRefs": [
				{
					"pageNumber": 1528,
					"articleName": "Finding Insecure State Dependency in DApps via Multi-Source Tracing and Semantic Enrichment",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b528/573300b528.pdf"
				}
			]
		},
		{
			"affiliation": "Pengcheng Laboratory, China",
			"articleRefs": [
				{
					"pageNumber": 3604,
					"articleName": "IntelliTopo: An IaC Generation Service for Industrial Network Topology Construction",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d604/573300d604.pdf"
				}
			]
		},
		{
			"affiliation": "Pennsylvania State University",
			"articleRefs": [
				{
					"pageNumber": 2893,
					"articleName": "Better Safe than Sorry: Preventing Policy Violations Through Predictive Root-Cause-Analysis for IoT Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c893/573300c893.pdf"
				}
			]
		},
		{
			"affiliation": "Pennsylvania State University, USA",
			"articleRefs": [
				{
					"pageNumber": 1679,
					"articleName": "Uncovering Discrimination Clusters: Quantifying and Explaining Systematic Fairness Violations",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b679/573300b679.pdf"
				}
			]
		},
		{
			"affiliation": "Philipps-Universit\u00E4t Marburg, Germany",
			"articleRefs": [
				{
					"pageNumber": 277,
					"articleName": "LLMs Choose the Right Stack: From Patterns to Tools",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a277/850300a277.pdf"
				}
			]
		},
		{
			"affiliation": "Polytechnic University of Bari, Italy",
			"articleRefs": [
				{
					"pageNumber": 2400,
					"articleName": "LLMs for Automated Unit Test Generation and Assessment in Java: The AgoneTest Framework",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c400/573300c400.pdf"
				}
			]
		},
		{
			"affiliation": "Polytechnique Montr\u00E9al, Canada",
			"articleRefs": [
				{
					"pageNumber": 3461,
					"articleName": "From Technical Excellence to Practical Adoption: Lessons Learned Building an ML-Enhanced Trace Analysis Tool",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d461/573300d461.pdf"
				}
			]
		},
		{
			"affiliation": "Polytechnique Montreal, Canada",
			"articleRefs": [
				{
					"pageNumber": 4113,
					"articleName": "PROXiFY: A Bytecode Analysis Tool for Detecting and Classifying Proxy Contracts in Ethereum Smart Contracts",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e113/573300e113.pdf"
				}
			]
		},
		{
			"affiliation": "Purdue University, USA",
			"articleRefs": [
				{
					"pageNumber": 1220,
					"articleName": "RFCAudit: AI Agent for Auditing Protocol Implementations Against RFC Specifications",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b220/573300b220.pdf"
				},
				{
					"pageNumber": 3107,
					"articleName": "LLM-Assisted Synthesis of High-Assurance C Programs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d107/573300d107.pdf"
				}
			]
		},
		{
			"affiliation": "Quantstamp, Singapore",
			"articleRefs": [
				{
					"pageNumber": 1868,
					"articleName": "ORFUZZ: Fuzzing the \"Other Side\" of LLM Safety \u2013 Testing Over-Refusal",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b868/573300b868.pdf"
				}
			]
		},
		{
			"affiliation": "Queen's University, Canada",
			"articleRefs": [
				{
					"pageNumber": 739,
					"articleName": "Watson: A Cognitive Observability Framework for the Reasoning of LLM-Powered Agents",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a739/573300a739.pdf"
				},
				{
					"pageNumber": 1628,
					"articleName": "Characterizing Multi-Hunk Patches: Divergence, Proximity, and LLM Repair Challenges",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b628/573300b628.pdf"
				},
				{
					"pageNumber": 2324,
					"articleName": "SPICE\uD83C\uDF36\uFE0F: An Automated SWE-Bench Labeling Pipeline for Issue Clarity, Test Coverage, and Effort Estimation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c324/573300c324.pdf"
				},
				{
					"pageNumber": 3286,
					"articleName": "Context-Aware CodeLLM Eviction for AI-Assisted Coding",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d286/573300d286.pdf"
				},
				{
					"pageNumber": 3718,
					"articleName": "MobileUPReg: Identifying User-Perceived Performance Regressions in Mobile OS Versions",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d718/573300d718.pdf"
				}
			]
		},
		{
			"affiliation": "Queen\u2019s University, Canada",
			"articleRefs": [
				{
					"pageNumber": 2324,
					"articleName": "SPICE\uD83C\uDF36\uFE0F: An Automated SWE-Bench Labeling Pipeline for Issue Clarity, Test Coverage, and Effort Estimation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c324/573300c324.pdf"
				}
			]
		},
		{
			"affiliation": "Renmin University of China, China",
			"articleRefs": [
				{
					"pageNumber": 241,
					"articleName": "Interaction2Code: Benchmarking MLLM-Based Interactive Webpage Code Generation from Interactive Prototyping",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a241/573300a241.pdf"
				},
				{
					"pageNumber": 2905,
					"articleName": "Metamorphic Testing for Audio Content Moderation Software",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c905/573300c905.pdf"
				}
			]
		},
		{
			"affiliation": "Reykjavik University, Iceland",
			"articleRefs": [
				{
					"pageNumber": 4113,
					"articleName": "PROXiFY: A Bytecode Analysis Tool for Detecting and Classifying Proxy Contracts in Ethereum Smart Contracts",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e113/573300e113.pdf"
				}
			]
		},
		{
			"affiliation": "RISE Research Institutes of Sweden, Sweden",
			"articleRefs": [
				{
					"pageNumber": 58,
					"articleName": "Leveraging Large Language Models for Cybersecurity Risk Assessment \u2014 A Case from Forestry Cyber-Physical Systems",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a058/850300a058.pdf"
				}
			]
		},
		{
			"affiliation": "RISE Research Institutes of Sweden, Sweden; University of Gothenburg, Sweden; University of Gothenburg, Sweden",
			"articleRefs": [
				{
					"pageNumber": 58,
					"articleName": "Leveraging Large Language Models for Cybersecurity Risk Assessment \u2014 A Case from Forestry Cyber-Physical Systems",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a058/850300a058.pdf"
				}
			]
		},
		{
			"affiliation": "Royal Holloway University of London, United Kingdom",
			"articleRefs": [
				{
					"pageNumber": 3793,
					"articleName": "Measuring Software Resilience Using Socially Aware Truck Factor Estimation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d793/573300d793.pdf"
				}
			]
		},
		{
			"affiliation": "Ruhr University Bochum",
			"articleRefs": [
				{
					"pageNumber": 342,
					"articleName": "Risk Estimation in Differential Fuzzing via Extreme Value Theory",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a342/573300a342.pdf"
				}
			]
		},
		{
			"affiliation": "Ruhr University Bochum, Germany",
			"articleRefs": [
				{
					"pageNumber": 3895,
					"articleName": "Simulated Interactive Debugging",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d895/573300d895.pdf"
				}
			]
		},
		{
			"affiliation": "Saarland University",
			"articleRefs": [
				{
					"pageNumber": 166,
					"articleName": "An Empirical Study of Knowledge Transfer in AI Pair Programming",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a166/573300a166.pdf"
				}
			]
		},
		{
			"affiliation": "Saarland University, Germany",
			"articleRefs": [
				{
					"pageNumber": 166,
					"articleName": "An Empirical Study of Knowledge Transfer in AI Pair Programming",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a166/573300a166.pdf"
				},
				{
					"pageNumber": 2490,
					"articleName": "The Fault in our Stats",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c490/573300c490.pdf"
				}
			]
		},
		{
			"affiliation": "San Diego State University, USA ; Samsung Research America",
			"articleRefs": [
				{
					"pageNumber": 893,
					"articleName": "LineBreaker: Finding Token-Inconsistency Bugs with Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a893/573300a893.pdf"
				}
			]
		},
		{
			"affiliation": "Shandong Normal University, China",
			"articleRefs": [
				{
					"pageNumber": 1918,
					"articleName": "SemGuard: Real-Time Semantic Evaluator for Correcting LLM-Generated Code",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b918/573300b918.pdf"
				}
			]
		},
		{
			"affiliation": "Shandong University, China",
			"articleRefs": [
				{
					"pageNumber": 791,
					"articleName": "Hit The Bullseye On The First Shot: Improving LLMs Using Multi-Sample Self-Reward Feedback for Vulnerability Repair",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a791/573300a791.pdf"
				},
				{
					"pageNumber": 1855,
					"articleName": "Can Mamba Be Better? An Experimental Evaluation of Mamba in Code Intelligence",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b855/573300b855.pdf"
				},
				{
					"pageNumber": 2057,
					"articleName": "FirmProj: Detecting Firmware Leakage in IoT Update Processes via Companion App Analysis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c057/573300c057.pdf"
				},
				{
					"pageNumber": 3226,
					"articleName": "TRON: Fuzzing Linux Network Stack via Protocol-System Call Payload Synthesis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d226/573300d226.pdf"
				}
			]
		},
		{
			"affiliation": " Shandong University, China; Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China",
			"articleRefs": [
				{
					"pageNumber": 919,
					"articleName": "Lares: LLM-Driven Code Slice Semantic Search for Patch Presence Testing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a919/573300a919.pdf"
				}
			]
		},
		{
			"affiliation": "Shanghai Jiao Tong University",
			"articleRefs": [
				{
					"pageNumber": 317,
					"articleName": "PrefGen: A Preference-Driven Methodology for Secure Yet Gas-Efficient Smart Contract Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a317/573300a317.pdf"
				}
			]
		},
		{
			"affiliation": "Shanghai Jiaotong University",
			"articleRefs": [
				{
					"pageNumber": 1044,
					"articleName": "PROMFUZZ: Leveraging LLM-Driven and Bug-Oriented Composite Analysis for Detecting Functional Bugs in Smart Contracts",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b044/573300b044.pdf"
				}
			]
		},
		{
			"affiliation": "Shanghai Jiao Tong University, China",
			"articleRefs": [
				{
					"pageNumber": 141,
					"articleName": "LongCodeZip: Compress Long Context for Code Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a141/573300a141.pdf"
				},
				{
					"pageNumber": 1376,
					"articleName": "Learning Project-Wise Subsequent Code Edits via Interleaving Neural-Based Induction and Tool-Based Deduction",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b376/573300b376.pdf"
				},
				{
					"pageNumber": 2057,
					"articleName": "FirmProj: Detecting Firmware Leakage in IoT Update Processes via Companion App Analysis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c057/573300c057.pdf"
				}
			]
		},
		{
			"affiliation": "Shanghai Jiao Tong University, China; National University of Singapore, Singapore",
			"articleRefs": [
				{
					"pageNumber": 1376,
					"articleName": "Learning Project-Wise Subsequent Code Edits via Interleaving Neural-Based Induction and Tool-Based Deduction",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b376/573300b376.pdf"
				}
			]
		},
		{
			"affiliation": "ShanghaiTech University, China",
			"articleRefs": [
				{
					"pageNumber": 3942,
					"articleName": "STaint: Detecting Second-Order Vulnerabilities in PHP Applications with LLM-Assisted Bi-Directional Static Taint Analysis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d942/573300d942.pdf"
				}
			]
		},
		{
			"affiliation": "Shenyang University of Technology, China",
			"articleRefs": [
				{
					"pageNumber": 1893,
					"articleName": "Diplomatist: What Do Cross-Language Dependencies Reflect Software Ecosystem Health?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b893/573300b893.pdf"
				}
			]
		},
		{
			"affiliation": "Shenzhen Research Institute of Nanjing University, China",
			"articleRefs": [
				{
					"pageNumber": 1168,
					"articleName": "When Autonomous Vehicle Meets V2X Cooperative Perception: How Far Are We?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b168/573300b168.pdf"
				}
			]
		},
		{
			"affiliation": "Shuimu Yulin Technology Co., Ltd",
			"articleRefs": [
				{
					"pageNumber": 547,
					"articleName": "DNAFuzz: Descriptor-Aware Fuzzing for USB Drivers",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a547/573300a547.pdf"
				}
			]
		},
		{
			"affiliation": "Siemens AG, China",
			"articleRefs": [
				{
					"pageNumber": 3592,
					"articleName": "AutoPLC: Generating Vendor-Aware Structured Text for Programmable Logic Controllers",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d592/573300d592.pdf"
				}
			]
		},
		{
			"affiliation": "Siemens AG, Germany",
			"articleRefs": [
				{
					"pageNumber": 166,
					"articleName": "An Empirical Study of Knowledge Transfer in AI Pair Programming",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a166/573300a166.pdf"
				},
				{
					"pageNumber": 300,
					"articleName": "Bridging the Prototype-Production Gap: A Multi-Agent System for Notebooks Transformation",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a300/850300a300.pdf"
				}
			]
		},
		{
			"affiliation": "Simula Research Laboratory, Norway",
			"articleRefs": [
				{
					"pageNumber": 3402,
					"articleName": "Out of Distribution Detection in Self-Adaptive Robots with AI-Powered Digital Twins",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d402/573300d402.pdf"
				}
			]
		},
		{
			"affiliation": "Simula Research Laboratory, Norway; University of Oslo, Norway",
			"articleRefs": [
				{
					"pageNumber": 3402,
					"articleName": "Out of Distribution Detection in Self-Adaptive Robots with AI-Powered Digital Twins",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d402/573300d402.pdf"
				}
			]
		},
		{
			"affiliation": "Singapore Management University",
			"articleRefs": [
				{
					"pageNumber": 1155,
					"articleName": "Seeing is Fixing: Cross-Modal Reasoning with Multimodal LLMs for Visual Software Issue Repair",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b155/573300b155.pdf"
				},
				{
					"pageNumber": 1181,
					"articleName": "Backdoors in Code Summarizers: How Bad Is It?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b181/573300b181.pdf"
				},
				{
					"pageNumber": 2070,
					"articleName": "Why Is My Transaction Risky? Understanding Smart Contract Semantics and Interactions in the NFT Ecosystem",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c070/573300c070.pdf"
				},
				{
					"pageNumber": 2439,
					"articleName": "Token Sugar: Making Source Code Sweeter for LLMs Through Token-Efficient Shorthand",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c439/573300c439.pdf"
				}
			]
		},
		{
			"affiliation": "Singapore Management University, Singapore",
			"articleRefs": [
				{
					"pageNumber": 154,
					"articleName": "CODE-DITING: Automatic Evaluation of Code Generation Without References or Test Cases",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a154/573300a154.pdf"
				},
				{
					"pageNumber": 191,
					"articleName": "\"My Productivity is Boosted, but \u2026\" Demystifying Users' Perception on AI Coding Assistants",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a191/573300a191.pdf"
				},
				{
					"pageNumber": 241,
					"articleName": "Interaction2Code: Benchmarking MLLM-Based Interactive Webpage Code Generation from Interactive Prototyping",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a241/573300a241.pdf"
				},
				{
					"pageNumber": 254,
					"articleName": "Defects4C: Benchmarking Large Language Model Repair Capability with C/C++ Bugs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a254/573300a254.pdf"
				},
				{
					"pageNumber": 495,
					"articleName": "RSFuzz: A Robustness-Guided Swarm Fuzzing Framework Based on Behavioral Constraints",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a495/573300a495.pdf"
				},
				{
					"pageNumber": 1780,
					"articleName": "Detecting Various DeFi Price Manipulations with LLM Reasoning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b780/573300b780.pdf"
				},
				{
					"pageNumber": 2095,
					"articleName": "SPEC2CODE: Mapping Protocol Specification to Function-Level Code Implementation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c095/573300c095.pdf"
				},
				{
					"pageNumber": 2311,
					"articleName": "Effective Code Membership Inference for Code Completion Models via Adversarial Prompts",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c311/573300c311.pdf"
				},
				{
					"pageNumber": 2605,
					"articleName": "SE-Jury: An LLM-as-Ensemble-Judge Metric for Narrowing the Gap with Human Evaluation in SE",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c605/573300c605.pdf"
				},
				{
					"pageNumber": 3333,
					"articleName": "Multi-Modal Requirements Data-Based Acceptance Criteria Generation Using LLMs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d333/573300d333.pdf"
				},
				{
					"pageNumber": 3855,
					"articleName": "Exploring Autonomous Agents: A Closer Look at Why They Fail When Completing Tasks",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d855/573300d855.pdf"
				},
				{
					"pageNumber": 3895,
					"articleName": "Simulated Interactive Debugging",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d895/573300d895.pdf"
				},
				{
					"pageNumber": 3931,
					"articleName": "Requirements Development and Formalization for Reliable Code Generation: A Multi-Agent Vision",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d931/573300d931.pdf"
				}
			]
		},
		{
			"affiliation": "Singapore University of Technology and Design, Singapore",
			"articleRefs": [
				{
					"pageNumber": 3895,
					"articleName": "Simulated Interactive Debugging",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d895/573300d895.pdf"
				}
			]
		},
		{
			"affiliation": "Sinosoft Co., Ltd., China",
			"articleRefs": [
				{
					"pageNumber": 1666,
					"articleName": "Leveraging Mixture-of-Experts Framework for Smart Contract Vulnerability Repair with Large Language Model",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b666/573300b666.pdf"
				}
			]
		},
		{
			"affiliation": "SKLP, Institute of Computing Technology, CAS, China",
			"articleRefs": [
				{
					"pageNumber": 2681,
					"articleName": "Understanding Resource Injection Vulnerabilities in Kubernetes Ecosystems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c681/573300c681.pdf"
				}
			]
		},
		{
			"affiliation": "SnT-University of Luxembourg",
			"articleRefs": [
				{
					"pageNumber": 4117,
					"articleName": "evalSmarT: An LLM-Based Framework for Evaluating Smart Contract Generated Comments",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e117/573300e117.pdf"
				}
			]
		},
		{
			"affiliation": "Software Engineering Application Technology Lab, China",
			"articleRefs": [
				{
					"pageNumber": 2719,
					"articleName": "PALM: Synergizing Program Analysis and LLMs to Enhance Rust Unit Test Coverage",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c719/573300c719.pdf"
				}
			]
		},
		{
			"affiliation": "South China University of Technology, China; MOE of China",
			"articleRefs": [
				{
					"pageNumber": 2247,
					"articleName": "Mixture-of-Experts Low-Rank Adaptation for Multilingual Code Summarization",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c247/573300c247.pdf"
				}
			]
		},
		{
			"affiliation": "Southeast University, China",
			"articleRefs": [
				{
					"pageNumber": 191,
					"articleName": "\"My Productivity is Boosted, but \u2026\" Demystifying Users' Perception on AI Coding Assistants",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a191/573300a191.pdf"
				},
				{
					"pageNumber": 726,
					"articleName": "Improving LLM-Based Log Parsing by Learning from Errors in Reasoning Traces",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a726/573300a726.pdf"
				}
			]
		},
		{
			"affiliation": "Southern University of Science and Technology, China",
			"articleRefs": [
				{
					"pageNumber": 2208,
					"articleName": "LSPFuzz: Hunting Bugs in Language Servers",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c208/573300c208.pdf"
				}
			]
		},
		{
			"affiliation": "Southwest Jiaotong University, China",
			"articleRefs": [
				{
					"pageNumber": 3823,
					"articleName": "Is Measurement Enough? Rethinking Output Validation in Quantum Program Testing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d823/573300d823.pdf"
				}
			]
		},
		{
			"affiliation": "Southwest University, China",
			"articleRefs": [
				{
					"pageNumber": 237,
					"articleName": "Towards MPC-Driven Software Adaptation: A Dual-Layer Approach Combining ICNN-Based Modeling and Delta-Based Tuning",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a237/850300a237.pdf"
				},
				{
					"pageNumber": 241,
					"articleName": "Interaction2Code: Benchmarking MLLM-Based Interactive Webpage Code Generation from Interactive Prototyping",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a241/573300a241.pdf"
				}
			]
		},
		{
			"affiliation": "Stanford University, USA",
			"articleRefs": [
				{
					"pageNumber": 141,
					"articleName": "LongCodeZip: Compress Long Context for Code Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a141/573300a141.pdf"
				}
			]
		},
		{
			"affiliation": "State Key Laboratory of Mathematical Engineering and Advanced Computing, China",
			"articleRefs": [
				{
					"pageNumber": 2145,
					"articleName": "Don't Mess with Bro's Cheese! An Empirical Study of Resource Conflict in Android Multi-Window",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c145/573300c145.pdf"
				}
			]
		},
		{
			"affiliation": "State University, USA",
			"articleRefs": [
				{
					"pageNumber": 1679,
					"articleName": "Uncovering Discrimination Clusters: Quantifying and Explaining Systematic Fairness Violations",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b679/573300b679.pdf"
				}
			]
		},
		{
			"affiliation": "Sungkyunkwan University, Republic of Korea",
			"articleRefs": [
				{
					"pageNumber": 2956,
					"articleName": "When Does Wasm Malware Detection Fail? A Systematic Analysis of Their Robustness to Evasion",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c956/573300c956.pdf"
				},
				{
					"pageNumber": 3070,
					"articleName": "Amur: Fixing Multi-Resource Leaks Guided by Resource Flow Analysis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d070/573300d070.pdf"
				}
			]
		},
		{
			"affiliation": "Sungkyunkwan University, South Korea",
			"articleRefs": [
				{
					"pageNumber": 78,
					"articleName": "Debun: Detecting Bundled JavaScript Libraries on Web using Property-Order Graphs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a078/573300a078.pdf"
				}
			]
		},
		{
			"affiliation": "Sun Yat-sen University",
			"articleRefs": [
				{
					"pageNumber": 571,
					"articleName": "SSR: Safeguarding Staking Rewards by Defining and Detecting Logical Defects in DeFi Staking",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a571/573300a571.pdf"
				},
				{
					"pageNumber": 3425,
					"articleName": "Automated Proactive Logging Quality Improvement for Large-Scale Codebases ",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d425/573300d425.pdf"
				}
			]
		},
		{
			"affiliation": "Sun Yat-sen University, China",
			"articleRefs": [
				{
					"pageNumber": 1,
					"articleName": "AlertGuardian: Intelligent Alert Life-Cycle Management for Large-Scale Cloud Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a001/573300a001.pdf"
				},
				{
					"pageNumber": 482,
					"articleName": "VRExplorer: A Model-Based Approach for Semi-Automated Testing of Virtual Reality Scenes",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a482/573300a482.pdf"
				},
				{
					"pageNumber": 610,
					"articleName": "RustRepoTrans: Repository-Level Context Code Translation Benchmark Targeting Rust",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a610/573300a610.pdf"
				},
				{
					"pageNumber": 778,
					"articleName": "DrainCode: Stealthy Energy Consumption Attacks on Retrieval-Augmented Code Generation via Context Poisoning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a778/573300a778.pdf"
				},
				{
					"pageNumber": 971,
					"articleName": "AlignCoder: Aligning Retrieval with Target Intent for Repository-Level Code Completion",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a971/573300a971.pdf"
				},
				{
					"pageNumber": 1528,
					"articleName": "Finding Insecure State Dependency in DApps via Multi-Source Tracing and Semantic Enrichment",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b528/573300b528.pdf"
				},
				{
					"pageNumber": 2857,
					"articleName": "SolContractEval: A Benchmark for Evaluating Contract-Level Solidity Code Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c857/573300c857.pdf"
				},
				{
					"pageNumber": 3533,
					"articleName": "ErrorPrism: Reconstructing Error Propagation Paths in Cloud Service Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d533/573300d533.pdf"
				}
			]
		},
		{
			"affiliation": "Sun Yat-sen University, China; Peng Cheng Laboratory, China",
			"articleRefs": [
				{
					"pageNumber": 482,
					"articleName": "VRExplorer: A Model-Based Approach for Semi-Automated Testing of Virtual Reality Scenes",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a482/573300a482.pdf"
				},
				{
					"pageNumber": 1528,
					"articleName": "Finding Insecure State Dependency in DApps via Multi-Source Tracing and Semantic Enrichment",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b528/573300b528.pdf"
				}
			]
		},
		{
			"affiliation": "Sun Yat-sen University; Peng Cheng Laboratory",
			"articleRefs": [
				{
					"pageNumber": 571,
					"articleName": "SSR: Safeguarding Staking Rewards by Defining and Detecting Logical Defects in DeFi Staking",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a571/573300a571.pdf"
				}
			]
		},
		{
			"affiliation": "Sun Yat sen University; Peng Cheng Laboratory",
			"articleRefs": [
				{
					"pageNumber": 571,
					"articleName": "SSR: Safeguarding Staking Rewards by Defining and Detecting Logical Defects in DeFi Staking",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a571/573300a571.pdf"
				}
			]
		},
		{
			"affiliation": "Swinburne University of Technology, Australia",
			"articleRefs": [
				{
					"pageNumber": 2387,
					"articleName": "FailMapper: Automated Generation of Unit Tests Guided by Failure Scenarios",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c387/573300c387.pdf"
				},
				{
					"pageNumber": 2579,
					"articleName": "WINGMUZZ: Blackbox Testing of IoT Protocols via Two-Dimensional Fuzzing Schedule",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c579/573300c579.pdf"
				},
				{
					"pageNumber": 2881,
					"articleName": "DIFFFIX: Incrementally Fixing AST Diffs via Context and Type Information",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c881/573300c881.pdf"
				}
			]
		},
		{
			"affiliation": "Taiyuan University of Technology, China",
			"articleRefs": [
				{
					"pageNumber": 304,
					"articleName": "Advancing Binary Code Similarity Detection via Context-Content Fusion and LLM Verification",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a304/573300a304.pdf"
				}
			]
		},
		{
			"affiliation": "Tata Consultancy Services, INDIA",
			"articleRefs": [
				{
					"pageNumber": 14,
					"articleName": "Leveraging LLM for Software Modernization: COBOL Functionality Extraction Case Study",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a014/850300a014.pdf"
				},
				{
					"pageNumber": 22,
					"articleName": "Microservices Identification Using LLM",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a022/850300a022.pdf"
				}
			]
		},
		{
			"affiliation": "TCS Research, Tata Consultancy Services, India",
			"articleRefs": [
				{
					"pageNumber": 22,
					"articleName": "Microservices Identification Using LLM",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a022/850300a022.pdf"
				}
			]
		},
		{
			"affiliation": "Technical University of Munich",
			"articleRefs": [
				{
					"pageNumber": 369,
					"articleName": "On the Importance of Context Filtering in Retrieval-Augmented Code Completion",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a369/850300a369.pdf"
				},
				{
					"pageNumber": 1155,
					"articleName": "Seeing is Fixing: Cross-Modal Reasoning with Multimodal LLMs for Visual Software Issue Repair",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b155/573300b155.pdf"
				}
			]
		},
		{
			"affiliation": "Technical University of Munich, Germany",
			"articleRefs": [
				{
					"pageNumber": 222,
					"articleName": "Leveraging Large Language Models for Use Case Model Generation from Software Requirements",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a222/850300a222.pdf"
				},
				{
					"pageNumber": 300,
					"articleName": "Bridging the Prototype-Production Gap: A Multi-Agent System for Notebooks Transformation",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a300/850300a300.pdf"
				},
				{
					"pageNumber": 1602,
					"articleName": "Beyond Static GUI Agent: Evolving LLM-Based GUI Testing via Dynamic Memory",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b602/573300b602.pdf"
				},
				{
					"pageNumber": 1793,
					"articleName": "Multi-Dimensional Assessment of Crowdsourced Testing Reports via LLMs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b793/573300b793.pdf"
				},
				{
					"pageNumber": 2807,
					"articleName": "A Multi-Modality Evaluation of the Reality Gap in Autonomous Driving Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c807/573300c807.pdf"
				},
				{
					"pageNumber": 3215,
					"articleName": "Should We Evaluate LLM Based Security Analysis Approaches on Open Source Systems?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d215/573300d215.pdf"
				},
				{
					"pageNumber": 4130,
					"articleName": "Dynamic Testing of GUI Exercises in Headless Environments",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e130/573300e130.pdf"
				}
			]
		},
		{
			"affiliation": "Technische Universit\u00E4t Clausthal, Germany",
			"articleRefs": [
				{
					"pageNumber": 169,
					"articleName": "LLM-Assisted Tool for Joint Generation of Formulas and Functions in Rule-Based Verification of Map Transformations",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a169/850300a169.pdf"
				}
			]
		},
		{
			"affiliation": "Technische Universit\u00E4t M\u00FCnchen, Germany",
			"articleRefs": [
				{
					"pageNumber": 204,
					"articleName": "Explainability in Automated Cross-Domain Model-Driven Brake System Development",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a204/850300a204.pdf"
				}
			]
		},
		{
			"affiliation": "Tel Aviv University",
			"articleRefs": [
				{
					"pageNumber": 1181,
					"articleName": "Backdoors in Code Summarizers: How Bad Is It?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b181/573300b181.pdf"
				}
			]
		},
		{
			"affiliation": "Tel Aviv University, Israel",
			"articleRefs": [
				{
					"pageNumber": 266,
					"articleName": "Evolution-Aware Heuristics for GR(1) Realizability Checking",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a266/573300a266.pdf"
				}
			]
		},
		{
			"affiliation": "Tencent, China",
			"articleRefs": [
				{
					"pageNumber": 1,
					"articleName": "AlertGuardian: Intelligent Alert Life-Cycle Management for Large-Scale Cloud Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a001/573300a001.pdf"
				},
				{
					"pageNumber": 1843,
					"articleName": "MCTS-Refined CoT: High-Quality Fine-Tuning Data for LLM-Based Repository Issue Resolution",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b843/573300b843.pdf"
				}
			]
		},
		{
			"affiliation": "Tencent Inc., China",
			"articleRefs": [
				{
					"pageNumber": 26,
					"articleName": "Vul-R2: A Reasoning LLM for Automated Vulnerability Repair",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a026/573300a026.pdf"
				},
				{
					"pageNumber": 3132,
					"articleName": "JSidentify-V2: Leveraging Dynamic Memory Fingerprinting for Mini-Game Plagiarism Detection",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d132/573300d132.pdf"
				},
				{
					"pageNumber": 3144,
					"articleName": "Practical Escape of Exploration Tarpits for Mini-Game Testing in an Industrial Setting",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d144/573300d144.pdf"
				},
				{
					"pageNumber": 3449,
					"articleName": "Automated Prompt Generation for Code Intelligence: An Empirical Study and Experience in WeChat",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d449/573300d449.pdf"
				},
				{
					"pageNumber": 3580,
					"articleName": "Element-Aware Fine-Tuning of Vision-Language Models for Cost-Efficient GUI Testing in an Industrial Setting",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d580/573300d580.pdf"
				}
			]
		},
		{
			"affiliation": "Tencent Inc, China ",
			"articleRefs": [
				{
					"pageNumber": 3414,
					"articleName": "Data Dependency-Aware Code Generation from Enhanced UML Sequence Diagrams",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d414/573300d414.pdf"
				}
			]
		},
		{
			"affiliation": "Tencent Inc., China; The Chinese University of Hong Kong, China",
			"articleRefs": [
				{
					"pageNumber": 3132,
					"articleName": "JSidentify-V2: Leveraging Dynamic Memory Fingerprinting for Mini-Game Plagiarism Detection",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d132/573300d132.pdf"
				}
			]
		},
		{
			"affiliation": "The Australian National University, Australia",
			"articleRefs": [
				{
					"pageNumber": 687,
					"articleName": "Navigating the Labyrinth: Path-Sensitive Unit Test Generation with Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a687/573300a687.pdf"
				}
			]
		},
		{
			"affiliation": "The Chinese University of Hong Hong, Shenzhen",
			"articleRefs": [
				{
					"pageNumber": 674,
					"articleName": "Triangle: Empowering Incident Triage with Multi-Agent",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a674/573300a674.pdf"
				}
			]
		},
		{
			"affiliation": "The Chinese University of Hong Kong",
			"articleRefs": [
				{
					"pageNumber": 3298,
					"articleName": "LogPilot: Intent-Aware and Scalable Alert Diagnosis for Large-Scale Online Service Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d298/573300d298.pdf"
				},
				{
					"pageNumber": 3425,
					"articleName": "Automated Proactive Logging Quality Improvement for Large-Scale Codebases ",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d425/573300d425.pdf"
				}
			]
		},
		{
			"affiliation": "The Chinese University of Hong Kong, China",
			"articleRefs": [
				{
					"pageNumber": 26,
					"articleName": "Vul-R2: A Reasoning LLM for Automated Vulnerability Repair",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a026/573300a026.pdf"
				},
				{
					"pageNumber": 241,
					"articleName": "Interaction2Code: Benchmarking MLLM-Based Interactive Webpage Code Generation from Interactive Prototyping",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a241/573300a241.pdf"
				},
				{
					"pageNumber": 958,
					"articleName": "iKnow: an Intent-Guided Chatbot for Cloud Operations with Retrieval-Augmented Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a958/573300a958.pdf"
				},
				{
					"pageNumber": 1830,
					"articleName": "PEACE: Towards Efficient Project-Level Efficiency Optimization via Hybrid Code Editing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b830/573300b830.pdf"
				},
				{
					"pageNumber": 2905,
					"articleName": "Metamorphic Testing for Audio Content Moderation Software",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c905/573300c905.pdf"
				},
				{
					"pageNumber": 3132,
					"articleName": "JSidentify-V2: Leveraging Dynamic Memory Fingerprinting for Mini-Game Plagiarism Detection",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d132/573300d132.pdf"
				},
				{
					"pageNumber": 3414,
					"articleName": "Data Dependency-Aware Code Generation from Enhanced UML Sequence Diagrams",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d414/573300d414.pdf"
				},
				{
					"pageNumber": 3449,
					"articleName": "Automated Prompt Generation for Code Intelligence: An Empirical Study and Experience in WeChat",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d449/573300d449.pdf"
				},
				{
					"pageNumber": 3533,
					"articleName": "ErrorPrism: Reconstructing Error Propagation Paths in Cloud Service Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d533/573300d533.pdf"
				}
			]
		},
		{
			"affiliation": "The Chinese University of Hong Kong, Hong Kong",
			"articleRefs": [
				{
					"pageNumber": 3855,
					"articleName": "Exploring Autonomous Agents: A Closer Look at Why They Fail When Completing Tasks",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d855/573300d855.pdf"
				}
			]
		},
		{
			"affiliation": "The Chinese University of Hong Kong, Shenzhen",
			"articleRefs": [
				{
					"pageNumber": 674,
					"articleName": "Triangle: Empowering Incident Triage with Multi-Agent",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a674/573300a674.pdf"
				}
			]
		},
		{
			"affiliation": "The Hong Kong Polytechnic University, China",
			"articleRefs": [
				{
					"pageNumber": 2541,
					"articleName": "Soleker: Uncovering Vulnerabilities in Solana Smart Contracts",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c541/573300c541.pdf"
				},
				{
					"pageNumber": 3660,
					"articleName": "The Gold Digger in the Dark Forest: Industrial-Scale MEV Analysis in Ethereum",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d660/573300d660.pdf"
				}
			]
		},
		{
			"affiliation": "The Hong Kong University of Science and Technology, China",
			"articleRefs": [
				{
					"pageNumber": 893,
					"articleName": "LineBreaker: Finding Token-Inconsistency Bugs with Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a893/573300a893.pdf"
				},
				{
					"pageNumber": 945,
					"articleName": "Demystifying OpenZeppelin's Own Vulnerabilities and Analyzing Their Propagation in Smart Contracts",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a945/573300a945.pdf"
				},
				{
					"pageNumber": 1767,
					"articleName": "Demystifying Cross-Language C/C++ Binaries: A Robust Software Component Analysis Approach",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b767/573300b767.pdf"
				},
				{
					"pageNumber": 1994,
					"articleName": "Have We Solved Access Control Vulnerability Detection in Smart Contracts? A Benchmark Study",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b994/573300b994.pdf"
				},
				{
					"pageNumber": 2969,
					"articleName": "Vulnerability-Affected Versions Identification: How Far Are We?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c969/573300c969.pdf"
				},
				{
					"pageNumber": 3132,
					"articleName": "JSidentify-V2: Leveraging Dynamic Memory Fingerprinting for Mini-Game Plagiarism Detection",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d132/573300d132.pdf"
				}
			]
		},
		{
			"affiliation": "The Hong Kong University of Science and Technology, China; Guangzhou HKUST Fok Ying Tung Research Institute, China",
			"articleRefs": [
				{
					"pageNumber": 1743,
					"articleName": "CROSS2OH: Enabling Seamless Porting of C/C++ Software Libraries to OpenHarmony",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b743/573300b743.pdf"
				}
			]
		},
		{
			"affiliation": "The Hong Kong University of Science and Technology, Guangzhou",
			"articleRefs": [
				{
					"pageNumber": 3057,
					"articleName": "Who's to Blame? Rethinking the Brittleness of Automated Web GUI Testing from a Pragmatic Perspective",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d057/573300d057.pdf"
				}
			]
		},
		{
			"affiliation": "The Hong Kong University of Science and Technology (Guangzhou), China",
			"articleRefs": [
				{
					"pageNumber": 1930,
					"articleName": "Defects4Log: Benchmarking LLMs for Logging Code Defect Detection and Reasoning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b930/573300b930.pdf"
				}
			]
		},
		{
			"affiliation": "The Hong Kong University of Science and Technology, Hong Kong SAR",
			"articleRefs": [
				{
					"pageNumber": 2208,
					"articleName": "LSPFuzz: Hunting Bugs in Language Servers",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c208/573300c208.pdf"
				}
			]
		},
		{
			"affiliation": "The State Key Laboratory of Blockchain and Data Security, Zhejiang University, China",
			"articleRefs": [
				{
					"pageNumber": 687,
					"articleName": "Navigating the Labyrinth: Path-Sensitive Unit Test Generation with Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a687/573300a687.pdf"
				}
			]
		},
		{
			"affiliation": "The University of Alabama",
			"articleRefs": [
				{
					"pageNumber": 380,
					"articleName": "Relative Positioning Based Code Chunking Method For Rich Context Retrieval In Repository Level Code Completion Task With Code Language Model",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a380/850300a380.pdf"
				}
			]
		},
		{
			"affiliation": "The University of British Columbia, Canada",
			"articleRefs": [
				{
					"pageNumber": 79,
					"articleName": "Reliable and Interpretable Android Malware Detection at Scale",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a079/850300a079.pdf"
				}
			]
		},
		{
			"affiliation": "The University of Chicago, USA",
			"articleRefs": [
				{
					"pageNumber": 380,
					"articleName": "Towards More Accurate Static Analysis for Taint-Style Bug Detection in Linux Kernel",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a380/573300a380.pdf"
				}
			]
		},
		{
			"affiliation": "The University of Manchester, United Kingdom",
			"articleRefs": [
				{
					"pageNumber": 1414,
					"articleName": "VeriExploit: Automatic Bug Reproduction in Smart Contracts via LLMs and Formal Methods",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b414/573300b414.pdf"
				}
			]
		},
		{
			"affiliation": "The University of Melbourne, Australia",
			"articleRefs": [
				{
					"pageNumber": 3380,
					"articleName": "AdaptiveGuard: Towards Adaptive Runtime Safety for LLM-Powered Software",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d380/573300d380.pdf"
				},
				{
					"pageNumber": 3759,
					"articleName": "What Types of Code Review Comments Do Developers Most Frequently Resolve?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d759/573300d759.pdf"
				}
			]
		},
		{
			"affiliation": "The University of Osaka, Japan",
			"articleRefs": [
				{
					"pageNumber": 261,
					"articleName": "Exploring the SECURITY.md in the Dependency Chain: Preliminary Analysis of the PyPI Ecosystem",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a261/850300a261.pdf"
				},
				{
					"pageNumber": 3996,
					"articleName": "PyGress: Tool for Analyzing the Progression of Code Proficiency in Python OSS Projects",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d996/573300d996.pdf"
				}
			]
		},
		{
			"affiliation": "The University of Queensland, Australia",
			"articleRefs": [
				{
					"pageNumber": 2145,
					"articleName": "Don't Mess with Bro's Cheese! An Empirical Study of Resource Conflict in Android Multi-Window",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c145/573300c145.pdf"
				}
			]
		},
		{
			"affiliation": "The University of Sheffield, UK",
			"articleRefs": [
				{
					"pageNumber": 4012,
					"articleName": "XRINTTEST: An Automated Framework for User Interaction Testing in Extended Reality Applications",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e012/573300e012.pdf"
				}
			]
		},
		{
			"affiliation": "The University of Sydney, Australia",
			"articleRefs": [
				{
					"pageNumber": 3818,
					"articleName": "Uncovering Systematic Failures of LLMs in Verifying Code Against Natural Language Specifications",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d818/573300d818.pdf"
				}
			]
		},
		{
			"affiliation": "the University of Texas at Austin, USA",
			"articleRefs": [
				{
					"pageNumber": 2157,
					"articleName": "FlakyGuard: Automatically Fixing Flaky Tests at Industry Scale",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c157/573300c157.pdf"
				}
			]
		},
		{
			"affiliation": "The University of Texas at San Antonio, USA",
			"articleRefs": [
				{
					"pageNumber": 338,
					"articleName": "ARTRIP: Automatic AR Testing with Randomized Interaction Patterns",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a338/850300a338.pdf"
				},
				{
					"pageNumber": 3808,
					"articleName": "How Does ChatGPT Make Assumptions When Creating Erroneous Programs?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d808/573300d808.pdf"
				}
			]
		},
		{
			"affiliation": "The University of Tokyo, Japan",
			"articleRefs": [
				{
					"pageNumber": 4081,
					"articleName": "TRUSTVIS: A Multi-Dimensional Trustworthiness Evaluation Framework for Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e081/573300e081.pdf"
				}
			]
		},
		{
			"affiliation": "The University of Tokyo, Japan; University of Alberta, Canada",
			"articleRefs": [
				{
					"pageNumber": 4081,
					"articleName": "TRUSTVIS: A Multi-Dimensional Trustworthiness Evaluation Framework for Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e081/573300e081.pdf"
				}
			]
		},
		{
			"affiliation": "Tianjin University, China",
			"articleRefs": [
				{
					"pageNumber": 95,
					"articleName": "DroidNative: A Greedy-Constructed Large-Scale Indexing for Android Native Libraries",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a095/850300a095.pdf"
				},
				{
					"pageNumber": 178,
					"articleName": "Wired for Reuse: Automating Context-Aware Code Adaptation in IDEs via LLM-Based Agent",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a178/573300a178.pdf"
				},
				{
					"pageNumber": 254,
					"articleName": "Defects4C: Benchmarking Large Language Model Repair Capability with C/C++ Bugs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a254/573300a254.pdf"
				},
				{
					"pageNumber": 2095,
					"articleName": "SPEC2CODE: Mapping Protocol Specification to Function-Level Code Implementation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c095/573300c095.pdf"
				},
				{
					"pageNumber": 2375,
					"articleName": "Interleaved Learning and Exploration: A Self-Adaptive Fuzz Testing Framework for MLIR",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c375/573300c375.pdf"
				},
				{
					"pageNumber": 2833,
					"articleName": "Reflective Unit Test Generation for Precise Type Error Detection with Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c833/573300c833.pdf"
				},
				{
					"pageNumber": 2982,
					"articleName": "LAURA: Enhancing Code Review Generation with Context-Enriched Retrieval-Augmented LLM",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c982/573300c982.pdf"
				},
				{
					"pageNumber": 3045,
					"articleName": "Clarifying Semantics of In-Context Examples for Unit Test Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d045/573300d045.pdf"
				},
				{
					"pageNumber": 4061,
					"articleName": "DSBox: A Data Selection Framework for Efficient Deep Code Learning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e061/573300e061.pdf"
				}
			]
		},
		{
			"affiliation": "Tongyi Lab, Alibaba Group",
			"articleRefs": [
				{
					"pageNumber": 3729,
					"articleName": "Thinking Longer, Not Larger: Enhancing Software Engineering Agents via Scaling Test-Time Compute",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d729/573300d729.pdf"
				}
			]
		},
		{
			"affiliation": "Transurban, Australia",
			"articleRefs": [
				{
					"pageNumber": 3380,
					"articleName": "AdaptiveGuard: Towards Adaptive Runtime Safety for LLM-Powered Software",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d380/573300d380.pdf"
				}
			]
		},
		{
			"affiliation": "Tsinghua University",
			"articleRefs": [
				{
					"pageNumber": 674,
					"articleName": "Triangle: Empowering Incident Triage with Multi-Agent",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a674/573300a674.pdf"
				},
				{
					"pageNumber": 3497,
					"articleName": "Adaptive Performance Regression Detection Using A Semi-Supervised Siamese Network",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d497/573300d497.pdf"
				}
			]
		},
		{
			"affiliation": "Tsinghua University, China",
			"articleRefs": [
				{
					"pageNumber": 241,
					"articleName": "Interaction2Code: Benchmarking MLLM-Based Interactive Webpage Code Generation from Interactive Prototyping",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a241/573300a241.pdf"
				},
				{
					"pageNumber": 393,
					"articleName": "Democratizing the Cryptocurrency Ecosystem by Just-In-Time Transformation of Mining Programs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a393/573300a393.pdf"
				},
				{
					"pageNumber": 547,
					"articleName": "DNAFuzz: Descriptor-Aware Fuzzing for USB Drivers",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a547/573300a547.pdf"
				},
				{
					"pageNumber": 726,
					"articleName": "Improving LLM-Based Log Parsing by Learning from Errors in Reasoning Traces",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a726/573300a726.pdf"
				},
				{
					"pageNumber": 765,
					"articleName": "DualFuzz: Detecting Vulnerability in Wi-Fi NICs through Dual-Directional Fuzzing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a765/573300a765.pdf"
				},
				{
					"pageNumber": 893,
					"articleName": "LineBreaker: Finding Token-Inconsistency Bugs with Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a893/573300a893.pdf"
				},
				{
					"pageNumber": 1806,
					"articleName": "ARG: Testing Query Rewriters via Abstract Rule Guided Fuzzing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b806/573300b806.pdf"
				},
				{
					"pageNumber": 2095,
					"articleName": "SPEC2CODE: Mapping Protocol Specification to Function-Level Code Implementation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c095/573300c095.pdf"
				},
				{
					"pageNumber": 2618,
					"articleName": "EfficientEdit: Accelerating Code Editing via Edit-Oriented Speculative Decoding",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c618/573300c618.pdf"
				},
				{
					"pageNumber": 3226,
					"articleName": "TRON: Fuzzing Linux Network Stack via Protocol-System Call Payload Synthesis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d226/573300d226.pdf"
				},
				{
					"pageNumber": 3545,
					"articleName": "LLM-Assisted Industrial-Scale Differential Testing of Package Incompatibilities in Linux Distributions",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d545/573300d545.pdf"
				},
				{
					"pageNumber": 3615,
					"articleName": "RPG: Linux Kernel Fuzzing Guided by Distribution-Specific Runtime Parameter Interfaces",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d615/573300d615.pdf"
				}
			]
		},
		{
			"affiliation": "Tsinghua University, China; Shuimu Yulin Technology Co., Ltd, China",
			"articleRefs": [
				{
					"pageNumber": 3156,
					"articleName": "Industry Practice of LLM-Assisted Protocol Fuzzing for Commercial Communication Modules",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d156/573300d156.pdf"
				}
			]
		},
		{
			"affiliation": "TurinTech AI, UK",
			"articleRefs": [
				{
					"pageNumber": 3568,
					"articleName": "Tuning LLM-Based Code Optimization via Meta-Prompting: An Industrial Perspective",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d568/573300d568.pdf"
				}
			]
		},
		{
			"affiliation": "TU Wien, Austria",
			"articleRefs": [
				{
					"pageNumber": 906,
					"articleName": "Profile Coverage: Using Android Compilation Profiles to Evaluate Dynamic Testing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a906/573300a906.pdf"
				},
				{
					"pageNumber": 1942,
					"articleName": "Efficient Understanding of Machine Learning Model Mispredictions",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b942/573300b942.pdf"
				},
				{
					"pageNumber": 3833,
					"articleName": "Fault Injection for Simulink-Based CPS Models: Insights and Future Directions",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d833/573300d833.pdf"
				}
			]
		},
		{
			"affiliation": "TU Wien/UAS Technikum Wien, Austria",
			"articleRefs": [
				{
					"pageNumber": 2694,
					"articleName": "From Characters to Structure: Rethinking Real-Time Collaborative Programming Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c694/573300c694.pdf"
				}
			]
		},
		{
			"affiliation": "Uber Technologies, USA",
			"articleRefs": [
				{
					"pageNumber": 2157,
					"articleName": "FlakyGuard: Automatically Fixing Flaky Tests at Industry Scale",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c157/573300c157.pdf"
				}
			]
		},
		{
			"affiliation": "UCAS, China",
			"articleRefs": [
				{
					"pageNumber": 2969,
					"articleName": "Vulnerability-Affected Versions Identification: How Far Are We?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c969/573300c969.pdf"
				}
			]
		},
		{
			"affiliation": "UFRPE, Brazil",
			"articleRefs": [
				{
					"pageNumber": 3916,
					"articleName": "Tether: A Personalized Support Assistant for Software Engineers with ADHD",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d916/573300d916.pdf"
				}
			]
		},
		{
			"affiliation": "Ume\u00E5 University",
			"articleRefs": [
				{
					"pageNumber": 3906,
					"articleName": "ConfuseTaint: Exploiting Vulnerabilities to Bypass Dynamic Taint Analysis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d906/573300d906.pdf"
				}
			]
		},
		{
			"affiliation": "Unaffiliated, USA",
			"articleRefs": [
				{
					"pageNumber": 1552,
					"articleName": "It's Not Easy Being Green: On the Energy Efficiency of Programming Languages",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b552/573300b552.pdf"
				}
			]
		},
		{
			"affiliation": "Universidad de los Andes, Colombia",
			"articleRefs": [
				{
					"pageNumber": 83,
					"articleName": "Finding Keywords for Architectural Erosion Detection in GitHub Commits for Android Applications",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a083/850300a083.pdf"
				},
				{
					"pageNumber": 3952,
					"articleName": "Autonomous Agents for Accessibility: Simulating Visual Impairments in Web Interfaces",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d952/573300d952.pdf"
				},
				{
					"pageNumber": 4056,
					"articleName": "EyeNav: Accessible Webpage Interaction and Testing Using Eye-Tracking and NLP",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e056/573300e056.pdf"
				}
			]
		},
		{
			"affiliation": "Universidad de Sevilla, Spain",
			"articleRefs": [
				{
					"pageNumber": 1363,
					"articleName": "SATORI: Static Test Oracle Generation for REST APIs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b363/573300b363.pdf"
				}
			]
		},
		{
			"affiliation": "Universit\u00E0 della Svizzera italiana, Switzerland",
			"articleRefs": [
				{
					"pageNumber": 278,
					"articleName": "Do LLMs Generate Useful Test Oracles? An Empirical Study with an Unbiased Dataset",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a278/573300a278.pdf"
				},
				{
					"pageNumber": 1363,
					"articleName": "SATORI: Static Test Oracle Generation for REST APIs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b363/573300b363.pdf"
				},
				{
					"pageNumber": 3356,
					"articleName": "Bridging Research and Practice in Simulation-Based Testing of Industrial Robot Navigation Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d356/573300d356.pdf"
				}
			]
		},
		{
			"affiliation": "Universit\u00E4t der Bundeswehr M\u00FCnchen, Germany",
			"articleRefs": [
				{
					"pageNumber": 2732,
					"articleName": "TEPHRA: Principled Discovery of Fuzzer Limitations",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c732/573300c732.pdf"
				}
			]
		},
		{
			"affiliation": "Universitat Oberta de Catalunya, Spain",
			"articleRefs": [
				{
					"pageNumber": 3890,
					"articleName": "Towards Automated Governance: A DSL for Human-Agent Collaboration in Software Projects",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d890/573300d890.pdf"
				}
			]
		},
		{
			"affiliation": "Universit\u00E9 Bretagne Sud, France",
			"articleRefs": [
				{
					"pageNumber": 291,
					"articleName": "Loupe: End-to-End Learning of Loop Unrolling Heuristics for Abstract Interpretation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a291/573300a291.pdf"
				}
			]
		},
		{
			"affiliation": "Universit\u00E9 Cheikh Anta Diop",
			"articleRefs": [
				{
					"pageNumber": 4117,
					"articleName": "evalSmarT: An LLM-Based Framework for Evaluating Smart Contract Generated Comments",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e117/573300e117.pdf"
				}
			]
		},
		{
			"affiliation": "Universit\u00E9 de Toulouse, France",
			"articleRefs": [
				{
					"pageNumber": 2669,
					"articleName": "How Big is the Automaton? Certified Lower Bounds on the Size of Presburger DFAs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c669/573300c669.pdf"
				}
			]
		},
		{
			"affiliation": "Universit\u00E9 Paris-Saclay, France",
			"articleRefs": [
				{
					"pageNumber": 291,
					"articleName": "Loupe: End-to-End Learning of Loop Unrolling Heuristics for Abstract Interpretation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a291/573300a291.pdf"
				}
			]
		},
		{
			"affiliation": "Universit\u00E9 Paris-Saclay, Universit\u00E9 Bretagne Sud, France",
			"articleRefs": [
				{
					"pageNumber": 291,
					"articleName": "Loupe: End-to-End Learning of Loop Unrolling Heuristics for Abstract Interpretation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a291/573300a291.pdf"
				}
			]
		},
		{
			"affiliation": "University College Dublin, Ireland",
			"articleRefs": [
				{
					"pageNumber": 365,
					"articleName": "SpareCodeSearch: Searching for Code Context When You Have No Spare GPU",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a365/850300a365.pdf"
				}
			]
		},
		{
			"affiliation": "University College London, UK",
			"articleRefs": [
				{
					"pageNumber": 107,
					"articleName": "From Kotlin to Swift and Back: Toward Fully Automated Cross-Language Code Transpilation",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a107/850300a107.pdf"
				},
				{
					"pageNumber": 1311,
					"articleName": "Detecting Semantic Clones of Unseen Functionality",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b311/573300b311.pdf"
				},
				{
					"pageNumber": 3901,
					"articleName": "LLM-Guided Genetic Improvement: Envisioning Semantic Aware Automated Software Evolution",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d901/573300d901.pdf"
				}
			]
		},
		{
			"affiliation": "University College London, United Kingdom",
			"articleRefs": [
				{
					"pageNumber": 367,
					"articleName": "Automated Repair of Ambiguous Problem Descriptions for LLM-Based Code Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a367/573300a367.pdf"
				}
			]
		},
		{
			"affiliation": "University of Alberta",
			"articleRefs": [
				{
					"pageNumber": 2439,
					"articleName": "Token Sugar: Making Source Code Sweeter for LLMs Through Token-Efficient Shorthand",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c439/573300c439.pdf"
				}
			]
		},
		{
			"affiliation": "University of Alberta; Alberta Machine Intelligence Institute",
			"articleRefs": [
				{
					"pageNumber": 1181,
					"articleName": "Backdoors in Code Summarizers: How Bad Is It?",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b181/573300b181.pdf"
				}
			]
		},
		{
			"affiliation": "University of Alberta, Canada",
			"articleRefs": [
				{
					"pageNumber": 191,
					"articleName": "\"My Productivity is Boosted, but \u2026\" Demystifying Users' Perception on AI Coding Assistants",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a191/573300a191.pdf"
				},
				{
					"pageNumber": 867,
					"articleName": "An Empirical Study of Python Library Migration Using Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a867/573300a867.pdf"
				},
				{
					"pageNumber": 4081,
					"articleName": "TRUSTVIS: A Multi-Dimensional Trustworthiness Evaluation Framework for Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e081/573300e081.pdf"
				}
			]
		},
		{
			"affiliation": "University of Applied Sciences Munich, Germany",
			"articleRefs": [
				{
					"pageNumber": 145,
					"articleName": "BMuzz: Combining Bounded Model Checking and Fuzzing to Enhance Code Coverage",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a145/850300a145.pdf"
				}
			]
		},
		{
			"affiliation": "University of Athens, Greece",
			"articleRefs": [
				{
					"pageNumber": 4069,
					"articleName": "PyTrim: A Practical Tool for Reducing Python Dependency Bloat",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e069/573300e069.pdf"
				}
			]
		},
		{
			"affiliation": "University of Auckland, New Zealand",
			"articleRefs": [
				{
					"pageNumber": 2121,
					"articleName": "PAT-Agent: Autoformalization for Model Checking",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c121/573300c121.pdf"
				},
				{
					"pageNumber": 2208,
					"articleName": "LSPFuzz: Hunting Bugs in Language Servers",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c208/573300c208.pdf"
				},
				{
					"pageNumber": 4085,
					"articleName": "Metamorphic Testing of Deep Reinforcement Learning Agents with MDPMORPH",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e085/573300e085.pdf"
				},
				{
					"pageNumber": 4101,
					"articleName": "LLMORPH: Automated Metamorphic Testing of Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e101/573300e101.pdf"
				}
			]
		},
		{
			"affiliation": "University of Bari, Italy",
			"articleRefs": [
				{
					"pageNumber": 2400,
					"articleName": "LLMs for Automated Unit Test Generation and Assessment in Java: The AgoneTest Framework",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c400/573300c400.pdf"
				}
			]
		},
		{
			"affiliation": "University of Bern, Switzerland",
			"articleRefs": [
				{
					"pageNumber": 3356,
					"articleName": "Bridging Research and Practice in Simulation-Based Testing of Industrial Robot Navigation Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d356/573300d356.pdf"
				}
			]
		},
		{
			"affiliation": "University of Bern, Switzerland; Universit\u00E0 della Svizzera italiana, Switzerland",
			"articleRefs": [
				{
					"pageNumber": 3356,
					"articleName": "Bridging Research and Practice in Simulation-Based Testing of Industrial Robot Navigation Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d356/573300d356.pdf"
				}
			]
		},
		{
			"affiliation": "University of Birmingham, United Kingdom",
			"articleRefs": [
				{
					"pageNumber": 1489,
					"articleName": "CoTune: Co-Evolutionary Configuration Tuning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b489/573300b489.pdf"
				}
			]
		},
		{
			"affiliation": "University of British Columbia, Canada",
			"articleRefs": [
				{
					"pageNumber": 1628,
					"articleName": "Characterizing Multi-Hunk Patches: Divergence, Proximity, and LLM Repair Challenges",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b628/573300b628.pdf"
				}
			]
		},
		{
			"affiliation": "University of Calgary, Canada",
			"articleRefs": [
				{
					"pageNumber": 2931,
					"articleName": "The Cost of Downgrading Build Systems A Case Study of Kubernetes",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c931/573300c931.pdf"
				},
				{
					"pageNumber": 3916,
					"articleName": "Tether: A Personalized Support Assistant for Software Engineers with ADHD",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d916/573300d916.pdf"
				}
			]
		},
		{
			"affiliation": "University of California, Davis",
			"articleRefs": [
				{
					"pageNumber": 4073,
					"articleName": "OSSPREY: AI-Driven Forecasting and Intervention for OSS Project Sustainability",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e073/573300e073.pdf"
				}
			]
		},
		{
			"affiliation": "University of California, Irvine",
			"articleRefs": [
				{
					"pageNumber": 2170,
					"articleName": "Spinner: Detecting Locking Violations in the eBPF Runtime",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c170/573300c170.pdf"
				},
				{
					"pageNumber": 2528,
					"articleName": "Automated Insertion of Flushes and Fences for Persistency",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c528/573300c528.pdf"
				}
			]
		},
		{
			"affiliation": "University of California, Irvine, USA",
			"articleRefs": [
				{
					"pageNumber": 1259,
					"articleName": "What's DAT Smell? Untangling and Weaving the Disjoint Assertion Tangle Test Smell",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b259/573300b259.pdf"
				},
				{
					"pageNumber": 1905,
					"articleName": "Automated Detection of Web Application Navigation Barriers for Screen Reader Users",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b905/573300b905.pdf"
				}
			]
		},
		{
			"affiliation": "University of California, Los Angeles",
			"articleRefs": [
				{
					"pageNumber": 2260,
					"articleName": "Automated Repair of OpenID Connect Programs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c260/573300c260.pdf"
				}
			]
		},
		{
			"affiliation": "University of California, Los Angelos",
			"articleRefs": [
				{
					"pageNumber": 1044,
					"articleName": "PROMFUZZ: Leveraging LLM-Driven and Bug-Oriented Composite Analysis for Detecting Functional Bugs in Smart Contracts",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b044/573300b044.pdf"
				}
			]
		},
		{
			"affiliation": "University of California, Riverside, USA",
			"articleRefs": [
				{
					"pageNumber": 828,
					"articleName": "Repairing Leaks in Resource Wrappers",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a828/573300a828.pdf"
				}
			]
		},
		{
			"affiliation": "University of California, San Diego",
			"articleRefs": [
				{
					"pageNumber": 2260,
					"articleName": "Automated Repair of OpenID Connect Programs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c260/573300c260.pdf"
				}
			]
		},
		{
			"affiliation": "University of California, Santa Barbara",
			"articleRefs": [
				{
					"pageNumber": 2260,
					"articleName": "Automated Repair of OpenID Connect Programs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c260/573300c260.pdf"
				}
			]
		},
		{
			"affiliation": "University of California, USA",
			"articleRefs": [
				{
					"pageNumber": 380,
					"articleName": "Towards More Accurate Static Analysis for Taint-Style Bug Detection in Linux Kernel",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a380/573300a380.pdf"
				},
				{
					"pageNumber": 534,
					"articleName": "RustAssure: Differential Symbolic Testing for LLM-Transpiled C-to-Rust Code",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a534/573300a534.pdf"
				},
				{
					"pageNumber": 828,
					"articleName": "Repairing Leaks in Resource Wrappers",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a828/573300a828.pdf"
				},
				{
					"pageNumber": 4044,
					"articleName": "Chrysalis: A Lightweight Logging and Replay Framework for Metamorphic Testing in Python",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e044/573300e044.pdf"
				}
			]
		},
		{
			"affiliation": "University of Canterbury, New Zealand",
			"articleRefs": [
				{
					"pageNumber": 4028,
					"articleName": "FETT: Fault Injection as an Educational and Training Tool in Cybersecurity",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e028/573300e028.pdf"
				}
			]
		},
		{
			"affiliation": "University of Catania, Italy",
			"articleRefs": [
				{
					"pageNumber": 4065,
					"articleName": "BenGQL: An Extensible Benchmarking Framework for Automated GraphQL Testing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e065/573300e065.pdf"
				}
			]
		},
		{
			"affiliation": "University of Central Florida, USA",
			"articleRefs": [
				{
					"pageNumber": 2195,
					"articleName": "Generating Failure-Based Oracles to Support Testing of Reported Bugs in Android Apps",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c195/573300c195.pdf"
				}
			]
		},
		{
			"affiliation": "University of Central Oklahoma",
			"articleRefs": [
				{
					"pageNumber": 1590,
					"articleName": "IMUFUZZER: Resilience-Based Discovery of Signal Injection Attacks on Robotic Aerial Vehicles",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b590/573300b590.pdf"
				}
			]
		},
		{
			"affiliation": "University of Chicago, United States",
			"articleRefs": [
				{
					"pageNumber": 253,
					"articleName": "Fair Developer Score: Build-Adjusted Measurement of Effort and Impact",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a253/850300a253.pdf"
				}
			]
		},
		{
			"affiliation": "University of Cologne, Germany",
			"articleRefs": [
				{
					"pageNumber": 186,
					"articleName": "From Facts to Foils: Designing and Evaluating Counterfactual Explanations for Smart Environments",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a186/850300a186.pdf"
				}
			]
		},
		{
			"affiliation": "University of Colorado Boulder, USA",
			"articleRefs": [
				{
					"pageNumber": 1679,
					"articleName": "Uncovering Discrimination Clusters: Quantifying and Explaining Systematic Fairness Violations",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b679/573300b679.pdf"
				}
			]
		},
		{
			"affiliation": "University of Dhaka, Bangladesh",
			"articleRefs": [
				{
					"pageNumber": 4109,
					"articleName": "CLARA: A Developer's Companion for Code Comprehension and Analysis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e109/573300e109.pdf"
				}
			]
		},
		{
			"affiliation": "University of Duisburg-Essen, Germany",
			"articleRefs": [
				{
					"pageNumber": 186,
					"articleName": "From Facts to Foils: Designing and Evaluating Counterfactual Explanations for Smart Environments",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a186/850300a186.pdf"
				}
			]
		},
		{
			"affiliation": "University of Electronic Science and Technology of China, China",
			"articleRefs": [
				{
					"pageNumber": 1489,
					"articleName": "CoTune: Co-Evolutionary Configuration Tuning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b489/573300b489.pdf"
				}
			]
		},
		{
			"affiliation": "University of Foggia, Italy",
			"articleRefs": [
				{
					"pageNumber": 3828,
					"articleName": "The Future of Software Transparency: Bridging Understanding, Measurement, and Practice",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d828/573300d828.pdf"
				}
			]
		},
		{
			"affiliation": "University of Gothenburg, Sweden",
			"articleRefs": [
				{
					"pageNumber": 58,
					"articleName": "Leveraging Large Language Models for Cybersecurity Risk Assessment \u2014 A Case from Forestry Cyber-Physical Systems",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a058/850300a058.pdf"
				}
			]
		},
		{
			"affiliation": "University of Gothenburg, Sweden; Carnegie Mellon University, USA",
			"articleRefs": [
				{
					"pageNumber": 58,
					"articleName": "Leveraging Large Language Models for Cybersecurity Risk Assessment \u2014 A Case from Forestry Cyber-Physical Systems",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a058/850300a058.pdf"
				}
			]
		},
		{
			"affiliation": "University of Illinois Chicago",
			"articleRefs": [
				{
					"pageNumber": 342,
					"articleName": "Risk Estimation in Differential Fuzzing via Extreme Value Theory",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a342/573300a342.pdf"
				}
			]
		},
		{
			"affiliation": "University of Illinois Chicago, USA",
			"articleRefs": [
				{
					"pageNumber": 1679,
					"articleName": "Uncovering Discrimination Clusters: Quantifying and Explaining Systematic Fairness Violations",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b679/573300b679.pdf"
				}
			]
		},
		{
			"affiliation": "University of Illinois Urbana-Champaign, USA",
			"articleRefs": [
				{
					"pageNumber": 393,
					"articleName": "Democratizing the Cryptocurrency Ecosystem by Just-In-Time Transformation of Mining Programs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a393/573300a393.pdf"
				},
				{
					"pageNumber": 1082,
					"articleName": "DebCovDiff: Differential Testing of Coverage Measurement Tools on Real-World Projects",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b082/573300b082.pdf"
				}
			]
		},
		{
			"affiliation": "University of Kassel, Germany",
			"articleRefs": [
				{
					"pageNumber": 277,
					"articleName": "LLMs Choose the Right Stack: From Patterns to Tools",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a277/850300a277.pdf"
				}
			]
		},
		{
			"affiliation": "University of L'Aquila, Italy",
			"articleRefs": [
				{
					"pageNumber": 2451,
					"articleName": "Advancing Automated Ethical Profiling in SE: a Zero-Shot Evaluation of LLM Reasoning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c451/573300c451.pdf"
				}
			]
		},
		{
			"affiliation": "University of Leeds; Kuaishou Inc.",
			"articleRefs": [
				{
					"pageNumber": 3191,
					"articleName": "KAIOps: A Platform Solution of End-to-End Multi-Modal AIOps for AI Training at Scale",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d191/573300d191.pdf"
				}
			]
		},
		{
			"affiliation": "University of Leeds, UK",
			"articleRefs": [
				{
					"pageNumber": 3568,
					"articleName": "Tuning LLM-Based Code Optimization via Meta-Prompting: An Industrial Perspective",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d568/573300d568.pdf"
				},
				{
					"pageNumber": 3753,
					"articleName": "KAIR: A Statistical and Causal Approach to Pinpointing Stragglers in Distributed Model Training",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d753/573300d753.pdf"
				}
			]
		},
		{
			"affiliation": "University of Leeds, UK; TurinTech AI, UK",
			"articleRefs": [
				{
					"pageNumber": 3568,
					"articleName": "Tuning LLM-Based Code Optimization via Meta-Prompting: An Industrial Perspective",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d568/573300d568.pdf"
				}
			]
		},
		{
			"affiliation": "University of Limerick, Ireland",
			"articleRefs": [
				{
					"pageNumber": 3694,
					"articleName": "Quantum Machine Learning-Based Test Oracle for Autonomous Mobile Robots",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d694/573300d694.pdf"
				}
			]
		},
		{
			"affiliation": "University of Luxembourg",
			"articleRefs": [
				{
					"pageNumber": 3921,
					"articleName": "Measuring LLM Code Generation Stability via Structural Entropy",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d921/573300d921.pdf"
				}
			]
		},
		{
			"affiliation": "University of Luxembourg, Luxembourg",
			"articleRefs": [
				{
					"pageNumber": 2045,
					"articleName": "Demystifying the Evolution of Neural Networks with BOM Analysis: Insights from a Large-Scale Study of 55,997 GitHub Repositories",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c045/573300c045.pdf"
				},
				{
					"pageNumber": 3823,
					"articleName": "Is Measurement Enough? Rethinking Output Validation in Quantum Program Testing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d823/573300d823.pdf"
				},
				{
					"pageNumber": 3833,
					"articleName": "Fault Injection for Simulink-Based CPS Models: Insights and Future Directions",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d833/573300d833.pdf"
				},
				{
					"pageNumber": 3890,
					"articleName": "Towards Automated Governance: A DSL for Human-Agent Collaboration in Software Projects",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d890/573300d890.pdf"
				},
				{
					"pageNumber": 3962,
					"articleName": "RAML: Toward Retrieval-Augmented Localization of Malicious Payloads in Android Apps",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d962/573300d962.pdf"
				},
				{
					"pageNumber": 3980,
					"articleName": "DESIGNATOR: a Toolset for Automated GAN-Enhanced Search-Based Testing and Retraining of DNNs in Martian Environments",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d980/573300d980.pdf"
				}
			]
		},
		{
			"affiliation": "University of Mannheim, Germany",
			"articleRefs": [
				{
					"pageNumber": 4052,
					"articleName": "GUI-ReRank: Enhancing GUI Retrieval with Multi-Modal LLM-Based Reranking",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e052/573300e052.pdf"
				}
			]
		},
		{
			"affiliation": "University of Maryland",
			"articleRefs": [
				{
					"pageNumber": 1590,
					"articleName": "IMUFUZZER: Resilience-Based Discovery of Signal Injection Attacks on Robotic Aerial Vehicles",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b590/573300b590.pdf"
				}
			]
		},
		{
			"affiliation": "University of Maryland, USA",
			"articleRefs": [
				{
					"pageNumber": 2956,
					"articleName": "When Does Wasm Malware Detection Fail? A Systematic Analysis of Their Robustness to Evasion",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c956/573300c956.pdf"
				}
			]
		},
		{
			"affiliation": "University of Massachusetts Amherst, USA",
			"articleRefs": [
				{
					"pageNumber": 1552,
					"articleName": "It's Not Easy Being Green: On the Energy Efficiency of Programming Languages",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b552/573300b552.pdf"
				}
			]
		},
		{
			"affiliation": "University of Massachusetts Amherst USA; Amazon Web Services, USA",
			"articleRefs": [
				{
					"pageNumber": 1552,
					"articleName": "It's Not Easy Being Green: On the Energy Efficiency of Programming Languages",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b552/573300b552.pdf"
				}
			]
		},
		{
			"affiliation": "University of Michigan-Dearborn, USA",
			"articleRefs": [
				{
					"pageNumber": 1955,
					"articleName": "VRTestSniffer: Test Smell Detector for Virtual Reality (VR) Software Projects",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b955/573300b955.pdf"
				}
			]
		},
		{
			"affiliation": "University of Michigan-Flint, USA",
			"articleRefs": [
				{
					"pageNumber": 1955,
					"articleName": "VRTestSniffer: Test Smell Detector for Virtual Reality (VR) Software Projects",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b955/573300b955.pdf"
				}
			]
		},
		{
			"affiliation": "University of Minnesota, USA",
			"articleRefs": [
				{
					"pageNumber": 153,
					"articleName": "Improving Automated Program Verification for Java Programs with Fuzzing",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a153/850300a153.pdf"
				},
				{
					"pageNumber": 2195,
					"articleName": "Generating Failure-Based Oracles to Support Testing of Reported Bugs in Android Apps",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c195/573300c195.pdf"
				}
			]
		},
		{
			"affiliation": "University of Montreal, Canada",
			"articleRefs": [
				{
					"pageNumber": 4020,
					"articleName": "PrioTestCI: Efficient Test Case Prioritization in GitHub Workflows for CI Optimization",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e020/573300e020.pdf"
				}
			]
		},
		{
			"affiliation": "University of Namur, Belgium",
			"articleRefs": [
				{
					"pageNumber": 4028,
					"articleName": "FETT: Fault Injection as an Educational and Training Tool in Cybersecurity",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e028/573300e028.pdf"
				}
			]
		},
		{
			"affiliation": "University of New South Wales, Australia",
			"articleRefs": [
				{
					"pageNumber": 1069,
					"articleName": "A Large Scale Study of AI-Based Binary Function Similarity Detection Techniques for Security Researchers and Practitioners",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b069/573300b069.pdf"
				}
			]
		},
		{
			"affiliation": "University of North Carolina at Charlotte, USA",
			"articleRefs": [
				{
					"pageNumber": 2362,
					"articleName": "Polyglot: An Extensible Framework to Benchmark Code Translation with LLMs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c362/573300c362.pdf"
				}
			]
		},
		{
			"affiliation": "University of North Carolina, USA",
			"articleRefs": [
				{
					"pageNumber": 2362,
					"articleName": "Polyglot: An Extensible Framework to Benchmark Code Translation with LLMs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c362/573300c362.pdf"
				}
			]
		},
		{
			"affiliation": "University of Notre Dame",
			"articleRefs": [
				{
					"pageNumber": 1020,
					"articleName": "Programmers' Visual Attention on Function Call Graphs During Code Summarization",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b020/573300b020.pdf"
				}
			]
		},
		{
			"affiliation": "University of Notre Dame, USA",
			"articleRefs": [
				{
					"pageNumber": 4089,
					"articleName": "APIDA-Chat: Structured Synthesis of API Search Dialogues to Bootstrap Conversational Agents",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e089/573300e089.pdf"
				}
			]
		},
		{
			"affiliation": "University of Oldenburg, Germany",
			"articleRefs": [
				{
					"pageNumber": 194,
					"articleName": "Explaining Software Vulnerabilities with Large Language Models",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a194/850300a194.pdf"
				}
			]
		},
		{
			"affiliation": "University of Oslo, Norway",
			"articleRefs": [
				{
					"pageNumber": 3694,
					"articleName": "Quantum Machine Learning-Based Test Oracle for Autonomous Mobile Robots",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d694/573300d694.pdf"
				}
			]
		},
		{
			"affiliation": "University of Passau, Germany",
			"articleRefs": [
				{
					"pageNumber": 3988,
					"articleName": "LitterBox+: An Extensible Framework for LLM-Enhanced Scratch Static Code Analysis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d988/573300d988.pdf"
				}
			]
		},
		{
			"affiliation": "University of Pennsylvania, USA",
			"articleRefs": [
				{
					"pageNumber": 4124,
					"articleName": "First-Order Quantified Separator in Alloy Analyzer",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e124/573300e124.pdf"
				}
			]
		},
		{
			"affiliation": "University of Porto, Portugal",
			"articleRefs": [
				{
					"pageNumber": 3310,
					"articleName": "Streamlining Acceptance Test Generation for Mobile Applications Through Large Language Models: An Industrial Case Study",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d310/573300d310.pdf"
				}
			]
		},
		{
			"affiliation": "University of Rio Cuarto and CONICET, Argentina",
			"articleRefs": [
				{
					"pageNumber": 2918,
					"articleName": "Automated Combinatorial Test Generation for Alloy",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c918/573300c918.pdf"
				}
			]
		},
		{
			"affiliation": "University of Rio Cuarto and CONICET, Argentina; Guangdong Technion-Israel Institute of Technology, China",
			"articleRefs": [
				{
					"pageNumber": 2706,
					"articleName": "State Field Coverage: A Metric for Oracle Quality",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c706/573300c706.pdf"
				},
				{
					"pageNumber": 2918,
					"articleName": "Automated Combinatorial Test Generation for Alloy",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c918/573300c918.pdf"
				}
			]
		},
		{
			"affiliation": "University of Sannio, Italy",
			"articleRefs": [
				{
					"pageNumber": 3828,
					"articleName": "The Future of Software Transparency: Bridging Understanding, Measurement, and Practice",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d828/573300d828.pdf"
				},
				{
					"pageNumber": 3992,
					"articleName": "CodeGenLink: A Tool to Find the Likely Origin and License of Automatically Generated Code",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d992/573300d992.pdf"
				}
			]
		},
		{
			"affiliation": "University of Science and Technology Beijing, China",
			"articleRefs": [
				{
					"pageNumber": 2881,
					"articleName": "DIFFFIX: Incrementally Fixing AST Diffs via Context and Type Information",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c881/573300c881.pdf"
				}
			]
		},
		{
			"affiliation": "University of Science and Technology of China, China",
			"articleRefs": [
				{
					"pageNumber": 495,
					"articleName": "RSFuzz: A Robustness-Guided Swarm Fuzzing Framework Based on Behavioral Constraints",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a495/573300a495.pdf"
				},
				{
					"pageNumber": 841,
					"articleName": "PseudoFix: Refactoring Distorted Structures in Decompiled C Pseudocode",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a841/573300a841.pdf"
				},
				{
					"pageNumber": 1730,
					"articleName": "Function Clustering-Based Fuzzing Termination: Toward Smarter Early Stopping",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b730/573300b730.pdf"
				},
				{
					"pageNumber": 2045,
					"articleName": "Demystifying the Evolution of Neural Networks with BOM Analysis: Insights from a Large-Scale Study of 55,997 GitHub Repositories",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c045/573300c045.pdf"
				},
				{
					"pageNumber": 2234,
					"articleName": "Enhancing LLM to Decompile Optimized PTX to Readable CUDA for Tensor Programs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c234/573300c234.pdf"
				}
			]
		},
		{
			"affiliation": "University of Science and Technology of China, China; Anhui Province Key Laboratory of Digital Security, China",
			"articleRefs": [
				{
					"pageNumber": 841,
					"articleName": "PseudoFix: Refactoring Distorted Structures in Decompiled C Pseudocode",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a841/573300a841.pdf"
				}
			]
		},
		{
			"affiliation": "University of Seoul, South Korea",
			"articleRefs": [
				{
					"pageNumber": 176,
					"articleName": "K-SNAC: Robust Neuron Coverage for OOD Generalization and Test Adequacy",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a176/850300a176.pdf"
				}
			]
		},
		{
			"affiliation": "University of Sheffield, UK",
			"articleRefs": [
				{
					"pageNumber": 326,
					"articleName": "A Test Automation Framework for User Interaction in Extended Reality Applications",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a326/850300a326.pdf"
				}
			]
		},
		{
			"affiliation": "University of Sheffield, United Kingdom",
			"articleRefs": [
				{
					"pageNumber": 3865,
					"articleName": "Unseen Data Detection using Routing Entropy in Mixture-of-Experts for Autonomous Vehicles",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d865/573300d865.pdf"
				}
			]
		},
		{
			"affiliation": "University of Southern California, USA",
			"articleRefs": [
				{
					"pageNumber": 393,
					"articleName": "Democratizing the Cryptocurrency Ecosystem by Just-In-Time Transformation of Mining Programs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a393/573300a393.pdf"
				},
				{
					"pageNumber": 2956,
					"articleName": "When Does Wasm Malware Detection Fail? A Systematic Analysis of Their Robustness to Evasion",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c956/573300c956.pdf"
				}
			]
		},
		{
			"affiliation": "University of Stirling, UK",
			"articleRefs": [
				{
					"pageNumber": 3901,
					"articleName": "LLM-Guided Genetic Improvement: Envisioning Semantic Aware Automated Software Evolution",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d901/573300d901.pdf"
				}
			]
		},
		{
			"affiliation": "University of Stuttgart, Germany",
			"articleRefs": [
				{
					"pageNumber": 816,
					"articleName": "Execution-Aware Program Reduction for WebAssembly via Record and Replay",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a816/573300a816.pdf"
				}
			]
		},
		{
			"affiliation": "University of Surrey, UK; TurinTech AI, UK",
			"articleRefs": [
				{
					"pageNumber": 3568,
					"articleName": "Tuning LLM-Based Code Optimization via Meta-Prompting: An Industrial Perspective",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d568/573300d568.pdf"
				}
			]
		},
		{
			"affiliation": "University of Surrey, United Kingdom",
			"articleRefs": [
				{
					"pageNumber": 3793,
					"articleName": "Measuring Software Resilience Using Socially Aware Truck Factor Estimation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d793/573300d793.pdf"
				}
			]
		},
		{
			"affiliation": "University of Texas at Dallas",
			"articleRefs": [
				{
					"pageNumber": 1590,
					"articleName": "IMUFUZZER: Resilience-Based Discovery of Signal Injection Attacks on Robotic Aerial Vehicles",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b590/573300b590.pdf"
				}
			]
		},
		{
			"affiliation": "University of Texas at Dallas, USA",
			"articleRefs": [
				{
					"pageNumber": 181,
					"articleName": "SeedUI: Understanding Initial Seeds in Fuzzing",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a181/850300a181.pdf"
				},
				{
					"pageNumber": 3580,
					"articleName": "Element-Aware Fine-Tuning of Vision-Language Models for Cost-Efficient GUI Testing in an Industrial Setting",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d580/573300d580.pdf"
				}
			]
		},
		{
			"affiliation": "University of Texas at El Paso",
			"articleRefs": [
				{
					"pageNumber": 342,
					"articleName": "Risk Estimation in Differential Fuzzing via Extreme Value Theory",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a342/573300a342.pdf"
				}
			]
		},
		{
			"affiliation": "University of Texas at El Paso, USA",
			"articleRefs": [
				{
					"pageNumber": 2918,
					"articleName": "Automated Combinatorial Test Generation for Alloy",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c918/573300c918.pdf"
				}
			]
		},
		{
			"affiliation": "University of Utah, United States",
			"articleRefs": [
				{
					"pageNumber": 1131,
					"articleName": "GUIFuzz++: Unleashing Grey-box Fuzzing on Desktop Graphical User Interfacing Applications ",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b131/573300b131.pdf"
				}
			]
		},
		{
			"affiliation": "University of Utah, USA",
			"articleRefs": [
				{
					"pageNumber": 204,
					"articleName": "Finding Bugs in WebAssembly Interface Type Binding Generators",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a204/573300a204.pdf"
				}
			]
		},
		{
			"affiliation": "University of Virginia, USA",
			"articleRefs": [
				{
					"pageNumber": 1233,
					"articleName": "RFCScope: Detecting Logical Ambiguities in Internet Protocol Specifications",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b233/573300b233.pdf"
				}
			]
		},
		{
			"affiliation": "University of Washington, USA",
			"articleRefs": [
				{
					"pageNumber": 278,
					"articleName": "Do LLMs Generate Useful Test Oracles? An Empirical Study with an Unbiased Dataset",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a278/573300a278.pdf"
				},
				{
					"pageNumber": 828,
					"articleName": "Repairing Leaks in Resource Wrappers",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a828/573300a828.pdf"
				}
			]
		},
		{
			"affiliation": "University of Waterloo",
			"articleRefs": [
				{
					"pageNumber": 1285,
					"articleName": "Agentic Specification Generator for Move Programs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b285/573300b285.pdf"
				},
				{
					"pageNumber": 3057,
					"articleName": "Who's to Blame? Rethinking the Brittleness of Automated Web GUI Testing from a Pragmatic Perspective",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d057/573300d057.pdf"
				}
			]
		},
		{
			"affiliation": "University of Waterloo, Canada",
			"articleRefs": [
				{
					"pageNumber": 1426,
					"articleName": "Rechecking Recheck Requests in Continuous Integration: An Empirical Study of OpenStack",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b426/573300b426.pdf"
				},
				{
					"pageNumber": 1704,
					"articleName": "ADPerf: Investigating and Testing Performance in Autonomous Driving Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b704/573300b704.pdf"
				},
				{
					"pageNumber": 2273,
					"articleName": "Latra: A Template-Based Language-Agnostic Transformation Framework for Effective Program Reduction",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c273/573300c273.pdf"
				},
				{
					"pageNumber": 2931,
					"articleName": "The Cost of Downgrading Build Systems A Case Study of Kubernetes",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c931/573300c931.pdf"
				}
			]
		},
		{
			"affiliation": "University of Waterloo, Canada; University College London, UK",
			"articleRefs": [
				{
					"pageNumber": 1426,
					"articleName": "Rechecking Recheck Requests in Continuous Integration: An Empirical Study of OpenStack",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b426/573300b426.pdf"
				}
			]
		},
		{
			"affiliation": "University of West London, UK; TurinTech AI, UK",
			"articleRefs": [
				{
					"pageNumber": 3568,
					"articleName": "Tuning LLM-Based Code Optimization via Meta-Prompting: An Industrial Perspective",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d568/573300d568.pdf"
				}
			]
		},
		{
			"affiliation": "University of Wollongong, Australia",
			"articleRefs": [
				{
					"pageNumber": 312,
					"articleName": "Towards Multi-Agentic AI for Automated Software Design and Modelling: Challenges and Opportunities",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a312/850300a312.pdf"
				},
				{
					"pageNumber": 1032,
					"articleName": "An LLM-Based Multi-Agent Framework for Agile Effort Estimation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b032/573300b032.pdf"
				}
			]
		},
		{
			"affiliation": "University of Zurich",
			"articleRefs": [
				{
					"pageNumber": 4093,
					"articleName": "Quirx: A Mutation-Based Framework for Evaluating Prompt Robustness in LLM-Based Software",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e093/573300e093.pdf"
				}
			]
		},
		{
			"affiliation": "University of Zurich, Switzerland",
			"articleRefs": [
				{
					"pageNumber": 1311,
					"articleName": "Detecting Semantic Clones of Unseen Functionality",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b311/573300b311.pdf"
				},
				{
					"pageNumber": 1981,
					"articleName": "Automated Generation of Issue-Reproducing Tests by Combining LLMs and Search-Based Testing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b981/573300b981.pdf"
				},
				{
					"pageNumber": 4020,
					"articleName": "PrioTestCI: Efficient Test Case Prioritization in GitHub Workflows for CI Optimization",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300e020/573300e020.pdf"
				}
			]
		},
		{
			"affiliation": "Univ. Lille, CNRS, France",
			"articleRefs": [
				{
					"pageNumber": 1654,
					"articleName": "When Faster Isn't Greener: The Hidden Costs of LLM-Based Code Optimization",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b654/573300b654.pdf"
				}
			]
		},
		{
			"affiliation": "UNSW Sydney, Australia",
			"articleRefs": [
				{
					"pageNumber": 3683,
					"articleName": "Securing Millions of Decentralized Identities in Alipay Super App with End-to-End Formal Verification",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d683/573300d683.pdf"
				}
			]
		},
		{
			"affiliation": "US Naval Research Laboratory, USA",
			"articleRefs": [
				{
					"pageNumber": 3870,
					"articleName": "CodeACT-R: A Cognitive Simulation Framework for Human Attention in Code Reading",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d870/573300d870.pdf"
				}
			]
		},
		{
			"affiliation": "Vanderbilt University",
			"articleRefs": [
				{
					"pageNumber": 1020,
					"articleName": "Programmers' Visual Attention on Function Call Graphs During Code Summarization",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b020/573300b020.pdf"
				}
			]
		},
		{
			"affiliation": "Vanderbilt University, USA",
			"articleRefs": [
				{
					"pageNumber": 3870,
					"articleName": "CodeACT-R: A Cognitive Simulation Framework for Human Attention in Code Reading",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d870/573300d870.pdf"
				}
			]
		},
		{
			"affiliation": "Victoria University of Wellington, New Zealand",
			"articleRefs": [
				{
					"pageNumber": 3627,
					"articleName": "DALEQ - Explainable Equivalence for Java Bytecode",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d627/573300d627.pdf"
				}
			]
		},
		{
			"affiliation": "Villanova University, U.S.",
			"articleRefs": [
				{
					"pageNumber": 332,
					"articleName": "NavAI: A Generalizable LLM Framework for Navigation Tasks in Virtual Reality Environments",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a332/850300a332.pdf"
				}
			]
		},
		{
			"affiliation": "Virginia Tech",
			"articleRefs": [
				{
					"pageNumber": 43,
					"articleName": "LLMs in Debate: Does Arguing Make Them Better at Detecting Metamorphic Relations?",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a043/850300a043.pdf"
				}
			]
		},
		{
			"affiliation": "Waseda University, Japan",
			"articleRefs": [
				{
					"pageNumber": 237,
					"articleName": "Towards MPC-Driven Software Adaptation: A Dual-Layer Approach Combining ICNN-Based Modeling and Delta-Based Tuning",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a237/850300a237.pdf"
				},
				{
					"pageNumber": 3967,
					"articleName": "A Secure Mocking Approach Towards Software Supply Chain Security",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d967/573300d967.pdf"
				}
			]
		},
		{
			"affiliation": "Western University, Canada",
			"articleRefs": [
				{
					"pageNumber": 3286,
					"articleName": "Context-Aware CodeLLM Eviction for AI-Assisted Coding",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d286/573300d286.pdf"
				}
			]
		},
		{
			"affiliation": "Wideverse, Italy",
			"articleRefs": [
				{
					"pageNumber": 2400,
					"articleName": "LLMs for Automated Unit Test Generation and Assessment in Java: The AgoneTest Framework",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c400/573300c400.pdf"
				}
			]
		},
		{
			"affiliation": "William & Mary, USA",
			"articleRefs": [
				{
					"pageNumber": 2195,
					"articleName": "Generating Failure-Based Oracles to Support Testing of Reported Bugs in Android Apps",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c195/573300c195.pdf"
				}
			]
		},
		{
			"affiliation": "Wuhan University, China",
			"articleRefs": [
				{
					"pageNumber": 726,
					"articleName": "Improving LLM-Based Log Parsing by Learning from Errors in Reasoning Traces",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a726/573300a726.pdf"
				},
				{
					"pageNumber": 996,
					"articleName": "Not Every Patch is an Island: LLM-Enhanced Identification of Multiple Vulnerability Patches",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a996/573300a996.pdf"
				},
				{
					"pageNumber": 3414,
					"articleName": "Data Dependency-Aware Code Generation from Enhanced UML Sequence Diagrams",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d414/573300d414.pdf"
				},
				{
					"pageNumber": 3875,
					"articleName": "Envisioning Intelligent Requirements Engineering via Knowledge-Guided Multi-Agent Collaboration",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d875/573300d875.pdf"
				},
				{
					"pageNumber": 3931,
					"articleName": "Requirements Development and Formalization for Reliable Code Generation: A Multi-Agent Vision",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d931/573300d931.pdf"
				}
			]
		},
		{
			"affiliation": "Wuhan University of Technology, China",
			"articleRefs": [
				{
					"pageNumber": 3020,
					"articleName": "RealisticCodeBench: Towards More Realistic Evaluation of Large Language Models for Code Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d020/573300d020.pdf"
				}
			]
		},
		{
			"affiliation": "Xiamen University, China",
			"articleRefs": [
				{
					"pageNumber": 854,
					"articleName": "DLBENCH: A Comprehensive Benchmark for SQL Translation with Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a854/573300a854.pdf"
				},
				{
					"pageNumber": 1246,
					"articleName": "Protecting Source Code Privacy When Hunting Memory Bugs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b246/573300b246.pdf"
				},
				{
					"pageNumber": 2032,
					"articleName": "Characterizing and Repairing Color-Related Accessibility Issues in Android Apps",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c032/573300c032.pdf"
				}
			]
		},
		{
			"affiliation": "Xi'an Jiaotong University",
			"articleRefs": [
				{
					"pageNumber": 228,
					"articleName": "RELIA: Accelerating the Analysis of Cloud Access Control Policies",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a228/573300a228.pdf"
				},
				{
					"pageNumber": 1044,
					"articleName": "PROMFUZZ: Leveraging LLM-Driven and Bug-Oriented Composite Analysis for Detecting Functional Bugs in Smart Contracts",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b044/573300b044.pdf"
				}
			]
		},
		{
			"affiliation": "Xi'an Jiaotong University, China",
			"articleRefs": [
				{
					"pageNumber": 3020,
					"articleName": "RealisticCodeBench: Towards More Realistic Evaluation of Large Language Models for Code Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d020/573300d020.pdf"
				}
			]
		},
		{
			"affiliation": "Xiaohongshu Inc., China",
			"articleRefs": [
				{
					"pageNumber": 521,
					"articleName": "GlassWing: A Tailored Static Analysis Approach for Flutter Android Apps",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a521/573300a521.pdf"
				}
			]
		},
		{
			"affiliation": "Xidian University, China",
			"articleRefs": [
				{
					"pageNumber": 495,
					"articleName": "RSFuzz: A Robustness-Guided Swarm Fuzzing Framework Based on Behavioral Constraints",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a495/573300a495.pdf"
				},
				{
					"pageNumber": 791,
					"articleName": "Hit The Bullseye On The First Shot: Improving LLMs Using Multi-Sample Self-Reward Feedback for Vulnerability Repair",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a791/573300a791.pdf"
				},
				{
					"pageNumber": 1142,
					"articleName": "Hypergraph Neural Network-Based Multi-Granular Root Cause Localization for Microservice Systems",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b142/573300b142.pdf"
				},
				{
					"pageNumber": 1207,
					"articleName": "Bridging Natural Language and Formal Specification Automated Translation of Software Requirements to LTL via Hierarchical Semantics Decomposition Using LLMs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b207/573300b207.pdf"
				},
				{
					"pageNumber": 3931,
					"articleName": "Requirements Development and Formalization for Reliable Code Generation: A Multi-Agent Vision",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d931/573300d931.pdf"
				}
			]
		},
		{
			"affiliation": "Yale Law School",
			"articleRefs": [
				{
					"pageNumber": 1452,
					"articleName": "VERT: Polyglot Verified Equivalent Rust Transpilation with Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b452/573300b452.pdf"
				}
			]
		},
		{
			"affiliation": "Yale University, USA",
			"articleRefs": [
				{
					"pageNumber": 1324,
					"articleName": "Efficient and Verifiable Proof Logging for MaxSAT Solving",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b324/573300b324.pdf"
				}
			]
		},
		{
			"affiliation": "Yiqiyin (Hangzhou) Technology Co., Ltd. Xi\u2019an Branch, China",
			"articleRefs": [
				{
					"pageNumber": 495,
					"articleName": "RSFuzz: A Robustness-Guided Swarm Fuzzing Framework Based on Behavioral Constraints",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a495/573300a495.pdf"
				}
			]
		},
		{
			"affiliation": "York University, Canada",
			"articleRefs": [
				{
					"pageNumber": 1930,
					"articleName": "Defects4Log: Benchmarking LLMs for Logging Code Defect Detection and Reasoning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b930/573300b930.pdf"
				}
			]
		},
		{
			"affiliation": "ZGC National Laboratory, China",
			"articleRefs": [
				{
					"pageNumber": 237,
					"articleName": "Towards MPC-Driven Software Adaptation: A Dual-Layer Approach Combining ICNN-Based Modeling and Delta-Based Tuning",
					"articleLocation": "pdfs/ASEW2025-pvb85GFXPvzwDObiRFzW6/850300a237/850300a237.pdf"
				}
			]
		},
		{
			"affiliation": "Zhejiang University",
			"articleRefs": [
				{
					"pageNumber": 317,
					"articleName": "PrefGen: A Preference-Driven Methodology for Secure Yet Gas-Efficient Smart Contract Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a317/573300a317.pdf"
				},
				{
					"pageNumber": 1044,
					"articleName": "PROMFUZZ: Leveraging LLM-Driven and Bug-Oriented Composite Analysis for Detecting Functional Bugs in Smart Contracts",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b044/573300b044.pdf"
				},
				{
					"pageNumber": 2070,
					"articleName": "Why Is My Transaction Risky? Understanding Smart Contract Semantics and Interactions in the NFT Ecosystem",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c070/573300c070.pdf"
				}
			]
		},
		{
			"affiliation": "Zhejiang University, China",
			"articleRefs": [
				{
					"pageNumber": 91,
					"articleName": "When AllClose Fails: Round-Off Error Estimation for Deep Learning Programs",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a091/573300a091.pdf"
				},
				{
					"pageNumber": 154,
					"articleName": "CODE-DITING: Automatic Evaluation of Code Generation Without References or Test Cases",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a154/573300a154.pdf"
				},
				{
					"pageNumber": 508,
					"articleName": "Provable Fairness Repair for Deep Neural Networks",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a508/573300a508.pdf"
				},
				{
					"pageNumber": 623,
					"articleName": "Enhancing LLM's Ability to Generate More Repository-Aware Unit Tests Through Precise Context Injection",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a623/573300a623.pdf"
				},
				{
					"pageNumber": 687,
					"articleName": "Navigating the Labyrinth: Path-Sensitive Unit Test Generation with Large Language Models",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a687/573300a687.pdf"
				},
				{
					"pageNumber": 1337,
					"articleName": "FGIT: Fault-Guided Fine-Tuning for Code Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b337/573300b337.pdf"
				},
				{
					"pageNumber": 1830,
					"articleName": "PEACE: Towards Efficient Project-Level Efficiency Optimization via Hybrid Code Editing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b830/573300b830.pdf"
				},
				{
					"pageNumber": 1868,
					"articleName": "ORFUZZ: Fuzzing the \"Other Side\" of LLM Safety \u2013 Testing Over-Refusal",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b868/573300b868.pdf"
				},
				{
					"pageNumber": 2070,
					"articleName": "Why Is My Transaction Risky? Understanding Smart Contract Semantics and Interactions in the NFT Ecosystem",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c070/573300c070.pdf"
				},
				{
					"pageNumber": 2503,
					"articleName": "Unit Test Update Through LLM-Driven Context Collection and Error-Type-Aware Refinement",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c503/573300c503.pdf"
				},
				{
					"pageNumber": 2554,
					"articleName": "ACTaint: Agent-Based Taint Analysis for Access Control Vulnerabilities in Smart Contracts",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c554/573300c554.pdf"
				},
				{
					"pageNumber": 2579,
					"articleName": "WINGMUZZ: Blackbox Testing of IoT Protocols via Two-Dimensional Fuzzing Schedule",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c579/573300c579.pdf"
				},
				{
					"pageNumber": 2605,
					"articleName": "SE-Jury: An LLM-as-Ensemble-Judge Metric for Narrowing the Gap with Human Evaluation in SE",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c605/573300c605.pdf"
				},
				{
					"pageNumber": 2630,
					"articleName": "AutoFid: Adaptive and Noise-Aware Fidelity Measurement for Quantum Programs via Circuit Graph Analysis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c630/573300c630.pdf"
				},
				{
					"pageNumber": 2745,
					"articleName": "HFuzzer: Testing Large Language Models for Package Hallucinations via Phrase-Based Fuzzing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c745/573300c745.pdf"
				},
				{
					"pageNumber": 2857,
					"articleName": "SolContractEval: A Benchmark for Evaluating Contract-Level Solidity Code Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c857/573300c857.pdf"
				},
				{
					"pageNumber": 3020,
					"articleName": "RealisticCodeBench: Towards More Realistic Evaluation of Large Language Models for Code Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d020/573300d020.pdf"
				},
				{
					"pageNumber": 3033,
					"articleName": "Issue Localization via LLM-Driven Iterative Code Graph Searching",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d033/573300d033.pdf"
				},
				{
					"pageNumber": 3485,
					"articleName": "BitsAI-Fix: LLM-Driven Approach for Automated Lint Error Resolution in Practice",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d485/573300d485.pdf"
				},
				{
					"pageNumber": 3683,
					"articleName": "Securing Millions of Decentralized Identities in Alipay Super App with End-to-End Formal Verification",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d683/573300d683.pdf"
				},
				{
					"pageNumber": 3823,
					"articleName": "Is Measurement Enough? Rethinking Output Validation in Quantum Program Testing",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d823/573300d823.pdf"
				}
			]
		},
		{
			"affiliation": "Zhejiang University, China; Hangzhou High-Tech Zone (Binjiang) Institute of Blockchain and Data Security, China",
			"articleRefs": [
				{
					"pageNumber": 2857,
					"articleName": "SolContractEval: A Benchmark for Evaluating Contract-Level Solidity Code Generation",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c857/573300c857.pdf"
				}
			]
		},
		{
			"affiliation": "Zhejiang University, China; Shanghai Qi Zhi Institute, China",
			"articleRefs": [
				{
					"pageNumber": 2630,
					"articleName": "AutoFid: Adaptive and Noise-Aware Fidelity Measurement for Quantum Programs via Circuit Graph Analysis",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300c630/573300c630.pdf"
				}
			]
		},
		{
			"affiliation": "Zhejiang University of Technology, China",
			"articleRefs": [
				{
					"pageNumber": 508,
					"articleName": "Provable Fairness Repair for Deep Neural Networks",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a508/573300a508.pdf"
				},
				{
					"pageNumber": 3777,
					"articleName": "SGCR: A Specification-Grounded Framework for Trustworthy LLM Code Review",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300d777/573300d777.pdf"
				}
			]
		},
		{
			"affiliation": "Zhejiang University; Southeast University, Ministry of Education",
			"articleRefs": [
				{
					"pageNumber": 1044,
					"articleName": "PROMFUZZ: Leveraging LLM-Driven and Bug-Oriented Composite Analysis for Detecting Functional Bugs in Smart Contracts",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300b044/573300b044.pdf"
				}
			]
		},
		{
			"affiliation": "Zhongguancun Laboratory, China",
			"articleRefs": [
				{
					"pageNumber": 304,
					"articleName": "Advancing Binary Code Similarity Detection via Context-Content Fusion and LLM Verification",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a304/573300a304.pdf"
				}
			]
		},
		{
			"affiliation": "ZTE Corporation, China",
			"articleRefs": [
				{
					"pageNumber": 661,
					"articleName": "United We Stand: Towards End-to-End Log-Based Fault Diagnosis via Interactive Multi-Task Learning",
					"articleLocation": "pdfs/ASE2025-5DQL9ko9OwpjaORDC0qal7/573300a661/573300a661.pdf"
				}
			]
		}
	]
}};